[{"path":"https://philchalmers.github.io/mirt/articles/mirt-vignettes.html","id":"mirt-vignette-files","dir":"Articles","previous_headings":"","what":"mirt Vignette Files","title":"","text":"access examples, vignettes, exercise files generated knitr please visit link.","code":""},{"path":"https://philchalmers.github.io/mirt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Phil Chalmers. Author, maintainer. Joshua Pritikin. Contributor. Alexander Robitzsch. Contributor. Mateusz Zoltak. Contributor. KwonHyun Kim. Contributor. Carl F. Falk. Contributor. Adam Meade. Contributor. Lennart Schneider. Contributor. David King. Contributor. Chen-Wei Liu. Contributor. Ogreden Oguzhan. Contributor.","code":""},{"path":"https://philchalmers.github.io/mirt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"R. Philip Chalmers (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":"@Article{,   title = {{mirt}: A Multidimensional Item Response Theory Package for the {R} Environment},   author = {R. Philip Chalmers},   journal = {Journal of Statistical Software},   year = {2012},   volume = {48},   number = {6},   pages = {1--29},   doi = {10.18637/jss.v048.i06}, }"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"mirt-multidimensional-item-response-theory-in-r-","dir":"","previous_headings":"","what":"Multidimensional Item Response Theory","title":"Multidimensional Item Response Theory","text":"Analysis dichotomous polytomous response data using unidimensional multidimensional latent trait models Item Response Theory paradigm. Exploratory confirmatory models can estimated quadrature (EM) stochastic (MHRM) methods. Confirmatory bi-factor two-tier analyses available modeling item testlets. Multiple group analysis mixed effects designs also available detecting differential item functioning modeling item person covariates.","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"examples-and-evaluated-help-files-are-available-on-the-wiki","dir":"","previous_headings":"","what":"Examples and evaluated help files are available on the wiki","title":"Multidimensional Item Response Theory","text":"Various examples worked help files compiled using knitr package generate HTML output, available package wiki. User contributions welcome!","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"installing-from-source","dir":"","previous_headings":"","what":"Installing from source","title":"Multidimensional Item Response Theory","text":"’s recommended use development version package since likely date version CRAN. install package source: Obtain recent gcc, g++, gfortran compilers. Windows users can install Rtools suite Mac users download necessary tools Xcode suite related command line tools (found within Xcode’s Preference Pane Downloads/Components); Linux distributions already date compilers (can updated easily). Windows users include checkbox option installing Rtools path easier command line usage. Install devtools package (necessary). R, paste following console: Load devtools package (requires version 1.4+) install Github source code.","code":"install.packages('devtools') library('devtools') install_github('philchalmers/mirt')"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"installing-from-source-via-git","dir":"","previous_headings":"Installing from source","what":"Installing from source via git","title":"Multidimensional Item Response Theory","text":"devtools approach work system, can download install repository directly. Obtain recent gcc, g++, gfortran compilers (see instructions). Install git command line tools. Open terminal/command-line tool. following code download repository code computer, install package directly using R tools (Windows users may also add R git path)","code":"git clone https://github.com/philchalmers/mirt R CMD INSTALL mirt"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"special-mac-os-x-installation-instructions","dir":"","previous_headings":"Installing from source","what":"Special Mac OS X Installation Instructions","title":"Multidimensional Item Response Theory","text":"reported cases XCode install appropriate gfortran compilers correct location, therefore installed manually instead. accomplished inputing following instructions terminal:","code":"curl -O http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2 sudo tar fvxz gfortran-4.8.2-darwin13.tar.bz2 -C /"},{"path":"https://philchalmers.github.io/mirt/index.html","id":"licence","dir":"","previous_headings":"","what":"Licence","title":"Multidimensional Item Response Theory","text":"package free open source software, licensed GPL (>= 3).","code":""},{"path":"https://philchalmers.github.io/mirt/index.html","id":"bugs-and-questions","dir":"","previous_headings":"","what":"Bugs and Questions","title":"Multidimensional Item Response Theory","text":"Bug reports always welcome preferred way address bugs Github ‘issues’. Feel free submit issues feature requests site, ’ll address ASAP. Also, questions package, IRT general, feel free create ‘New Topic’ mirt-package Google group. Cheers!","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of ASVAB data — ASVAB","title":"Description of ASVAB data — ASVAB","text":"Table counts extracted Mislvey (1985). Data 16 possible response patterns observed four items arithmetic reasoning test Armed Services Vocational Aptitude Battery (ASVAB), Form 8A, samples white males females black males females.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of ASVAB data — ASVAB","text":"Mislevy, R. J. (1985). Estimation latent group effects. Journal American Statistical Association, 80, 993-997.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of ASVAB data — ASVAB","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/ASVAB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of ASVAB data — ASVAB","text":"","code":"data(ASVAB) datWM <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, White_Male))) datWF <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, White_Female))) datBM <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, Black_Male))) datBF <- expand.table(subset(ASVAB, select=c(Item.1:Item.4, Black_Female)))  dat <- rbind(datWM, datWF, datBM, datBF) sex <- rep(c(\"Male\", \"Female\", \"Male\", \"Female\"),   times=c(nrow(datWM), nrow(datWF), nrow(datBM), nrow(datBF))) |> factor() color <- rep(c(\"White\", \"Black\"),   times=c(nrow(datWM) + nrow(datWF), nrow(datBM) + nrow(datBF))) |> factor() group <- sex:color  itemstats(dat, group=group) #> $`Female:Black` #> $`Female:Black`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  145            1.462          1.014 0.046 0.087 0.176     0.921 #>  #> $`Female:Black`$itemstats #>          N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 145 2 0.503 0.502   0.659         0.213      -0.078 #> Item.2 145 2 0.421 0.495   0.550         0.074       0.152 #> Item.3 145 2 0.283 0.452   0.501         0.064       0.164 #> Item.4 145 2 0.255 0.437   0.421        -0.011       0.256 #>  #> $`Female:Black`$proportions #>            0     1 #> Item.1 0.497 0.503 #> Item.2 0.579 0.421 #> Item.3 0.717 0.283 #> Item.4 0.745 0.255 #>  #>  #> $`Female:White` #> $`Female:White`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  228            2.118          1.255 0.208 0.037 0.512     0.877 #>  #> $`Female:White`$itemstats #>          N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 228 2 0.618 0.487   0.615         0.277       0.464 #> Item.2 228 2 0.605 0.490   0.642         0.312       0.432 #> Item.3 228 2 0.487 0.501   0.629         0.284       0.458 #> Item.4 228 2 0.408 0.493   0.662         0.339       0.408 #>  #> $`Female:White`$proportions #>            0     1 #> Item.1 0.382 0.618 #> Item.2 0.395 0.605 #> Item.3 0.513 0.487 #> Item.4 0.592 0.408 #>  #>  #> $`Male:Black` #> $`Male:Black`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  140            1.443          1.027 0.051 0.102  0.18      0.93 #>  #> $`Male:Black`$itemstats #>          N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 140 2 0.443 0.499   0.612         0.158       0.029 #> Item.2 140 2 0.400 0.492   0.587         0.133       0.071 #> Item.3 140 2 0.329 0.471   0.426        -0.037       0.304 #> Item.4 140 2 0.271 0.446   0.521         0.100       0.123 #>  #> $`Male:Black`$proportions #>            0     1 #> Item.1 0.557 0.443 #> Item.2 0.600 0.400 #> Item.3 0.671 0.329 #> Item.4 0.729 0.271 #>  #>  #> $`Male:White` #> $`Male:White`$overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  263            2.475          1.361  0.34 0.075 0.673     0.779 #>  #> $`Male:White`$itemstats #>          N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 263 2 0.741 0.439   0.705         0.475       0.596 #> Item.2 263 2 0.635 0.482   0.649         0.361       0.667 #> Item.3 263 2 0.593 0.492   0.734         0.481       0.588 #> Item.4 263 2 0.506 0.501   0.754         0.507       0.569 #>  #> $`Male:White`$proportions #>            0     1 #> Item.1 0.259 0.741 #> Item.2 0.365 0.635 #> Item.3 0.407 0.593 #> Item.4 0.494 0.506 #>  #>"},{"path":"https://philchalmers.github.io/mirt/reference/Attitude.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of Attitude data — Attitude","title":"Description of Attitude data — Attitude","text":"Table counts extracted Andrich (1988). Data response patterns observed eight item survey.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Attitude.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Description of Attitude data — Attitude","text":"items survey : Capital punishment one hideous practices time. state teach sacredness human life destroying . Capital punishment effective deterrent crime. believe capital punishment sure     necessary. think capital punishment necessary wish . find civilized way prevent crime must capital    punishment. Capital punishment justified act    deterrent crime. Capital punishment gives criminal deserves.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Attitude.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of Attitude data — Attitude","text":"Andrich, D. (1988). Application Unfolding Model PIRT Type Measurement Attitude. Applied Psychological Measurement, 12, 33-51.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Attitude.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of Attitude data — Attitude","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Attitude.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of Attitude data — Attitude","text":"","code":"head(Attitude) #>   hideous state_teaching deterrent believe_not.necessary necessary_wish.not #> 1       0              1         1                     0                  0 #> 2       1              1         1                     0                  0 #> 3       0              1         1                     1                  0 #> 4       1              1         1                     1                  0 #> 5       0              1         1                     1                  1 #> 6       0              1         1                     1                  0 #>   must.have justified deserved freq #> 1         0         0        0    4 #> 2         0         0        0   10 #> 3         0         0        0    3 #> 4         0         0        0    8 #> 5         0         0        0    1 #> 6         0         1        0    1 df <- expand.table(Attitude) itemstats(df) #> $overall #>   N mean_total.score sd_total.score  ave.r  sd.r  alpha SEM.alpha #>  54            3.852          1.053 -0.064 0.524 -0.849     1.433 #>  #> $itemstats #>                        N K  mean    sd total.r total.r_if_rm alpha_if_rm #> hideous               54 2 0.444 0.502   0.056        -0.388      -0.340 #> state_teaching        54 2 0.648 0.482  -0.290        -0.616      -0.046 #> deterrent             54 2 0.667 0.476  -0.251        -0.587      -0.088 #> believe_not.necessary 54 2 0.463 0.503   0.523         0.053      -1.260 #> necessary_wish.not    54 2 0.481 0.504   0.669         0.249      -1.836 #> must.have             54 2 0.444 0.502   0.591         0.141      -1.499 #> justified             54 2 0.352 0.482   0.402        -0.061      -0.959 #> deserved              54 2 0.352 0.482   0.402        -0.061      -0.959 #>  #> $proportions #>                           0     1 #> hideous               0.556 0.444 #> state_teaching        0.352 0.648 #> deterrent             0.333 0.667 #> believe_not.necessary 0.537 0.463 #> necessary_wish.not    0.519 0.481 #> must.have             0.556 0.444 #> justified             0.648 0.352 #> deserved              0.648 0.352 #>   # \\donttest{  # estimate SSLM with estimated \" latitude of acceptance\" (rho) mod.rho <- mirt(df, 1, itemtype = 'sslm') #>  coef(mod.rho) #> $hideous #>     a1      d log_rho1 #> par  1 -0.929    0.089 #>  #> $state_teaching #>     a1      d log_rho1 #> par  1 -3.072    1.274 #>  #> $deterrent #>     a1      d log_rho1 #> par  1 -2.529    1.124 #>  #> $believe_not.necessary #>     a1      d log_rho1 #> par  1 -0.012   -0.236 #>  #> $necessary_wish.not #>     a1     d log_rho1 #> par  1 2.101    0.703 #>  #> $must.have #>     a1     d log_rho1 #> par  1 2.719    0.915 #>  #> $justified #>     a1     d log_rho1 #> par  1 2.278    0.605 #>  #> $deserved #>     a1     d log_rho1 #> par  1 8.142    2.032 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  coef(mod.rho, simplify=TRUE)  # slope-intercept-log_rho #> $items #>                       a1      d log_rho1 #> hideous                1 -0.929    0.089 #> state_teaching         1 -3.072    1.274 #> deterrent              1 -2.529    1.124 #> believe_not.necessary  1 -0.012   -0.236 #> necessary_wish.not     1  2.101    0.703 #> must.have              1  2.719    0.915 #> justified              1  2.278    0.605 #> deserved               1  8.142    2.032 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  coef(mod.rho, simplify=TRUE, IRTpars=TRUE)  # discrimination-difficulty-rho #> $items #>                       a      b  rho1 #> hideous               1  0.929 1.093 #> state_teaching        1  3.072 3.575 #> deterrent             1  2.529 3.076 #> believe_not.necessary 1  0.012 0.790 #> necessary_wish.not    1 -2.101 2.020 #> must.have             1 -2.719 2.497 #> justified             1 -2.278 1.830 #> deserved              1 -8.142 7.629 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  plot(mod.rho)  plot(mod.rho, type = 'trace')   # without estimating rho, and fixing to rho^2 = 1  (hence, #   log_rho = -exp(1) = -2.718282 in order to obtain (exp(exp(log_rho))) = 1) syntax <- \"Theta = 1-8            FIXED = (1-8, log_rho1)            START = (1-8, log_rho1, -2.71828)\" mod <- mirt(df, syntax, itemtype = 'sslm')  # model found in Andrich (1988) #>  coef(mod) #> $hideous #>     a1      d log_rho1 #> par  1 -0.622   -2.718 #>  #> $state_teaching #>     a1      d log_rho1 #> par  1 -0.517   -2.718 #>  #> $deterrent #>     a1      d log_rho1 #> par  1 -0.504   -2.718 #>  #> $believe_not.necessary #>     a1     d log_rho1 #> par  1 -0.05   -2.718 #>  #> $necessary_wish.not #>     a1     d log_rho1 #> par  1 0.783   -2.718 #>  #> $must.have #>     a1     d log_rho1 #> par  1 0.893   -2.718 #>  #> $justified #>     a1     d log_rho1 #> par  1 1.031   -2.718 #>  #> $deserved #>     a1     d log_rho1 #> par  1 1.099   -2.718 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  coef(mod, simplify=TRUE)  # slope-intercept-log_rho #> $items #>                       a1      d log_rho1 #> hideous                1 -0.622   -2.718 #> state_teaching         1 -0.517   -2.718 #> deterrent              1 -0.504   -2.718 #> believe_not.necessary  1 -0.050   -2.718 #> necessary_wish.not     1  0.783   -2.718 #> must.have              1  0.893   -2.718 #> justified              1  1.031   -2.718 #> deserved               1  1.099   -2.718 #>  #> $means #> Theta  #>     0  #>  #> $cov #>       Theta #> Theta     1 #>  coef(mod, simplify=TRUE, IRTpars=TRUE)  # discrimination-difficulty-rho #> $items #>                       a      b  rho1 #> hideous               1  0.622 0.066 #> state_teaching        1  0.517 0.066 #> deterrent             1  0.504 0.066 #> believe_not.necessary 1  0.050 0.066 #> necessary_wish.not    1 -0.783 0.066 #> must.have             1 -0.893 0.066 #> justified             1 -1.031 0.066 #> deserved              1 -1.099 0.066 #>  #> $means #> Theta  #>     0  #>  #> $cov #>       Theta #> Theta     1 #>  plot(mod)  plot(mod, type = 'trace') # notice that all curves have a fixed height of .5   # goodness of fit (less constrained model fits better) anova(mod, mod.rho) # original model fits much worse #>             AIC   SABIC      HQ     BIC   logLik      X2 df p #> mod     581.139 571.917 587.275 597.051 -282.569              #> mod.rho 422.326 403.882 434.599 454.149 -195.163 174.813  8 0 M2(mod) #>             M2 df p     RMSEA   RMSEA_5  RMSEA_95    SRMSR       TLI       CFI #> stats 271.0979 28 0 0.4047377 0.3582323 0.4451614 0.423321 0.3590415 0.3590415 M2(mod.rho) #>             M2 df          p  RMSEA    RMSEA_5 RMSEA_95      SRMSR       TLI #> stats 34.70944 20 0.02170751 0.1178 0.04456401 0.180314 0.07963288 0.9457034 #>             CFI #> stats 0.9612167 itemfit(mod, p.adjust='fdr') #>                    item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1               hideous  9.192       4      0.156  0.075 #> 2        state_teaching 37.649       4      0.398  0.000 #> 3             deterrent 23.743       4      0.305  0.000 #> 4 believe_not.necessary  6.454       3      0.147  0.105 #> 5    necessary_wish.not 14.371       3      0.267  0.007 #> 6             must.have  8.953       3      0.193  0.048 #> 7             justified  4.967       4      0.068  0.291 #> 8              deserved 11.061       3      0.225  0.023 itemfit(mod.rho, p.adjust='fdr') #>                    item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1               hideous  0.893       2      0.000  0.640 #> 2        state_teaching 12.861       2      0.320  0.013 #> 3             deterrent  1.824       1      0.125  0.301 #> 4 believe_not.necessary  0.310       1      0.000  0.640 #> 5    necessary_wish.not  2.816       1      0.185  0.249 #> 6             must.have  1.465       1      0.094  0.301 #> 7             justified  1.494       1      0.097  0.301 #> 8              deserved  6.713       2      0.211  0.139  # }"},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of Bock 1997 data — Bock1997","title":"Description of Bock 1997 data — Bock1997","text":"3-item tabulated data set extracted Table 3 Chapter Two.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of Bock 1997 data — Bock1997","text":"Bock, R. D. (1997). Nominal Categories Model. van der Linden, W. J. & Hambleton, R. K. Handbook modern item response theory. New York: Springer.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of Bock 1997 data — Bock1997","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Bock1997.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of Bock 1997 data — Bock1997","text":"","code":"# \\donttest{ dat <- expand.table(Bock1997) head(dat) #>   Item.1 Item.2 Item.3 #> 1      1      1      1 #> 2      1      1      1 #> 3      1      1      1 #> 4      1      1      1 #> 5      1      1      1 #> 6      1      1      1 itemstats(dat, use_ts=FALSE) #> $overall #>      N #> 1 2000 #>  #> $itemstats #>           N K  mean    sd #> Item.1 2000 4 2.443 1.070 #> Item.2 2000 4 2.666 0.957 #> Item.3 2000 4 2.780 1.059 #>  #> $proportions #>            1     2     3     4 #> Item.1 0.240 0.284 0.267 0.208 #> Item.2 0.122 0.314 0.340 0.224 #> Item.3 0.141 0.273 0.253 0.334 #>   mod <- mirt(dat, 1, 'nominal') #>   # reproduce table 3 in Bock (1997) fs <- round(fscores(mod, verbose = FALSE, full.scores = FALSE)[,c('F1','SE_F1')],2) fttd <- residuals(mod, type = 'exp') table <- data.frame(fttd[,-ncol(fttd)], fs) table #>    Item.1 Item.2 Item.3 freq        exp    F1 SE_F1 #> 1       1      1      1   50  46.444027 -1.72  0.68 #> 2       1      1      2   32  37.215496 -1.22  0.64 #> 3       1      1      3   15  18.069304 -0.95  0.62 #> 4       1      1      4   10   8.692424 -0.61  0.61 #> 5       1      2      1   54  59.965727 -1.38  0.65 #> 6       1      2      2   80  70.000273 -0.91  0.62 #> 7       1      2      3   40  41.674601 -0.65  0.61 #> 8       1      2      4   24  25.832371 -0.33  0.61 #> 9       1      3      1   27  28.065138 -1.07  0.63 #> 10      1      3      2   52  46.689631 -0.62  0.61 #> 11      1      3      3   33  33.847511 -0.37  0.61 #> 12      1      3      4   27  26.935712 -0.04  0.61 #> 13      1      4      1    4   3.940514 -0.63  0.61 #> 14      1      4      2   13  10.897962 -0.19  0.61 #> 15      1      4      3   10  10.571253  0.06  0.61 #> 16      1      4      4   10  12.283469  0.40  0.63 #> 17      2      1      1   27  20.191927 -1.29  0.64 #> 18      2      1      2   19  26.271170 -0.82  0.62 #> 19      2      1      3   11  16.603995 -0.57  0.61 #> 20      2      1      4   11  11.097212 -0.24  0.61 #> 21      2      2      1   30  36.068703 -0.98  0.63 #> 22      2      2      2   78  66.604897 -0.53  0.61 #> 23      2      2      3   69  51.217364 -0.28  0.61 #> 24      2      2      4   48  43.966108  0.05  0.61 #> 25      2      3      1   24  22.900098 -0.68  0.61 #> 26      2      3      2   48  59.345066 -0.25  0.61 #> 27      2      3      3   52  55.428529  0.01  0.61 #> 28      2      3      4   53  61.277297  0.34  0.62 #> 29      2      4      1    3   4.974192 -0.25  0.61 #> 30      2      4      2   21  21.301177  0.19  0.62 #> 31      2      4      3   20  26.765813  0.45  0.63 #> 32      2      4      4   54  43.946401  0.81  0.65 #> 33      3      1      1    9   7.040049 -0.96  0.62 #> 34      3      1      2   12  13.275569 -0.51  0.61 #> 35      3      1      3   13  10.330678 -0.26  0.61 #> 36      3      1      4    7   9.005107  0.06  0.61 #> 37      3      2      1   11  16.098345 -0.66  0.61 #> 38      3      2      2   29  42.609506 -0.23  0.61 #> 39      3      2      3   37  40.289025  0.03  0.61 #> 40      3      2      4   44  45.264883  0.36  0.62 #> 41      3      3      1   15  12.966052 -0.38  0.61 #> 42      3      3      2   62  47.984143  0.06  0.61 #> 43      3      3      3   60  55.255840  0.32  0.62 #> 44      3      3      4   88  80.660157  0.67  0.64 #> 45      3      4      1    4   3.999324  0.05  0.61 #> 46      3      4      2   27  24.639934  0.50  0.63 #> 47      3      4      3   43  38.630407  0.78  0.65 #> 48      3      4      4   73  85.862836  1.17  0.68 #> 49      4      1      1    4   2.538215 -0.75  0.62 #> 50      4      1      2    8   6.100809 -0.31  0.61 #> 51      4      1      3    7   5.455196 -0.06  0.61 #> 52      4      1      4    9   5.695962  0.27  0.62 #> 53      4      2      1    7   6.816068 -0.46  0.61 #> 54      4      2      2   21  22.926076 -0.02  0.61 #> 55      4      2      3   25  24.946447  0.23  0.62 #> 56      4      2      4   31  33.758294  0.58  0.64 #> 57      4      3      1    8   6.427237 -0.17  0.61 #> 58      4      3      2   23  30.276410  0.27  0.62 #> 59      4      3      3   35  40.293621  0.54  0.63 #> 60      4      3      4   73  71.523729  0.90  0.66 #> 61      4      4      1    4   2.513701  0.26  0.62 #> 62      4      4      2   21  19.940144  0.73  0.65 #> 63      4      4      3   36  36.579513  1.02  0.67 #> 64      4      4      4  105 101.211362  1.43  0.71  mod <- mirt(dat, 1, 'nominal') #>  coef(mod) #> $Item.1 #>       a1 ak0   ak1   ak2 ak3 d0    d1    d2     d3 #> par 0.79   0 1.269 2.304   3  0 0.673 0.538 -0.013 #>  #> $Item.2 #>        a1 ak0   ak1   ak2 ak3 d0    d1    d2    d3 #> par 0.898   0 0.859 1.717   3  0 1.452 1.636 0.647 #>  #> $Item.3 #>        a1 ak0   ak1   ak2 ak3 d0    d1    d2    d3 #> par 0.908   0 1.289 2.038   3  0 1.495 1.508 1.457 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>    # }"},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential item functioning statistics — DIF","title":"Differential item functioning statistics — DIF","text":"function runs Wald likelihood-ratio approaches testing differential item functioning (DIF) two groups. primarily convenience wrapper multipleGroup function performing standard DIF procedures. Independent models can estimated parallel defining parallel object mirtCluster, help decrease run time. best results, baseline model contain set 'anchor' items freely estimated hyper-parameters focal groups.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential item functioning statistics — DIF","text":"","code":"DIF(   MGmodel,   which.par,   scheme = \"add\",   items2test = 1:extract.mirt(MGmodel, \"nitems\"),   groups2test = \"all\",   seq_stat = \"SABIC\",   Wald = FALSE,   p.adjust = \"none\",   pairwise = FALSE,   return_models = FALSE,   return_seq_model = FALSE,   max_run = Inf,   plotdif = FALSE,   type = \"trace\",   simplify = TRUE,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential item functioning statistics — DIF","text":"MGmodel object returned multipleGroup used reference model .par character vector containing parameter names inspected DIF scheme type DIF analysis perform, either adding dropping constraints across   groups. can : 'add' parameters .par constrained item one time     items specified items2test. beneficial examining DIF     model parameters freely estimated across groups, inspecting differences via     Wald test 'drop' parameters .par freely estimated items     specified items2test. useful supplying overly restrictive model     attempting detect DIF slightly less restrictive model 'add_sequential' sequentially loop items tested, end     loop treat DIF tests satisfy seq_stat criteria invariant. loop     re-run remaining invariant items determine now displaying DIF     less constrained model, new invariant item found algorithm stops     returns items displayed DIF. Note DIF statistics relative final,     less constrained model includes DIF effects 'drop_sequential' sequentially loop items tested, end     loop treat items violate seq_stat criteria demonstrating DIF. loop     re-run, leaving items previously demonstrated DIF variable across groups,     remaining test items previously showed invariance re-tested. algorithm     stops items showing DIF found returns items displayed DIF.     Note DIF statistics relative final,     less constrained model includes DIF effects items2test numeric vector, character vector containing item names, indicating items tested DIF. models anchor items known, omit vector. example, items 1 2 anchors 10 item test, items2test = 3:10 work testing remaining items (important remember using sequential schemes) groups2test character vector indicating groups use DIF testing investigations. Default '', uses group information perform joint hypothesis tests DIF (two group setup result pair-wise tests). example, group names 'g1', 'g2' 'g3', DIF investigated group 'g1' 'g3' pass groups2test = c('g1', 'g3') seq_stat select statistic test sequential schemes. Potential values (descending order power) 'AIC', 'SABIC', 'HQ', 'BIC'. numeric value input ranges 0 1, 'p' value tested (e.g., seq_stat = .05 test difference p < .05 add scheme, p > .05 drop scheme), along specified p.adjust input Wald logical; perform Wald tests DIF instead likelihood ratio test? p.adjust string passed p.adjust function adjust p-values. Adjustments located adj_p element returned list pairwise logical; perform pairwise tests groups number groups greater 2? Useful quickly specified post-hoc tests return_models logical; return estimated model objects analysis? Default FALSE return_seq_model logical; last iteration sequential schemes, return fitted multiple-group model containing freely estimated parameters indicative DIF? generally useful scheme = 'add_sequential'. Default FALSE max_run number indicating maximum number cycles perform sequential searches. default perform search DIF found plotdif logical; create item plots items displaying DIF according seq_stat criteria? available 'add' type schemes type type plot argument passed plot(). Default 'trace', though another good option 'infotrace'. ease viewing, facet_item argument mirt's plot() function set TRUE simplify logical; simplify output returning data.frame object differences AIC, BIC, etc, well chi-squared test (X2) associated df p-values verbose logical print extra information console? ... additional arguments passed multipleGroup plot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential item functioning statistics — DIF","text":"mirt_df object information-based criteria DIF, though may changed   list output return_models simplify modified. well, silent   'DIF_coefficeints' attribute included view item parameter differences   groups","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Differential item functioning statistics — DIF","text":"Generally, pre-computed baseline model configured two estimation properties: 1) set 'anchor' items, anchor items various parameters constrained equal across groups, 2) contain freely estimated latent mean variance terms one group (-called 'reference' group). two properties help fix metric groups item parameter estimates contain latent distribution characteristics.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential item functioning statistics — DIF","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P., Counsell, ., Flora, D. B. (2016). might   make big DIF: Improved Differential Test Functioning statistics account   sampling variability. Educational Psychological Measurement, 76, 114-140.   doi:10.1177/0013164415584576","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Differential item functioning statistics — DIF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DIF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential item functioning statistics — DIF","text":"","code":"# \\donttest{  # simulate data where group 2 has a smaller slopes and more extreme intercepts set.seed(12345) a1 <- a2 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d1 <- d2 <- matrix(rnorm(15,0,.7),ncol=1) a2[1:2, ] <- a1[1:2, ]/3 d1[c(1,3), ] <- d2[c(1,3), ]/4 head(data.frame(a.group1 = a1, a.group2 = a2, d.group1 = d1, d.group2 = d2)) #>    a.group1  a.group2    d.group1   d.group2 #> 1 1.1756586 0.3918862  0.14295747  0.5718299 #> 2 1.2128398 0.4042799 -0.62045026 -0.6204503 #> 3 0.9672090 0.9672090 -0.05802608 -0.2321043 #> 4 0.8639508 0.8639508  0.78449886  0.7844989 #> 5 1.1817662 1.1817662  0.20910659  0.2091066 #> 6 0.4546132 0.4546132  0.54573535  0.5457353 itemtype <- rep('2PL', nrow(a1)) N <- 1000 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  #### no anchors, all items tested for DIF by adding item constrains one item at a time. # define a parallel cluster (optional) to help speed up internal functions if(interactive()) mirtCluster()  # Information matrix with Oakes' identity (not controlling for latent group differences) # NOTE: Without properly equating the groups the following example code is not testing for DIF,      # but instead reflects a combination of DIF + latent-trait distribution effects model <- multipleGroup(dat, 1, group, SE = TRUE) #>  #>  #> Calculating information matrix...  # Likelihood-ratio test for DIF (as well as model information) dif <- DIF(model, c('a1', 'd')) #> NOTE: No hyper-parameters were estimated in the DIF model.  #>       For effective DIF testing, freeing the focal group hyper-parameters is recommended. dif #>         groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1   D1,D2      TRUE -34.621 -29.773 -30.507 -23.419 38.621  2     0 #> Item_2   D1,D2      TRUE -20.364 -15.516 -16.251  -9.162 24.364  2     0 #> Item_3   D1,D2      TRUE -10.101  -5.253  -5.988   1.101 14.101  2 0.001 #> Item_4   D1,D2      TRUE  -0.356   4.492   3.757  10.846  4.356  2 0.113 #> Item_5   D1,D2      TRUE   0.968   5.815   5.081  12.169  3.032  2  0.22 #> Item_6   D1,D2      TRUE   3.441   8.289   7.554  14.643  0.559  2 0.756 #> Item_7   D1,D2      TRUE   3.340   8.188   7.453  14.542   0.66  2 0.719 #> Item_8   D1,D2      TRUE  -2.371   2.477   1.742   8.831  6.371  2 0.041 #> Item_9   D1,D2      TRUE   0.546   5.393   4.659  11.748  3.454  2 0.178 #> Item_10  D1,D2      TRUE   3.215   8.062   7.328  14.416  0.785  2 0.675 #> Item_11  D1,D2      TRUE  -4.853  -0.006  -0.740   6.348  8.853  2 0.012 #> Item_12  D1,D2      TRUE   1.497   6.345   5.610  12.699  2.503  2 0.286 #> Item_13  D1,D2      TRUE   1.854   6.702   5.967  13.056  2.146  2 0.342 #> Item_14  D1,D2      TRUE  -4.350   0.498  -0.237   6.852   8.35  2 0.015 #> Item_15  D1,D2      TRUE   3.831   8.679   7.944  15.033  0.169  2 0.919  # function silently includes \"DIF_coefficients\" attribute to view # the IRT parameters post-completion extract.mirt(dif, \"DIF_coefficients\") #> $Item_1 #>           a1         d g u #> D1 0.7472578 0.3483822 0 1 #> D2 0.7472578 0.3483822 0 1 #>  #> $Item_2 #>           a1          d g u #> D1 0.8277687 -0.6535244 0 1 #> D2 0.8277687 -0.6535244 0 1 #>  #> $Item_3 #>          a1          d g u #> D1 1.213165 -0.1452843 0 1 #> D2 1.213165 -0.1452843 0 1 #>  #> $Item_4 #>          a1         d g u #> D1 1.017216 0.9327436 0 1 #> D2 1.017216 0.9327436 0 1 #>  #> $Item_5 #>          a1         d g u #> D1 1.216819 0.1966309 0 1 #> D2 1.216819 0.1966309 0 1 #>  #> $Item_6 #>           a1        d g u #> D1 0.5196433 0.652555 0 1 #> D2 0.5196433 0.652555 0 1 #>  #> $Item_7 #>          a1        d g u #> D1 1.348864 1.016455 0 1 #> D2 1.348864 1.016455 0 1 #>  #> $Item_8 #>          a1          d g u #> D1 1.089472 -0.3447219 0 1 #> D2 1.089472 -0.3447219 0 1 #>  #> $Item_9 #>          a1         d g u #> D1 0.993117 -1.006033 0 1 #> D2 0.993117 -1.006033 0 1 #>  #> $Item_10 #>          a1         d g u #> D1 0.791053 -1.099697 0 1 #> D2 0.791053 -1.099697 0 1 #>  #> $Item_11 #>          a1        d g u #> D1 1.053996 1.235564 0 1 #> D2 1.053996 1.235564 0 1 #>  #> $Item_12 #>          a1          d g u #> D1 1.593305 -0.1832728 0 1 #> D2 1.593305 -0.1832728 0 1 #>  #> $Item_13 #>          a1         d g u #> D1 1.389336 0.4619023 0 1 #> D2 1.389336 0.4619023 0 1 #>  #> $Item_14 #>          a1         d g u #> D1 1.294955 0.4870637 0 1 #> D2 1.294955 0.4870637 0 1 #>  #> $Item_15 #>           a1           d g u #> D1 0.8797218 -0.04575426 0 1 #> D2 0.8797218 -0.04575426 0 1 #>   # same as above, but using Wald tests with Benjamini & Hochberg adjustment DIF(model, c('a1', 'd'), Wald = TRUE, p.adjust = 'fdr') #> NOTE: No hyper-parameters were estimated in the DIF model.  #>       For effective DIF testing, freeing the focal group hyper-parameters is recommended. #>         groups      W df     p adj_p #> Item_1   D1,D2 36.513  2     0 0.000 #> Item_2   D1,D2 22.089  2     0 0.000 #> Item_3   D1,D2 13.444  2 0.001 0.006 #> Item_4   D1,D2  4.293  2 0.117 0.251 #> Item_5   D1,D2  3.009  2 0.222 0.370 #> Item_6   D1,D2  0.558  2 0.756 0.810 #> Item_7   D1,D2  0.658  2  0.72 0.810 #> Item_8   D1,D2  6.238  2 0.044 0.111 #> Item_9   D1,D2  3.438  2 0.179 0.336 #> Item_10  D1,D2  0.785  2 0.675 0.810 #> Item_11  D1,D2  8.621  2 0.013 0.050 #> Item_12  D1,D2  2.485  2 0.289 0.433 #> Item_13  D1,D2  2.133  2 0.344 0.469 #> Item_14  D1,D2  8.062  2 0.018 0.053 #> Item_15  D1,D2  0.168  2 0.919 0.919  # equate the groups by assuming the last 5 items have no DIF itemnames <- colnames(dat) model <- multipleGroup(dat, 1, group, SE = TRUE,    invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var')) #>  #>  #> Calculating information matrix...  # test whether adding slopes and intercepts constraints results in DIF. Plot items showing DIF resulta1d <- DIF(model, c('a1', 'd'), plotdif = TRUE, items2test=1:10)  resulta1d #>         groups converged     AIC   SABIC      HQ     BIC    X2 df     p #> Item_1   D1,D2      TRUE -43.490 -38.642 -39.377 -32.288 47.49  2     0 #> Item_2   D1,D2      TRUE -33.840 -28.993 -29.727 -22.638 37.84  2     0 #> Item_3   D1,D2      TRUE  -5.497  -0.649  -1.384   5.705 9.497  2 0.009 #> Item_4   D1,D2      TRUE   2.395   7.242   6.508  13.596 1.605  2 0.448 #> Item_5   D1,D2      TRUE   3.140   7.988   7.253  14.342  0.86  2 0.651 #> Item_6   D1,D2      TRUE   1.122   5.970   5.235  12.324 2.878  2 0.237 #> Item_7   D1,D2      TRUE   3.083   7.931   7.196  14.285 0.917  2 0.632 #> Item_8   D1,D2      TRUE   2.857   7.705   6.970  14.059 1.143  2 0.565 #> Item_9   D1,D2      TRUE   3.674   8.521   7.787  14.875 0.326  2 0.849 #> Item_10  D1,D2      TRUE   3.154   8.001   7.267  14.355 0.846  2 0.655  # test whether adding only slope constraints results in DIF for all items DIF(model, 'a1', items2test=1:10) #>         groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1   D1,D2      TRUE -20.871 -18.447 -18.815 -15.270 22.871  1     0 #> Item_2   D1,D2      TRUE -34.675 -32.252 -32.619 -29.075 36.675  1     0 #> Item_3   D1,D2      TRUE   0.435   2.859   2.492   6.036  1.565  1 0.211 #> Item_4   D1,D2      TRUE   1.980   4.404   4.036   7.581   0.02  1 0.887 #> Item_5   D1,D2      TRUE   1.754   4.178   3.811   7.355  0.246  1  0.62 #> Item_6   D1,D2      TRUE  -0.564   1.860   1.492   5.037  2.564  1 0.109 #> Item_7   D1,D2      TRUE   1.093   3.517   3.150   6.694  0.907  1 0.341 #> Item_8   D1,D2      TRUE   1.431   3.855   3.488   7.032  0.569  1 0.451 #> Item_9   D1,D2      TRUE   1.863   4.287   3.920   7.464  0.137  1 0.712 #> Item_10  D1,D2      TRUE   1.775   4.199   3.832   7.376  0.225  1 0.636  # Determine whether it's a1 or d parameter causing DIF (could be joint, however) (a1s <- DIF(model, 'a1', items2test = 1:3)) #>        groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1  D1,D2      TRUE -20.871 -18.447 -18.815 -15.270 22.871  1     0 #> Item_2  D1,D2      TRUE -34.675 -32.252 -32.619 -29.075 36.675  1     0 #> Item_3  D1,D2      TRUE   0.435   2.859   2.492   6.036  1.565  1 0.211 (ds <- DIF(model, 'd', items2test = 1:3)) #>        groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1  D1,D2      TRUE -18.568 -16.145 -16.512 -12.968 20.568  1     0 #> Item_2  D1,D2      TRUE   1.843   4.266   3.899   7.443  0.157  1 0.691 #> Item_3  D1,D2      TRUE  -6.229  -3.805  -4.173  -0.628  8.229  1 0.004  ### drop down approach (freely estimating parameters across groups) when ### specifying a highly constrained model with estimated latent parameters model_constrained <- multipleGroup(dat, 1, group,   invariance = c(colnames(dat), 'free_means', 'free_var')) #>  dropdown <- DIF(model_constrained, c('a1', 'd'), scheme = 'drop') dropdown #>         groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1   D1,D2      TRUE -43.297 -38.450 -39.184 -32.096 47.297  2     0 #> Item_2   D1,D2      TRUE -32.642 -27.794 -28.529 -21.440 36.642  2     0 #> Item_3   D1,D2      TRUE -10.510  -5.662  -6.397   0.692  14.51  2 0.001 #> Item_4   D1,D2      TRUE   1.885   6.733   5.998  13.087  2.115  2 0.347 #> Item_5   D1,D2      TRUE   3.155   8.003   7.268  14.357  0.845  2 0.655 #> Item_6   D1,D2      TRUE   1.914   6.761   6.027  13.116  2.086  2 0.352 #> Item_7   D1,D2      TRUE   3.887   8.735   8.000  15.089  0.113  2 0.945 #> Item_8   D1,D2      TRUE   0.703   5.550   4.816  11.905  3.297  2 0.192 #> Item_9   D1,D2      TRUE   3.059   7.907   7.172  14.261  0.941  2 0.625 #> Item_10  D1,D2      TRUE   3.631   8.479   7.744  14.833  0.369  2 0.832 #> Item_11  D1,D2      TRUE  -0.765   4.083   3.348  10.437  4.765  2 0.092 #> Item_12  D1,D2      TRUE   3.511   8.359   7.624  14.713  0.489  2 0.783 #> Item_13  D1,D2      TRUE   3.416   8.263   7.529  14.618  0.584  2 0.747 #> Item_14  D1,D2      TRUE  -0.690   4.157   3.423  10.511   4.69  2 0.096 #> Item_15  D1,D2      TRUE   3.599   8.447   7.712  14.801  0.401  2 0.818  # View silent \"DIF_coefficients\" attribute extract.mirt(dropdown, \"DIF_coefficients\") #> $Item_1 #>           a1         d g u #> D1 1.0070333 0.1008689 0 1 #> D2 0.4519451 0.5696948 0 1 #>  #> $Item_2 #>           a1          d g u #> D1 1.2404964 -0.7051772 0 1 #> D2 0.4454868 -0.6639707 0 1 #>  #> $Item_3 #>           a1           d g u #> D1 0.9753304 -0.02503532 0 1 #> D2 1.3391630 -0.38511564 0 1 #>  #> $Item_4 #>           a1         d g u #> D1 0.8791819 0.8382862 0 1 #> D2 1.0156000 0.9950612 0 1 #>  #> $Item_5 #>          a1         d g u #> D1 1.121610 0.1289461 0 1 #> D2 1.174548 0.2229443 0 1 #>  #> $Item_6 #>           a1         d g u #> D1 0.5623518 0.6822046 0 1 #> D2 0.4157185 0.6026837 0 1 #>  #> $Item_7 #>          a1         d g u #> D1 1.283799 1.0057389 0 1 #> D2 1.237164 0.9681292 0 1 #>  #> $Item_8 #>           a1          d g u #> D1 0.8938398 -0.3260637 0 1 #> D2 1.1477262 -0.4254126 0 1 #>  #> $Item_9 #>           a1          d g u #> D1 0.8827366 -1.0565622 0 1 #> D2 0.9625327 -0.9928805 0 1 #>  #> $Item_10 #>           a1         d g u #> D1 0.7335219 -1.085299 0 1 #> D2 0.7456898 -1.154238 0 1 #>  #> $Item_11 #>           a1        d g u #> D1 0.8342628 1.189315 0 1 #> D2 1.1656520 1.241327 0 1 #>  #> $Item_12 #>          a1          d g u #> D1 1.476098 -0.2510092 0 1 #> D2 1.492375 -0.1714954 0 1 #>  #> $Item_13 #>          a1         d g u #> D1 1.236010 0.4387954 0 1 #> D2 1.358438 0.4178786 0 1 #>  #> $Item_14 #>          a1         d g u #> D1 1.042360 0.4541474 0 1 #> D2 1.400258 0.4556598 0 1 #>  #> $Item_15 #>           a1           d g u #> D1 0.8583058 -0.06114579 0 1 #> D2 0.7771780 -0.06825570 0 1 #>   ### sequential schemes (add constraints)  ### sequential searches using SABIC as the selection criteria # starting from completely different models stepup <- DIF(model, c('a1', 'd'), scheme = 'add_sequential',               items2test=1:10) #>  Checking for DIF in 3 more items #> Computing final DIF estimates... stepup #>        groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1  D1,D2      TRUE -43.161 -38.314 -39.048 -31.959 47.161  2     0 #> Item_2  D1,D2      TRUE -34.224 -29.377 -30.111 -23.022 38.224  2     0 #> Item_3  D1,D2      TRUE  -7.368  -2.520  -3.255   3.834 11.368  2 0.003  # step down procedure for highly constrained model stepdown <- DIF(model_constrained, c('a1', 'd'), scheme = 'drop_sequential') #>  Checking for DIF in 12 more items #> Computing final DIF estimates... stepdown #>        groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> Item_1  D1,D2      TRUE -43.161 -38.314 -39.048 -31.959 47.161  2     0 #> Item_2  D1,D2      TRUE -34.224 -29.377 -30.111 -23.022 38.224  2     0 #> Item_3  D1,D2      TRUE  -7.368  -2.520  -3.255   3.834 11.368  2 0.003  # view final MG model (only useful when scheme is 'add_sequential') updated_mod <- DIF(model, c('a1', 'd'), scheme = 'add_sequential',                return_seq_model=TRUE) #>  Checking for DIF in 3 more items #> Computing final DIF estimates... plot(updated_mod, type='trace')    ################################### # Multi-group example  a1 <- a2 <- a3 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d1 <- d2 <- d3 <- matrix(rnorm(15,0,.7),ncol=1) a2[1:2, ] <- a1[1:2, ]/3 d3[c(1,3), ] <- d2[c(1,3), ]/4 head(data.frame(a.group1 = a1, a.group2 = a2, a.group3 = a3,                 d.group1 = d1, d.group2 = d2, d.group3 = d3)) #>    a.group1  a.group2  a.group3   d.group1   d.group2   d.group3 #> 1 0.9921262 0.3307087 0.9921262 -0.6923662 -0.6923662 -0.1730916 #> 2 0.6115843 0.2038614 0.6115843 -0.4398444 -0.4398444 -0.4398444 #> 3 1.0571399 1.0571399 1.0571399  0.5243734  0.5243734  0.1310934 #> 4 1.1508422 1.1508422 1.1508422 -1.0133952 -1.0133952 -1.0133952 #> 5 1.2447020 1.2447020 1.2447020 -0.4542548 -0.4542548 -0.4542548 #> 6 0.6518627 0.6518627 0.6518627  0.7766470  0.7766470  0.7766470 itemtype <- rep('2PL', nrow(a1)) N <- 1000 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5)) dataset3 <- simdata(a3, d3, N, itemtype, mu = .2) dat <- rbind(dataset1, dataset2, dataset3) group <- gl(3, N, labels = c('g1', 'g2', 'g3'))  # equate the groups by assuming the last 5 items have no DIF itemnames <- colnames(dat) model <- multipleGroup(dat, group=group, SE=TRUE,    invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var')) #>  #>  #> Calculating information matrix... coef(model, simplify=TRUE) #> $g1 #> $items #>            a1      d g u #> Item_1  0.982 -0.707 0 1 #> Item_2  0.571 -0.458 0 1 #> Item_3  0.991  0.557 0 1 #> Item_4  1.240 -1.133 0 1 #> Item_5  1.095 -0.475 0 1 #> Item_6  0.711  0.712 0 1 #> Item_7  0.952 -1.641 0 1 #> Item_8  0.709 -0.568 0 1 #> Item_9  1.131  0.736 0 1 #> Item_10 1.211  0.397 0 1 #> Item_11 1.089 -0.384 0 1 #> Item_12 0.523 -1.044 0 1 #> Item_13 0.983  0.345 0 1 #> Item_14 0.950  0.330 0 1 #> Item_15 1.292 -0.246 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $g2 #> $items #>            a1      d g u #> Item_1  0.286 -0.788 0 1 #> Item_2  0.080 -0.397 0 1 #> Item_3  0.898  0.505 0 1 #> Item_4  1.025 -0.994 0 1 #> Item_5  1.023 -0.364 0 1 #> Item_6  0.717  0.832 0 1 #> Item_7  1.100 -1.903 0 1 #> Item_8  0.783 -0.487 0 1 #> Item_9  0.956  0.820 0 1 #> Item_10 1.095  0.428 0 1 #> Item_11 1.089 -0.384 0 1 #> Item_12 0.523 -1.044 0 1 #> Item_13 0.983  0.345 0 1 #> Item_14 0.950  0.330 0 1 #> Item_15 1.292 -0.246 0 1 #>  #> $means #>    F1  #> 0.038  #>  #> $cov #>       F1 #> F1 1.653 #>  #>  #> $g3 #> $items #>            a1      d g u #> Item_1  1.029 -0.180 0 1 #> Item_2  0.766 -0.442 0 1 #> Item_3  1.175  0.171 0 1 #> Item_4  1.319 -1.101 0 1 #> Item_5  1.345 -0.567 0 1 #> Item_6  0.620  0.694 0 1 #> Item_7  1.073 -1.699 0 1 #> Item_8  0.842 -0.678 0 1 #> Item_9  1.227  0.945 0 1 #> Item_10 1.344  0.540 0 1 #> Item_11 1.089 -0.384 0 1 #> Item_12 0.523 -1.044 0 1 #> Item_13 0.983  0.345 0 1 #> Item_14 0.950  0.330 0 1 #> Item_15 1.292 -0.246 0 1 #>  #> $means #>    F1  #> 0.189  #>  #> $cov #>       F1 #> F1 0.893 #>  #>   # omnibus tests dif <- DIF(model, which.par = c('a1', 'd'), items2test=1:9) dif #>          groups converged      AIC   SABIC      HQ     BIC      X2 df     p #> Item_1 g1,g2,g3      TRUE -100.312 -88.996 -91.670 -76.286 108.312  4     0 #> Item_2 g1,g2,g3      TRUE  -39.696 -28.380 -31.054 -15.670  47.696  4     0 #> Item_3 g1,g2,g3      TRUE   -8.644   2.672  -0.002  15.382  16.644  4 0.002 #> Item_4 g1,g2,g3      TRUE    4.559  15.875  13.201  28.584   3.441  4 0.487 #> Item_5 g1,g2,g3      TRUE    3.087  14.402  11.728  27.112   4.913  4 0.296 #> Item_6 g1,g2,g3      TRUE    5.556  16.872  14.198  29.581   2.444  4 0.655 #> Item_7 g1,g2,g3      TRUE    4.844  16.160  13.486  28.869   3.156  4 0.532 #> Item_8 g1,g2,g3      TRUE    4.504  15.819  13.145  28.529   3.496  4 0.478 #> Item_9 g1,g2,g3      TRUE    2.263  13.578  10.904  26.288   5.737  4  0.22  # pairwise post-hoc tests for items flagged via omnibus tests dif.posthoc <- DIF(model, which.par = c('a1', 'd'), items2test=1:2,                    pairwise = TRUE) dif.posthoc #>     item groups converged     AIC   SABIC      HQ     BIC     X2 df     p #> 1 Item_1  g1,g2      TRUE -32.488 -26.830 -28.167 -20.475 36.488  2     0 #> 2 Item_2  g1,g2      TRUE -19.000 -13.342 -14.679  -6.988     23  2     0 #> 3 Item_1  g1,g3      TRUE -19.543 -13.885 -15.222  -7.530 23.543  2     0 #> 4 Item_2  g1,g3      TRUE   1.728   7.385   6.048  13.740  2.272  2 0.321 #> 5 Item_1  g2,g3      TRUE -90.300 -84.642 -85.979 -78.287   94.3  2     0 #> 6 Item_2  g2,g3      TRUE -36.756 -31.098 -32.435 -24.743 40.756  2     0  # further probing for df = 1 tests, this time with Wald tests DIF(model, which.par = c('a1'), items2test=1:2, pairwise = TRUE,     Wald=TRUE) #>     item groups      W df     p #> 1 Item_1  g1,g2 29.897  1     0 #> 2 Item_2  g1,g2 22.022  1     0 #> 3 Item_1  g1,g3  0.076  1 0.783 #> 4 Item_2  g1,g3  1.939  1 0.164 #> 5 Item_1  g2,g3 27.618  1     0 #> 6 Item_2  g2,g3 30.587  1     0 DIF(model, which.par = c('d'), items2test=1:2, pairwise = TRUE,     Wald=TRUE) #>     item groups      W df     p #> 1 Item_1  g1,g2  0.592  1 0.442 #> 2 Item_2  g1,g2  0.419  1 0.518 #> 3 Item_1  g1,g3 21.130  1     0 #> 4 Item_2  g1,g3  0.025  1 0.874 #> 5 Item_1  g2,g3 29.743  1     0 #> 6 Item_2  g2,g3  0.182  1  0.67  # }"},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential Response Functioning statistics — DRF","title":"Differential Response Functioning statistics — DRF","text":"Function performs various omnibus differential item (DIF), bundle (DBF), test (DTF) functioning procedures object estimated multipleGroup(). compensatory non-compensatory statistics provided described Chalmers (2018), generally can interpreted IRT generalizations SIBTEST CSIBTEST statistics. hypothesis tests, measures require ACOV matrix computed fitted multiple-group model (otherwise, sets plausible draws posterior explicitly required).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential Response Functioning statistics — DRF","text":"","code":"DRF(   mod,   draws = NULL,   focal_items = 1L:extract.mirt(mod, \"nitems\"),   param_set = NULL,   den.type = \"marginal\",   best_fitting = FALSE,   CI = 0.95,   npts = 1000,   quadpts = NULL,   theta_lim = c(-6, 6),   Theta_nodes = NULL,   plot = FALSE,   DIF = FALSE,   DIF.cats = FALSE,   groups2test = \"all\",   pairwise = FALSE,   simplify = TRUE,   p.adjust = \"none\",   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential Response Functioning statistics — DRF","text":"mod multipleGroup object estimated 2 groups draws number indicating many draws take form suitable multiple imputation bootstrap estimate expected test scores (100 ). boot = FALSE, requires estimated parameter information matrix. Returns list containing bootstrap/imputation distribution null hypothesis test sDRF statistics focal_items character/numeric vector indicating items include DRF tests. default uses items (note including anchors focal items effect exactly equal across groups). Selecting fewer items result tests 'differential bundle functioning' param_set N x p matrix parameter values drawn posterior (e.g., using parametric sampling approach, bootstrap, MCMC). supplied, used compute DRF measures. Can much efficient pre-compute values DIF, DBF, DTF evaluated within model (especially using bootstrap method). See draw_parameters den.type character specifying density latent traits computed. Default 'marginal' include proportional information groups, 'focal' just focal group, 'reference' reference group best_fitting logical; use best fitting parametric distribution (Gaussian default) used time model estimation? result much fast computations, however results dependent upon underlying modelling assumptions. Default FALSE, uses empirical histogram approach CI range confidence interval using draws input npts number points use plotting. Default 1000 quadpts number quadrature nodes use constructing DRF statistics. Default extracted input model object theta_lim lower upper limits latent trait (theta) evaluated, used conjunction quadpts npts Theta_nodes optional matrix Theta values evaluated draws sDRF statistics. However, values averaged across, instead give bootstrap confidence intervals respective Theta nodes. Useful following large sDRF uDRF statistic, example, determine difference test curves large (still accounting sampling variability). Returns matrix observed variability plot logical; plot 'sDRF' functions evaluated sDBF sDTF values across integration grid , DIF = TRUE, selected items faceted plot individual items? plausible parameter sets obtained/supplied imputed confidence intervals included DIF logical; return list item-level imputation properties using DRF statistics? can generally used DIF detection method graphical display understanding DIF within item DIF.cats logical; DIF = TRUE, however computations performed item category probability functions rather score functions. useful understanding DIF polytomous items groups2test 2 groups investigated two groups used effect size comparisons? pairwise logical; perform pairwise computations applying multi-group settings simplify logical; attempt simplify output rather returning larger lists? p.adjust string passed p.adjust function adjust p-values. Adjustments located adj_pvals element returned list. applicable DIF = TRUE par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice verbose logical; include additional information console? ... additional arguments passed lattice","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Differential Response Functioning statistics — DRF","text":"effect sizes estimates DRF function $$sDRF = \\int [S(C|\\bm{\\Psi}^{(R)},\\theta) S(C|\\bm{\\Psi}^{(F)},\\theta)] f(\\theta)d\\theta,$$ $$uDRF = \\int |S(C|\\bm{\\Psi}^{(R)},\\theta) S(C|\\bm{\\Psi}^{(F)},\\theta)| f(\\theta)d\\theta,$$ $$dDRF = \\sqrt{\\int [S(C|\\bm{\\Psi}^{(R)},\\theta) S(C|\\bm{\\Psi}^{(F)},\\theta)]^2 f(\\theta)d\\theta}$$ \\(S(.)\\) scoring equations used evaluate model-implied difference focal reference group. \\(f(\\theta)\\) terms can either estimated posterior via empirical histogram approach (default), can use best fitting prior distribution obtain post-convergence (default Guassian distribution). Note , comparison Chalmers (2018), focal group leftmost scoring function reference group rightmost scoring function. largely keep consistent similar effect size statistics, SIBTEST, DFIT, Wainer's measures impact, etc, general can seen special-case estimators family.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential Response Functioning statistics — DRF","text":"Chalmers, R. P. (2018). Model-Based Measures Detecting Quantifying Response Bias.   Psychometrika, 83(3), 696-732. doi:10.1007/s11336-018-9626-9","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Differential Response Functioning statistics — DRF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DRF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential Response Functioning statistics — DRF","text":"","code":"# \\donttest{  set.seed(1234) n <- 30 N <- 500  # only first 5 items as anchors model <- 'F = 1-30           CONSTRAINB = (1-5, a1), (1-5, d)'  a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... plot(mod)  plot(mod, which.items = 6:10) #DBF  plot(mod, type = 'itemscore')  plot(mod, type = 'itemscore', which.items = 10:15)   # empirical histogram approach DRF(mod) #>            groups n_focal_items   sDRF  uDRF  dDRF #> 1 Group_1,Group_2            30 -0.326 0.326 0.328 DRF(mod, focal_items = 6:10) #DBF #>            groups n_focal_items   sDRF  uDRF  dDRF #> 1 Group_1,Group_2             5 -0.069 0.071 0.084 DRF(mod, DIF=TRUE) #>             groups    item   sDIF  uDIF  dDIF #> 1  Group_1,Group_2  Item_1  0.000 0.000 0.000 #> 2  Group_1,Group_2  Item_2  0.000 0.000 0.000 #> 3  Group_1,Group_2  Item_3  0.000 0.000 0.000 #> 4  Group_1,Group_2  Item_4  0.000 0.000 0.000 #> 5  Group_1,Group_2  Item_5  0.000 0.000 0.000 #> 6  Group_1,Group_2  Item_6  0.000 0.016 0.018 #> 7  Group_1,Group_2  Item_7 -0.026 0.026 0.028 #> 8  Group_1,Group_2  Item_8 -0.008 0.008 0.008 #> 9  Group_1,Group_2  Item_9 -0.026 0.026 0.028 #> 10 Group_1,Group_2 Item_10 -0.010 0.036 0.044 #> 11 Group_1,Group_2 Item_11 -0.056 0.059 0.065 #> 12 Group_1,Group_2 Item_12 -0.016 0.016 0.017 #> 13 Group_1,Group_2 Item_13 -0.015 0.022 0.025 #> 14 Group_1,Group_2 Item_14 -0.033 0.046 0.054 #> 15 Group_1,Group_2 Item_15 -0.045 0.045 0.047 #> 16 Group_1,Group_2 Item_16 -0.030 0.030 0.032 #> 17 Group_1,Group_2 Item_17  0.018 0.019 0.023 #> 18 Group_1,Group_2 Item_18  0.011 0.013 0.014 #> 19 Group_1,Group_2 Item_19 -0.045 0.094 0.117 #> 20 Group_1,Group_2 Item_20 -0.008 0.010 0.010 #> 21 Group_1,Group_2 Item_21 -0.070 0.070 0.073 #> 22 Group_1,Group_2 Item_22  0.017 0.020 0.024 #> 23 Group_1,Group_2 Item_23  0.036 0.064 0.078 #> 24 Group_1,Group_2 Item_24  0.040 0.040 0.042 #> 25 Group_1,Group_2 Item_25  0.002 0.018 0.021 #> 26 Group_1,Group_2 Item_26 -0.019 0.047 0.065 #> 27 Group_1,Group_2 Item_27 -0.049 0.049 0.052 #> 28 Group_1,Group_2 Item_28  0.027 0.029 0.031 #> 29 Group_1,Group_2 Item_29  0.007 0.025 0.029 #> 30 Group_1,Group_2 Item_30 -0.029 0.031 0.033 DRF(mod, DIF=TRUE, focal_items = 10:15) #>            groups    item   sDIF  uDIF  dDIF #> 1 Group_1,Group_2 Item_10 -0.010 0.036 0.044 #> 2 Group_1,Group_2 Item_11 -0.056 0.059 0.065 #> 3 Group_1,Group_2 Item_12 -0.016 0.016 0.017 #> 4 Group_1,Group_2 Item_13 -0.015 0.022 0.025 #> 5 Group_1,Group_2 Item_14 -0.033 0.046 0.054 #> 6 Group_1,Group_2 Item_15 -0.045 0.045 0.047  # Best-fitting Gaussian distributions DRF(mod, best_fitting=TRUE) #>            groups n_focal_items   sDRF  uDRF  dDRF #> 1 Group_1,Group_2            30 -0.326 0.326 0.328 DRF(mod, focal_items = 6:10, best_fitting=TRUE) #DBF #>            groups n_focal_items   sDRF  uDRF  dDRF #> 1 Group_1,Group_2             5 -0.069 0.071 0.084 DRF(mod, DIF=TRUE, best_fitting=TRUE) #>             groups    item   sDIF  uDIF  dDIF #> 1  Group_1,Group_2  Item_1  0.000 0.000 0.000 #> 2  Group_1,Group_2  Item_2  0.000 0.000 0.000 #> 3  Group_1,Group_2  Item_3  0.000 0.000 0.000 #> 4  Group_1,Group_2  Item_4  0.000 0.000 0.000 #> 5  Group_1,Group_2  Item_5  0.000 0.000 0.000 #> 6  Group_1,Group_2  Item_6  0.000 0.016 0.018 #> 7  Group_1,Group_2  Item_7 -0.026 0.026 0.028 #> 8  Group_1,Group_2  Item_8 -0.008 0.008 0.008 #> 9  Group_1,Group_2  Item_9 -0.026 0.026 0.028 #> 10 Group_1,Group_2 Item_10 -0.010 0.036 0.045 #> 11 Group_1,Group_2 Item_11 -0.056 0.059 0.065 #> 12 Group_1,Group_2 Item_12 -0.016 0.016 0.017 #> 13 Group_1,Group_2 Item_13 -0.015 0.023 0.025 #> 14 Group_1,Group_2 Item_14 -0.033 0.046 0.054 #> 15 Group_1,Group_2 Item_15 -0.045 0.045 0.047 #> 16 Group_1,Group_2 Item_16 -0.030 0.030 0.032 #> 17 Group_1,Group_2 Item_17  0.018 0.019 0.023 #> 18 Group_1,Group_2 Item_18  0.011 0.013 0.014 #> 19 Group_1,Group_2 Item_19 -0.045 0.094 0.118 #> 20 Group_1,Group_2 Item_20 -0.008 0.010 0.010 #> 21 Group_1,Group_2 Item_21 -0.070 0.070 0.073 #> 22 Group_1,Group_2 Item_22  0.017 0.020 0.024 #> 23 Group_1,Group_2 Item_23  0.036 0.064 0.078 #> 24 Group_1,Group_2 Item_24  0.040 0.040 0.042 #> 25 Group_1,Group_2 Item_25  0.002 0.019 0.021 #> 26 Group_1,Group_2 Item_26 -0.019 0.047 0.065 #> 27 Group_1,Group_2 Item_27 -0.049 0.049 0.052 #> 28 Group_1,Group_2 Item_28  0.027 0.029 0.031 #> 29 Group_1,Group_2 Item_29  0.007 0.025 0.028 #> 30 Group_1,Group_2 Item_30 -0.029 0.031 0.033 DRF(mod, DIF=TRUE, focal_items = 10:15, best_fitting=TRUE) #>            groups    item   sDIF  uDIF  dDIF #> 1 Group_1,Group_2 Item_10 -0.010 0.036 0.045 #> 2 Group_1,Group_2 Item_11 -0.056 0.059 0.065 #> 3 Group_1,Group_2 Item_12 -0.016 0.016 0.017 #> 4 Group_1,Group_2 Item_13 -0.015 0.023 0.025 #> 5 Group_1,Group_2 Item_14 -0.033 0.046 0.054 #> 6 Group_1,Group_2 Item_15 -0.045 0.045 0.047  DRF(mod, plot = TRUE)  DRF(mod, focal_items = 6:10, plot = TRUE) #DBF  DRF(mod, DIF=TRUE, plot = TRUE)  DRF(mod, DIF=TRUE, focal_items = 10:15, plot = TRUE)   if(interactive()) mirtCluster() DRF(mod, draws = 500) #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2            30 -0.326 -0.957   0.360 0.982  1 0.322 #> uDRF Group_1,Group_2            30  0.326  0.102   0.957 2.642  2 0.267 #> dDRF Group_1,Group_2            30  0.328  0.125   1.044                DRF(mod, draws = 500, best_fitting=TRUE) #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2            30 -0.326 -0.977   0.339 0.939  1 0.333 #> uDRF Group_1,Group_2            30  0.326  0.095   0.977 2.613  2 0.271 #> dDRF Group_1,Group_2            30  0.328  0.108   1.086                DRF(mod, draws = 500, plot=TRUE)   # pre-draw parameter set to save computations #  (more useful when using non-parametric bootstrap) param_set <- draw_parameters(mod, draws = 500) DRF(mod, focal_items = 6, param_set=param_set) #DIF test #>               groups n_focal_items  stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2             1 0.000 -0.058   0.066     0  1 0.998 #> uDRF Group_1,Group_2             1 0.016  0.007   0.085 0.766  2 0.682 #> dDRF Group_1,Group_2             1 0.018  0.008   0.098                DRF(mod, DIF=TRUE, param_set=param_set) #DIF test #> $sDIF #>             groups    item   sDIF CI_2.5 CI_97.5    X2 df     p #> 1  Group_1,Group_2  Item_1  0.000  0.000   0.000                #> 2  Group_1,Group_2  Item_2  0.000  0.000   0.000                #> 3  Group_1,Group_2  Item_3  0.000  0.000   0.000                #> 4  Group_1,Group_2  Item_4  0.000  0.000   0.000                #> 5  Group_1,Group_2  Item_5  0.000  0.000   0.000                #> 6  Group_1,Group_2  Item_6  0.000 -0.058   0.066     0  1 0.998 #> 7  Group_1,Group_2  Item_7 -0.026 -0.087   0.040 0.653  1 0.419 #> 8  Group_1,Group_2  Item_8 -0.008 -0.060   0.058 0.065  1 0.798 #> 9  Group_1,Group_2  Item_9 -0.026 -0.091   0.031 0.648  1 0.421 #> 10 Group_1,Group_2 Item_10 -0.010 -0.072   0.048 0.101  1 0.751 #> 11 Group_1,Group_2 Item_11 -0.056 -0.116   0.003 3.556  1 0.059 #> 12 Group_1,Group_2 Item_12 -0.016 -0.074   0.038 0.305  1 0.581 #> 13 Group_1,Group_2 Item_13 -0.015 -0.075   0.042 0.233  1 0.629 #> 14 Group_1,Group_2 Item_14 -0.033 -0.096   0.027 1.029  1  0.31 #> 15 Group_1,Group_2 Item_15 -0.045 -0.103   0.012 2.479  1 0.115 #> 16 Group_1,Group_2 Item_16 -0.030 -0.098   0.036 0.882  1 0.348 #> 17 Group_1,Group_2 Item_17  0.018 -0.042   0.079  0.31  1 0.578 #> 18 Group_1,Group_2 Item_18  0.011 -0.051   0.072 0.126  1 0.723 #> 19 Group_1,Group_2 Item_19 -0.045 -0.103   0.011 2.292  1  0.13 #> 20 Group_1,Group_2 Item_20 -0.008 -0.045   0.034  0.16  1 0.689 #> 21 Group_1,Group_2 Item_21 -0.070 -0.133  -0.006 4.678  1 0.031 #> 22 Group_1,Group_2 Item_22  0.017 -0.048   0.071 0.312  1 0.576 #> 23 Group_1,Group_2 Item_23  0.036 -0.031   0.098 1.292  1 0.256 #> 24 Group_1,Group_2 Item_24  0.040 -0.021   0.097 1.787  1 0.181 #> 25 Group_1,Group_2 Item_25  0.002 -0.062   0.061 0.004  1 0.949 #> 26 Group_1,Group_2 Item_26 -0.019 -0.075   0.037  0.47  1 0.493 #> 27 Group_1,Group_2 Item_27 -0.049 -0.111   0.014 2.298  1  0.13 #> 28 Group_1,Group_2 Item_28  0.027 -0.036   0.090 0.681  1 0.409 #> 29 Group_1,Group_2 Item_29  0.007 -0.057   0.073  0.05  1 0.823 #> 30 Group_1,Group_2 Item_30 -0.029 -0.092   0.022 1.001  1 0.317 #>  #> $uDIF #>             groups    item  uDIF CI_2.5 CI_97.5     X2 df     p #> 1  Group_1,Group_2  Item_1 0.000  0.000   0.000                 #> 2  Group_1,Group_2  Item_2 0.000  0.000   0.000                 #> 3  Group_1,Group_2  Item_3 0.000  0.000   0.000                 #> 4  Group_1,Group_2  Item_4 0.000  0.000   0.000                 #> 5  Group_1,Group_2  Item_5 0.000  0.000   0.000                 #> 6  Group_1,Group_2  Item_6 0.016  0.007   0.085  0.766  2 0.682 #> 7  Group_1,Group_2  Item_7 0.026  0.008   0.090  1.944  2 0.378 #> 8  Group_1,Group_2  Item_8 0.008  0.005   0.073  0.225  2 0.894 #> 9  Group_1,Group_2  Item_9 0.026  0.009   0.093  2.093  2 0.351 #> 10 Group_1,Group_2 Item_10 0.036  0.008   0.107  3.278  2 0.194 #> 11 Group_1,Group_2 Item_11 0.059  0.015   0.113 10.148  2 0.006 #> 12 Group_1,Group_2 Item_12 0.016  0.005   0.074  0.848  2 0.654 #> 13 Group_1,Group_2 Item_13 0.022  0.007   0.084  1.691  2 0.429 #> 14 Group_1,Group_2 Item_14 0.046  0.012   0.108  5.685  2 0.058 #> 15 Group_1,Group_2 Item_15 0.045  0.013   0.103  6.042  2 0.049 #> 16 Group_1,Group_2 Item_16 0.030  0.008   0.100  2.552  2 0.279 #> 17 Group_1,Group_2 Item_17 0.019  0.006   0.087  0.994  2 0.608 #> 18 Group_1,Group_2 Item_18 0.013  0.005   0.081  0.397  2  0.82 #> 19 Group_1,Group_2 Item_19 0.094  0.046   0.145 24.256  2     0 #> 20 Group_1,Group_2 Item_20 0.010  0.004   0.051  0.567  2 0.753 #> 21 Group_1,Group_2 Item_21 0.070  0.016   0.132 10.312  2 0.006 #> 22 Group_1,Group_2 Item_22 0.020  0.007   0.087  1.065  2 0.587 #> 23 Group_1,Group_2 Item_23 0.064  0.022   0.119  8.046  2 0.018 #> 24 Group_1,Group_2 Item_24 0.040  0.011   0.100  2.796  2 0.247 #> 25 Group_1,Group_2 Item_25 0.018  0.009   0.094  0.867  2 0.648 #> 26 Group_1,Group_2 Item_26 0.047  0.012   0.098   6.43  2  0.04 #> 27 Group_1,Group_2 Item_27 0.049  0.010   0.111  5.454  2 0.065 #> 28 Group_1,Group_2 Item_28 0.029  0.008   0.098  1.636  2 0.441 #> 29 Group_1,Group_2 Item_29 0.025  0.008   0.086  1.643  2  0.44 #> 30 Group_1,Group_2 Item_30 0.031  0.010   0.094  3.233  2 0.199 #>  #> $dDIF #>             groups    item  dDIF CI_2.5 CI_97.5 #> 1  Group_1,Group_2  Item_1 0.000  0.000   0.000 #> 2  Group_1,Group_2  Item_2 0.000  0.000   0.000 #> 3  Group_1,Group_2  Item_3 0.000  0.000   0.000 #> 4  Group_1,Group_2  Item_4 0.000  0.000   0.000 #> 5  Group_1,Group_2  Item_5 0.000  0.000   0.000 #> 6  Group_1,Group_2  Item_6 0.018  0.008   0.098 #> 7  Group_1,Group_2  Item_7 0.028  0.009   0.101 #> 8  Group_1,Group_2  Item_8 0.008  0.006   0.084 #> 9  Group_1,Group_2  Item_9 0.028  0.011   0.102 #> 10 Group_1,Group_2 Item_10 0.044  0.010   0.127 #> 11 Group_1,Group_2 Item_11 0.065  0.015   0.123 #> 12 Group_1,Group_2 Item_12 0.017  0.007   0.091 #> 13 Group_1,Group_2 Item_13 0.025  0.009   0.094 #> 14 Group_1,Group_2 Item_14 0.054  0.014   0.124 #> 15 Group_1,Group_2 Item_15 0.047  0.015   0.112 #> 16 Group_1,Group_2 Item_16 0.032  0.009   0.109 #> 17 Group_1,Group_2 Item_17 0.023  0.007   0.101 #> 18 Group_1,Group_2 Item_18 0.014  0.006   0.091 #> 19 Group_1,Group_2 Item_19 0.117  0.058   0.179 #> 20 Group_1,Group_2 Item_20 0.010  0.005   0.079 #> 21 Group_1,Group_2 Item_21 0.073  0.017   0.140 #> 22 Group_1,Group_2 Item_22 0.024  0.008   0.097 #> 23 Group_1,Group_2 Item_23 0.078  0.025   0.140 #> 24 Group_1,Group_2 Item_24 0.042  0.012   0.108 #> 25 Group_1,Group_2 Item_25 0.021  0.010   0.102 #> 26 Group_1,Group_2 Item_26 0.065  0.015   0.130 #> 27 Group_1,Group_2 Item_27 0.052  0.012   0.122 #> 28 Group_1,Group_2 Item_28 0.031  0.010   0.106 #> 29 Group_1,Group_2 Item_29 0.029  0.009   0.096 #> 30 Group_1,Group_2 Item_30 0.033  0.011   0.100 #>  DRF(mod, focal_items = 6:10, param_set=param_set) #DBF test #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2             5 -0.069 -0.242   0.119 0.569  1 0.451 #> uDRF Group_1,Group_2             5  0.071  0.018   0.249 2.027  2 0.363 #> dDRF Group_1,Group_2             5  0.084  0.023   0.285                DRF(mod, param_set=param_set) #DTF test #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2            30 -0.326 -1.036   0.404 0.876  1 0.349 #> uDRF Group_1,Group_2            30  0.326  0.099   1.047 2.482  2 0.289 #> dDRF Group_1,Group_2            30  0.328  0.128   1.130                 DRF(mod, focal_items = 6:10, draws=500) #DBF test #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2             5 -0.069 -0.239   0.094 0.658  1 0.417 #> uDRF Group_1,Group_2             5  0.071  0.020   0.254 2.142  2 0.343 #> dDRF Group_1,Group_2             5  0.084  0.023   0.295                DRF(mod, focal_items = 10:15, draws=500) #DBF test #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2             6 -0.175 -0.382   0.024 2.989  1 0.084 #> uDRF Group_1,Group_2             6  0.175  0.047   0.392 7.228  2 0.027 #> dDRF Group_1,Group_2             6  0.185  0.054   0.415                 DIFs <- DRF(mod, draws = 500, DIF=TRUE) print(DIFs) #> $sDIF #>             groups    item   sDIF CI_2.5 CI_97.5    X2 df     p #> 1  Group_1,Group_2  Item_1  0.000  0.000   0.000                #> 2  Group_1,Group_2  Item_2  0.000  0.000   0.000                #> 3  Group_1,Group_2  Item_3  0.000  0.000   0.000                #> 4  Group_1,Group_2  Item_4  0.000  0.000   0.000                #> 5  Group_1,Group_2  Item_5  0.000  0.000   0.000                #> 6  Group_1,Group_2  Item_6  0.000 -0.058   0.062     0  1 0.998 #> 7  Group_1,Group_2  Item_7 -0.026 -0.087   0.035 0.717  1 0.397 #> 8  Group_1,Group_2  Item_8 -0.008 -0.074   0.053 0.058  1 0.809 #> 9  Group_1,Group_2  Item_9 -0.026 -0.084   0.044 0.717  1 0.397 #> 10 Group_1,Group_2 Item_10 -0.010 -0.063   0.041 0.119  1  0.73 #> 11 Group_1,Group_2 Item_11 -0.056 -0.118   0.003 3.205  1 0.073 #> 12 Group_1,Group_2 Item_12 -0.016 -0.078   0.041 0.288  1 0.591 #> 13 Group_1,Group_2 Item_13 -0.015 -0.073   0.042 0.261  1 0.609 #> 14 Group_1,Group_2 Item_14 -0.033 -0.097   0.036 1.077  1 0.299 #> 15 Group_1,Group_2 Item_15 -0.045 -0.101   0.013 2.454  1 0.117 #> 16 Group_1,Group_2 Item_16 -0.030 -0.096   0.033 0.869  1 0.351 #> 17 Group_1,Group_2 Item_17  0.018 -0.041   0.076 0.317  1 0.573 #> 18 Group_1,Group_2 Item_18  0.011 -0.051   0.068 0.131  1 0.717 #> 19 Group_1,Group_2 Item_19 -0.045 -0.105   0.012 2.273  1 0.132 #> 20 Group_1,Group_2 Item_20 -0.008 -0.044   0.039  0.15  1 0.699 #> 21 Group_1,Group_2 Item_21 -0.070 -0.128  -0.007 5.598  1 0.018 #> 22 Group_1,Group_2 Item_22  0.017 -0.044   0.084 0.294  1 0.588 #> 23 Group_1,Group_2 Item_23  0.036 -0.027   0.100 1.299  1 0.254 #> 24 Group_1,Group_2 Item_24  0.040 -0.026   0.112 1.451  1 0.228 #> 25 Group_1,Group_2 Item_25  0.002 -0.064   0.061 0.004  1 0.948 #> 26 Group_1,Group_2 Item_26 -0.019 -0.069   0.032 0.457  1 0.499 #> 27 Group_1,Group_2 Item_27 -0.049 -0.108   0.015 2.687  1 0.101 #> 28 Group_1,Group_2 Item_28  0.027 -0.028   0.087 0.835  1 0.361 #> 29 Group_1,Group_2 Item_29  0.007 -0.058   0.072 0.053  1 0.819 #> 30 Group_1,Group_2 Item_30 -0.029 -0.088   0.029 0.946  1 0.331 #>  #> $uDIF #>             groups    item  uDIF CI_2.5 CI_97.5     X2 df     p #> 1  Group_1,Group_2  Item_1 0.000  0.000   0.000                 #> 2  Group_1,Group_2  Item_2 0.000  0.000   0.000                 #> 3  Group_1,Group_2  Item_3 0.000  0.000   0.000                 #> 4  Group_1,Group_2  Item_4 0.000  0.000   0.000                 #> 5  Group_1,Group_2  Item_5 0.000  0.000   0.000                 #> 6  Group_1,Group_2  Item_6 0.016  0.005   0.083  0.761  2 0.684 #> 7  Group_1,Group_2  Item_7 0.026  0.007   0.087  2.145  2 0.342 #> 8  Group_1,Group_2  Item_8 0.008  0.007   0.083  0.189  2  0.91 #> 9  Group_1,Group_2  Item_9 0.026  0.009   0.090  2.362  2 0.307 #> 10 Group_1,Group_2 Item_10 0.036  0.008   0.094  3.754  2 0.153 #> 11 Group_1,Group_2 Item_11 0.059  0.018   0.119  9.247  2  0.01 #> 12 Group_1,Group_2 Item_12 0.016  0.008   0.081  0.891  2  0.64 #> 13 Group_1,Group_2 Item_13 0.022  0.007   0.079  1.965  2 0.374 #> 14 Group_1,Group_2 Item_14 0.046  0.011   0.109  5.687  2 0.058 #> 15 Group_1,Group_2 Item_15 0.045  0.012   0.101  5.996  2  0.05 #> 16 Group_1,Group_2 Item_16 0.030  0.008   0.096  2.457  2 0.293 #> 17 Group_1,Group_2 Item_17 0.019  0.007   0.084  1.061  2 0.588 #> 18 Group_1,Group_2 Item_18 0.013  0.007   0.078  0.439  2 0.803 #> 19 Group_1,Group_2 Item_19 0.094  0.047   0.148 22.425  2     0 #> 20 Group_1,Group_2 Item_20 0.010  0.004   0.053  0.533  2 0.766 #> 21 Group_1,Group_2 Item_21 0.070  0.022   0.129 12.429  2 0.002 #> 22 Group_1,Group_2 Item_22 0.020  0.006   0.089  1.017  2 0.601 #> 23 Group_1,Group_2 Item_23 0.064  0.018   0.121  7.167  2 0.028 #> 24 Group_1,Group_2 Item_24 0.040  0.008   0.112  2.247  2 0.325 #> 25 Group_1,Group_2 Item_25 0.018  0.006   0.086  0.917  2 0.632 #> 26 Group_1,Group_2 Item_26 0.047  0.013   0.096  6.621  2 0.036 #> 27 Group_1,Group_2 Item_27 0.049  0.013   0.108  6.466  2 0.039 #> 28 Group_1,Group_2 Item_28 0.029  0.010   0.088  1.805  2 0.405 #> 29 Group_1,Group_2 Item_29 0.025  0.009   0.085  1.808  2 0.405 #> 30 Group_1,Group_2 Item_30 0.031  0.008   0.093  3.105  2 0.212 #>  #> $dDIF #>             groups    item  dDIF CI_2.5 CI_97.5 #> 1  Group_1,Group_2  Item_1 0.000  0.000   0.000 #> 2  Group_1,Group_2  Item_2 0.000  0.000   0.000 #> 3  Group_1,Group_2  Item_3 0.000  0.000   0.000 #> 4  Group_1,Group_2  Item_4 0.000  0.000   0.000 #> 5  Group_1,Group_2  Item_5 0.000  0.000   0.000 #> 6  Group_1,Group_2  Item_6 0.018  0.006   0.092 #> 7  Group_1,Group_2  Item_7 0.028  0.008   0.095 #> 8  Group_1,Group_2  Item_8 0.008  0.007   0.094 #> 9  Group_1,Group_2  Item_9 0.028  0.011   0.097 #> 10 Group_1,Group_2 Item_10 0.044  0.010   0.114 #> 11 Group_1,Group_2 Item_11 0.065  0.020   0.131 #> 12 Group_1,Group_2 Item_12 0.017  0.009   0.088 #> 13 Group_1,Group_2 Item_13 0.025  0.008   0.088 #> 14 Group_1,Group_2 Item_14 0.054  0.013   0.126 #> 15 Group_1,Group_2 Item_15 0.047  0.014   0.111 #> 16 Group_1,Group_2 Item_16 0.032  0.009   0.103 #> 17 Group_1,Group_2 Item_17 0.023  0.008   0.096 #> 18 Group_1,Group_2 Item_18 0.014  0.008   0.091 #> 19 Group_1,Group_2 Item_19 0.117  0.056   0.183 #> 20 Group_1,Group_2 Item_20 0.010  0.006   0.079 #> 21 Group_1,Group_2 Item_21 0.073  0.025   0.138 #> 22 Group_1,Group_2 Item_22 0.024  0.007   0.099 #> 23 Group_1,Group_2 Item_23 0.078  0.019   0.144 #> 24 Group_1,Group_2 Item_24 0.042  0.009   0.118 #> 25 Group_1,Group_2 Item_25 0.021  0.007   0.104 #> 26 Group_1,Group_2 Item_26 0.065  0.017   0.135 #> 27 Group_1,Group_2 Item_27 0.052  0.014   0.118 #> 28 Group_1,Group_2 Item_28 0.031  0.011   0.099 #> 29 Group_1,Group_2 Item_29 0.029  0.010   0.095 #> 30 Group_1,Group_2 Item_30 0.033  0.009   0.101 #>  DRF(mod, draws = 500, DIF=TRUE, plot=TRUE)   DIFs <- DRF(mod, draws = 500, DIF=TRUE, focal_items = 6:10) print(DIFs) #> $sDIF #>            groups    item   sDIF CI_2.5 CI_97.5    X2 df     p #> 1 Group_1,Group_2  Item_6  0.000 -0.066   0.064     0  1 0.998 #> 2 Group_1,Group_2  Item_7 -0.026 -0.083   0.040 0.696  1 0.404 #> 3 Group_1,Group_2  Item_8 -0.008 -0.074   0.045 0.062  1 0.804 #> 4 Group_1,Group_2  Item_9 -0.026 -0.089   0.037 0.739  1  0.39 #> 5 Group_1,Group_2 Item_10 -0.010 -0.070   0.045 0.113  1 0.737 #>  #> $uDIF #>            groups    item  uDIF CI_2.5 CI_97.5    X2 df     p #> 1 Group_1,Group_2  Item_6 0.016  0.006   0.081 0.786  2 0.675 #> 2 Group_1,Group_2  Item_7 0.026  0.007   0.090 2.051  2 0.359 #> 3 Group_1,Group_2  Item_8 0.008  0.007   0.080 0.215  2 0.898 #> 4 Group_1,Group_2  Item_9 0.026  0.007   0.089 2.358  2 0.308 #> 5 Group_1,Group_2 Item_10 0.036  0.008   0.093  3.28  2 0.194 #>  #> $dDIF #>            groups    item  dDIF CI_2.5 CI_97.5 #> 1 Group_1,Group_2  Item_6 0.018  0.007   0.092 #> 2 Group_1,Group_2  Item_7 0.028  0.008   0.100 #> 3 Group_1,Group_2  Item_8 0.008  0.008   0.090 #> 4 Group_1,Group_2  Item_9 0.028  0.009   0.096 #> 5 Group_1,Group_2 Item_10 0.044  0.009   0.121 #>  DRF(mod, draws = 500, DIF=TRUE, focal_items = 6:10, plot = TRUE)   DRF(mod, DIF=TRUE, focal_items = 6) #>            groups   item sDIF  uDIF  dDIF #> 1 Group_1,Group_2 Item_6    0 0.016 0.018 DRF(mod, draws=500, DIF=TRUE, focal_items = 6) #> $sDIF #>            groups   item sDIF CI_2.5 CI_97.5 X2 df     p #> 1 Group_1,Group_2 Item_6    0 -0.059   0.058  0  1 0.998 #>  #> $uDIF #>            groups   item  uDIF CI_2.5 CI_97.5    X2 df     p #> 1 Group_1,Group_2 Item_6 0.016  0.006   0.076 0.823  2 0.663 #>  #> $dDIF #>            groups   item  dDIF CI_2.5 CI_97.5 #> 1 Group_1,Group_2 Item_6 0.018  0.006   0.088 #>   # evaluate specific values for sDRF Theta_nodes <- matrix(seq(-6,6,length.out = 100))  sDTF <- DRF(mod, Theta_nodes=Theta_nodes) head(sDTF) #>         Theta  sDRF #> sDRF.1 -6.000 0.006 #> sDRF.2 -5.879 0.006 #> sDRF.3 -5.758 0.006 #> sDRF.4 -5.636 0.007 #> sDRF.5 -5.515 0.007 #> sDRF.6 -5.394 0.008 sDTF <- DRF(mod, Theta_nodes=Theta_nodes, draws=200) head(sDTF) #>         Theta  sDRF CI_2.5 CI_97.5 #> sDRF.1 -6.000 0.006 -0.076   0.185 #> sDRF.2 -5.879 0.006 -0.083   0.199 #> sDRF.3 -5.758 0.006 -0.090   0.214 #> sDRF.4 -5.636 0.007 -0.098   0.230 #> sDRF.5 -5.515 0.007 -0.107   0.242 #> sDRF.6 -5.394 0.008 -0.117   0.256  # sDIF (isolate single item) sDIF <- DRF(mod, Theta_nodes=Theta_nodes, focal_items=6) head(sDIF) #>         Theta  sDRF #> sDRF.1 -6.000 0.001 #> sDRF.2 -5.879 0.001 #> sDRF.3 -5.758 0.001 #> sDRF.4 -5.636 0.002 #> sDRF.5 -5.515 0.002 #> sDRF.6 -5.394 0.002 sDIF <- DRF(mod, Theta_nodes=Theta_nodes, focal_items = 6, draws=200) head(sDIF) #>         Theta  sDRF CI_2.5 CI_97.5 #> sDRF.1 -6.000 0.001 -0.005   0.013 #> sDRF.2 -5.879 0.001 -0.005   0.014 #> sDRF.3 -5.758 0.001 -0.006   0.015 #> sDRF.4 -5.636 0.002 -0.006   0.017 #> sDRF.5 -5.515 0.002 -0.007   0.018 #> sDRF.6 -5.394 0.002 -0.008   0.020  ## ------------- ## random slopes and intercepts for 15 items, and latent mean difference ##    (no systematic DTF should exist, but DIF will be present) set.seed(1234) dat1 <- simdata(a, d, N, itemtype = 'dich', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 0, .25)),                 d + c(numeric(15), rnorm(n-15, 0, .5)), N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod1 <- multipleGroup(dat, 1, group=group) #>  plot(mod1)  DRF(mod1) #does not account for group differences! Need anchors #> No hyper-parameters were estimated in the DIF model. For effective #>                 \tDRF testing freeing the focal group hyper-parameters is recommended. #>            groups n_focal_items  sDRF  uDRF  dDRF #> 1 Group_1,Group_2            30 -3.25 3.268 3.642  mod2 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... plot(mod2)   # significant DIF in multiple items.... # DIF(mod2, which.par=c('a1', 'd'), items2test=16:30) DRF(mod2) #>            groups n_focal_items   sDRF  uDRF dDRF #> 1 Group_1,Group_2            30 -0.421 0.421 0.51 DRF(mod2, draws=500) #non-sig DTF due to item cancellation #>               groups n_focal_items   stat CI_2.5 CI_97.5    X2 df     p #> sDRF Group_1,Group_2            30 -0.421 -1.085   0.273 1.529  1 0.216 #> uDRF Group_1,Group_2            30  0.421  0.135   1.093 4.801  2 0.091 #> dDRF Group_1,Group_2            30  0.510  0.188   1.244                 ## ------------- ## systematic differing slopes and intercepts (clear DTF) set.seed(1234) dat1 <- simdata(a, d, N, itemtype = 'dich', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)),                 d + c(numeric(15), rnorm(n-15, 1, .5)),                 N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod3 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... plot(mod3) #visable DTF happening   # DIF(mod3, c('a1', 'd'), items2test=16:30) DRF(mod3) #unsigned bias. Signed bias (group 2 scores higher on average) #>            groups n_focal_items  sDRF  uDRF  dDRF #> 1 Group_1,Group_2            30 1.983 2.193 2.471 DRF(mod3, draws=500) #>               groups n_focal_items  stat CI_2.5 CI_97.5     X2 df p #> sDRF Group_1,Group_2            30 1.983  1.275   2.659 29.992  1 0 #> uDRF Group_1,Group_2            30 2.193  1.638   2.836 54.336  2 0 #> dDRF Group_1,Group_2            30 2.471  1.856   3.172             DRF(mod3, draws=500, plot=TRUE) #multiple DRF areas along Theta   # plot the DIF DRF(mod3, draws=500, DIF=TRUE, plot=TRUE)   # evaluate specific values for sDRF Theta_nodes <- matrix(seq(-6,6,length.out = 100)) sDTF <- DRF(mod3, Theta_nodes=Theta_nodes, draws=200) head(sDTF) #>         Theta   sDRF CI_2.5 CI_97.5 #> sDRF.1 -6.000 -0.012 -0.087   0.010 #> sDRF.2 -5.879 -0.014 -0.098   0.010 #> sDRF.3 -5.758 -0.016 -0.109   0.010 #> sDRF.4 -5.636 -0.019 -0.122   0.011 #> sDRF.5 -5.515 -0.022 -0.136   0.012 #> sDRF.6 -5.394 -0.026 -0.151   0.013  # DIF sDIF <- DRF(mod3, Theta_nodes=Theta_nodes, focal_items = 30, draws=200) head(sDIF) #>         Theta   sDRF CI_2.5 CI_97.5 #> sDRF.1 -6.000  0.000 -0.001       0 #> sDRF.2 -5.879  0.000 -0.002       0 #> sDRF.3 -5.758  0.000 -0.002       0 #> sDRF.4 -5.636  0.000 -0.002       0 #> sDRF.5 -5.515  0.000 -0.002       0 #> sDRF.6 -5.394 -0.001 -0.003       0  ## ---------------------------------------------------------------- # polytomous example # simulate data where group 2 has a different slopes/intercepts set.seed(4321) a1 <- a2 <- matrix(rlnorm(20,.2,.3)) a2[c(16:17, 19:20),] <- a1[c(16:17, 19:20),] + c(-.5, -.25, .25, .5)  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d1 <- d2 <- diffs + rnorm(20) rownames(d1) <- rownames(d2) <- paste0('Item.', 1:20) d2[16:20,] <- d1[16:20,] + matrix(c(-.5, -.5, -.5, -.5,                                     1, 0, 0, -1,                                     .5, .5, -.5, -.5,                                     1, .5, 0, -1,                                     .5, .5, .5, .5), byrow=TRUE, nrow=5)  tail(data.frame(a.group1 = a1, a.group2 = a2), 6) #>     a.group1  a.group2 #> 15 0.8465935 0.8465935 #> 16 1.9581395 1.4581395 #> 17 1.2486255 0.9986255 #> 18 0.8585293 0.8585293 #> 19 0.7584499 1.0084499 #> 20 0.9760766 1.4760766 list(d.group1 = d1[15:20,], d.group2 = d2[15:20,]) #> $d.group1 #>              [,1]       [,2]        [,3]          [,4] #> Item.15 2.0841033  1.2423287  0.38217647 -0.0009005437 #> Item.16 0.2454193 -0.2924192 -0.63521843 -1.5254133343 #> Item.17 1.3003614  0.5847340 -0.09046573 -0.9841542611 #> Item.18 1.5079114  0.6489106 -0.03799347 -0.3892116221 #> Item.19 1.3766077  0.4483499 -0.20715833 -0.8701328534 #> Item.20 0.1461006 -0.8364834 -1.32963653 -1.6894534436 #>  #> $d.group2 #>               [,1]       [,2]        [,3]          [,4] #> Item.15  2.0841033  1.2423287  0.38217647 -0.0009005437 #> Item.16 -0.2545807 -0.7924192 -1.13521843 -2.0254133343 #> Item.17  2.3003614  0.5847340 -0.09046573 -1.9841542611 #> Item.18  2.0079114  1.1489106 -0.53799347 -0.8892116221 #> Item.19  2.3766077  0.9483499 -0.20715833 -1.8701328534 #> Item.20  0.6461006 -0.3364834 -0.82963653 -1.1894534436 #>   itemtype <- rep('graded', nrow(a1)) N <- 600 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = -.25, sigma = matrix(1.25)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  # item 1-10 as anchors mod <- multipleGroup(dat, group=group, SE=TRUE,                      invariance=c(colnames(dat)[1:10], 'free_means', 'free_var')) #>  #>  #> Calculating information matrix... coef(mod, simplify=TRUE) #> $D1 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  1.194  0.911  0.177 -0.462 -1.105 #> Item_2  1.320  0.787  0.362 -0.152 -0.951 #> Item_3  1.561  0.794  0.013 -0.973 -1.774 #> Item_4  1.491  1.977  1.304  0.284 -0.236 #> Item_5  1.249  1.435  0.351 -0.329 -1.273 #> Item_6  2.071  0.517  0.072 -0.564 -1.551 #> Item_7  1.333  0.157 -0.374 -0.848 -1.911 #> Item_8  1.304  1.117  0.512 -0.467 -0.868 #> Item_9  1.830  1.501  0.639 -0.176 -0.906 #> Item_10 1.073  1.485  0.567 -0.190 -0.812 #> Item_11 1.327  2.039  1.529  0.756 -0.283 #> Item_12 1.481 -0.268 -1.021 -1.534 -2.229 #> Item_13 0.812  0.641  0.086 -0.832 -1.977 #> Item_14 1.713  1.850  1.191  0.511 -0.262 #> Item_15 0.913  2.168  1.401  0.468  0.058 #> Item_16 2.245  0.286 -0.345 -0.728 -1.687 #> Item_17 1.233  1.357  0.673  0.057 -0.916 #> Item_18 0.983  1.515  0.625 -0.171 -0.564 #> Item_19 0.946  1.415  0.521 -0.227 -0.966 #> Item_20 0.847  0.181 -0.828 -1.245 -1.624 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  1.194  0.911  0.177 -0.462 -1.105 #> Item_2  1.320  0.787  0.362 -0.152 -0.951 #> Item_3  1.561  0.794  0.013 -0.973 -1.774 #> Item_4  1.491  1.977  1.304  0.284 -0.236 #> Item_5  1.249  1.435  0.351 -0.329 -1.273 #> Item_6  2.071  0.517  0.072 -0.564 -1.551 #> Item_7  1.333  0.157 -0.374 -0.848 -1.911 #> Item_8  1.304  1.117  0.512 -0.467 -0.868 #> Item_9  1.830  1.501  0.639 -0.176 -0.906 #> Item_10 1.073  1.485  0.567 -0.190 -0.812 #> Item_11 1.106  1.818  1.282  0.635 -0.498 #> Item_12 1.562 -0.249 -0.917 -1.667 -2.266 #> Item_13 0.853  0.595 -0.044 -1.057 -1.890 #> Item_14 2.147  2.155  1.311  0.566 -0.248 #> Item_15 0.889  2.101  1.164  0.343 -0.010 #> Item_16 1.622 -0.395 -0.979 -1.278 -2.255 #> Item_17 1.060  2.345  0.587 -0.113 -2.040 #> Item_18 0.923  1.860  1.099 -0.508 -0.793 #> Item_19 1.051  2.528  0.960 -0.227 -1.976 #> Item_20 1.456  0.690 -0.277 -0.806 -1.164 #>  #> $means #>     F1  #> -0.303  #>  #> $cov #>       F1 #> F1 1.147 #>  #>  plot(mod)  plot(mod, type='itemscore')   # DIF tests vis Wald method DIF(mod, items2test=11:20,    which.par=c('a1', paste0('d', 1:4)),    Wald=TRUE, p.adjust='holm') #>         groups       W df     p adj_p #> Item_11  D1,D2   5.854  5 0.321     1 #> Item_12  D1,D2   4.808  5  0.44     1 #> Item_13  D1,D2   6.854  5 0.232     1 #> Item_14  D1,D2   4.854  5 0.434     1 #> Item_15  D1,D2   3.861  5  0.57     1 #> Item_16  D1,D2  35.918  5     0     0 #> Item_17  D1,D2 121.671  5     0     0 #> Item_18  D1,D2  45.135  5     0     0 #> Item_19  D1,D2  96.182  5     0     0 #> Item_20  D1,D2  32.769  5     0     0  DRF(mod) #>   groups n_focal_items   sDRF  uDRF  dDRF #> 1  D1,D2            20 -0.195 0.329 0.382 DRF(mod, DIF=TRUE, focal_items=11:20) #>    groups    item   sDIF  uDIF  dDIF #> 1   D1,D2 Item_11 -0.080 0.119 0.131 #> 2   D1,D2 Item_12  0.011 0.024 0.031 #> 3   D1,D2 Item_13 -0.068 0.069 0.072 #> 4   D1,D2 Item_14 -0.010 0.121 0.134 #> 5   D1,D2 Item_15 -0.083 0.083 0.085 #> 6   D1,D2 Item_16 -0.393 0.402 0.522 #> 7   D1,D2 Item_17 -0.053 0.219 0.248 #> 8   D1,D2 Item_18  0.038 0.093 0.110 #> 9   D1,D2 Item_19  0.073 0.104 0.122 #> 10  D1,D2 Item_20  0.370 0.425 0.542 DRF(mod, DIF.cats=TRUE, focal_items=11:20) #>    groups    item cat   sDIF  uDIF  dDIF #> 1   D1,D2 Item_11   1  0.009 0.021 0.024 #> 2   D1,D2 Item_11   2  0.012 0.012 0.012 #> 3   D1,D2 Item_11   3 -0.010 0.015 0.018 #> 4   D1,D2 Item_11   4  0.032 0.032 0.034 #> 5   D1,D2 Item_11   5 -0.041 0.045 0.056 #> 6   D1,D2 Item_12   1 -0.004 0.008 0.010 #> 7   D1,D2 Item_12   2 -0.015 0.015 0.017 #> 8   D1,D2 Item_12   3  0.031 0.031 0.036 #> 9   D1,D2 Item_12   4 -0.013 0.013 0.015 #> 10  D1,D2 Item_12   5  0.001 0.005 0.008 #> 11  D1,D2 Item_13   1  0.012 0.012 0.015 #> 12  D1,D2 Item_13   2  0.017 0.017 0.018 #> 13  D1,D2 Item_13   3  0.010 0.013 0.016 #> 14  D1,D2 Item_13   4 -0.050 0.050 0.053 #> 15  D1,D2 Item_13   5  0.011 0.011 0.016 #> 16  D1,D2 Item_14   1 -0.002 0.028 0.034 #> 17  D1,D2 Item_14   2  0.011 0.018 0.023 #> 18  D1,D2 Item_14   3 -0.004 0.012 0.013 #> 19  D1,D2 Item_14   4 -0.010 0.013 0.015 #> 20  D1,D2 Item_14   5  0.004 0.034 0.037 #> 21  D1,D2 Item_15   1  0.006 0.006 0.006 #> 22  D1,D2 Item_15   2  0.033 0.033 0.034 #> 23  D1,D2 Item_15   3 -0.014 0.014 0.018 #> 24  D1,D2 Item_15   4 -0.011 0.011 0.012 #> 25  D1,D2 Item_15   5 -0.014 0.014 0.015 #> 26  D1,D2 Item_16   1  0.099 0.103 0.126 #> 27  D1,D2 Item_16   2  0.004 0.025 0.031 #> 28  D1,D2 Item_16   3 -0.008 0.017 0.021 #> 29  D1,D2 Item_16   4 -0.001 0.033 0.047 #> 30  D1,D2 Item_16   5 -0.095 0.095 0.144 #> 31  D1,D2 Item_17   1 -0.147 0.147 0.175 #> 32  D1,D2 Item_17   2  0.154 0.154 0.170 #> 33  D1,D2 Item_17   3  0.024 0.024 0.024 #> 34  D1,D2 Item_17   4  0.132 0.132 0.152 #> 35  D1,D2 Item_17   5 -0.162 0.162 0.191 #> 36  D1,D2 Item_18   1 -0.055 0.055 0.064 #> 37  D1,D2 Item_18   2 -0.039 0.040 0.043 #> 38  D1,D2 Item_18   3  0.162 0.162 0.164 #> 39  D1,D2 Item_18   4 -0.023 0.023 0.024 #> 40  D1,D2 Item_18   5 -0.044 0.044 0.049 #> 41  D1,D2 Item_19   1 -0.133 0.133 0.145 #> 42  D1,D2 Item_19   2  0.054 0.059 0.083 #> 43  D1,D2 Item_19   3  0.078 0.078 0.083 #> 44  D1,D2 Item_19   4  0.137 0.137 0.155 #> 45  D1,D2 Item_19   5 -0.138 0.138 0.149 #> 46  D1,D2 Item_20   1 -0.072 0.098 0.110 #> 47  D1,D2 Item_20   2 -0.038 0.040 0.056 #> 48  D1,D2 Item_20   3  0.016 0.024 0.028 #> 49  D1,D2 Item_20   4  0.000 0.011 0.015 #> 50  D1,D2 Item_20   5  0.095 0.102 0.146  ## ---------------------------------------------------------------- ### multidimensional DTF  set.seed(1234) n <- 50 N <- 1000  # only first 5 items as anchors within each dimension model <- 'F1 = 1-25           F2 = 26-50           COV = F1*F2           CONSTRAINB = (1-5, a1), (1-5, 26-30, d), (26-30, a2)'  a <- matrix(c(rep(1, 25), numeric(50), rep(1, 25)), n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N)) Cov <- matrix(c(1, .5, .5, 1.5), 2) Mean <- c(0, 0.5)  # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich', sigma = cov2cor(Cov)) dat2 <- simdata(a, d, N, itemtype = 'dich', sigma = Cov, mu = Mean) dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... coef(mod, simplify=TRUE) #> $Group_1 #> $items #>            a1    a2      d g u #> Item_1  1.006 0.000 -1.208 0 1 #> Item_2  1.080 0.000  0.301 0 1 #> Item_3  0.833 0.000  1.126 0 1 #> Item_4  0.977 0.000 -2.342 0 1 #> Item_5  1.005 0.000  0.410 0 1 #> Item_6  0.864 0.000  0.428 0 1 #> Item_7  1.014 0.000 -0.495 0 1 #> Item_8  1.133 0.000 -0.472 0 1 #> Item_9  0.945 0.000 -0.585 0 1 #> Item_10 1.001 0.000 -0.787 0 1 #> Item_11 1.009 0.000 -0.390 0 1 #> Item_12 0.920 0.000 -1.061 0 1 #> Item_13 1.189 0.000 -0.711 0 1 #> Item_14 1.125 0.000  0.067 0 1 #> Item_15 1.122 0.000  0.896 0 1 #> Item_16 1.094 0.000 -0.203 0 1 #> Item_17 1.041 0.000 -0.479 0 1 #> Item_18 1.011 0.000 -0.849 0 1 #> Item_19 0.962 0.000 -0.768 0 1 #> Item_20 0.937 0.000  2.372 0 1 #> Item_21 0.935 0.000  0.082 0 1 #> Item_22 0.886 0.000 -0.482 0 1 #> Item_23 0.921 0.000 -0.443 0 1 #> Item_24 0.937 0.000  0.521 0 1 #> Item_25 0.959 0.000 -0.674 0 1 #> Item_26 0.000 0.999 -1.498 0 1 #> Item_27 0.000 0.978  0.590 0 1 #> Item_28 0.000 0.997 -1.035 0 1 #> Item_29 0.000 0.917 -0.055 0 1 #> Item_30 0.000 0.982 -0.970 0 1 #> Item_31 0.000 0.891  0.931 0 1 #> Item_32 0.000 0.863 -0.453 0 1 #> Item_33 0.000 1.140 -0.759 0 1 #> Item_34 0.000 0.943 -0.469 0 1 #> Item_35 0.000 1.289 -1.852 0 1 #> Item_36 0.000 0.791 -1.064 0 1 #> Item_37 0.000 0.980 -2.323 0 1 #> Item_38 0.000 1.051 -1.367 0 1 #> Item_39 0.000 1.097 -0.113 0 1 #> Item_40 0.000 0.908 -0.523 0 1 #> Item_41 0.000 1.059  1.708 0 1 #> Item_42 0.000 1.146 -1.078 0 1 #> Item_43 0.000 1.086 -0.967 0 1 #> Item_44 0.000 1.095 -0.415 0 1 #> Item_45 0.000 0.984 -1.066 0 1 #> Item_46 0.000 0.996 -0.726 0 1 #> Item_47 0.000 1.330 -1.037 0 1 #> Item_48 0.000 1.072 -1.148 0 1 #> Item_49 0.000 0.898 -0.429 0 1 #> Item_50 0.000 1.078 -0.525 0 1 #>  #> $means #> F1 F2  #>  0  0  #>  #> $cov #>       F1    F2 #> F1 1.000 0.453 #> F2 0.453 1.000 #>  #>  #> $Group_2 #> $items #>            a1    a2      d g u #> Item_1  1.006 0.000 -1.208 0 1 #> Item_2  1.080 0.000  0.301 0 1 #> Item_3  0.833 0.000  1.126 0 1 #> Item_4  0.977 0.000 -2.342 0 1 #> Item_5  1.005 0.000  0.410 0 1 #> Item_6  0.886 0.000  0.558 0 1 #> Item_7  0.967 0.000 -0.583 0 1 #> Item_8  0.988 0.000 -0.613 0 1 #> Item_9  0.962 0.000 -0.467 0 1 #> Item_10 0.865 0.000 -0.999 0 1 #> Item_11 1.076 0.000 -0.448 0 1 #> Item_12 1.145 0.000 -1.198 0 1 #> Item_13 0.991 0.000 -0.789 0 1 #> Item_14 1.039 0.000  0.070 0 1 #> Item_15 1.200 0.000  1.070 0 1 #> Item_16 0.989 0.000 -0.084 0 1 #> Item_17 0.995 0.000 -0.569 0 1 #> Item_18 0.932 0.000 -0.925 0 1 #> Item_19 0.866 0.000 -0.790 0 1 #> Item_20 1.122 0.000  2.463 0 1 #> Item_21 1.055 0.000  0.200 0 1 #> Item_22 1.107 0.000 -0.610 0 1 #> Item_23 0.992 0.000 -0.513 0 1 #> Item_24 0.992 0.000  0.388 0 1 #> Item_25 0.934 0.000 -0.794 0 1 #> Item_26 0.000 0.999 -1.498 0 1 #> Item_27 0.000 0.978  0.590 0 1 #> Item_28 0.000 0.997 -1.035 0 1 #> Item_29 0.000 0.917 -0.055 0 1 #> Item_30 0.000 0.982 -0.970 0 1 #> Item_31 0.000 1.015  0.962 0 1 #> Item_32 0.000 1.115 -0.595 0 1 #> Item_33 0.000 1.095 -0.874 0 1 #> Item_34 0.000 0.856 -0.486 0 1 #> Item_35 0.000 1.138 -1.636 0 1 #> Item_36 0.000 1.085 -1.353 0 1 #> Item_37 0.000 1.115 -2.169 0 1 #> Item_38 0.000 1.146 -1.450 0 1 #> Item_39 0.000 1.130 -0.441 0 1 #> Item_40 0.000 0.978 -0.632 0 1 #> Item_41 0.000 1.202  1.439 0 1 #> Item_42 0.000 0.942 -0.943 0 1 #> Item_43 0.000 1.033 -0.899 0 1 #> Item_44 0.000 1.144 -0.339 0 1 #> Item_45 0.000 0.844 -0.728 0 1 #> Item_46 0.000 1.068 -1.046 0 1 #> Item_47 0.000 0.952 -1.123 0 1 #> Item_48 0.000 1.018 -1.317 0 1 #> Item_49 0.000 0.881 -0.381 0 1 #> Item_50 0.000 1.092 -0.605 0 1 #>  #> $means #>    F1    F2  #> 0.072 0.505  #>  #> $cov #>       F1    F2 #> F1 1.068 0.518 #> F2 0.518 1.415 #>  #>  plot(mod, degrees = c(45,45))  DRF(mod) #>            groups n_focal_items   sDRF  uDRF  dDRF #> 1 Group_1,Group_2            50 -0.347 0.347 0.353  # some intercepts slightly higher in Group 2 d2 <- d d2[c(10:15, 31:35)] <- d2[c(10:15, 31:35)] + 1 dat1 <- simdata(a, d, N, itemtype = 'dich', sigma = cov2cor(Cov)) dat2 <- simdata(a, d2, N, itemtype = 'dich', sigma = Cov, mu = Mean) dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... coef(mod, simplify=TRUE) #> $Group_1 #> $items #>            a1    a2      d g u #> Item_1  0.942 0.000 -1.195 0 1 #> Item_2  0.973 0.000  0.294 0 1 #> Item_3  0.833 0.000  1.131 0 1 #> Item_4  1.049 0.000 -2.575 0 1 #> Item_5  1.078 0.000  0.517 0 1 #> Item_6  0.919 0.000  0.456 0 1 #> Item_7  0.929 0.000 -0.473 0 1 #> Item_8  0.918 0.000 -0.554 0 1 #> Item_9  0.907 0.000 -0.582 0 1 #> Item_10 1.096 0.000 -0.821 0 1 #> Item_11 1.000 0.000 -0.483 0 1 #> Item_12 0.986 0.000 -1.016 0 1 #> Item_13 1.013 0.000 -0.870 0 1 #> Item_14 0.861 0.000  0.104 0 1 #> Item_15 1.097 0.000  0.908 0 1 #> Item_16 0.871 0.000 -0.119 0 1 #> Item_17 0.949 0.000 -0.417 0 1 #> Item_18 1.019 0.000 -0.987 0 1 #> Item_19 1.031 0.000 -0.962 0 1 #> Item_20 0.904 0.000  2.378 0 1 #> Item_21 1.177 0.000  0.061 0 1 #> Item_22 1.044 0.000 -0.551 0 1 #> Item_23 0.948 0.000 -0.510 0 1 #> Item_24 0.915 0.000  0.387 0 1 #> Item_25 0.901 0.000 -0.778 0 1 #> Item_26 0.000 0.979 -1.450 0 1 #> Item_27 0.000 0.999  0.603 0 1 #> Item_28 0.000 1.105 -1.108 0 1 #> Item_29 0.000 1.034  0.043 0 1 #> Item_30 0.000 0.974 -0.925 0 1 #> Item_31 0.000 0.982  1.258 0 1 #> Item_32 0.000 1.012 -0.407 0 1 #> Item_33 0.000 0.957 -0.619 0 1 #> Item_34 0.000 1.076 -0.548 0 1 #> Item_35 0.000 0.761 -1.608 0 1 #> Item_36 0.000 0.962 -1.091 0 1 #> Item_37 0.000 0.891 -2.076 0 1 #> Item_38 0.000 0.895 -1.162 0 1 #> Item_39 0.000 1.023 -0.260 0 1 #> Item_40 0.000 0.949 -0.394 0 1 #> Item_41 0.000 1.145  1.451 0 1 #> Item_42 0.000 1.037 -1.063 0 1 #> Item_43 0.000 0.891 -0.937 0 1 #> Item_44 0.000 0.929 -0.397 0 1 #> Item_45 0.000 0.987 -0.887 0 1 #> Item_46 0.000 0.955 -1.032 0 1 #> Item_47 0.000 0.888 -1.063 0 1 #> Item_48 0.000 1.058 -1.267 0 1 #> Item_49 0.000 0.969 -0.486 0 1 #> Item_50 0.000 1.086 -0.442 0 1 #>  #> $means #> F1 F2  #>  0  0  #>  #> $cov #>       F1    F2 #> F1 1.000 0.409 #> F2 0.409 1.000 #>  #>  #> $Group_2 #> $items #>            a1    a2      d g u #> Item_1  0.942 0.000 -1.195 0 1 #> Item_2  0.973 0.000  0.294 0 1 #> Item_3  0.833 0.000  1.131 0 1 #> Item_4  1.049 0.000 -2.575 0 1 #> Item_5  1.078 0.000  0.517 0 1 #> Item_6  0.903 0.000  0.610 0 1 #> Item_7  1.006 0.000 -0.476 0 1 #> Item_8  0.889 0.000 -0.501 0 1 #> Item_9  0.855 0.000 -0.604 0 1 #> Item_10 0.892 0.000  0.069 0 1 #> Item_11 0.931 0.000  0.498 0 1 #> Item_12 0.962 0.000  0.065 0 1 #> Item_13 0.845 0.000  0.311 0 1 #> Item_14 0.893 0.000  1.036 0 1 #> Item_15 0.998 0.000  1.919 0 1 #> Item_16 0.949 0.000 -0.155 0 1 #> Item_17 0.989 0.000 -0.545 0 1 #> Item_18 0.866 0.000 -0.945 0 1 #> Item_19 0.893 0.000 -0.872 0 1 #> Item_20 0.732 0.000  2.195 0 1 #> Item_21 0.854 0.000  0.059 0 1 #> Item_22 0.783 0.000 -0.498 0 1 #> Item_23 0.966 0.000 -0.561 0 1 #> Item_24 0.944 0.000  0.384 0 1 #> Item_25 0.940 0.000 -0.794 0 1 #> Item_26 0.000 0.979 -1.450 0 1 #> Item_27 0.000 0.999  0.603 0 1 #> Item_28 0.000 1.105 -1.108 0 1 #> Item_29 0.000 1.034  0.043 0 1 #> Item_30 0.000 0.974 -0.925 0 1 #> Item_31 0.000 0.998  1.989 0 1 #> Item_32 0.000 1.190  0.252 0 1 #> Item_33 0.000 1.064  0.076 0 1 #> Item_34 0.000 0.885  0.444 0 1 #> Item_35 0.000 1.065 -0.597 0 1 #> Item_36 0.000 1.080 -1.273 0 1 #> Item_37 0.000 1.034 -2.217 0 1 #> Item_38 0.000 1.040 -1.451 0 1 #> Item_39 0.000 1.160 -0.496 0 1 #> Item_40 0.000 1.015 -0.711 0 1 #> Item_41 0.000 0.946  1.416 0 1 #> Item_42 0.000 1.006 -1.144 0 1 #> Item_43 0.000 0.969 -0.818 0 1 #> Item_44 0.000 1.099 -0.322 0 1 #> Item_45 0.000 1.062 -1.103 0 1 #> Item_46 0.000 1.064 -0.951 0 1 #> Item_47 0.000 1.025 -1.122 0 1 #> Item_48 0.000 0.975 -1.194 0 1 #> Item_49 0.000 1.083 -0.461 0 1 #> Item_50 0.000 0.935 -0.512 0 1 #>  #> $means #>    F1    F2  #> 0.003 0.578  #>  #> $cov #>       F1    F2 #> F1 1.165 0.459 #> F2 0.459 1.340 #>  #>  plot(mod, degrees = c(45,45))   DRF(mod) #>            groups n_focal_items  sDRF  uDRF  dDRF #> 1 Group_1,Group_2            50 1.803 1.803 1.831 DRF(mod, draws = 500) #>               groups n_focal_items  stat CI_2.5 CI_97.5     X2 df p #> sDRF Group_1,Group_2            50 1.803  1.232   2.303 44.609  1 0 #> uDRF Group_1,Group_2            50 1.803  1.232   2.303 47.432  2 0 #> dDRF Group_1,Group_2            50 1.831  1.278   2.354              # }"},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential test functioning statistics — DTF","title":"Differential test functioning statistics — DTF","text":"Function performs various omnibus differential test functioning procedures object estimated multipleGroup(). latent means/covariances suspected differ input object contain set 'anchor' items ensure differential test features detected rather group differences. Returns signed (average area ) unsigned (total area) statistics, descriptives percent average bias group total scores statistic. grid Theta values passed, can evaluated well determine specific DTF location effects.  best results, baseline model contain set 'anchor' items freely estimated hyper-parameters focal groups. See DIF details.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential test functioning statistics — DTF","text":"","code":"DTF(   mod,   draws = NULL,   CI = 0.95,   npts = 1000,   theta_lim = c(-6, 6),   Theta_nodes = NULL,   plot = \"none\",   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential test functioning statistics — DTF","text":"mod multipleGroup object estimated 2 groups draws number indicating many draws take form suitable multiple imputation estimate expected test scores (usually 100 ). Returns list containing imputation distribution null hypothesis test sDTF statistic CI range confidence interval using draws input npts number points use integration. Default 1000 theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts Theta_nodes optional matrix Theta values evaluated draws sDTF statistic. However, values averaged across, instead give bootstrap confidence intervals respective Theta nodes. Useful following large uDTF/sDTF statistic determine difference test curves large (still accounting sampling variability). Returns matrix observed variability plot character vector indicating plot draw. Possible values 'none', 'func' test score functions, 'sDTF' evaluated sDTF values across integration grid. plot drawn imputed confidence envelopes auto.key logical; automatically generate key lattice plot? ... additional arguments passed lattice boot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential test functioning statistics — DTF","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P., Counsell, ., Flora, D. B. (2016). might   make big DIF: Improved Differential Test Functioning statistics account   sampling variability. Educational Psychological Measurement, 76, 114-140.   doi:10.1177/0013164415584576","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Differential test functioning statistics — DTF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DTF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential test functioning statistics — DTF","text":"","code":"# \\donttest{ set.seed(1234) n <- 30 N <- 500  # only first 5 items as anchors model <- 'F = 1-30           CONSTRAINB = (1-5, a1), (1-5, d)'  a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = '2PL') dat2 <- simdata(a, d, N, itemtype = '2PL') dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... plot(mod)   DTF(mod) #>    sDTF.score sDTF(%).score    uDTF.score uDTF(%).score  #>     0.1742369     0.5807896     0.1768800     0.5896002  if(interactive()) mirtCluster() DTF(mod, draws = 1000) #95% C.I. for sDTF containing 0. uDTF is very small #> $observed #>    sDTF.score sDTF(%).score    uDTF.score uDTF(%).score  #>     0.1742369     0.5807896     0.1768800     0.5896002  #>  #> $CIs #>         sDTF.score sDTF(%).score uDTF.score uDTF(%).score #> CI_97.5  0.4728808     1.5762695 0.76426586     2.5475529 #> CI_2.5  -0.1233808    -0.4112693 0.08050925     0.2683642 #>  #> $tests #> P(sDTF.score = 0)  #>         0.2723393  #>  DTF(mod, draws = 1000, plot='sDTF') #sDTF 95% C.I.'s across Theta always include 0   ## ------------- ## random slopes and intercepts for 15 items, and latent mean difference ##    (no systematic DTF should exist, but DIF will be present) set.seed(1234) dat1 <- simdata(a, d, N, itemtype = '2PL', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), runif(n-15, -.2, .2)),                 d + c(numeric(15), runif(n-15, -.5, .5)), N, itemtype = '2PL') dat <- rbind(dat1, dat2) mod1 <- multipleGroup(dat, 1, group=group) #>  plot(mod1) #does not account for group differences! Need anchors   mod2 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... plot(mod2)   # significant DIF in multiple items.... # DIF(mod2, which.par=c('a1', 'd'), items2test=16:30) DTF(mod2) #>    sDTF.score sDTF(%).score    uDTF.score uDTF(%).score  #>     0.1937470     0.6458234     0.1944098     0.6480326  DTF(mod2, draws=1000) #non-sig DTF due to item cancellation #> $observed #>    sDTF.score sDTF(%).score    uDTF.score uDTF(%).score  #>     0.1937470     0.6458234     0.1944098     0.6480326  #>  #> $CIs #>         sDTF.score sDTF(%).score uDTF.score uDTF(%).score #> CI_97.5  0.4949249     1.6497498 0.66772934     2.2257645 #> CI_2.5  -0.0600406    -0.2001353 0.08150818     0.2716939 #>  #> $tests #> P(sDTF.score = 0)  #>         0.1694501  #>   ## ------------- ## systematic differing slopes and intercepts (clear DTF) dat1 <- simdata(a, d, N, itemtype = '2PL', mu=.50, sigma=matrix(1.5)) dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, .5)),                 N, itemtype = '2PL') dat <- rbind(dat1, dat2) mod3 <- multipleGroup(dat, model, group=group, SE=TRUE,                       invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix... plot(mod3) #visable DTF happening   # DIF(mod3, c('a1', 'd'), items2test=16:30) DTF(mod3) #unsigned bias. Signed bias indicates group 2 scores generally higher on average #>    sDTF.score sDTF(%).score    uDTF.score uDTF(%).score  #>    -0.8317365    -2.7724550     1.0764408     3.5881361  DTF(mod3, draws=1000) #> $observed #>    sDTF.score sDTF(%).score    uDTF.score uDTF(%).score  #>    -0.8317365    -2.7724550     1.0764408     3.5881361  #>  #> $CIs #>         sDTF.score sDTF(%).score uDTF.score uDTF(%).score #> CI_97.5 -0.5503085     -1.834362  1.3842919      4.614306 #> CI_2.5  -1.1248651     -3.749550  0.7954752      2.651584 #>  #> $tests #> P(sDTF.score = 0)  #>      2.738111e-08  #>  DTF(mod3, draws=1000, plot='func')  DTF(mod3, draws=1000, plot='sDTF') #multiple DTF areas along Theta   # evaluate specific values for sDTF Theta_nodes <- matrix(seq(-6,6,length.out = 100)) sDTF <- DTF(mod3, Theta_nodes=Theta_nodes) head(sDTF) #>             Theta       sDTF #> score.1 -6.000000 0.03153791 #> score.2 -5.878788 0.03604196 #> score.3 -5.757576 0.04118184 #> score.4 -5.636364 0.04704370 #> score.5 -5.515152 0.05372403 #> score.6 -5.393939 0.06133041 sDTF <- DTF(mod3, Theta_nodes=Theta_nodes, draws=100) head(sDTF) #>             Theta       sDTF   CI_97.5      CI_2.5 #> score.1 -6.000000 0.03153791 0.1630118 -0.01734655 #> score.2 -5.878788 0.03604196 0.1785965 -0.01768471 #> score.3 -5.757576 0.04118184 0.1955885 -0.01792454 #> score.4 -5.636364 0.04704370 0.2140994 -0.01804610 #> score.5 -5.515152 0.05372403 0.2342469 -0.01802792 #> score.6 -5.393939 0.06133041 0.2561549 -0.01784738  # }"},{"path":"https://philchalmers.github.io/mirt/reference/DeltaMethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerical derivative version of delta method — DeltaMethod","title":"Numerical derivative version of delta method — DeltaMethod","text":"Delta method using numerical derivatives (via numerical_deriv) provided function. Convenient target transformation function easier automate programmatically instead using explicit formula math expressions. Can also useful checking analytic results.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DeltaMethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerical derivative version of delta method — DeltaMethod","text":"","code":"DeltaMethod(fn, par, acov, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/DeltaMethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerical derivative version of delta method — DeltaMethod","text":"fn function specifying type transformation make new parameter interest. Must form fn(par, ...), simply fn(par), return numeric vector one element par numerical vector passed fn(par) (typically vector MLEs) acov numeric matrix ACOV MLEs ... additional arguments passed fn","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DeltaMethod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerical derivative version of delta method — DeltaMethod","text":"returns list transformed parameters, ACOV,   SEs","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DeltaMethod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numerical derivative version of delta method — DeltaMethod","text":"","code":"# Slightly modified example from ?msm::deltamethod # Multiple linear regression, E(y) = alpha + beta1 x + beta2 g x <- 1:100 g <- rep(0:1, each=50) y <- rnorm(100, 4*x, 5) toy.lm <- lm(y ~ x + g) estmean <- coef(toy.lm) estvar <- vcov(toy.lm)  # Estimate of (1 / (b0 + b1)) and (1 / (b0 + b1 + b2)) 1 / (estmean[1] + estmean[2]) #> (Intercept)  #>   0.2355943  1 / (estmean[1] + estmean[2] + estmean[3]) #> (Intercept)  #>    0.158912   if (FALSE) { # \\dontrun{ ## Approximate standard error msm::deltamethod (~ 1 / (x1 + x2), estmean, estvar) msm::deltamethod (~ 1 / (x1 + x2 + x3), estmean, estvar) } # }  # with DeltaMethod fn <- function(par) 1 / sum(par[1:2]) fn2 <- function(par) 1 / sum(par[1:3]) DeltaMethod(fn, estmean, estvar)$se #> [1] 0.0615558 DeltaMethod(fn2, estmean, estvar)$se #> [1] 0.06784448  # index argument for easier flexibility fn <- function(par, index) 1 / sum(par[index]) DeltaMethod(fn, estmean, estvar, index=1:2)$se #> [1] 0.0615558 DeltaMethod(fn, estmean, estvar, index=1:3)$se #> [1] 0.06784448"},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned mdirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"print signature(x = \"DiscreteClass\") show signature(object = \"DiscreteClass\") anova signature(object = \"DiscreteClass\") coef signature(x = \"DiscreteClass\") summary signature(object = \"DiscreteClass\") residuals signature(object = \"DiscreteClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/DiscreteClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of LSAT6 data — LSAT6","title":"Description of LSAT6 data — LSAT6","text":"Data Thissen (1982); contains 5 dichotomously scored items obtained Law School Admissions Test, section 6.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of LSAT6 data — LSAT6","text":"Thissen, D. (1982). Marginal maximum likelihood estimation one-parameter logistic model. Psychometrika, 47, 175-186.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of LSAT6 data — LSAT6","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT6.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of LSAT6 data — LSAT6","text":"","code":"# \\donttest{ dat <- expand.table(LSAT6) head(dat) #>   Item_1 Item_2 Item_3 Item_4 Item_5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      1 #> 5      0      0      0      0      1 #> 6      0      0      0      0      1 itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>  1000            3.819          1.035 0.077 0.03 0.295     0.869 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1 1000 2 0.924 0.265   0.362         0.113       0.275 #> Item_2 1000 2 0.709 0.454   0.567         0.153       0.238 #> Item_3 1000 2 0.553 0.497   0.618         0.173       0.217 #> Item_4 1000 2 0.763 0.425   0.534         0.144       0.246 #> Item_5 1000 2 0.870 0.336   0.435         0.122       0.266 #>  #> $proportions #>            0     1 #> Item_1 0.076 0.924 #> Item_2 0.291 0.709 #> Item_3 0.447 0.553 #> Item_4 0.237 0.763 #> Item_5 0.130 0.870 #>   model <- 'F = 1-5          CONSTRAIN = (1-5, a1)' (mod <- mirt(dat, model)) #>  #>  #> Call: #> mirt(data = dat, model = model) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 12 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2466.938 #> Estimated parameters: 6  #> AIC = 4945.875 #> BIC = 4975.322; SABIC = 4956.265 #> G2 (25) = 21.8, p = 0.6474 #> RMSEA = 0, CFI = NaN, TLI = NaN M2(mod) #>             M2 df         p RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI CFI #> stats 5.292566  9 0.8080952     0       0 0.02254275 0.02242068 1.072511   1 itemfit(mod) #>     item  S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1 Item_1 0.436       2          0  0.804 #> 2 Item_2 1.576       2          0  0.455 #> 3 Item_3 0.871       1          0  0.351 #> 4 Item_4 0.190       2          0  0.909 #> 5 Item_5 0.190       2          0  0.909 coef(mod, simplify=TRUE) #> $items #>           a1     d g u #> Item_1 0.755 2.730 0 1 #> Item_2 0.755 0.999 0 1 #> Item_3 0.755 0.240 0 1 #> Item_4 0.755 1.307 0 1 #> Item_5 0.755 2.100 0 1 #>  #> $means #> F  #> 0  #>  #> $cov #>   F #> F 1 #>   # equivalentely, but with a different parameterization mod2 <- mirt(dat, 1, itemtype = 'Rasch') #>  anova(mod, mod2) #equal #>           AIC    SABIC       HQ      BIC    logLik X2 df   p #> mod  4945.875 4956.265 4957.067 4975.322 -2466.938           #> mod2 4945.875 4956.266 4957.067 4975.322 -2466.938  0  0 NaN M2(mod2) #>             M2 df         p RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI CFI #> stats 5.292803  9 0.8080735     0       0 0.02254395 0.02242588 1.072506   1 itemfit(mod2) #>     item  S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1 Item_1 0.436       2          0  0.804 #> 2 Item_2 1.576       2          0  0.455 #> 3 Item_3 0.872       1          0  0.351 #> 4 Item_4 0.190       2          0  0.909 #> 5 Item_5 0.190       2          0  0.909 coef(mod2, simplify=TRUE) #> $items #>        a1     d g u #> Item_1  1 2.731 0 1 #> Item_2  1 0.999 0 1 #> Item_3  1 0.240 0 1 #> Item_4  1 1.307 0 1 #> Item_5  1 2.100 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 0.572 #>  sqrt(coef(mod2)$GroupPars[2]) #latent SD equal to the slope in mod #> [1] 0.7561877  # }"},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of LSAT7 data — LSAT7","title":"Description of LSAT7 data — LSAT7","text":"Data Bock & Lieberman (1970); contains 5 dichotomously scored items obtained Law School Admissions Test, section 7. Data ","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of LSAT7 data — LSAT7","text":"Bock, R. D., & Lieberman, M. (1970). Fitting response model n dichotomously scored items. Psychometrika, 35(2), 179-197. Bock, R. D., & Lieberman, M. (1970). Fitting response model n dichotomously scored items. Psychometrika, 35(2), 179-197.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of LSAT7 data — LSAT7","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/LSAT7.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of LSAT7 data — LSAT7","text":"","code":"# \\donttest{ dat <- expand.table(LSAT7) head(dat) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 2 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 2 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 2 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 2 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 2 0.843 0.364   0.461         0.175       0.438 #>  #> $proportions #>            0     1 #> Item.1 0.172 0.828 #> Item.2 0.342 0.658 #> Item.3 0.228 0.772 #> Item.4 0.394 0.606 #> Item.5 0.157 0.843 #>   (mod <- mirt(dat, 1)) #>  #>  #> Call: #> mirt(data = dat, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN coef(mod) #> $Item.1 #>        a1     d g u #> par 0.988 1.856 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.081 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.804 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.765 0.486 0 1 #>  #> $Item.5 #>        a1     d g u #> par 0.736 1.855 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  # }  # \\donttest{ dat <- expand.table(LSAT7) head(dat) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 2 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 2 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 2 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 2 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 2 0.843 0.364   0.461         0.175       0.438 #>  #> $proportions #>            0     1 #> Item.1 0.172 0.828 #> Item.2 0.342 0.658 #> Item.3 0.228 0.772 #> Item.4 0.394 0.606 #> Item.5 0.157 0.843 #>   (mod <- mirt(dat, 1)) #>  #>  #> Call: #> mirt(data = dat, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN coef(mod) #> $Item.1 #>        a1     d g u #> par 0.988 1.856 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.081 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.804 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.765 0.486 0 1 #>  #> $Item.5 #>        a1     d g u #> par 0.736 1.855 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  # }"},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the M2 model fit statistic — M2","title":"Compute the M2 model fit statistic — M2","text":"Computes M2 (Maydeu-Olivares & Joe, 2006) statistic data dichotomous, collapsed M2* statistic (collapsing univariate bivariate response categories; see Cai Hansen, 2013), hybrid C2 statistic collapses bivariate moments (Cai Monro, 2014). C2 variant mainly useful polytomous response models sufficient degrees freedom compute M2*. function also computes associated fit indices based fitting null model. Supports single multiple-group models. latent trait density approximated (e.g., Davidian curves, Empirical histograms, etc) passing use_dentype_estimate = TRUE use internally saved quadrature density components (applicable).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the M2 model fit statistic — M2","text":"","code":"M2(   obj,   type = \"M2*\",   calcNull = TRUE,   quadpts = NULL,   theta_lim = c(-6, 6),   CI = 0.9,   residmat = FALSE,   QMC = FALSE,   suppress = 1,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the M2 model fit statistic — M2","text":"obj estimated model object mirt package type type fit statistic compute. Options \"M2\", \"M2*\" univariate bivariate collapsed version M2 statistic (\"M2\" currently limited dichotomous response data ), \"C2\" hybrid M2 M2* bivariate moments collapsed calcNull logical; calculate statistics null model well? Allows statistics limited information TLI CFI. valid items suitable null model (e.g., created via createItem ) quadpts number quadrature points use estimation. NULL, suitable value chosen based rubric found fscores theta_lim lower upper range evaluate latent trait integral dimension CI numeric value 0 1 indicating range confidence interval RMSEA. Default returns 90% interval residmat logical; return residual matrix used compute SRMSR statistic? lower triangle residual correlation matrix returned (upper triangle filled NA's) QMC logical; use quasi-Monte Carlo integration? Useful higher dimensional models. quadpts specified, 5000 nodes used default suppress numeric value indicating parameter residual dependency combinations flag high. Absolute values standardized residuals greater value returned, values less value set NA. Must used conjunction argument residmat = TRUE ... additional arguments pass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the M2 model fit statistic — M2","text":"Returns data.frame object M2-type statistic, along degrees freedom,   p-value, RMSEA (90% confidence interval), SRMSR group,   optionally TLI CFI model fit statistics calcNull = TRUE.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the M2 model fit statistic — M2","text":"Cai, L. & Hansen, M. (2013). Limited-information goodness--fit testing hierarchical item factor models. British Journal Mathematical Statistical Psychology, 66, 245-276. Cai, L. & Monro, S. (2014). new statistic evaluating item response theory models ordinal data. National Center Research Evaluation, Standards, & Student Testing. Technical Report. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Maydeu-Olivares, . & Joe, H. (2006). Limited information goodness--fit testing multidimensional contingency tables. Psychometrika, 71, 713-732.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the M2 model fit statistic — M2","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/M2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the M2 model fit statistic — M2","text":"","code":"# \\donttest{ dat <- as.matrix(expand.table(LSAT7)) (mod1 <- mirt(dat, 1)) #>  #>  #> Call: #> mirt(data = dat, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN M2(mod1) #>             M2 df          p     RMSEA     RMSEA_5   RMSEA_95      SRMSR #> stats 11.93769  5 0.03565165 0.0372683 0.008950922 0.06496573 0.03195919 #>             TLI       CFI #> stats 0.9369332 0.9684666 resids <- M2(mod1, residmat=TRUE) #lower triangle of residual correlation matrix resids #>             Item.1      Item.2       Item.3       Item.4 Item.5 #> Item.1          NA          NA           NA           NA     NA #> Item.2 -0.02212010          NA           NA           NA     NA #> Item.3 -0.03265942  0.03335601           NA           NA     NA #> Item.4  0.05155184 -0.01642572 -0.012476892           NA     NA #> Item.5  0.05443241 -0.03867705 -0.001860395 7.235425e-05     NA summary(resids[lower.tri(resids)]) #>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.  #> -0.038677 -0.020697 -0.007169  0.001519  0.025035  0.054432   # M2 with missing data present dat[sample(1:prod(dim(dat)), 250)] <- NA mod2 <- mirt(dat, 1) #>  M2(mod2) #>             M2 df         p      RMSEA RMSEA_5   RMSEA_95      SRMSR       TLI #> stats 8.239687  5 0.1435113 0.02546735       0 0.05530946 0.03324067 0.9630427 #>             CFI #> stats 0.9815213  # C2 statistic (useful when polytomous IRT models have too few df) pmod <- mirt(Science, 1) #>  # This fails with too few df: # M2(pmod) # This, however, works: M2(pmod, type = 'C2') #>             M2 df           p     RMSEA    RMSEA_5  RMSEA_95      SRMSR #> stats 19.17929  2 6.84337e-05 0.1482174 0.09234204 0.2116368 0.07257313 #>             TLI       CFI #> stats 0.7300952 0.9100317  # }"},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute multidimensional difficulty index — MDIFF","title":"Compute multidimensional difficulty index — MDIFF","text":"Returns matrix containing MDIFF values (Reckase, 2009). supported items class 'dich' 'graded'.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute multidimensional difficulty index — MDIFF","text":"","code":"MDIFF(x, which.items = NULL, group = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute multidimensional difficulty index — MDIFF","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied .items vector indicating items select. NULL used (default) MDISC computed items group group argument pass extract.group function. Required input object multiple-group model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute multidimensional difficulty index — MDIFF","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Reckase, M. D. (2009). Multidimensional Item Response Theory. Springer.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute multidimensional difficulty index — MDIFF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDIFF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute multidimensional difficulty index — MDIFF","text":"","code":"# \\donttest{  mod <- mirt(Science, 2) #>  MDIFF(mod) #>           MDIFF_1    MDIFF_2   MDIFF_3 #> Comfort -3.892829 -2.1408175 1.1974522 #> Work    -1.806316 -0.5623950 1.4163829 #> Future  -2.486824 -1.0433836 0.9256248 #> Benefit -2.316311 -0.6940864 1.1869606  mod <- mirt(expand.table(LSAT7), 2) #>  MDIFF(mod) #>           MDIFF_1 #> Item.1 -1.2103317 #> Item.2 -0.7903550 #> Item.3 -0.8774211 #> Item.4 -0.6408189 #> Item.5 -2.4615861  # }"},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute multidimensional discrimination index — MDISC","title":"Compute multidimensional discrimination index — MDISC","text":"Returns vector containing MDISC values item model input object (Reckase, 2009).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute multidimensional discrimination index — MDISC","text":"","code":"MDISC(x, group = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute multidimensional discrimination index — MDISC","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied group group argument pass extract.group function. Required input object multiple-group model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute multidimensional discrimination index — MDISC","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Reckase, M. D. (2009). Multidimensional Item Response Theory. Springer.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute multidimensional discrimination index — MDISC","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MDISC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute multidimensional discrimination index — MDISC","text":"","code":"# \\donttest{  mod <- mirt(Science, 2) #>  MDISC(mod) #>  Comfort     Work   Future  Benefit  #> 1.338530 2.050473 1.875270 1.722043   # }"},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned mixedmirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"coef signature(object = \"MixedClass\") print signature(x = \"MixedClass\") residuals signature(object = \"MixedClass\") show signature(object = \"MixedClass\") summary signature(object = \"MixedClass\") logLik signature(object = \"MixedClass\") anova signature(object = \"MixedClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixedClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned multipleGroup estimated mixture distributions.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"coef signature(object = \"MixtureClass\") print signature(x = \"MixtureClass\") show signature(object = \"MixtureClass\") anova signature(object = \"MixtureClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MixtureClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned multipleGroup.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"coef signature(object = \"MultipleGroupClass\") print signature(x = \"MultipleGroupClass\") show signature(object = \"MultipleGroupClass\") anova signature(object = \"MultipleGroupClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/MultipleGroupClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"Computes profiled-likelihood based confidence intervals. Supports inclusion equality constraints. Object returns confidence intervals whether respective interval found.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"","code":"PLCI.mirt(   mod,   parnum = NULL,   alpha = 0.05,   search_bound = TRUE,   step = 0.5,   lower = TRUE,   upper = TRUE,   inf2val = 30,   NealeMiller = FALSE,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"mod converged mirt model parnum numeric vector indicating parameters estimate. Use mod2values determine parameter numbers. NULL, possible parameters used alpha two-tailed alpha critical level search_bound logical; use fixed grid values around ML estimate determine suitable optimization bounds? Using much better behaviour setting fixed upper/lower bound values searching extreme ends step magnitude steps used search_bound TRUE. Smaller values create points search suitable bound (lower bound value visible mod2values). upper/lower bounds detected value adjusted accordingly lower logical; search lower CI? upper logical; search upper CI? inf2val numeric used change parameter bounds infinity finite number. Decreasing much may allow suitable bound located. Default 30 NealeMiller logical; use Neale Miller 1997 approximation? Default FALSE verbose logical; include additional information console? ... additional arguments pass estimation functions","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P., Pek, J., & Liu, Y. (2017). Profile-likelihood Confidence Intervals Item Response Theory Models. Multivariate Behavioral Research, 52, 533-550. doi:10.1080/00273171.2017.1329082 Neale, M. C. & Miller, M. B. (1997). use likelihood-based confidence intervals genetic models. Behavior Genetics, 27, 113-120.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/PLCI.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute profiled-likelihood (or posterior) confidence intervals — PLCI.mirt","text":"","code":"# \\donttest{ if(interactive()) mirtCluster() #use all available cores to estimate CI's in parallel dat <- expand.table(LSAT7) mod <- mirt(dat, 1) #>   result <- PLCI.mirt(mod) result #>      Item class parnam parnum     value lower_2.5 upper_97.5 lower_conv #> 1  Item.1  dich     a1      1 0.9879254 0.6705382  1.3819761       TRUE #> 2  Item.1  dich      d      2 1.8560605 1.6203325  2.1474211       TRUE #> 3  Item.2  dich     a1      5 1.0808847 0.7816287  1.4614714       TRUE #> 4  Item.2  dich      d      6 0.8079786 0.6373152  0.9994390       TRUE #> 5  Item.3  dich     a1      9 1.7058006 1.1965700  2.6063138       TRUE #> 6  Item.3  dich      d     10 1.8042187 1.4754050  2.3765517       TRUE #> 7  Item.4  dich     a1     13 0.7651853 0.5211915  1.0554405       TRUE #> 8  Item.4  dich      d     14 0.4859966 0.3417041  0.6365806       TRUE #> 9  Item.5  dich     a1     17 0.7357980 0.4551545  1.0555079       TRUE #> 10 Item.5  dich      d     18 1.8545127 1.6438380  2.0976038       TRUE #>    upper_conv #> 1        TRUE #> 2        TRUE #> 3        TRUE #> 4        TRUE #> 5        TRUE #> 6        TRUE #> 7        TRUE #> 8        TRUE #> 9        TRUE #> 10       TRUE   mod2 <- mirt(Science, 1) #>  result2 <- PLCI.mirt(mod2) result2 #>       Item  class parnam parnum      value  lower_2.5 upper_97.5 lower_conv #> 1  Comfort graded     a1      1  1.0417547  0.7008509   1.453043       TRUE #> 2  Comfort graded     d1      2  4.8641542  4.0112194   5.966782       TRUE #> 3  Comfort graded     d2      3  2.6399417  2.2332766   3.115799       TRUE #> 4  Comfort graded     d3      4 -1.4660135 -1.7996417  -1.171326       TRUE #> 5     Work graded     a1      5  1.2259618  0.8942261   1.620993       TRUE #> 6     Work graded     d1      6  2.9240027  2.4851419   3.430756       TRUE #> 7     Work graded     d2      7  0.9011651  0.6307977   1.195238       TRUE #> 8     Work graded     d3      8 -2.2665647 -2.6975967  -1.893557       TRUE #> 9   Future graded     a1      9  2.2933717  1.5687257   3.986967       TRUE #> 10  Future graded     d1     10  5.2339928  4.1279881   7.822343       TRUE #> 11  Future graded     d2     11  2.2137728  1.6589420   3.416513       TRUE #> 12  Future graded     d3     12 -1.9637062 -3.0256934  -1.453916       TRUE #> 13 Benefit graded     a1     13  1.0949151  0.7659052   1.501997       TRUE #> 14 Benefit graded     d1     14  3.3479196  2.8453841   3.940600       TRUE #> 15 Benefit graded     d2     15  0.9916289  0.7267311   1.282508       TRUE #> 16 Benefit graded     d3     16 -1.6882599 -2.0443917  -1.375841       TRUE #>    upper_conv #> 1        TRUE #> 2        TRUE #> 3        TRUE #> 4        TRUE #> 5        TRUE #> 6        TRUE #> 7        TRUE #> 8        TRUE #> 9        TRUE #> 10       TRUE #> 11       TRUE #> 12       TRUE #> 13       TRUE #> 14       TRUE #> 15       TRUE #> 16       TRUE  # only estimate CI's slopes sv <- mod2values(mod2) parnum <- sv$parnum[sv$name == 'a1'] result3 <- PLCI.mirt(mod2, parnum) result3 #>      Item  class parnam parnum    value lower_2.5 upper_97.5 lower_conv #> 1 Comfort graded     a1      1 1.041755 0.7008509   1.453043       TRUE #> 2    Work graded     a1      5 1.225962 0.8942261   1.620993       TRUE #> 3  Future graded     a1      9 2.293372 1.5687257   3.986967       TRUE #> 4 Benefit graded     a1     13 1.094915 0.7659052   1.501997       TRUE #>   upper_conv #> 1       TRUE #> 2       TRUE #> 3       TRUE #> 4       TRUE  # }"},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based Reliable Change Index — RCI","title":"Model-based Reliable Change Index — RCI","text":"Computes IRT version \"reliable change index\" (RCI) proposed Jacobson Traux (1991) modified use IRT information scores measurement error (see Jabrayilov, Emons, Sijtsma (2016)). Main benefit IRT approach inclusion response pattern information pre/post data score estimates, well conditional standard error measurement information. Models can specified separate unidimensional IRT models fitted via mirt (extracted multipleGroup via extract.group), two-dimensional model latent traits correspond two test administrations.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based Reliable Change Index — RCI","text":"","code":"RCI(   mod_pre,   predat,   postdat,   mod_post = mod_pre,   cutoffs = NULL,   SEM.pre = NULL,   SEM.post = NULL,   Fisher = FALSE,   zero_cor = TRUE,   shiny = FALSE,   main = \"Test Scores\",   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based Reliable Change Index — RCI","text":"mod_pre single-group model fitted mirt. supplied information extracted data input objects compute classical test theory version RCI statistics predat vector (one individual) matrix/data.frame   response data scored, individuals' responses   included exactly one row. total score information used instead   complete response matrix   matrix object exactly ncol = 1 columns   provided postdat predat, respect post/follow-  measurement. Ignored two-dimensional IRT model included. original RCI approach, matrix containing complete responses,   matrix one column containing total scores, can provided mod_post (optional) IRT model post-test different pre-test; otherwise, pre-test model used. Ignored two-dimensional model IRT included cutoffs optional vector length 2 indicating type cut-offs report (e.g., c(-1.96, 1.96) reflects 95 percent z-score type cut-) SEM.pre standard error measurement pretest. can used instead rxx.pre SD.pre SEM.post (optional) standard error measurement post-test. Using create pooled version SEM; otherwise, SEM.post = SEM.pre Fisher logical; use Fisher/expected information function compute SE terms? FALSE SE information extracted select fscores method (default). applicable unidimensional models zero_cor logical; supplied mod_pre two-factor model covariance/correlation latent traits forced 0? shiny logical; launch interactive shiny applications real-time scoring supplied total-scores response vectors? requires mod_pre (optional) mod_post inputs main main label use shiny=TRUE ... additional arguments passed fscores","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model-based Reliable Change Index — RCI","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Jacobson, N. S., & Truax, P. (1991). Clinical significance: statistical approach defining meaningful change psychotherapy research. Journal Consulting Clinical Psychology, 59, 12-19. Jabrayilov, R. , Emons, W. H. M., & Sijtsma, K. (2016). Comparison Classical Test Theory Item Response Theory Individual Change Assessment. Applied Psychological Measurement, 40 (8), 559-572.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model-based Reliable Change Index — RCI","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RCI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based Reliable Change Index — RCI","text":"","code":"# \\donttest{  # simulate some data N <- 1000 J <- 20     # number of items a <- matrix(rlnorm(J,.2,.3)) d <- rnorm(J)  theta <- matrix(rnorm(N)) dat_pre <- simdata(a, d, itemtype = '2PL', Theta = theta)  # first 3 cases decrease by 1/2 theta2 <- theta - c(1/2, 1/2, 1/2, numeric(N-3)) dat_post <- simdata(a, d, itemtype = '2PL', Theta = theta2)  mod <- mirt(dat_pre) #>   # all changes using fitted model from pre data RCI(mod, predat=dat_pre, postdat=dat_post) #>      pre.score post.score converged   diff    SE      z     p #> 1        1.714      1.970      TRUE  0.256 0.759  0.337 0.736 #> 2        1.406     -0.120      TRUE -1.526 0.582 -2.620 0.009 #> 3        0.960     -0.150      TRUE -1.111 0.536 -2.073 0.038 #> 4        0.302      0.202      TRUE -0.100 0.496 -0.202  0.84 #> 5       -0.973     -0.906      TRUE  0.067 0.548  0.122 0.903 #> 6       -0.797     -0.298      TRUE  0.499 0.508  0.983 0.326 #> 7        0.151     -0.466      TRUE -0.617 0.492 -1.253  0.21 #> 8        0.111      1.052      TRUE  0.940 0.547  1.721 0.085 #> 9       -1.367     -1.355      TRUE  0.013 0.626  0.020 0.984 #> 10      -0.946     -0.416      TRUE  0.530 0.521  1.016  0.31 #> 11      -1.876     -0.774      TRUE  1.101 0.646  1.705 0.088 #> 12       1.258      0.788      TRUE -0.470 0.599 -0.786 0.432 #> 13       0.342      0.038      TRUE -0.303 0.494 -0.615 0.539 #> 14       0.201     -0.033      TRUE -0.234 0.488 -0.480 0.631 #> 15       1.434      1.527      TRUE  0.094 0.683  0.137 0.891 #> 16      -1.862     -1.179      TRUE  0.683 0.671  1.018 0.309 #> 17       0.141     -0.291      TRUE -0.432 0.487 -0.886 0.376 #> 18       0.196      0.222      TRUE  0.026 0.493  0.054 0.957 #> 19       1.084      0.421      TRUE -0.663 0.560 -1.185 0.236 #> 20       0.912      0.037      TRUE -0.875 0.532 -1.644   0.1 #> 21      -0.526     -0.624      TRUE -0.098 0.504 -0.195 0.846 #> 22      -0.371      0.377      TRUE  0.748 0.497  1.503 0.133 #> 23      -1.486     -0.978      TRUE  0.508 0.606  0.838 0.402 #> 24      -0.742     -0.495      TRUE  0.247 0.509  0.484 0.628 #> 25       0.798      0.923      TRUE  0.124 0.568  0.219 0.827 #> 26      -0.207     -0.503      TRUE -0.296 0.491 -0.603 0.547 #> 27       1.265      1.233      TRUE -0.032 0.637 -0.051 0.959 #> 28      -1.011     -0.104      TRUE  0.907 0.523  1.736 0.083 #> 29       0.671      1.011      TRUE  0.340 0.567  0.600 0.549 #> 30      -1.045     -0.551      TRUE  0.494 0.534  0.925 0.355 #> 31      -1.481     -2.133      TRUE -0.651 0.737 -0.883 0.377 #> 32      -0.158     -0.636      TRUE -0.478 0.496 -0.963 0.335 #> 33       2.251      2.251      TRUE  0.000 0.846  0.000     1 #> 34      -0.255     -0.541      TRUE -0.286 0.493 -0.581 0.561 #> 35      -1.237     -1.002      TRUE  0.235 0.580  0.405 0.685 #> 36       0.789      1.120      TRUE  0.331 0.585  0.565 0.572 #> 37      -0.252     -0.135      TRUE  0.118 0.484  0.243 0.808 #> 38       1.078      0.586      TRUE -0.492 0.568 -0.867 0.386 #> 39      -0.022      0.480      TRUE  0.502 0.500  1.004 0.315 #> 40       1.691      1.629      TRUE -0.062 0.720 -0.086 0.931 #> 41       0.252     -0.130      TRUE -0.382 0.489 -0.782 0.434 #> 42       0.162     -0.282      TRUE -0.443 0.488 -0.909 0.363 #> 43      -0.287     -0.374      TRUE -0.087 0.488 -0.179 0.858 #> 44      -0.016      0.057      TRUE  0.074 0.484  0.152 0.879 #> 45      -0.406     -0.159      TRUE  0.247 0.487  0.507 0.612 #> 46      -0.363     -0.140      TRUE  0.223 0.486  0.458 0.647 #> 47      -0.548     -0.161      TRUE  0.387 0.492  0.786 0.432 #> 48      -0.657     -0.344      TRUE  0.313 0.500  0.626 0.531 #> 49      -0.642     -0.206      TRUE  0.436 0.497  0.877 0.381 #> 50      -0.390      0.102      TRUE  0.492 0.489  1.006 0.314 #> 51       0.676      1.310      TRUE  0.634 0.597  1.063 0.288 #> 52      -0.601     -0.481      TRUE  0.120 0.501  0.239 0.811 #> 53       1.972      0.685      TRUE -1.287 0.675 -1.906 0.057 #> 54      -0.606      0.133      TRUE  0.740 0.498  1.486 0.137 #> 55      -0.147     -0.157      TRUE -0.010 0.483 -0.022 0.983 #> 56      -0.400     -0.318      TRUE  0.082 0.489  0.167 0.867 #> 57      -0.246     -0.602      TRUE -0.356 0.496 -0.718 0.473 #> 58      -1.014     -1.271      TRUE -0.257 0.584 -0.440  0.66 #> 59       0.090     -0.219      TRUE -0.310 0.485 -0.638 0.523 #> 60       0.781      0.685      TRUE -0.096 0.548 -0.175 0.861 #> 61       0.477      0.424      TRUE -0.053 0.513 -0.103 0.918 #> 62       1.066      0.712      TRUE -0.354 0.574 -0.616 0.538 #> 63       0.419      0.486      TRUE  0.067 0.513  0.130 0.896 #> 64      -0.863     -0.870      TRUE -0.007 0.538 -0.012  0.99 #> 65      -0.866     -0.907      TRUE -0.041 0.540 -0.076  0.94 #> 66      -0.863     -1.125      TRUE -0.262 0.559 -0.470 0.639 #> 67       1.714      0.792      TRUE -0.922 0.650 -1.419 0.156 #> 68      -0.136     -0.445      TRUE -0.309 0.488 -0.633 0.527 #> 69       0.184     -0.046      TRUE -0.231 0.487 -0.473 0.636 #> 70       1.972      1.470      TRUE -0.502 0.735 -0.682 0.495 #> 71      -0.153     -0.738      TRUE -0.586 0.502 -1.166 0.244 #> 72       1.290      0.929      TRUE -0.361 0.612 -0.590 0.555 #> 73      -0.041      0.003      TRUE  0.044 0.484  0.090 0.928 #> 74       0.156      0.281      TRUE  0.125 0.494  0.252 0.801 #> 75       0.590      0.043      TRUE -0.547 0.507 -1.078 0.281 #> 76       0.818      0.796      TRUE -0.022 0.559 -0.039 0.969 #> 77      -0.693     -0.942      TRUE -0.249 0.532 -0.468  0.64 #> 78       0.237      0.147      TRUE -0.090 0.492 -0.182 0.855 #> 79       0.852     -0.057      TRUE -0.909 0.526 -1.727 0.084 #> 80       0.297      0.201      TRUE -0.097 0.495 -0.195 0.845 #> 81      -0.117     -0.324      TRUE -0.207 0.485 -0.426  0.67 #> 82       0.499      0.262      TRUE -0.236 0.507 -0.466 0.641 #> 83       0.297      0.112      TRUE -0.185 0.493 -0.375 0.707 #> 84      -0.821     -1.876      TRUE -1.055 0.648 -1.627 0.104 #> 85      -0.500     -0.136      TRUE  0.363 0.490  0.741 0.459 #> 86      -0.554      0.157      TRUE  0.711 0.496  1.434 0.152 #> 87      -1.099     -0.542      TRUE  0.557 0.539  1.033 0.302 #> 88      -0.200      0.099      TRUE  0.299 0.485  0.615 0.538 #> 89      -0.297     -0.068      TRUE  0.229 0.485  0.473 0.636 #> 90       0.372      0.170      TRUE -0.202 0.498 -0.406 0.685 #> 91      -0.634     -1.629      TRUE -0.995 0.604 -1.646   0.1 #> 92      -0.666     -0.443      TRUE  0.223 0.503  0.444 0.657 #> 93      -1.257     -0.891      TRUE  0.366 0.573  0.638 0.524 #> 94       0.197      0.503      TRUE  0.307 0.505  0.607 0.544 #> 95       1.648      1.090      TRUE -0.558 0.664 -0.840 0.401 #> 96      -0.162     -0.492      TRUE -0.329 0.490 -0.672 0.501 #> 97      -0.390      0.107      TRUE  0.497 0.489  1.017 0.309 #> 98      -0.520     -0.462      TRUE  0.058 0.497  0.117 0.907 #> 99       0.268      0.095      TRUE -0.173 0.492 -0.352 0.725 #> 100     -0.113     -0.109      TRUE  0.004 0.483  0.007 0.994 #> 101     -0.782     -0.793      TRUE -0.011 0.527 -0.021 0.983 #> 102      0.897      1.091      TRUE  0.194 0.590  0.329 0.743 #> 103     -0.105     -0.130      TRUE -0.025 0.483 -0.053 0.958 #> 104     -0.364      0.941      TRUE  1.305 0.537  2.431 0.015 #> 105     -1.638     -1.441      TRUE  0.198 0.666  0.297 0.767 #> 106     -0.453     -0.084      TRUE  0.369 0.489  0.756  0.45 #> 107      0.294      0.262      TRUE -0.033 0.497 -0.066 0.947 #> 108     -1.638     -1.503      TRUE  0.135 0.673  0.201 0.841 #> 109      0.567      0.431      TRUE -0.137 0.518 -0.263 0.792 #> 110     -0.501     -0.961      TRUE -0.460 0.525 -0.876 0.381 #> 111      0.754     -0.118      TRUE -0.872 0.518 -1.683 0.092 #> 112     -0.804     -0.828      TRUE -0.023 0.531 -0.044 0.965 #> 113      1.003      1.654      TRUE  0.652 0.658  0.990 0.322 #> 114     -1.492     -2.133      TRUE -0.640 0.738 -0.867 0.386 #> 115     -0.190      0.455      TRUE  0.646 0.498  1.295 0.195 #> 116      0.804      0.776      TRUE -0.028 0.556 -0.051  0.96 #> 117     -0.203     -0.434      TRUE -0.231 0.488 -0.473 0.636 #> 118     -0.684     -0.888      TRUE -0.204 0.528 -0.386   0.7 #> 119      0.478     -0.047      TRUE -0.525 0.500 -1.051 0.293 #> 120     -0.386     -1.201      TRUE -0.815 0.544 -1.497 0.134 #> 121     -0.165      0.462      TRUE  0.627 0.499  1.257 0.209 #> 122     -1.403     -0.744      TRUE  0.660 0.581  1.136 0.256 #> 123     -0.280     -0.537      TRUE -0.257 0.493 -0.521 0.602 #> 124     -1.451     -0.856      TRUE  0.595 0.593  1.003 0.316 #> 125      0.345      0.253      TRUE -0.092 0.499 -0.185 0.854 #> 126      1.234      1.972      TRUE  0.738 0.714  1.033 0.302 #> 127      0.603      0.776      TRUE  0.173 0.542  0.318  0.75 #> 128      0.656      0.738      TRUE  0.082 0.543  0.152 0.879 #> 129      0.685      0.722      TRUE  0.037 0.544  0.069 0.945 #> 130     -0.316      0.634      TRUE  0.949 0.511  1.857 0.063 #> 131      0.268      0.009      TRUE -0.260 0.490 -0.530 0.596 #> 132     -1.131     -1.242      TRUE -0.112 0.591 -0.189  0.85 #> 133      0.936      0.862      TRUE -0.075 0.574 -0.130 0.896 #> 134      1.707      1.955      TRUE  0.248 0.757  0.327 0.743 #> 135     -1.495     -0.960      TRUE  0.535 0.605  0.884 0.377 #> 136      0.386     -0.097      TRUE -0.484 0.495 -0.978 0.328 #> 137      0.428      0.471      TRUE  0.043 0.513  0.084 0.933 #> 138     -0.469     -1.073      TRUE -0.604 0.534 -1.131 0.258 #> 139      0.609      0.070      TRUE -0.539 0.509 -1.059 0.289 #> 140     -0.253     -0.848      TRUE -0.594 0.510 -1.164 0.244 #> 141      1.650      1.431      TRUE -0.218 0.695 -0.314 0.754 #> 142      0.860      0.826      TRUE -0.034 0.565 -0.061 0.952 #> 143     -0.471     -0.057      TRUE  0.415 0.489  0.847 0.397 #> 144      0.643     -0.130      TRUE -0.772 0.510 -1.515  0.13 #> 145     -1.411     -0.965      TRUE  0.446 0.596  0.749 0.454 #> 146     -1.736     -1.536      TRUE  0.200 0.689  0.290 0.772 #> 147     -0.848     -0.577      TRUE  0.271 0.520  0.521 0.602 #> 148     -0.279     -0.351      TRUE -0.072 0.487 -0.148 0.882 #> 149      0.510      0.886      TRUE  0.376 0.546  0.689 0.491 #> 150     -0.174     -0.160      TRUE  0.014 0.483  0.028 0.977 #> 151     -0.440     -0.313      TRUE  0.127 0.490  0.258 0.796 #> 152     -1.513     -1.876      TRUE -0.362 0.705 -0.514 0.607 #> 153     -1.120     -1.223      TRUE -0.103 0.588 -0.175 0.861 #> 154     -0.576     -0.927      TRUE -0.351 0.526 -0.669 0.504 #> 155      1.141      0.518      TRUE -0.623 0.570 -1.093 0.275 #> 156     -0.197      0.304      TRUE  0.501 0.491  1.019 0.308 #> 157      0.826      1.407      TRUE  0.581 0.617  0.942 0.346 #> 158     -0.111     -0.823      TRUE -0.712 0.508 -1.403 0.161 #> 159     -0.270     -0.091      TRUE  0.179 0.484  0.370 0.712 #> 160      1.481      0.197      TRUE -1.284 0.595 -2.159 0.031 #> 161      0.693     -0.442      TRUE -1.135 0.519 -2.189 0.029 #> 162     -0.416     -0.250      TRUE  0.166 0.488  0.340 0.734 #> 163     -1.237     -0.850      TRUE  0.387 0.569  0.681 0.496 #> 164      1.236     -0.394      TRUE -1.630 0.567 -2.875 0.004 #> 165     -0.030     -0.357      TRUE -0.327 0.486 -0.673 0.501 #> 166     -0.427     -0.285      TRUE  0.143 0.489  0.291 0.771 #> 167      1.077      1.036      TRUE -0.040 0.601 -0.067 0.947 #> 168      1.046      1.691      TRUE  0.645 0.666  0.968 0.333 #> 169     -1.220     -1.363      TRUE -0.143 0.612 -0.233 0.815 #> 170     -1.876     -1.638      TRUE  0.237 0.718  0.331 0.741 #> 171     -1.449     -2.133      TRUE -0.684 0.734 -0.931 0.352 #> 172      2.251      1.020      TRUE -1.231 0.731 -1.683 0.092 #> 173      0.054      0.386      TRUE  0.332 0.496  0.670 0.503 #> 174     -0.176     -1.199      TRUE -1.024 0.541 -1.893 0.058 #> 175     -0.798      0.984      TRUE  1.781 0.559  3.187 0.001 #> 176     -0.305     -0.533      TRUE -0.227 0.493 -0.461 0.645 #> 177      0.820      1.071      TRUE  0.250 0.583  0.430 0.667 #> 178     -1.645     -0.911      TRUE  0.735 0.621  1.182 0.237 #> 179      1.675      2.251      TRUE  0.576 0.787  0.732 0.464 #> 180     -0.043     -0.341      TRUE -0.297 0.486 -0.613  0.54 #> 181     -0.639     -0.688      TRUE -0.049 0.513 -0.096 0.923 #> 182     -1.247     -0.804      TRUE  0.442 0.567  0.781 0.435 #> 183      0.019     -0.488      TRUE -0.507 0.491 -1.033 0.301 #> 184     -0.346      0.020      TRUE  0.367 0.486  0.754 0.451 #> 185     -0.786     -1.155      TRUE -0.369 0.556 -0.662 0.508 #> 186     -0.537     -0.933      TRUE -0.396 0.524 -0.756  0.45 #> 187     -0.400     -1.088      TRUE -0.688 0.533 -1.290 0.197 #> 188     -0.069     -0.136      TRUE -0.067 0.483 -0.139  0.89 #> 189      1.306      0.482      TRUE -0.824 0.586 -1.408 0.159 #> 190     -1.299     -1.122      TRUE  0.177 0.596  0.297 0.767 #> 191      0.834      1.047      TRUE  0.213 0.581  0.366 0.714 #> 192     -0.534     -0.061      TRUE  0.473 0.492  0.962 0.336 #> 193     -0.013      0.406      TRUE  0.420 0.496  0.846 0.398 #> 194     -1.449     -0.607      TRUE  0.842 0.580  1.452 0.146 #> 195     -1.046     -1.390      TRUE -0.345 0.600 -0.575 0.565 #> 196      0.280     -0.244      TRUE -0.524 0.491 -1.068 0.286 #> 197     -0.719     -1.629      TRUE -0.910 0.608 -1.495 0.135 #> 198     -0.864     -1.645      TRUE -0.781 0.618 -1.263 0.206 #> 199      1.356      1.427      TRUE  0.071 0.665  0.107 0.915 #> 200     -0.813     -1.227      TRUE -0.414 0.565 -0.732 0.464 #> 201      0.455      0.406      TRUE -0.049 0.511 -0.096 0.923 #> 202      0.809      0.356      TRUE -0.453 0.532 -0.851 0.395 #> 203     -1.403     -1.384      TRUE  0.020 0.633  0.031 0.975 #> 204      0.082     -0.052      TRUE -0.133 0.485 -0.275 0.783 #> 205     -0.021      0.020      TRUE  0.041 0.484  0.085 0.932 #> 206      0.509      0.218      TRUE -0.291 0.506 -0.575 0.565 #> 207      1.331      1.628      TRUE  0.297 0.683  0.434 0.664 #> 208      0.824      1.009      TRUE  0.185 0.577  0.320 0.749 #> 209      1.662      1.707      TRUE  0.045 0.725  0.061 0.951 #> 210     -1.481     -2.133      TRUE -0.651 0.737 -0.883 0.377 #> 211     -0.151      0.141      TRUE  0.293 0.486  0.602 0.547 #> 212      0.268      0.477      TRUE  0.209 0.506  0.413  0.68 #> 213      1.175      0.763      TRUE -0.412 0.588 -0.700 0.484 #> 214     -1.554     -1.443      TRUE  0.111 0.656  0.170 0.865 #> 215     -1.395     -1.021      TRUE  0.374 0.598  0.626 0.532 #> 216      0.644      1.470      TRUE  0.826 0.612  1.350 0.177 #> 217      0.762      0.317      TRUE -0.445 0.527 -0.845 0.398 #> 218     -1.186     -0.858      TRUE  0.329 0.564  0.583  0.56 #> 219     -0.128     -0.455      TRUE -0.327 0.489 -0.669 0.503 #> 220     -2.133     -1.854      TRUE  0.279 0.778  0.358  0.72 #> 221      0.809      0.333      TRUE -0.476 0.531 -0.896  0.37 #> 222     -1.432     -1.660      TRUE -0.228 0.668 -0.341 0.733 #> 223     -0.774     -0.017      TRUE  0.757 0.505  1.500 0.133 #> 224     -0.236      0.910      TRUE  1.146 0.532  2.155 0.031 #> 225      0.411      0.628      TRUE  0.218 0.521  0.418 0.676 #> 226      0.741      0.542      TRUE -0.199 0.536 -0.372  0.71 #> 227      0.273      0.123      TRUE -0.150 0.492 -0.305 0.761 #> 228     -0.121     -0.127      TRUE -0.006 0.483 -0.013  0.99 #> 229      1.481      0.947      TRUE -0.534 0.634 -0.842   0.4 #> 230     -1.577     -1.495      TRUE  0.082 0.665  0.123 0.902 #> 231     -0.718     -0.224      TRUE  0.494 0.502  0.985 0.325 #> 232      0.073      0.782      TRUE  0.709 0.522  1.358 0.174 #> 233      0.424      0.548      TRUE  0.124 0.517  0.240  0.81 #> 234      0.424      1.400      TRUE  0.975 0.593  1.644   0.1 #> 235      0.510     -0.562      TRUE -1.071 0.511 -2.097 0.036 #> 236     -0.269     -0.372      TRUE -0.103 0.487 -0.211 0.833 #> 237     -0.318     -0.243      TRUE  0.075 0.486  0.155 0.877 #> 238     -0.579      0.279      TRUE  0.858 0.501  1.714 0.086 #> 239     -0.072     -0.135      TRUE -0.063 0.483 -0.130 0.896 #> 240     -0.539      0.226      TRUE  0.765 0.497  1.538 0.124 #> 241      1.353      1.662      TRUE  0.310 0.689  0.449 0.653 #> 242     -1.018     -1.260      TRUE -0.242 0.583 -0.414 0.679 #> 243     -1.793     -1.645      TRUE  0.148 0.708  0.209 0.834 #> 244     -1.305     -1.824      TRUE -0.519 0.677 -0.767 0.443 #> 245     -0.877     -0.782      TRUE  0.095 0.533  0.178 0.859 #> 246     -0.979     -1.136      TRUE -0.158 0.568 -0.278 0.781 #> 247      1.288      1.483      TRUE  0.195 0.664  0.293 0.769 #> 248      2.251      1.595      TRUE -0.656 0.779 -0.842   0.4 #> 249     -0.192     -0.129      TRUE  0.063 0.483  0.130 0.897 #> 250      0.804      1.461      TRUE  0.657 0.622  1.057 0.291 #> 251      0.843      0.406      TRUE -0.437 0.537 -0.814 0.416 #> 252     -0.204     -0.179      TRUE  0.025 0.483  0.053 0.958 #> 253     -0.379     -0.135      TRUE  0.244 0.486  0.502 0.616 #> 254      0.253      0.346      TRUE  0.093 0.499  0.186 0.852 #> 255      1.624      1.229      TRUE -0.395 0.674 -0.586 0.558 #> 256     -0.031      0.341      TRUE  0.372 0.493  0.755  0.45 #> 257      1.546      1.096      TRUE -0.450 0.653 -0.688 0.491 #> 258      0.004      0.183      TRUE  0.180 0.488  0.368 0.713 #> 259     -0.997     -1.336      TRUE -0.340 0.590 -0.576 0.564 #> 260      0.215      0.633      TRUE  0.417 0.514  0.812 0.417 #> 261      0.687      0.251      TRUE -0.436 0.519 -0.840 0.401 #> 262      0.779      0.500      TRUE -0.279 0.537 -0.519 0.604 #> 263      1.953      1.437      TRUE -0.517 0.730 -0.708 0.479 #> 264     -0.856     -0.750      TRUE  0.106 0.529  0.201 0.841 #> 265      1.482      1.433      TRUE -0.050 0.678 -0.073 0.942 #> 266     -0.179      0.385      TRUE  0.563 0.495  1.138 0.255 #> 267     -1.002     -0.592      TRUE  0.411 0.532  0.772  0.44 #> 268      0.860      0.373      TRUE -0.486 0.537 -0.905 0.365 #> 269     -0.348     -0.435      TRUE -0.087 0.491 -0.178 0.859 #> 270     -0.270      0.211      TRUE  0.481 0.489  0.983 0.326 #> 271     -1.862     -1.588      TRUE  0.274 0.711  0.385   0.7 #> 272     -0.369     -0.643      TRUE -0.274 0.500 -0.549 0.583 #> 273     -0.704     -0.665      TRUE  0.039 0.515  0.075  0.94 #> 274      1.431      1.112      TRUE -0.319 0.642 -0.496  0.62 #> 275      0.544      0.213      TRUE -0.331 0.508 -0.652 0.515 #> 276     -1.431     -1.876      TRUE -0.444 0.696 -0.638 0.523 #> 277     -0.233     -0.083      TRUE  0.151 0.483  0.312 0.755 #> 278     -1.633     -2.133      TRUE -0.500 0.753 -0.664 0.507 #> 279      0.208      0.290      TRUE  0.082 0.495  0.166 0.868 #> 280      1.163      1.427      TRUE  0.264 0.646  0.408 0.683 #> 281      0.988      1.280      TRUE  0.292 0.616  0.474 0.636 #> 282      0.796      1.009      TRUE  0.213 0.575  0.370 0.711 #> 283      1.019      1.064      TRUE  0.045 0.598  0.076  0.94 #> 284     -1.192     -1.861      TRUE -0.669 0.672 -0.996 0.319 #> 285      1.163      1.678      TRUE  0.515 0.674  0.764 0.445 #> 286      0.084     -0.365      TRUE -0.449 0.488 -0.920 0.358 #> 287      0.370      0.728      TRUE  0.358 0.526  0.680 0.496 #> 288      0.896      1.431      TRUE  0.535 0.625  0.856 0.392 #> 289      1.413      0.898      TRUE -0.514 0.623 -0.826 0.409 #> 290      0.878      0.408      TRUE -0.471 0.540 -0.871 0.384 #> 291      0.867      0.569      TRUE -0.299 0.548 -0.545 0.585 #> 292      0.083      0.002      TRUE -0.082 0.485 -0.168 0.866 #> 293     -2.133     -1.403      TRUE  0.729 0.730  0.999 0.318 #> 294      0.289     -0.243      TRUE -0.533 0.491 -1.084 0.278 #> 295     -1.058     -0.487      TRUE  0.571 0.533  1.070 0.284 #> 296      1.090      0.801      TRUE -0.290 0.583 -0.497 0.619 #> 297      1.574      1.297      TRUE -0.277 0.674 -0.411 0.681 #> 298     -0.235     -0.406      TRUE -0.171 0.488 -0.350 0.727 #> 299      1.635      0.461      TRUE -1.174 0.622 -1.887 0.059 #> 300     -2.133     -1.861      TRUE  0.272 0.779  0.349 0.727 #> 301     -0.984      0.084      TRUE  1.068 0.522  2.046 0.041 #> 302     -0.068     -0.273      TRUE -0.204 0.484 -0.422 0.673 #> 303     -0.845     -1.609      TRUE -0.764 0.612 -1.248 0.212 #> 304      1.972      1.476      TRUE -0.496 0.736 -0.675   0.5 #> 305      0.125     -0.538      TRUE -0.663 0.494 -1.340  0.18 #> 306      0.785      1.022      TRUE  0.237 0.576  0.412 0.681 #> 307     -0.048      0.324      TRUE  0.372 0.492  0.757 0.449 #> 308      0.251     -0.111      TRUE -0.362 0.489 -0.739  0.46 #> 309     -0.114     -0.508      TRUE -0.394 0.491 -0.803 0.422 #> 310     -0.238     -0.745      TRUE -0.507 0.503 -1.007 0.314 #> 311      0.837      0.901      TRUE  0.064 0.569  0.113  0.91 #> 312      1.010      0.146      TRUE -0.865 0.543 -1.592 0.111 #> 313     -0.809     -1.004      TRUE -0.194 0.544 -0.357 0.721 #> 314      0.255      0.215      TRUE -0.040 0.494 -0.081 0.935 #> 315     -0.380     -0.574      TRUE -0.194 0.497 -0.389 0.697 #> 316     -0.088      0.094      TRUE  0.182 0.485  0.376 0.707 #> 317     -0.480      0.272      TRUE  0.752 0.496  1.514  0.13 #> 318     -1.821     -0.874      TRUE  0.947 0.643  1.471 0.141 #> 319      0.011      0.000      TRUE -0.011 0.484 -0.023 0.982 #> 320      0.465      0.106      TRUE -0.358 0.501 -0.716 0.474 #> 321      0.483     -0.025      TRUE -0.508 0.500 -1.016  0.31 #> 322      0.603     -0.292      TRUE -0.895 0.509 -1.760 0.078 #> 323     -1.793     -1.495      TRUE  0.298 0.692  0.431 0.666 #> 324      0.575      0.654      TRUE  0.080 0.532  0.150 0.881 #> 325      0.496      0.624      TRUE  0.127 0.525  0.242 0.808 #> 326      0.683      0.552      TRUE -0.131 0.533 -0.246 0.806 #> 327     -0.578     -0.635      TRUE -0.057 0.507 -0.113  0.91 #> 328     -0.132      0.314      TRUE  0.447 0.491  0.909 0.364 #> 329      0.525      0.555      TRUE  0.030 0.523  0.058 0.954 #> 330     -0.648      0.534      TRUE  1.181 0.516  2.288 0.022 #> 331      0.358      0.783      TRUE  0.425 0.530  0.802 0.423 #> 332     -0.182     -0.859      TRUE -0.677 0.511 -1.326 0.185 #> 333      0.575      0.305      TRUE -0.269 0.513 -0.525   0.6 #> 334      0.543      0.792      TRUE  0.249 0.540  0.461 0.645 #> 335     -0.068      0.230      TRUE  0.297 0.488  0.608 0.543 #> 336      0.018     -0.276      TRUE -0.294 0.485 -0.606 0.545 #> 337      0.468      0.446      TRUE -0.022 0.513 -0.042 0.966 #> 338      1.082      0.610      TRUE -0.472 0.569 -0.828 0.408 #> 339     -0.797     -0.082      TRUE  0.715 0.506  1.413 0.158 #> 340      1.350      1.084      TRUE -0.266 0.631 -0.421 0.674 #> 341      0.407      0.718      TRUE  0.311 0.527  0.590 0.555 #> 342     -0.607     -0.720      TRUE -0.113 0.513 -0.220 0.826 #> 343     -0.949     -0.043      TRUE  0.906 0.517  1.751  0.08 #> 344     -0.688     -1.058      TRUE -0.370 0.542 -0.683 0.495 #> 345     -0.748     -0.283      TRUE  0.465 0.504  0.923 0.356 #> 346      0.379     -0.363      TRUE -0.742 0.497 -1.492 0.136 #> 347      0.169      0.343      TRUE  0.175 0.496  0.352 0.725 #> 348     -0.444      0.075      TRUE  0.518 0.490  1.058  0.29 #> 349     -0.861     -0.613      TRUE  0.249 0.522  0.477 0.634 #> 350      0.235      0.299      TRUE  0.064 0.497  0.129 0.897 #> 351     -0.268     -0.238      TRUE  0.030 0.485  0.063  0.95 #> 352      1.610      1.046      TRUE -0.564 0.656 -0.859  0.39 #> 353     -0.267      0.103      TRUE  0.369 0.486  0.760 0.447 #> 354     -0.962     -1.295      TRUE -0.333 0.583 -0.571 0.568 #> 355      0.393      1.483      TRUE  1.090 0.601  1.813  0.07 #> 356      1.016      0.671      TRUE -0.344 0.567 -0.607 0.544 #> 357     -0.203      0.359      TRUE  0.562 0.494  1.139 0.255 #> 358      0.033     -0.544      TRUE -0.577 0.493 -1.171 0.242 #> 359     -1.876     -1.197      TRUE  0.679 0.674  1.007 0.314 #> 360     -0.026      0.341      TRUE  0.368 0.493  0.746 0.455 #> 361     -0.752     -0.800      TRUE -0.048 0.526 -0.091 0.927 #> 362      0.706      0.838      TRUE  0.133 0.554  0.239 0.811 #> 363     -0.154      0.351      TRUE  0.505 0.493  1.024 0.306 #> 364      0.552      0.863      TRUE  0.311 0.546  0.569 0.569 #> 365     -0.232     -1.007      TRUE -0.775 0.523 -1.482 0.138 #> 366      1.229      1.309      TRUE  0.080 0.641  0.124 0.901 #> 367     -0.901     -1.513      TRUE -0.612 0.604 -1.015  0.31 #> 368      0.350     -0.035      TRUE -0.385 0.493 -0.781 0.435 #> 369     -1.293     -0.073      TRUE  1.220 0.551  2.214 0.027 #> 370      0.279      0.458      TRUE  0.179 0.505  0.354 0.723 #> 371      0.786      1.531      TRUE  0.745 0.628  1.187 0.235 #> 372     -0.170      0.296      TRUE  0.467 0.491  0.950 0.342 #> 373     -0.479     -0.199      TRUE  0.280 0.490  0.571 0.568 #> 374     -1.039     -0.627      TRUE  0.412 0.537  0.767 0.443 #> 375      0.097     -0.872      TRUE -0.970 0.513 -1.889 0.059 #> 376      1.252      0.813      TRUE -0.438 0.600 -0.731 0.465 #> 377      1.041      1.017      TRUE -0.023 0.596 -0.039 0.969 #> 378      0.526      0.448      TRUE -0.078 0.517 -0.152  0.88 #> 379     -2.133     -1.409      TRUE  0.723 0.730  0.990 0.322 #> 380     -0.630     -0.446      TRUE  0.184 0.501  0.367 0.714 #> 381     -0.659     -0.404      TRUE  0.254 0.502  0.507 0.612 #> 382     -0.538     -0.527      TRUE  0.012 0.500  0.023 0.982 #> 383     -0.701     -0.207      TRUE  0.494 0.500  0.987 0.324 #> 384     -1.109     -1.071      TRUE  0.038 0.573  0.065 0.948 #> 385     -1.214     -0.948      TRUE  0.265 0.573  0.463 0.643 #> 386     -1.577     -0.660      TRUE  0.917 0.598  1.533 0.125 #> 387     -0.237     -0.039      TRUE  0.198 0.484  0.409 0.682 #> 388      1.970      0.778      TRUE -1.192 0.680 -1.753  0.08 #> 389     -1.189     -0.742      TRUE  0.447 0.557  0.803 0.422 #> 390     -2.133     -1.492      TRUE  0.641 0.738  0.868 0.385 #> 391      1.056      0.679      TRUE -0.378 0.571 -0.661 0.509 #> 392      0.174     -1.067      TRUE -1.240 0.531 -2.335  0.02 #> 393     -1.005     -0.480      TRUE  0.525 0.528  0.995  0.32 #> 394     -1.459     -1.685      TRUE -0.226 0.674 -0.335 0.738 #> 395     -0.321      0.380      TRUE  0.701 0.497  1.412 0.158 #> 396      0.515      0.275      TRUE -0.240 0.509 -0.472 0.637 #> 397      0.900      0.892      TRUE -0.008 0.573 -0.013 0.989 #> 398     -1.495     -0.944      TRUE  0.551 0.604  0.911 0.362 #> 399      0.493     -0.680      TRUE -1.173 0.516 -2.275 0.023 #> 400      0.846     -0.109      TRUE -0.955 0.526 -1.817 0.069 #> 401     -0.437     -0.204      TRUE  0.233 0.488  0.478 0.633 #> 402     -1.117     -1.387      TRUE -0.270 0.605 -0.446 0.655 #> 403     -0.021      0.116      TRUE  0.137 0.486  0.283 0.777 #> 404      1.379      1.433      TRUE  0.053 0.668  0.080 0.936 #> 405     -1.876     -1.013      TRUE  0.862 0.660  1.306 0.192 #> 406     -1.097     -1.481      TRUE -0.384 0.614 -0.625 0.532 #> 407     -0.404     -0.073      TRUE  0.332 0.487  0.681 0.496 #> 408     -0.429      0.098      TRUE  0.527 0.490  1.076 0.282 #> 409      0.251      0.492      TRUE  0.241 0.506  0.477 0.634 #> 410     -0.212     -0.655      TRUE -0.443 0.498 -0.891 0.373 #> 411     -0.305     -1.038      TRUE -0.732 0.527 -1.390 0.164 #> 412      0.920      0.138      TRUE -0.782 0.535 -1.463 0.143 #> 413     -0.810     -1.296      TRUE -0.486 0.572 -0.848 0.396 #> 414      1.101      1.420      TRUE  0.319 0.640  0.498 0.618 #> 415      0.082      0.805      TRUE  0.723 0.524  1.380 0.167 #> 416      0.750      0.364      TRUE -0.385 0.528 -0.730 0.465 #> 417      0.665      0.872      TRUE  0.206 0.554  0.373 0.709 #> 418     -0.836     -0.634      TRUE  0.202 0.521  0.387 0.699 #> 419     -0.834     -0.041      TRUE  0.794 0.509  1.560 0.119 #> 420      0.134      0.592      TRUE  0.458 0.509  0.899 0.368 #> 421     -1.249     -1.645      TRUE -0.397 0.648 -0.612  0.54 #> 422      1.434      1.435      TRUE  0.001 0.673  0.002 0.998 #> 423      0.034      0.274      TRUE  0.240 0.491  0.489 0.625 #> 424      0.928      0.478      TRUE -0.451 0.548 -0.823 0.411 #> 425      1.093     -0.256      TRUE -1.348 0.549 -2.454 0.014 #> 426      0.826      1.069      TRUE  0.243 0.583  0.418 0.676 #> 427      0.155     -0.483      TRUE -0.638 0.493 -1.295 0.195 #> 428     -0.260      0.130      TRUE  0.390 0.487  0.802 0.423 #> 429      0.404      0.520      TRUE  0.116 0.514  0.226 0.822 #> 430     -0.198      0.085      TRUE  0.282 0.485  0.582  0.56 #> 431      1.015      0.756      TRUE -0.258 0.573 -0.451 0.652 #> 432     -1.876     -1.108      TRUE  0.768 0.667  1.151  0.25 #> 433     -1.189     -1.331      TRUE -0.142 0.605 -0.234 0.815 #> 434      0.276      0.784      TRUE  0.508 0.527  0.964 0.335 #> 435     -1.446     -1.143      TRUE  0.303 0.614  0.494 0.622 #> 436     -0.471      0.163      TRUE  0.634 0.493  1.287 0.198 #> 437     -1.418     -2.133      TRUE -0.714 0.731 -0.977 0.328 #> 438      0.564      0.693      TRUE  0.129 0.534  0.241 0.809 #> 439      1.592      0.623      TRUE -0.969 0.625 -1.549 0.121 #> 440     -0.591      0.379      TRUE  0.970 0.505  1.920 0.055 #> 441      0.763      0.389      TRUE -0.374 0.530 -0.705 0.481 #> 442     -1.090     -0.748      TRUE  0.342 0.548  0.625 0.532 #> 443      0.058     -0.020      TRUE -0.078 0.484 -0.161 0.872 #> 444      1.635      1.499      TRUE -0.136 0.701 -0.194 0.846 #> 445      1.379      1.211      TRUE -0.168 0.646 -0.260 0.795 #> 446      1.172      1.299      TRUE  0.127 0.634  0.201 0.841 #> 447     -2.133     -2.133      TRUE  0.000 0.814  0.000     1 #> 448      0.171     -0.076      TRUE -0.248 0.487 -0.509 0.611 #> 449     -1.035     -0.602      TRUE  0.433 0.536  0.808 0.419 #> 450     -1.710     -0.945      TRUE  0.765 0.632  1.210 0.226 #> 451      1.946      1.587      TRUE -0.359 0.743 -0.483 0.629 #> 452     -0.348     -0.893      TRUE -0.544 0.515 -1.056 0.291 #> 453     -0.248      0.158      TRUE  0.406 0.487  0.833 0.405 #> 454     -0.865     -0.051      TRUE  0.814 0.511  1.594 0.111 #> 455      1.527      1.389      TRUE -0.138 0.678 -0.204 0.839 #> 456      0.432      0.178      TRUE -0.254 0.501 -0.507 0.612 #> 457     -0.794     -0.264      TRUE  0.530 0.507  1.046 0.296 #> 458     -1.586     -0.841      TRUE  0.745 0.609  1.223 0.221 #> 459     -1.878     -1.587      TRUE  0.290 0.713  0.407 0.684 #> 460      1.909      1.652      TRUE -0.256 0.746 -0.344 0.731 #> 461      0.889      1.301      TRUE  0.412 0.610  0.675   0.5 #> 462      1.341      0.591      TRUE -0.750 0.595 -1.260 0.208 #> 463      0.457      0.746      TRUE  0.289 0.532  0.544 0.587 #> 464      0.713      0.733      TRUE  0.020 0.547  0.037 0.971 #> 465     -0.649     -0.029      TRUE  0.620 0.497  1.247 0.212 #> 466     -0.197     -0.976      TRUE -0.780 0.520 -1.500 0.134 #> 467      1.252      1.003      TRUE -0.248 0.615 -0.404 0.686 #> 468     -1.250     -1.442      TRUE -0.192 0.623 -0.308 0.758 #> 469     -1.629     -0.540      TRUE  1.089 0.601  1.813  0.07 #> 470      0.715     -0.029      TRUE -0.744 0.515 -1.445 0.149 #> 471     -0.998     -0.921      TRUE  0.076 0.551  0.139  0.89 #> 472     -0.582     -0.500      TRUE  0.081 0.501  0.163 0.871 #> 473      2.251      1.953      TRUE -0.297 0.815 -0.365 0.715 #> 474     -0.482     -0.279      TRUE  0.203 0.491  0.414 0.679 #> 475     -1.862     -1.629      TRUE  0.233 0.716  0.326 0.745 #> 476      0.921      0.585      TRUE -0.336 0.553 -0.608 0.543 #> 477      1.069      0.020      TRUE -1.050 0.547 -1.919 0.055 #> 478      1.009      0.246      TRUE -0.763 0.546 -1.398 0.162 #> 479      0.217      0.042      TRUE -0.175 0.489 -0.358  0.72 #> 480      0.994      0.881      TRUE -0.113 0.580 -0.194 0.846 #> 481     -0.312     -0.421      TRUE -0.109 0.489 -0.223 0.823 #> 482      0.909      0.378      TRUE -0.532 0.542 -0.981 0.326 #> 483      1.066      1.160      TRUE  0.095 0.611  0.155 0.877 #> 484      0.335      0.294      TRUE -0.041 0.500 -0.081 0.935 #> 485      0.277      0.171      TRUE -0.106 0.494 -0.215  0.83 #> 486     -0.893     -0.448      TRUE  0.445 0.518  0.858 0.391 #> 487     -0.054      0.407      TRUE  0.461 0.496  0.930 0.353 #> 488      0.350      0.643      TRUE  0.293 0.520  0.563 0.573 #> 489      1.205      1.483      TRUE  0.278 0.656  0.424 0.671 #> 490     -0.380     -0.342      TRUE  0.038 0.489  0.077 0.939 #> 491      1.913      1.691      TRUE -0.222 0.750 -0.296 0.767 #> 492     -0.964     -0.877      TRUE  0.087 0.545  0.160 0.873 #> 493      1.943      1.129      TRUE -0.814 0.702 -1.160 0.246 #> 494     -0.324     -0.101      TRUE  0.224 0.485  0.461 0.645 #> 495      0.035      0.922      TRUE  0.887 0.533  1.664 0.096 #> 496     -0.703     -0.681      TRUE  0.022 0.516  0.043 0.966 #> 497      0.352     -0.369      TRUE -0.720 0.496 -1.452 0.147 #> 498     -1.276     -0.186      TRUE  1.090 0.549  1.984 0.047 #> 499     -0.250     -0.190      TRUE  0.060 0.484  0.124 0.902 #> 500     -0.481      0.225      TRUE  0.706 0.495  1.426 0.154 #> 501      0.372      1.213      TRUE  0.841 0.571  1.474  0.14 #> 502      0.379     -0.077      TRUE -0.456 0.494 -0.921 0.357 #> 503     -2.133     -1.854      TRUE  0.279 0.778  0.358  0.72 #> 504     -1.143     -0.860      TRUE  0.283 0.560  0.504 0.614 #> 505     -1.026     -0.657      TRUE  0.369 0.537  0.686 0.493 #> 506      0.167      0.142      TRUE -0.025 0.489 -0.051 0.959 #> 507      1.540      1.252      TRUE -0.289 0.667 -0.433 0.665 #> 508      0.578      0.763      TRUE  0.185 0.540  0.342 0.733 #> 509     -0.724     -0.547      TRUE  0.177 0.510  0.347 0.728 #> 510     -0.371      0.078      TRUE  0.448 0.488  0.919 0.358 #> 511     -0.788      0.044      TRUE  0.832 0.506  1.642 0.101 #> 512     -0.383     -0.007      TRUE  0.376 0.487  0.772  0.44 #> 513     -0.862     -0.715      TRUE  0.147 0.528  0.279  0.78 #> 514     -0.802     -0.158      TRUE  0.644 0.506  1.272 0.203 #> 515     -0.100      0.190      TRUE  0.291 0.487  0.597 0.551 #> 516      1.452      1.364      TRUE -0.088 0.668 -0.132 0.895 #> 517      0.649      0.480      TRUE -0.169 0.526 -0.321 0.748 #> 518     -0.306      0.930      TRUE  1.237 0.535  2.313 0.021 #> 519      0.535      0.813      TRUE  0.278 0.541  0.514 0.607 #> 520      0.522     -0.375      TRUE -0.897 0.505 -1.776 0.076 #> 521      0.695      0.308      TRUE -0.386 0.522 -0.741 0.459 #> 522     -0.637     -1.638      TRUE -1.001 0.606 -1.653 0.098 #> 523      1.331      0.928      TRUE -0.403 0.617 -0.653 0.514 #> 524      0.546      0.643      TRUE  0.098 0.529  0.185 0.854 #> 525      0.704      0.739      TRUE  0.035 0.546  0.064 0.949 #> 526      1.209      0.427      TRUE -0.782 0.573 -1.365 0.172 #> 527      0.379     -0.010      TRUE -0.389 0.495 -0.786 0.432 #> 528      0.838      1.211      TRUE  0.374 0.597  0.625 0.532 #> 529      0.593      0.194      TRUE -0.399 0.511 -0.780 0.435 #> 530      0.020      0.090      TRUE  0.070 0.485  0.145 0.885 #> 531      0.203     -0.429      TRUE -0.632 0.492 -1.283   0.2 #> 532      2.251      2.251      TRUE  0.000 0.846  0.000     1 #> 533      1.245      0.443      TRUE -0.803 0.577 -1.391 0.164 #> 534     -0.528     -0.402      TRUE  0.127 0.495  0.255 0.798 #> 535      1.972      1.662      TRUE -0.310 0.754 -0.411 0.681 #> 536      0.332      0.387      TRUE  0.056 0.504  0.110 0.912 #> 537     -0.121     -0.518      TRUE -0.397 0.491 -0.809 0.419 #> 538     -0.691     -0.914      TRUE -0.223 0.530 -0.421 0.674 #> 539     -0.274     -0.317      TRUE -0.043 0.486 -0.088  0.93 #> 540      0.243      0.334      TRUE  0.091 0.498  0.183 0.855 #> 541     -1.086     -0.472      TRUE  0.614 0.535  1.148 0.251 #> 542     -1.503     -1.315      TRUE  0.188 0.637  0.295 0.768 #> 543     -0.783     -0.861      TRUE -0.078 0.532 -0.146 0.884 #> 544      0.389      0.053      TRUE -0.336 0.496 -0.678 0.498 #> 545     -0.874     -0.738      TRUE  0.136 0.530  0.256 0.798 #> 546      0.255     -0.022      TRUE -0.276 0.490 -0.565 0.572 #> 547      0.775      0.411      TRUE -0.365 0.532 -0.686 0.493 #> 548      0.621      1.013      TRUE  0.392 0.564  0.695 0.487 #> 549      0.400     -0.168      TRUE -0.568 0.495 -1.147 0.251 #> 550      0.238      0.260      TRUE  0.021 0.495  0.043 0.966 #> 551     -0.351     -1.496      TRUE -1.145 0.578 -1.981 0.048 #> 552      0.730      0.617      TRUE -0.113 0.540 -0.209 0.834 #> 553      0.138      0.902      TRUE  0.764 0.533  1.434 0.152 #> 554      0.582      0.407      TRUE -0.175 0.518 -0.338 0.736 #> 555     -1.418     -1.367      TRUE  0.052 0.632  0.082 0.935 #> 556     -0.275      0.317      TRUE  0.592 0.493  1.201  0.23 #> 557      0.015      0.366      TRUE  0.351 0.494  0.711 0.477 #> 558     -0.275      0.369      TRUE  0.644 0.495  1.300 0.193 #> 559      0.223      0.337      TRUE  0.114 0.498  0.229 0.819 #> 560      1.953      1.654      TRUE -0.299 0.751 -0.398  0.69 #> 561      0.361      0.280      TRUE -0.081 0.501 -0.161 0.872 #> 562      0.330     -0.254      TRUE -0.584 0.493 -1.185 0.236 #> 563     -1.228     -0.661      TRUE  0.567 0.557  1.018 0.309 #> 564     -1.058     -2.133      TRUE -1.075 0.701 -1.532 0.125 #> 565      0.741      0.497      TRUE -0.244 0.534 -0.458 0.647 #> 566     -1.165     -1.023      TRUE  0.142 0.574  0.247 0.805 #> 567      1.542      1.147      TRUE -0.395 0.657 -0.600 0.548 #> 568     -1.165     -1.363      TRUE -0.198 0.607 -0.326 0.744 #> 569      1.449      1.913      TRUE  0.464 0.726  0.639 0.523 #> 570      0.106     -0.181      TRUE -0.287 0.485 -0.592 0.554 #> 571      0.962      0.430      TRUE -0.532 0.549 -0.969 0.332 #> 572     -0.139     -0.427      TRUE -0.288 0.488 -0.590 0.555 #> 573      0.981      1.413      TRUE  0.432 0.629  0.686 0.493 #> 574     -0.474      0.294      TRUE  0.767 0.497  1.544 0.123 #> 575     -0.743     -1.588      TRUE -0.846 0.604 -1.400 0.161 #> 576      0.103      0.741      TRUE  0.638 0.519  1.229 0.219 #> 577      0.463      0.418      TRUE -0.045 0.512 -0.088  0.93 #> 578      1.481      0.628      TRUE -0.853 0.613 -1.393 0.164 #> 579     -0.748     -0.130      TRUE  0.618 0.503  1.230 0.219 #> 580      0.257      1.455      TRUE  1.197 0.594  2.017 0.044 #> 581      0.236     -0.064      TRUE -0.301 0.489 -0.615 0.538 #> 582     -0.637      0.411      TRUE  1.049 0.509  2.059 0.039 #> 583      0.094      0.433      TRUE  0.339 0.499  0.680 0.497 #> 584      1.215      1.517      TRUE  0.302 0.661  0.457 0.647 #> 585     -0.304     -0.499      TRUE -0.194 0.492 -0.395 0.693 #> 586     -0.435     -0.073      TRUE  0.362 0.488  0.741 0.458 #> 587      0.315      0.181      TRUE -0.134 0.496 -0.270 0.787 #> 588     -0.147     -0.331      TRUE -0.184 0.485 -0.379 0.705 #> 589     -0.121     -0.801      TRUE -0.680 0.506 -1.344 0.179 #> 590      0.676      0.559      TRUE -0.117 0.532 -0.220 0.825 #> 591      0.901      0.639      TRUE -0.261 0.555 -0.471 0.637 #> 592      1.913      1.036      TRUE -0.877 0.691 -1.269 0.205 #> 593     -0.701     -0.253      TRUE  0.449 0.501  0.895 0.371 #> 594     -0.922     -1.165      TRUE -0.242 0.566 -0.428 0.669 #> 595     -1.004     -0.647      TRUE  0.357 0.535  0.667 0.505 #> 596     -1.060     -1.065      TRUE -0.005 0.568 -0.009 0.993 #> 597     -0.914     -1.003      TRUE -0.088 0.551 -0.160 0.873 #> 598     -0.097     -0.722      TRUE -0.625 0.501 -1.247 0.213 #> 599     -0.118      0.737      TRUE  0.855 0.517  1.654 0.098 #> 600     -0.269      0.290      TRUE  0.560 0.492  1.138 0.255 #> 601     -0.051      0.470      TRUE  0.521 0.499  1.044 0.296 #> 602      0.229      0.035      TRUE -0.194 0.489 -0.396 0.692 #> 603      0.730     -0.024      TRUE -0.754 0.517 -1.461 0.144 #> 604      0.195      0.251      TRUE  0.056 0.494  0.113  0.91 #> 605     -1.398     -1.004      TRUE  0.394 0.597  0.659  0.51 #> 606      0.921      0.746      TRUE -0.175 0.564 -0.310 0.757 #> 607     -1.645     -1.876      TRUE -0.230 0.719 -0.320 0.749 #> 608     -1.379     -1.598      TRUE -0.219 0.655 -0.335 0.738 #> 609     -0.672     -0.803      TRUE -0.131 0.521 -0.251 0.802 #> 610      1.000      0.050      TRUE -0.950 0.541 -1.757 0.079 #> 611     -0.460     -0.658      TRUE -0.197 0.503 -0.392 0.695 #> 612      0.731      1.691      TRUE  0.960 0.643  1.492 0.136 #> 613     -0.333      0.703      TRUE  1.036 0.516  2.007 0.045 #> 614      1.628      0.936      TRUE -0.692 0.650 -1.065 0.287 #> 615     -0.274     -0.716      TRUE -0.442 0.502 -0.880 0.379 #> 616      0.386      0.085      TRUE -0.301 0.496 -0.607 0.544 #> 617     -0.730     -1.334      TRUE -0.604 0.572 -1.057 0.291 #> 618     -0.234     -0.437      TRUE -0.203 0.489 -0.414 0.679 #> 619     -1.232     -1.502      TRUE -0.270 0.629 -0.430 0.667 #> 620     -0.462     -1.092      TRUE -0.629 0.536 -1.175  0.24 #> 621     -0.197      0.066      TRUE  0.264 0.485  0.544 0.586 #> 622      1.224      1.218      TRUE -0.006 0.631 -0.009 0.993 #> 623     -0.952     -1.432      TRUE -0.481 0.597 -0.805 0.421 #> 624      0.552      0.836      TRUE  0.284 0.544  0.522 0.602 #> 625      0.293      0.176      TRUE -0.116 0.495 -0.235 0.814 #> 626      0.716      0.549      TRUE -0.166 0.535 -0.311 0.756 #> 627     -0.985     -0.284      TRUE  0.702 0.522  1.345 0.179 #> 628     -0.589     -0.347      TRUE  0.242 0.497  0.487 0.626 #> 629      0.885     -0.024      TRUE -0.909 0.529 -1.717 0.086 #> 630     -1.492     -1.331      TRUE  0.161 0.637  0.252 0.801 #> 631     -1.367     -1.336      TRUE  0.031 0.624  0.050  0.96 #> 632     -0.279     -0.738      TRUE -0.459 0.503 -0.912 0.362 #> 633     -0.351     -0.966      TRUE -0.614 0.521 -1.179 0.239 #> 634      0.462      1.675      TRUE  1.213 0.627  1.934 0.053 #> 635      1.049      0.838      TRUE -0.211 0.582 -0.362 0.717 #> 636     -0.067      0.125      TRUE  0.191 0.485  0.394 0.693 #> 637     -1.318     -1.331      TRUE -0.013 0.618 -0.021 0.983 #> 638      0.704      0.759      TRUE  0.055 0.548  0.100  0.92 #> 639     -0.050     -0.640      TRUE -0.590 0.497 -1.187 0.235 #> 640     -1.609     -0.909      TRUE  0.700 0.616  1.136 0.256 #> 641      0.910      1.482      TRUE  0.572 0.632  0.906 0.365 #> 642     -0.929     -1.645      TRUE -0.716 0.623 -1.150  0.25 #> 643      0.375      0.565      TRUE  0.190 0.516  0.368 0.713 #> 644     -0.030     -0.471      TRUE -0.441 0.489 -0.902 0.367 #> 645     -1.407     -1.070      TRUE  0.337 0.603  0.559 0.576 #> 646     -1.002     -1.645      TRUE -0.644 0.628 -1.025 0.305 #> 647     -1.471     -0.696      TRUE  0.774 0.587  1.320 0.187 #> 648      0.116     -0.240      TRUE -0.356 0.486 -0.732 0.464 #> 649     -0.181     -0.067      TRUE  0.113 0.483  0.235 0.814 #> 650      1.453      1.254      TRUE -0.199 0.658 -0.302 0.763 #> 651     -0.322      0.054      TRUE  0.376 0.486  0.774 0.439 #> 652     -0.192     -0.175      TRUE  0.017 0.483  0.035 0.972 #> 653      1.345      1.379      TRUE  0.034 0.659  0.052 0.959 #> 654      0.965      0.397      TRUE -0.568 0.547 -1.037   0.3 #> 655      0.880      1.972      TRUE  1.091 0.687  1.589 0.112 #> 656     -0.197      0.812      TRUE  1.008 0.523  1.928 0.054 #> 657      0.507      0.640      TRUE  0.133 0.527  0.252 0.801 #> 658     -0.456      0.369      TRUE  0.825 0.500  1.651 0.099 #> 659      0.111      0.217      TRUE  0.105 0.490  0.214  0.83 #> 660      0.526      0.093      TRUE -0.433 0.504 -0.858 0.391 #> 661     -0.484     -0.488      TRUE -0.004 0.497 -0.009 0.993 #> 662     -0.289     -0.752      TRUE -0.462 0.505 -0.917 0.359 #> 663     -0.383     -0.813      TRUE -0.430 0.511 -0.842   0.4 #> 664      0.586     -0.004      TRUE -0.590 0.506 -1.166 0.244 #> 665      1.407      1.835      TRUE  0.428 0.714  0.600 0.549 #> 666     -0.147     -0.641      TRUE -0.493 0.497 -0.993 0.321 #> 667     -1.346     -1.312      TRUE  0.034 0.619  0.055 0.956 #> 668      1.019      0.311      TRUE -0.708 0.549 -1.290 0.197 #> 669     -0.522     -0.349      TRUE  0.173 0.494  0.351 0.726 #> 670      0.242      0.450      TRUE  0.208 0.504  0.413 0.679 #> 671      0.602      0.536      TRUE -0.066 0.526 -0.125 0.901 #> 672      1.255      2.251      TRUE  0.996 0.749  1.329 0.184 #> 673      0.594     -0.166      TRUE -0.760 0.507 -1.500 0.134 #> 674      0.757      1.190      TRUE  0.433 0.590  0.735 0.463 #> 675     -0.478     -1.432      TRUE -0.954 0.573 -1.664 0.096 #> 676     -0.020     -0.632      TRUE -0.612 0.497 -1.232 0.218 #> 677      0.100      0.436      TRUE  0.336 0.499  0.673 0.501 #> 678     -0.399     -0.212      TRUE  0.186 0.487  0.383 0.702 #> 679     -1.058     -0.412      TRUE  0.646 0.531  1.216 0.224 #> 680     -1.485     -1.023      TRUE  0.461 0.609  0.758 0.449 #> 681      0.618     -0.023      TRUE -0.642 0.508 -1.262 0.207 #> 682     -0.911      0.454      TRUE  1.366 0.529  2.583  0.01 #> 683     -0.943     -0.748      TRUE  0.195 0.536  0.365 0.715 #> 684     -0.153     -0.451      TRUE -0.297 0.489 -0.609 0.543 #> 685      0.573      0.336      TRUE -0.236 0.514 -0.459 0.646 #> 686      1.455      1.943      TRUE  0.489 0.730  0.669 0.503 #> 687      0.087      0.394      TRUE  0.308 0.497  0.619 0.536 #> 688     -0.881      0.082      TRUE  0.963 0.514  1.875 0.061 #> 689     -0.626     -1.032      TRUE -0.405 0.536 -0.756  0.45 #> 690     -1.139     -0.756      TRUE  0.383 0.553  0.693 0.488 #> 691      0.306      0.724      TRUE  0.418 0.524  0.798 0.425 #> 692     -0.600     -1.586      TRUE -0.986 0.597 -1.651 0.099 #> 693     -0.375      0.047      TRUE  0.422 0.487  0.867 0.386 #> 694      0.473      0.095      TRUE -0.378 0.501 -0.754 0.451 #> 695      0.439      1.029      TRUE  0.590 0.555  1.063 0.288 #> 696      1.005      1.040      TRUE  0.035 0.595  0.059 0.953 #> 697      1.188      0.386      TRUE -0.802 0.569 -1.410 0.159 #> 698     -1.365     -1.360      TRUE  0.005 0.626  0.009 0.993 #> 699      0.120      0.897      TRUE  0.777 0.532  1.459 0.144 #> 700      0.318      0.863      TRUE  0.544 0.535  1.017 0.309 #> 701     -1.233     -1.258      TRUE -0.024 0.602 -0.040 0.968 #> 702      2.251      2.251      TRUE  0.000 0.846  0.000     1 #> 703     -0.510      0.053      TRUE  0.563 0.492  1.144 0.252 #> 704     -0.246      0.674      TRUE  0.920 0.513  1.794 0.073 #> 705     -0.700     -0.621      TRUE  0.079 0.512  0.154 0.877 #> 706     -1.511     -1.302      TRUE  0.209 0.636  0.329 0.742 #> 707      0.660      1.191      TRUE  0.532 0.583  0.912 0.362 #> 708     -0.753     -0.508      TRUE  0.244 0.511  0.479 0.632 #> 709     -0.247     -0.295      TRUE -0.048 0.485 -0.098 0.922 #> 710      0.946      1.648      TRUE  0.702 0.653  1.075 0.282 #> 711     -1.351     -1.710      TRUE -0.359 0.666 -0.539  0.59 #> 712     -0.675     -0.852      TRUE -0.177 0.525 -0.338 0.736 #> 713     -0.774     -1.044      TRUE -0.271 0.546 -0.496  0.62 #> 714      0.994      1.190      TRUE  0.196 0.608  0.323 0.747 #> 715      0.364      0.165      TRUE -0.198 0.497 -0.399  0.69 #> 716     -0.221     -0.748      TRUE -0.527 0.503 -1.047 0.295 #> 717     -0.917     -1.552      TRUE -0.635 0.610 -1.042 0.297 #> 718     -1.316     -0.954      TRUE  0.362 0.584  0.619 0.536 #> 719     -1.452     -0.519      TRUE  0.933 0.577  1.618 0.106 #> 720     -1.091     -0.700      TRUE  0.391 0.546  0.717 0.473 #> 721      0.115      0.341      TRUE  0.226 0.495  0.456 0.648 #> 722      1.150      0.604      TRUE -0.545 0.576 -0.947 0.344 #> 723     -1.331     -1.588      TRUE -0.257 0.649 -0.397 0.692 #> 724      0.350     -0.218      TRUE -0.568 0.494 -1.151  0.25 #> 725      1.288      0.920      TRUE -0.368 0.612 -0.602 0.547 #> 726     -0.385     -0.273      TRUE  0.112 0.488  0.230 0.818 #> 727     -0.237     -0.068      TRUE  0.169 0.484  0.349 0.727 #> 728      1.148      0.463      TRUE -0.686 0.568 -1.207 0.227 #> 729      0.274      0.899      TRUE  0.625 0.537  1.164 0.244 #> 730     -0.951     -0.291      TRUE  0.660 0.519  1.272 0.203 #> 731     -0.694     -0.765      TRUE -0.071 0.520 -0.136 0.892 #> 732     -0.998     -1.260      TRUE -0.262 0.582 -0.450 0.653 #> 733     -0.256     -0.708      TRUE -0.452 0.501 -0.902 0.367 #> 734      1.626      1.972      TRUE  0.346 0.750  0.461 0.645 #> 735      0.051      0.112      TRUE  0.061 0.486  0.125   0.9 #> 736      0.096      0.421      TRUE  0.324 0.498  0.651 0.515 #> 737      1.656      2.251      TRUE  0.595 0.785  0.758 0.449 #> 738      0.272     -0.694      TRUE -0.966 0.506 -1.907 0.056 #> 739      1.389      1.258      TRUE -0.131 0.651 -0.202  0.84 #> 740     -1.185     -0.865      TRUE  0.320 0.564  0.567 0.571 #> 741      1.104      0.817      TRUE -0.287 0.585 -0.490 0.624 #> 742     -0.185     -0.140      TRUE  0.046 0.483  0.094 0.925 #> 743     -0.131     -0.676      TRUE -0.545 0.498 -1.094 0.274 #> 744      1.233      0.388      TRUE -0.845 0.574 -1.474  0.14 #> 745      0.780      0.590      TRUE -0.191 0.542 -0.352 0.725 #> 746     -0.401     -0.644      TRUE -0.242 0.501 -0.484 0.628 #> 747     -0.958     -0.052      TRUE  0.906 0.518  1.748  0.08 #> 748     -1.267     -1.689      TRUE -0.422 0.655 -0.644  0.52 #> 749     -0.809     -0.426      TRUE  0.383 0.511  0.749 0.454 #> 750      1.388      0.537      TRUE -0.851 0.597 -1.424 0.154 #> 751      1.039      0.947      TRUE -0.092 0.590 -0.156 0.876 #> 752     -0.873     -0.645      TRUE  0.228 0.525  0.435 0.664 #> 753      0.054      0.368      TRUE  0.314 0.495  0.635 0.526 #> 754      1.211      0.546      TRUE -0.665 0.579 -1.150  0.25 #> 755      0.403      0.377      TRUE -0.026 0.507 -0.051 0.959 #> 756      0.477      0.660      TRUE  0.183 0.527  0.348 0.728 #> 757      0.786     -0.051      TRUE -0.837 0.521 -1.607 0.108 #> 758      0.230      0.796      TRUE  0.566 0.527  1.075 0.282 #> 759     -1.689     -2.133      TRUE -0.444 0.759 -0.584 0.559 #> 760      0.546      1.315      TRUE  0.769 0.590  1.304 0.192 #> 761      1.398      1.943      TRUE  0.546 0.725  0.752 0.452 #> 762     -1.050     -1.094      TRUE -0.044 0.570 -0.078 0.938 #> 763      0.088     -0.505      TRUE -0.593 0.492 -1.205 0.228 #> 764      1.031      0.858      TRUE -0.173 0.582 -0.297 0.766 #> 765      0.042      0.302      TRUE  0.261 0.492  0.530 0.596 #> 766     -1.401     -1.627      TRUE -0.225 0.660 -0.341 0.733 #> 767      1.008      0.958      TRUE -0.050 0.588 -0.085 0.932 #> 768      0.830      0.473      TRUE -0.356 0.539 -0.661 0.509 #> 769      1.013      0.691      TRUE -0.323 0.568 -0.568  0.57 #> 770     -0.479     -1.255      TRUE -0.776 0.553 -1.405  0.16 #> 771     -0.433     -1.192      TRUE -0.759 0.545 -1.394 0.163 #> 772      0.939      0.778      TRUE -0.160 0.568 -0.283 0.778 #> 773      0.150      0.295      TRUE  0.145 0.494  0.293  0.77 #> 774     -1.588     -1.862      TRUE -0.274 0.711 -0.385   0.7 #> 775     -1.295     -0.605      TRUE  0.690 0.562  1.228 0.219 #> 776      1.087      1.207      TRUE  0.119 0.617  0.193 0.847 #> 777      0.733     -0.209      TRUE -0.942 0.517 -1.822 0.068 #> 778      0.778      0.789      TRUE  0.011 0.555  0.020 0.984 #> 779      0.808      0.567      TRUE -0.242 0.543 -0.446 0.656 #> 780      0.606      0.012      TRUE -0.594 0.508 -1.169 0.242 #> 781      0.687      0.170      TRUE -0.517 0.517 -1.002 0.316 #> 782     -0.809      0.563      TRUE  1.372 0.528  2.601 0.009 #> 783      0.268      0.415      TRUE  0.147 0.503  0.293 0.769 #> 784     -0.424     -0.242      TRUE  0.182 0.488  0.373 0.709 #> 785      1.459      1.152      TRUE -0.307 0.649 -0.473 0.636 #> 786      0.191      0.045      TRUE -0.146 0.488 -0.299 0.765 #> 787      0.403      0.141      TRUE -0.262 0.498 -0.525 0.599 #> 788     -0.539     -0.191      TRUE  0.348 0.492  0.708 0.479 #> 789     -1.439     -1.627      TRUE -0.187 0.664 -0.282 0.778 #> 790     -1.736     -1.300      TRUE  0.436 0.664  0.656 0.512 #> 791     -1.336     -0.285      TRUE  1.051 0.557  1.887 0.059 #> 792      0.858      1.046      TRUE  0.188 0.583  0.323 0.747 #> 793     -0.993     -0.467      TRUE  0.526 0.527  0.999 0.318 #> 794      0.828      1.307      TRUE  0.479 0.607  0.789  0.43 #> 795      1.013      0.538      TRUE -0.475 0.559 -0.849 0.396 #> 796     -0.323     -0.472      TRUE -0.149 0.491 -0.304 0.761 #> 797     -0.558     -1.119      TRUE -0.561 0.542 -1.036   0.3 #> 798     -0.556     -0.604      TRUE -0.047 0.504 -0.094 0.925 #> 799      0.116     -0.123      TRUE -0.239 0.485 -0.493 0.622 #> 800     -0.155      0.220      TRUE  0.375 0.488  0.768 0.442 #> 801     -0.631     -1.284      TRUE -0.653 0.562 -1.163 0.245 #> 802     -0.420     -1.459      TRUE -1.040 0.575 -1.809  0.07 #> 803     -0.146     -0.121      TRUE  0.025 0.483  0.053 0.958 #> 804      1.320      0.787      TRUE -0.532 0.605 -0.880 0.379 #> 805     -0.598     -0.409      TRUE  0.189 0.499  0.379 0.705 #> 806      0.749      0.563      TRUE -0.186 0.538 -0.346 0.729 #> 807     -0.713      0.396      TRUE  1.109 0.513  2.163 0.031 #> 808     -0.561     -0.246      TRUE  0.315 0.494  0.639 0.523 #> 809      1.482      1.382      TRUE -0.100 0.673 -0.149 0.882 #> 810     -1.365     -0.660      TRUE  0.705 0.572  1.233 0.218 #> 811      1.035      1.486      TRUE  0.451 0.642  0.703 0.482 #> 812      0.053      0.095      TRUE  0.041 0.486  0.085 0.933 #> 813     -0.428     -1.645      TRUE -1.218 0.600 -2.031 0.042 #> 814      0.435      0.622      TRUE  0.187 0.522  0.359  0.72 #> 815     -0.318     -0.056      TRUE  0.262 0.485  0.540 0.589 #> 816     -0.273     -0.448      TRUE -0.175 0.490 -0.358 0.721 #> 817      1.041     -0.706      TRUE -1.747 0.559 -3.125 0.002 #> 818      0.108      0.189      TRUE  0.081 0.489  0.165 0.869 #> 819     -0.085      0.660      TRUE  0.745 0.511  1.459 0.145 #> 820     -0.566     -0.836      TRUE -0.270 0.518 -0.522 0.602 #> 821      0.455      0.427      TRUE -0.028 0.512 -0.054 0.957 #> 822     -0.163      0.496      TRUE  0.659 0.501  1.316 0.188 #> 823     -1.139     -1.117      TRUE  0.022 0.580  0.037  0.97 #> 824      1.382      1.691      TRUE  0.309 0.695  0.445 0.657 #> 825     -0.600     -0.701      TRUE -0.101 0.511 -0.197 0.844 #> 826     -0.806     -0.478      TRUE  0.329 0.513  0.641 0.521 #> 827      0.879      0.730      TRUE -0.148 0.559 -0.266 0.791 #> 828     -1.219     -0.412      TRUE  0.807 0.547  1.476  0.14 #> 829     -1.225     -1.329      TRUE -0.104 0.609 -0.171 0.864 #> 830      2.251      1.221      TRUE -1.029 0.746 -1.379 0.168 #> 831     -0.259     -0.839      TRUE -0.580 0.510 -1.138 0.255 #> 832      0.500      1.441      TRUE  0.941 0.601  1.565 0.118 #> 833      0.840      0.970      TRUE  0.131 0.575  0.227  0.82 #> 834      1.077      1.403      TRUE  0.327 0.636  0.513 0.608 #> 835     -0.578     -0.846      TRUE -0.268 0.520 -0.515 0.606 #> 836      1.234      1.145      TRUE -0.089 0.625 -0.143 0.887 #> 837     -0.229     -0.177      TRUE  0.053 0.484  0.109 0.913 #> 838      0.014      1.194      TRUE  1.180 0.560  2.108 0.035 #> 839     -0.100      0.305      TRUE  0.405 0.491  0.825  0.41 #> 840      1.207      1.266      TRUE  0.059 0.634  0.092 0.926 #> 841      0.806      0.971      TRUE  0.165 0.573  0.289 0.773 #> 842      0.451      0.358      TRUE -0.093 0.508 -0.183 0.855 #> 843      1.013      1.078      TRUE  0.065 0.599  0.109 0.913 #> 844     -0.058     -0.353      TRUE -0.294 0.486 -0.606 0.544 #> 845      0.221     -0.099      TRUE -0.320 0.488 -0.655 0.513 #> 846      0.114      0.463      TRUE  0.349 0.501  0.697 0.486 #> 847     -0.330     -0.571      TRUE -0.241 0.496 -0.486 0.627 #> 848     -0.461     -1.397      TRUE -0.936 0.568 -1.646   0.1 #> 849     -0.883     -0.892      TRUE -0.009 0.540 -0.017 0.986 #> 850      1.913      1.113      TRUE -0.799 0.697 -1.147 0.251 #> 851      0.872      0.853      TRUE -0.019 0.568 -0.033 0.973 #> 852      0.494     -0.364      TRUE -0.858 0.503 -1.705 0.088 #> 853     -0.079      0.008      TRUE  0.087 0.483  0.179 0.858 #> 854     -0.475     -0.220      TRUE  0.255 0.490  0.520 0.603 #> 855     -0.148     -0.304      TRUE -0.156 0.485 -0.322 0.747 #> 856      0.442      0.549      TRUE  0.106 0.518  0.206 0.837 #> 857      0.031     -0.432      TRUE -0.463 0.489 -0.946 0.344 #> 858      0.520     -0.123      TRUE -0.643 0.502 -1.281   0.2 #> 859      0.007      0.026      TRUE  0.018 0.484  0.038  0.97 #> 860     -0.936     -0.471      TRUE  0.465 0.522  0.890 0.374 #> 861     -0.997     -1.183      TRUE -0.186 0.574 -0.324 0.746 #> 862      0.455      0.660      TRUE  0.205 0.526  0.390 0.696 #> 863     -1.265     -0.726      TRUE  0.538 0.564  0.954  0.34 #> 864     -0.363     -0.956      TRUE -0.593 0.521 -1.139 0.255 #> 865      0.074      0.378      TRUE  0.304 0.496  0.614 0.539 #> 866      0.482      0.477      TRUE -0.005 0.516 -0.010 0.992 #> 867     -0.050     -0.009      TRUE  0.041 0.483  0.084 0.933 #> 868      0.435      0.509      TRUE  0.074 0.515  0.144 0.885 #> 869     -0.075     -0.572      TRUE -0.497 0.493 -1.008 0.313 #> 870      0.613      0.563      TRUE -0.050 0.528 -0.095 0.924 #> 871      0.563      0.482      TRUE -0.081 0.521 -0.155 0.877 #> 872     -0.196     -0.026      TRUE  0.169 0.483  0.350 0.726 #> 873     -1.876     -1.854      TRUE  0.022 0.744  0.029 0.977 #> 874     -0.394      0.301      TRUE  0.695 0.495  1.405  0.16 #> 875      0.727      1.040      TRUE  0.313 0.573  0.547 0.585 #> 876     -0.108     -0.295      TRUE -0.187 0.484 -0.386 0.699 #> 877      1.165      1.296      TRUE  0.131 0.633  0.206 0.837 #> 878      0.629      0.789      TRUE  0.160 0.545  0.293 0.769 #> 879     -0.390     -0.092      TRUE  0.298 0.487  0.612  0.54 #> 880     -0.691     -1.325      TRUE -0.633 0.569 -1.113 0.266 #> 881     -0.745     -1.503      TRUE -0.758 0.593 -1.279 0.201 #> 882     -0.548     -0.050      TRUE  0.498 0.492  1.012 0.311 #> 883      0.196      0.117      TRUE -0.078 0.490 -0.160 0.873 #> 884     -0.735     -0.782      TRUE -0.047 0.523 -0.091 0.928 #> 885      0.730      0.629      TRUE -0.101 0.541 -0.187 0.852 #> 886     -1.062     -0.461      TRUE  0.601 0.533  1.128 0.259 #> 887     -1.097     -0.144      TRUE  0.953 0.530  1.796 0.073 #> 888     -0.074     -0.490      TRUE -0.415 0.490 -0.848 0.396 #> 889     -1.638     -0.667      TRUE  0.971 0.607  1.600  0.11 #> 890      0.941      0.240      TRUE -0.701 0.539 -1.300 0.193 #> 891     -0.018     -0.610      TRUE -0.592 0.495 -1.195 0.232 #> 892      0.188      0.162      TRUE -0.026 0.491 -0.053 0.958 #> 893      1.411      1.249      TRUE -0.162 0.653 -0.248 0.804 #> 894      0.318      0.314      TRUE -0.003 0.500 -0.007 0.995 #> 895     -0.233      0.079      TRUE  0.312 0.485  0.643  0.52 #> 896      1.000      0.554      TRUE -0.445 0.559 -0.797 0.425 #> 897      1.345      1.205      TRUE -0.140 0.642 -0.218 0.827 #> 898     -0.526     -0.170      TRUE  0.356 0.491  0.725 0.468 #> 899     -0.024     -0.351      TRUE -0.326 0.486 -0.672 0.502 #> 900     -0.598     -0.895      TRUE -0.297 0.524 -0.567 0.571 #> 901     -0.600     -0.714      TRUE -0.114 0.512 -0.223 0.824 #> 902      1.254      1.972      TRUE  0.718 0.716  1.004 0.316 #> 903      1.261      1.943      TRUE  0.682 0.713  0.957 0.339 #> 904      0.351     -0.065      TRUE -0.416 0.493 -0.844 0.399 #> 905     -0.637     -0.612      TRUE  0.026 0.508  0.050  0.96 #> 906      1.880      2.251      TRUE  0.371 0.807  0.459 0.646 #> 907      0.911      0.285      TRUE -0.626 0.538 -1.164 0.245 #> 908     -0.016     -0.820      TRUE -0.803 0.508 -1.582 0.114 #> 909     -1.645     -2.133      TRUE -0.487 0.754 -0.646 0.518 #> 910      1.420      0.067      TRUE -1.353 0.585 -2.311 0.021 #> 911     -1.644     -2.133      TRUE -0.488 0.754 -0.647 0.517 #> 912      2.251      1.425      TRUE -0.825 0.764 -1.080  0.28 #> 913     -1.081     -1.503      TRUE -0.422 0.616 -0.686 0.493 #> 914      1.152      1.361      TRUE  0.208 0.639  0.326 0.744 #> 915      0.771      1.055      TRUE  0.284 0.578  0.491 0.623 #> 916      1.599      0.643      TRUE -0.956 0.627 -1.525 0.127 #> 917      1.040      1.413      TRUE  0.373 0.634  0.588 0.557 #> 918      0.986      1.519      TRUE  0.533 0.641  0.831 0.406 #> 919      0.638      0.057      TRUE -0.581 0.511 -1.137 0.255 #> 920      0.248     -0.197      TRUE -0.444 0.489 -0.908 0.364 #> 921     -0.914     -1.408      TRUE -0.494 0.592 -0.835 0.404 #> 922     -0.454      0.094      TRUE  0.547 0.491  1.116 0.264 #> 923      0.330      0.111      TRUE -0.219 0.494 -0.442 0.658 #> 924      1.650      1.589      TRUE -0.062 0.711 -0.087 0.931 #> 925     -0.898     -0.861      TRUE  0.037 0.539  0.069 0.945 #> 926      1.972      1.814      TRUE -0.158 0.770 -0.205 0.838 #> 927     -0.490     -0.761      TRUE -0.271 0.510 -0.532 0.595 #> 928     -0.261     -1.052      TRUE -0.791 0.527 -1.500 0.134 #> 929      0.965      1.972      TRUE  1.007 0.693  1.454 0.146 #> 930      0.869     -0.077      TRUE -0.946 0.528 -1.794 0.073 #> 931      0.353      0.208      TRUE -0.145 0.498 -0.291 0.771 #> 932      0.358      0.091      TRUE -0.267 0.495 -0.540 0.589 #> 933      0.426      0.718      TRUE  0.291 0.528  0.551 0.581 #> 934     -0.155     -0.759      TRUE -0.604 0.504 -1.199 0.231 #> 935      0.768      0.876      TRUE  0.108 0.562  0.192 0.848 #> 936     -0.530     -0.519      TRUE  0.011 0.500  0.021 0.983 #> 937     -0.749     -0.721      TRUE  0.028 0.520  0.054 0.957 #> 938     -0.231     -0.155      TRUE  0.076 0.484  0.158 0.875 #> 939     -1.279     -1.645      TRUE -0.367 0.651 -0.564 0.573 #> 940      0.243      0.142      TRUE -0.101 0.492 -0.205 0.838 #> 941      0.559      0.936      TRUE  0.377 0.553  0.682 0.495 #> 942      0.670      0.744      TRUE  0.075 0.544  0.137 0.891 #> 943      0.261     -0.270      TRUE -0.531 0.491 -1.083 0.279 #> 944      0.843      0.495      TRUE -0.348 0.542 -0.642 0.521 #> 945      0.042      0.335      TRUE  0.293 0.493  0.593 0.553 #> 946      0.263      0.241      TRUE -0.022 0.495 -0.045 0.964 #> 947      0.355     -0.018      TRUE -0.373 0.494 -0.755  0.45 #> 948      0.052      0.581      TRUE  0.529 0.507  1.043 0.297 #> 949     -1.795     -1.470      TRUE  0.325 0.689  0.472 0.637 #> 950     -0.394      0.473      TRUE  0.867 0.503  1.724 0.085 #> 951     -0.390     -0.468      TRUE -0.078 0.493 -0.159 0.874 #> 952      0.982      0.348      TRUE -0.633 0.547 -1.158 0.247 #> 953     -0.554     -1.070      TRUE -0.516 0.537 -0.961 0.337 #> 954     -1.586     -0.702      TRUE  0.884 0.602  1.470 0.142 #> 955     -0.619     -0.916      TRUE -0.297 0.527 -0.564 0.573 #> 956     -1.292     -1.290      TRUE  0.002 0.611  0.004 0.997 #> 957     -0.987     -0.726      TRUE  0.261 0.538  0.484 0.628 #> 958     -0.629     -0.651      TRUE -0.023 0.510 -0.044 0.965 #> 959      0.723      1.451      TRUE  0.728 0.615  1.183 0.237 #> 960     -0.701     -0.579      TRUE  0.122 0.510  0.239 0.811 #> 961     -1.264     -1.638      TRUE -0.374 0.648 -0.577 0.564 #> 962      0.443      0.162      TRUE -0.281 0.501 -0.560 0.576 #> 963     -0.730     -1.011      TRUE -0.280 0.540 -0.519 0.603 #> 964      1.458      0.276      TRUE -1.182 0.594 -1.988 0.047 #> 965     -0.922     -0.508      TRUE  0.414 0.522  0.793 0.428 #> 966      0.580      1.124      TRUE  0.544 0.572  0.951 0.341 #> 967      1.076      1.167      TRUE  0.091 0.613  0.149 0.882 #> 968      0.439     -0.218      TRUE -0.657 0.498 -1.320 0.187 #> 969      0.935      0.495      TRUE -0.440 0.549 -0.801 0.423 #> 970      0.737      1.210      TRUE  0.473 0.590  0.801 0.423 #> 971     -0.743     -0.472      TRUE  0.271 0.509  0.534 0.594 #> 972      1.208      1.205      TRUE -0.003 0.628 -0.004 0.996 #> 973     -1.259     -1.821      TRUE -0.562 0.672 -0.836 0.403 #> 974     -0.829     -0.870      TRUE -0.042 0.535 -0.078 0.938 #> 975     -0.389     -1.197      TRUE -0.809 0.544 -1.487 0.137 #> 976      0.547      0.480      TRUE -0.067 0.520 -0.129 0.897 #> 977     -0.060      0.378      TRUE  0.438 0.494  0.886 0.375 #> 978     -1.503     -0.950      TRUE  0.553 0.606  0.913 0.361 #> 979     -1.418     -0.196      TRUE  1.222 0.566  2.159 0.031 #> 980     -0.032     -0.002      TRUE  0.030 0.484  0.062 0.951 #> 981     -0.993     -1.649      TRUE -0.656 0.627 -1.046 0.295 #> 982     -0.526     -1.183      TRUE -0.657 0.547 -1.202 0.229 #> 983      1.334      0.407      TRUE -0.928 0.585 -1.585 0.113 #> 984      1.506      1.064      TRUE -0.443 0.646 -0.685 0.494 #> 985      1.254      0.239      TRUE -1.015 0.570 -1.779 0.075 #> 986     -0.725     -1.319      TRUE -0.594 0.570 -1.042 0.297 #> 987      0.685      0.698      TRUE  0.013 0.542  0.024 0.981 #> 988      0.141     -0.361      TRUE -0.502 0.489 -1.027 0.304 #> 989     -1.366      0.469      TRUE  1.835 0.573  3.201 0.001 #> 990     -0.193      0.204      TRUE  0.397 0.488  0.814 0.416 #> 991      0.140     -0.560      TRUE -0.700 0.496 -1.413 0.158 #> 992      0.246      0.044      TRUE -0.202 0.490 -0.411 0.681 #> 993     -0.439     -0.614      TRUE -0.176 0.500 -0.351 0.726 #> 994     -1.649     -1.018      TRUE  0.631 0.629  1.003 0.316 #> 995      0.107     -0.521      TRUE -0.628 0.493 -1.273 0.203 #> 996     -0.003     -0.821      TRUE -0.818 0.508 -1.611 0.107 #> 997     -0.394     -0.621      TRUE -0.227 0.499 -0.454  0.65 #> 998      0.065      0.413      TRUE  0.348 0.497  0.699 0.485 #> 999      0.198     -0.517      TRUE -0.715 0.495 -1.443 0.149 #> 1000    -1.854     -1.519      TRUE  0.335 0.702  0.477 0.633  # single response pattern change using EAP information RCI(mod, predat=dat_pre[1,], postdat=dat_post[1,]) #>   pre.score post.score converged  diff    SE     z     p #> 1     1.714       1.97      TRUE 0.256 0.759 0.337 0.736  # WLE estimator with Fisher information for SE (see Jabrayilov et al. 2016) RCI(mod, predat = dat_pre[1,], postdat = dat_post[1,],     method = 'WLE', Fisher = TRUE) #>   pre.score post.score converged  diff    SE     z     p #> 1     2.161      2.769      TRUE 0.609 1.199 0.508 0.612  # multiple respondents RCI(mod, predat = dat_pre[1:6,], postdat = dat_post[1:6,]) #>   pre.score post.score converged   diff    SE      z     p #> 1     1.714      1.970      TRUE  0.256 0.759  0.337 0.736 #> 2     1.406     -0.120      TRUE -1.526 0.582 -2.620 0.009 #> 3     0.960     -0.150      TRUE -1.111 0.536 -2.073 0.038 #> 4     0.302      0.202      TRUE -0.100 0.496 -0.202  0.84 #> 5    -0.973     -0.906      TRUE  0.067 0.548  0.122 0.903 #> 6    -0.797     -0.298      TRUE  0.499 0.508  0.983 0.326  # include large-sample z-type cutoffs RCI(mod, predat = dat_pre[1:6,], postdat = dat_post[1:6,],     cutoffs = c(-1.96, 1.96)) #>   pre.score post.score converged   diff    SE      z     p cut_decision #> 1     1.714      1.970      TRUE  0.256 0.759  0.337 0.736    unchanged #> 2     1.406     -0.120      TRUE -1.526 0.582 -2.620 0.009    decreased #> 3     0.960     -0.150      TRUE -1.111 0.536 -2.073 0.038    decreased #> 4     0.302      0.202      TRUE -0.100 0.496 -0.202  0.84    unchanged #> 5    -0.973     -0.906      TRUE  0.067 0.548  0.122 0.903    unchanged #> 6    -0.797     -0.298      TRUE  0.499 0.508  0.983 0.326    unchanged  ###### # CTT version by omitting IRT model     # Requires either sample or population SEM's as input (istats <- itemstats(dat_pre)$overall) #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            9.785          4.846 0.214 0.065 0.846     1.901 SEM.alpha <- istats$SEM.alpha    # SEM estimate of dat_pre  # assumes SEM.post = SEM.pre RCI(predat = dat_pre, postdat = dat_post, SEM.pre=SEM.alpha) #>      pre.score post.score diff    SE      z     p #> 1           18         19    1 2.688  0.372  0.71 #> 2           18          9   -9 2.688 -3.349 0.001 #> 3           15          9   -6 2.688 -2.232 0.026 #> 4           11         10   -1 2.688 -0.372  0.71 #> 5            4          5    1 2.688  0.372  0.71 #> 6            4          8    4 2.688  1.488 0.137 #> 7           11          8   -3 2.688 -1.116 0.264 #> 8           11         15    4 2.688  1.488 0.137 #> 9            3          3    0 2.688  0.000     1 #> 10           4          8    4 2.688  1.488 0.137 #> 11           1          5    4 2.688  1.488 0.137 #> 12          16         14   -2 2.688 -0.744 0.457 #> 13          12         10   -2 2.688 -0.744 0.457 #> 14          11         10   -1 2.688 -0.372  0.71 #> 15          17         18    1 2.688  0.372  0.71 #> 16           1          4    3 2.688  1.116 0.264 #> 17          10          8   -2 2.688 -0.744 0.457 #> 18          12         11   -1 2.688 -0.372  0.71 #> 19          15         12   -3 2.688 -1.116 0.264 #> 20          16         10   -6 2.688 -2.232 0.026 #> 21           7          6   -1 2.688 -0.372  0.71 #> 22           7         12    5 2.688  1.860 0.063 #> 23           2          4    2 2.688  0.744 0.457 #> 24           5          7    2 2.688  0.744 0.457 #> 25          14         15    1 2.688  0.372  0.71 #> 26           9          6   -3 2.688 -1.116 0.264 #> 27          17         17    0 2.688  0.000     1 #> 28           4          9    5 2.688  1.860 0.063 #> 29          14         16    2 2.688  0.744 0.457 #> 30           4          7    3 2.688  1.116 0.264 #> 31           2          0   -2 2.688 -0.744 0.457 #> 32           9          6   -3 2.688 -1.116 0.264 #> 33          20         20    0 2.688  0.000     1 #> 34           9          6   -3 2.688 -1.116 0.264 #> 35           3          4    1 2.688  0.372  0.71 #> 36          14         15    1 2.688  0.372  0.71 #> 37           8          9    1 2.688  0.372  0.71 #> 38          15         13   -2 2.688 -0.744 0.457 #> 39           9         12    3 2.688  1.116 0.264 #> 40          18         18    0 2.688  0.000     1 #> 41          11         10   -1 2.688 -0.372  0.71 #> 42          12          9   -3 2.688 -1.116 0.264 #> 43           8          7   -1 2.688 -0.372  0.71 #> 44          10         11    1 2.688  0.372  0.71 #> 45           7         10    3 2.688  1.116 0.264 #> 46           8          9    1 2.688  0.372  0.71 #> 47           6          8    2 2.688  0.744 0.457 #> 48           6          7    1 2.688  0.372  0.71 #> 49           6          8    2 2.688  0.744 0.457 #> 50           8         11    3 2.688  1.116 0.264 #> 51          13         17    4 2.688  1.488 0.137 #> 52           6          6    0 2.688  0.000     1 #> 53          19         13   -6 2.688 -2.232 0.026 #> 54           6         11    5 2.688  1.860 0.063 #> 55           9          8   -1 2.688 -0.372  0.71 #> 56           7          8    1 2.688  0.372  0.71 #> 57           9          6   -3 2.688 -1.116 0.264 #> 58           3          3    0 2.688  0.000     1 #> 59          10          8   -2 2.688 -0.744 0.457 #> 60          14         14    0 2.688  0.000     1 #> 61          12         12    0 2.688  0.000     1 #> 62          15         14   -1 2.688 -0.372  0.71 #> 63          13         12   -1 2.688 -0.372  0.71 #> 64           5          5    0 2.688  0.000     1 #> 65           5          4   -1 2.688 -0.372  0.71 #> 66           5          4   -1 2.688 -0.372  0.71 #> 67          18         14   -4 2.688 -1.488 0.137 #> 68           9          8   -1 2.688 -0.372  0.71 #> 69          11          9   -2 2.688 -0.744 0.457 #> 70          19         17   -2 2.688 -0.744 0.457 #> 71           9          5   -4 2.688 -1.488 0.137 #> 72          16         15   -1 2.688 -0.372  0.71 #> 73          10          9   -1 2.688 -0.372  0.71 #> 74          11         11    0 2.688  0.000     1 #> 75          14         10   -4 2.688 -1.488 0.137 #> 76          14         15    1 2.688  0.372  0.71 #> 77           5          4   -1 2.688 -0.372  0.71 #> 78          11          9   -2 2.688 -0.744 0.457 #> 79          15         10   -5 2.688 -1.860 0.063 #> 80          11         11    0 2.688  0.000     1 #> 81          10          8   -2 2.688 -0.744 0.457 #> 82          12         12    0 2.688  0.000     1 #> 83          11         11    0 2.688  0.000     1 #> 84           5          1   -4 2.688 -1.488 0.137 #> 85           7          9    2 2.688  0.744 0.457 #> 86           7         10    3 2.688  1.116 0.264 #> 87           3          7    4 2.688  1.488 0.137 #> 88           9         11    2 2.688  0.744 0.457 #> 89           8          9    1 2.688  0.372  0.71 #> 90          12         11   -1 2.688 -0.372  0.71 #> 91           6          1   -5 2.688 -1.860 0.063 #> 92           6          8    2 2.688  0.744 0.457 #> 93           3          5    2 2.688  0.744 0.457 #> 94          12         12    0 2.688  0.000     1 #> 95          18         16   -2 2.688 -0.744 0.457 #> 96           9          7   -2 2.688 -0.744 0.457 #> 97           8         11    3 2.688  1.116 0.264 #> 98           7          7    0 2.688  0.000     1 #> 99          12         11   -1 2.688 -0.372  0.71 #> 100         10         10    0 2.688  0.000     1 #> 101          5          5    0 2.688  0.000     1 #> 102         14         15    1 2.688  0.372  0.71 #> 103          9          9    0 2.688  0.000     1 #> 104          8         15    7 2.688  2.604 0.009 #> 105          2          3    1 2.688  0.372  0.71 #> 106          7         10    3 2.688  1.116 0.264 #> 107         12         12    0 2.688  0.000     1 #> 108          2          2    0 2.688  0.000     1 #> 109         14         13   -1 2.688 -0.372  0.71 #> 110          6          4   -2 2.688 -0.744 0.457 #> 111         15         10   -5 2.688 -1.860 0.063 #> 112          5          5    0 2.688  0.000     1 #> 113         15         18    3 2.688  1.116 0.264 #> 114          2          0   -2 2.688 -0.744 0.457 #> 115          9         12    3 2.688  1.116 0.264 #> 116         14         14    0 2.688  0.000     1 #> 117         10          7   -3 2.688 -1.116 0.264 #> 118          6          5   -1 2.688 -0.372  0.71 #> 119         12          9   -3 2.688 -1.116 0.264 #> 120          7          3   -4 2.688 -1.488 0.137 #> 121          9         12    3 2.688  1.116 0.264 #> 122          2          6    4 2.688  1.488 0.137 #> 123          9          6   -3 2.688 -1.116 0.264 #> 124          2          5    3 2.688  1.116 0.264 #> 125         12         12    0 2.688  0.000     1 #> 126         16         19    3 2.688  1.116 0.264 #> 127         13         14    1 2.688  0.372  0.71 #> 128         13         14    1 2.688  0.372  0.71 #> 129         14         15    1 2.688  0.372  0.71 #> 130          7         14    7 2.688  2.604 0.009 #> 131         10         11    1 2.688  0.372  0.71 #> 132          3          3    0 2.688  0.000     1 #> 133         15         15    0 2.688  0.000     1 #> 134         18         19    1 2.688  0.372  0.71 #> 135          2          5    3 2.688  1.116 0.264 #> 136         12         10   -2 2.688 -0.744 0.457 #> 137         12         14    2 2.688  0.744 0.457 #> 138          6          3   -3 2.688 -1.116 0.264 #> 139         13          9   -4 2.688 -1.488 0.137 #> 140          8          5   -3 2.688 -1.116 0.264 #> 141         18         17   -1 2.688 -0.372  0.71 #> 142         15         15    0 2.688  0.000     1 #> 143          7          9    2 2.688  0.744 0.457 #> 144         14         10   -4 2.688 -1.488 0.137 #> 145          3          5    2 2.688  0.744 0.457 #> 146          1          2    1 2.688  0.372  0.71 #> 147          5          6    1 2.688  0.372  0.71 #> 148          8          8    0 2.688  0.000     1 #> 149         13         15    2 2.688  0.744 0.457 #> 150          9          9    0 2.688  0.000     1 #> 151          8          9    1 2.688  0.372  0.71 #> 152          2          1   -1 2.688 -0.372  0.71 #> 153          3          3    0 2.688  0.000     1 #> 154          7          5   -2 2.688 -0.744 0.457 #> 155         16         13   -3 2.688 -1.116 0.264 #> 156          9         12    3 2.688  1.116 0.264 #> 157         15         17    2 2.688  0.744 0.457 #> 158         10          5   -5 2.688 -1.860 0.063 #> 159          8         10    2 2.688  0.744 0.457 #> 160         17         11   -6 2.688 -2.232 0.026 #> 161         14          8   -6 2.688 -2.232 0.026 #> 162          8          8    0 2.688  0.000     1 #> 163          3          5    2 2.688  0.744 0.457 #> 164         16          8   -8 2.688 -2.976 0.003 #> 165          9          7   -2 2.688 -0.744 0.457 #> 166          7          8    1 2.688  0.372  0.71 #> 167         15         15    0 2.688  0.000     1 #> 168         15         18    3 2.688  1.116 0.264 #> 169          3          2   -1 2.688 -0.372  0.71 #> 170          1          2    1 2.688  0.372  0.71 #> 171          2          0   -2 2.688 -0.744 0.457 #> 172         20         15   -5 2.688 -1.860 0.063 #> 173         10         12    2 2.688  0.744 0.457 #> 174          9          3   -6 2.688 -2.232 0.026 #> 175          5         15   10 2.688  3.721     0 #> 176          9          7   -2 2.688 -0.744 0.457 #> 177         15         16    1 2.688  0.372  0.71 #> 178          2          5    3 2.688  1.116 0.264 #> 179         18         20    2 2.688  0.744 0.457 #> 180         10          8   -2 2.688 -0.744 0.457 #> 181          6          6    0 2.688  0.000     1 #> 182          3          5    2 2.688  0.744 0.457 #> 183          9          7   -2 2.688 -0.744 0.457 #> 184          7         10    3 2.688  1.116 0.264 #> 185          6          3   -3 2.688 -1.116 0.264 #> 186          7          5   -2 2.688 -0.744 0.457 #> 187          7          4   -3 2.688 -1.116 0.264 #> 188         10          9   -1 2.688 -0.372  0.71 #> 189         17         12   -5 2.688 -1.860 0.063 #> 190          2          4    2 2.688  0.744 0.457 #> 191         16         15   -1 2.688 -0.372  0.71 #> 192          6          9    3 2.688  1.116 0.264 #> 193         10         13    3 2.688  1.116 0.264 #> 194          2          7    5 2.688  1.860 0.063 #> 195          5          3   -2 2.688 -0.744 0.457 #> 196         12          8   -4 2.688 -1.488 0.137 #> 197          5          1   -4 2.688 -1.488 0.137 #> 198          5          2   -3 2.688 -1.116 0.264 #> 199         17         17    0 2.688  0.000     1 #> 200          4          2   -2 2.688 -0.744 0.457 #> 201         13         13    0 2.688  0.000     1 #> 202         14         12   -2 2.688 -0.744 0.457 #> 203          2          2    0 2.688  0.000     1 #> 204         11          9   -2 2.688 -0.744 0.457 #> 205         10         11    1 2.688  0.372  0.71 #> 206         13         11   -2 2.688 -0.744 0.457 #> 207         17         18    1 2.688  0.372  0.71 #> 208         14         15    1 2.688  0.372  0.71 #> 209         18         18    0 2.688  0.000     1 #> 210          2          0   -2 2.688 -0.744 0.457 #> 211          9         11    2 2.688  0.744 0.457 #> 212         10         12    2 2.688  0.744 0.457 #> 213         16         14   -2 2.688 -0.744 0.457 #> 214          2          2    0 2.688  0.000     1 #> 215          3          4    1 2.688  0.372  0.71 #> 216         15         17    2 2.688  0.744 0.457 #> 217         14         12   -2 2.688 -0.744 0.457 #> 218          3          5    2 2.688  0.744 0.457 #> 219          9          8   -1 2.688 -0.372  0.71 #> 220          0          1    1 2.688  0.372  0.71 #> 221         14         12   -2 2.688 -0.744 0.457 #> 222          2          1   -1 2.688 -0.372  0.71 #> 223          5         10    5 2.688  1.860 0.063 #> 224          8         15    7 2.688  2.604 0.009 #> 225         12         14    2 2.688  0.744 0.457 #> 226         14         14    0 2.688  0.000     1 #> 227         11         11    0 2.688  0.000     1 #> 228          9          9    0 2.688  0.000     1 #> 229         17         15   -2 2.688 -0.744 0.457 #> 230          2          2    0 2.688  0.000     1 #> 231          6          9    3 2.688  1.116 0.264 #> 232          9         14    5 2.688  1.860 0.063 #> 233         13         13    0 2.688  0.000     1 #> 234         13         17    4 2.688  1.488 0.137 #> 235         13          6   -7 2.688 -2.604 0.009 #> 236          8          8    0 2.688  0.000     1 #> 237          8          9    1 2.688  0.372  0.71 #> 238          6         12    6 2.688  2.232 0.026 #> 239          9          9    0 2.688  0.000     1 #> 240          7         12    5 2.688  1.860 0.063 #> 241         18         18    0 2.688  0.000     1 #> 242          4          3   -1 2.688 -0.372  0.71 #> 243          1          2    1 2.688  0.372  0.71 #> 244          3          1   -2 2.688 -0.744 0.457 #> 245          6          5   -1 2.688 -0.372  0.71 #> 246          4          4    0 2.688  0.000     1 #> 247         17         17    0 2.688  0.000     1 #> 248         20         18   -2 2.688 -0.744 0.457 #> 249          8         10    2 2.688  0.744 0.457 #> 250         15         18    3 2.688  1.116 0.264 #> 251         15         13   -2 2.688 -0.744 0.457 #> 252          8          8    0 2.688  0.000     1 #> 253          8          8    0 2.688  0.000     1 #> 254         11         13    2 2.688  0.744 0.457 #> 255         18         16   -2 2.688 -0.744 0.457 #> 256         10         11    1 2.688  0.372  0.71 #> 257         18         16   -2 2.688 -0.744 0.457 #> 258         10         11    1 2.688  0.372  0.71 #> 259          4          3   -1 2.688 -0.372  0.71 #> 260         11         14    3 2.688  1.116 0.264 #> 261         14         11   -3 2.688 -1.116 0.264 #> 262         14         13   -1 2.688 -0.372  0.71 #> 263         19         17   -2 2.688 -0.744 0.457 #> 264          4          6    2 2.688  0.744 0.457 #> 265         17         17    0 2.688  0.000     1 #> 266          9         12    3 2.688  1.116 0.264 #> 267          4          7    3 2.688  1.116 0.264 #> 268         15         12   -3 2.688 -1.116 0.264 #> 269          7          7    0 2.688  0.000     1 #> 270          8         11    3 2.688  1.116 0.264 #> 271          1          2    1 2.688  0.372  0.71 #> 272          8          6   -2 2.688 -0.744 0.457 #> 273          6          6    0 2.688  0.000     1 #> 274         17         16   -1 2.688 -0.372  0.71 #> 275         13         11   -2 2.688 -0.744 0.457 #> 276          2          1   -1 2.688 -0.372  0.71 #> 277          9         10    1 2.688  0.372  0.71 #> 278          2          0   -2 2.688 -0.744 0.457 #> 279         11         13    2 2.688  0.744 0.457 #> 280         17         17    0 2.688  0.000     1 #> 281         16         16    0 2.688  0.000     1 #> 282         14         15    1 2.688  0.372  0.71 #> 283         15         16    1 2.688  0.372  0.71 #> 284          4          1   -3 2.688 -1.116 0.264 #> 285         17         18    1 2.688  0.372  0.71 #> 286         10          7   -3 2.688 -1.116 0.264 #> 287         12         15    3 2.688  1.116 0.264 #> 288         15         17    2 2.688  0.744 0.457 #> 289         17         15   -2 2.688 -0.744 0.457 #> 290         14         11   -3 2.688 -1.116 0.264 #> 291         15         12   -3 2.688 -1.116 0.264 #> 292         10         10    0 2.688  0.000     1 #> 293          0          2    2 2.688  0.744 0.457 #> 294         12          8   -4 2.688 -1.488 0.137 #> 295          4          7    3 2.688  1.116 0.264 #> 296         15         15    0 2.688  0.000     1 #> 297         18         17   -1 2.688 -0.372  0.71 #> 298          9          7   -2 2.688 -0.744 0.457 #> 299         18         12   -6 2.688 -2.232 0.026 #> 300          0          1    1 2.688  0.372  0.71 #> 301          4         11    7 2.688  2.604 0.009 #> 302         10          8   -2 2.688 -0.744 0.457 #> 303          5          2   -3 2.688 -1.116 0.264 #> 304         19         17   -2 2.688 -0.744 0.457 #> 305         11          6   -5 2.688 -1.860 0.063 #> 306         15         15    0 2.688  0.000     1 #> 307         10         12    2 2.688  0.744 0.457 #> 308         11          8   -3 2.688 -1.116 0.264 #> 309         10          7   -3 2.688 -1.116 0.264 #> 310          8          6   -2 2.688 -0.744 0.457 #> 311         14         15    1 2.688  0.372  0.71 #> 312         16         11   -5 2.688 -1.860 0.063 #> 313          6          4   -2 2.688 -0.744 0.457 #> 314         11         11    0 2.688  0.000     1 #> 315          7          7    0 2.688  0.000     1 #> 316          9         11    2 2.688  0.744 0.457 #> 317          7         11    4 2.688  1.488 0.137 #> 318          1          5    4 2.688  1.488 0.137 #> 319         10          9   -1 2.688 -0.372  0.71 #> 320         13         10   -3 2.688 -1.116 0.264 #> 321         13         10   -3 2.688 -1.116 0.264 #> 322         13          9   -4 2.688 -1.488 0.137 #> 323          1          2    1 2.688  0.372  0.71 #> 324         13         13    0 2.688  0.000     1 #> 325         13         13    0 2.688  0.000     1 #> 326         13         13    0 2.688  0.000     1 #> 327          7          6   -1 2.688 -0.372  0.71 #> 328          9         12    3 2.688  1.116 0.264 #> 329         13         13    0 2.688  0.000     1 #> 330          6         14    8 2.688  2.976 0.003 #> 331         12         14    2 2.688  0.744 0.457 #> 332          9          5   -4 2.688 -1.488 0.137 #> 333         13         12   -1 2.688 -0.372  0.71 #> 334         13         14    1 2.688  0.372  0.71 #> 335          9         11    2 2.688  0.744 0.457 #> 336         10          9   -1 2.688 -0.372  0.71 #> 337         12         13    1 2.688  0.372  0.71 #> 338         16         14   -2 2.688 -0.744 0.457 #> 339          6         10    4 2.688  1.488 0.137 #> 340         17         15   -2 2.688 -0.744 0.457 #> 341         12         14    2 2.688  0.744 0.457 #> 342          6          5   -1 2.688 -0.372  0.71 #> 343          5          9    4 2.688  1.488 0.137 #> 344          5          4   -1 2.688 -0.372  0.71 #> 345          6          9    3 2.688  1.116 0.264 #> 346         12          8   -4 2.688 -1.488 0.137 #> 347         12         13    1 2.688  0.372  0.71 #> 348          8         11    3 2.688  1.116 0.264 #> 349          5          6    1 2.688  0.372  0.71 #> 350         11         12    1 2.688  0.372  0.71 #> 351          9          7   -2 2.688 -0.744 0.457 #> 352         18         16   -2 2.688 -0.744 0.457 #> 353          9         11    2 2.688  0.744 0.457 #> 354          4          3   -1 2.688 -0.372  0.71 #> 355         12         17    5 2.688  1.860 0.063 #> 356         16         15   -1 2.688 -0.372  0.71 #> 357          9         13    4 2.688  1.488 0.137 #> 358         10          7   -3 2.688 -1.116 0.264 #> 359          1          3    2 2.688  0.744 0.457 #> 360         10         12    2 2.688  0.744 0.457 #> 361          5          5    0 2.688  0.000     1 #> 362         13         15    2 2.688  0.744 0.457 #> 363          9         12    3 2.688  1.116 0.264 #> 364         13         14    1 2.688  0.372  0.71 #> 365          9          5   -4 2.688 -1.488 0.137 #> 366         17         17    0 2.688  0.000     1 #> 367          4          2   -2 2.688 -0.744 0.457 #> 368         12          9   -3 2.688 -1.116 0.264 #> 369          3         10    7 2.688  2.604 0.009 #> 370         12         12    0 2.688  0.000     1 #> 371         14         18    4 2.688  1.488 0.137 #> 372         10         11    1 2.688  0.372  0.71 #> 373          7          9    2 2.688  0.744 0.457 #> 374          4          6    2 2.688  0.744 0.457 #> 375         10          5   -5 2.688 -1.860 0.063 #> 376         16         14   -2 2.688 -0.744 0.457 #> 377         15         15    0 2.688  0.000     1 #> 378         13         12   -1 2.688 -0.372  0.71 #> 379          0          3    3 2.688  1.116 0.264 #> 380          7          8    1 2.688  0.372  0.71 #> 381          6          7    1 2.688  0.372  0.71 #> 382          6          6    0 2.688  0.000     1 #> 383          6          8    2 2.688  0.744 0.457 #> 384          4          4    0 2.688  0.000     1 #> 385          3          4    1 2.688  0.372  0.71 #> 386          2          7    5 2.688  1.860 0.063 #> 387          9          9    0 2.688  0.000     1 #> 388         19         14   -5 2.688 -1.860 0.063 #> 389          3          6    3 2.688  1.116 0.264 #> 390          0          2    2 2.688  0.744 0.457 #> 391         15         14   -1 2.688 -0.372  0.71 #> 392         11          4   -7 2.688 -2.604 0.009 #> 393          5          6    1 2.688  0.372  0.71 #> 394          2          1   -1 2.688 -0.372  0.71 #> 395          7         13    6 2.688  2.232 0.026 #> 396         13         11   -2 2.688 -0.744 0.457 #> 397         15         14   -1 2.688 -0.372  0.71 #> 398          2          4    2 2.688  0.744 0.457 #> 399         13          6   -7 2.688 -2.604 0.009 #> 400         15          9   -6 2.688 -2.232 0.026 #> 401          7          8    1 2.688  0.372  0.71 #> 402          3          3    0 2.688  0.000     1 #> 403          9         12    3 2.688  1.116 0.264 #> 404         17         17    0 2.688  0.000     1 #> 405          1          4    3 2.688  1.116 0.264 #> 406          4          2   -2 2.688 -0.744 0.457 #> 407          7         10    3 2.688  1.116 0.264 #> 408          7         11    4 2.688  1.488 0.137 #> 409         12         12    0 2.688  0.000     1 #> 410          8          6   -2 2.688 -0.744 0.457 #> 411          8          4   -4 2.688 -1.488 0.137 #> 412         14         11   -3 2.688 -1.116 0.264 #> 413          5          3   -2 2.688 -0.744 0.457 #> 414         16         17    1 2.688  0.372  0.71 #> 415         11         15    4 2.688  1.488 0.137 #> 416         15         12   -3 2.688 -1.116 0.264 #> 417         14         15    1 2.688  0.372  0.71 #> 418          5          6    1 2.688  0.372  0.71 #> 419          5         10    5 2.688  1.860 0.063 #> 420         10         13    3 2.688  1.116 0.264 #> 421          3          2   -1 2.688 -0.372  0.71 #> 422         17         17    0 2.688  0.000     1 #> 423         11         11    0 2.688  0.000     1 #> 424         14         13   -1 2.688 -0.372  0.71 #> 425         16          9   -7 2.688 -2.604 0.009 #> 426         15         16    1 2.688  0.372  0.71 #> 427         11          7   -4 2.688 -1.488 0.137 #> 428          8         11    3 2.688  1.116 0.264 #> 429         13         13    0 2.688  0.000     1 #> 430         10         10    0 2.688  0.000     1 #> 431         15         14   -1 2.688 -0.372  0.71 #> 432          1          4    3 2.688  1.116 0.264 #> 433          3          3    0 2.688  0.000     1 #> 434         11         15    4 2.688  1.488 0.137 #> 435          3          4    1 2.688  0.372  0.71 #> 436          6         11    5 2.688  1.860 0.063 #> 437          2          0   -2 2.688 -0.744 0.457 #> 438         13         14    1 2.688  0.372  0.71 #> 439         18         14   -4 2.688 -1.488 0.137 #> 440          6         13    7 2.688  2.604 0.009 #> 441         14         12   -2 2.688 -0.744 0.457 #> 442          4          5    1 2.688  0.372  0.71 #> 443         10          9   -1 2.688 -0.372  0.71 #> 444         18         18    0 2.688  0.000     1 #> 445         17         16   -1 2.688 -0.372  0.71 #> 446         16         17    1 2.688  0.372  0.71 #> 447          0          0    0 2.688  0.000     1 #> 448         12         10   -2 2.688 -0.744 0.457 #> 449          4          7    3 2.688  1.116 0.264 #> 450          1          4    3 2.688  1.116 0.264 #> 451         19         18   -1 2.688 -0.372  0.71 #> 452          8          5   -3 2.688 -1.116 0.264 #> 453          8         11    3 2.688  1.116 0.264 #> 454          5          9    4 2.688  1.488 0.137 #> 455         18         17   -1 2.688 -0.372  0.71 #> 456         12         11   -1 2.688 -0.372  0.71 #> 457          5          9    4 2.688  1.488 0.137 #> 458          2          5    3 2.688  1.116 0.264 #> 459          1          2    1 2.688  0.372  0.71 #> 460         19         18   -1 2.688 -0.372  0.71 #> 461         15         17    2 2.688  0.744 0.457 #> 462         17         13   -4 2.688 -1.488 0.137 #> 463         13         15    2 2.688  0.744 0.457 #> 464         14         14    0 2.688  0.000     1 #> 465          6          9    3 2.688  1.116 0.264 #> 466          9          5   -4 2.688 -1.488 0.137 #> 467         16         15   -1 2.688 -0.372  0.71 #> 468          3          2   -1 2.688 -0.372  0.71 #> 469          1          7    6 2.688  2.232 0.026 #> 470         13         10   -3 2.688 -1.116 0.264 #> 471          5          4   -1 2.688 -0.372  0.71 #> 472          6          7    1 2.688  0.372  0.71 #> 473         20         19   -1 2.688 -0.372  0.71 #> 474          7          9    2 2.688  0.744 0.457 #> 475          1          1    0 2.688  0.000     1 #> 476         15         13   -2 2.688 -0.744 0.457 #> 477         16         11   -5 2.688 -1.860 0.063 #> 478         16         12   -4 2.688 -1.488 0.137 #> 479         11         10   -1 2.688 -0.372  0.71 #> 480         15         16    1 2.688  0.372  0.71 #> 481          7          8    1 2.688  0.372  0.71 #> 482         15         12   -3 2.688 -1.116 0.264 #> 483         15         16    1 2.688  0.372  0.71 #> 484         12         11   -1 2.688 -0.372  0.71 #> 485         12         10   -2 2.688 -0.744 0.457 #> 486          5          8    3 2.688  1.116 0.264 #> 487          8         12    4 2.688  1.488 0.137 #> 488         11         13    2 2.688  0.744 0.457 #> 489         16         17    1 2.688  0.372  0.71 #> 490          7          8    1 2.688  0.372  0.71 #> 491         19         18   -1 2.688 -0.372  0.71 #> 492          4          5    1 2.688  0.372  0.71 #> 493         19         16   -3 2.688 -1.116 0.264 #> 494          8          9    1 2.688  0.372  0.71 #> 495         10         15    5 2.688  1.860 0.063 #> 496          6          7    1 2.688  0.372  0.71 #> 497         11          8   -3 2.688 -1.116 0.264 #> 498          3          9    6 2.688  2.232 0.026 #> 499          8          8    0 2.688  0.000     1 #> 500          7         11    4 2.688  1.488 0.137 #> 501         13         16    3 2.688  1.116 0.264 #> 502         11         10   -1 2.688 -0.372  0.71 #> 503          0          1    1 2.688  0.372  0.71 #> 504          4          5    1 2.688  0.372  0.71 #> 505          4          6    2 2.688  0.744 0.457 #> 506         12         10   -2 2.688 -0.744 0.457 #> 507         18         16   -2 2.688 -0.744 0.457 #> 508         13         14    1 2.688  0.372  0.71 #> 509          5          7    2 2.688  0.744 0.457 #> 510          8         10    2 2.688  0.744 0.457 #> 511          6         10    4 2.688  1.488 0.137 #> 512          7          9    2 2.688  0.744 0.457 #> 513          5          5    0 2.688  0.000     1 #> 514          5         10    5 2.688  1.860 0.063 #> 515          9         11    2 2.688  0.744 0.457 #> 516         17         17    0 2.688  0.000     1 #> 517         14         13   -1 2.688 -0.372  0.71 #> 518          8         15    7 2.688  2.604 0.009 #> 519         14         14    0 2.688  0.000     1 #> 520         13          8   -5 2.688 -1.860 0.063 #> 521         14         12   -2 2.688 -0.744 0.457 #> 522          6          2   -4 2.688 -1.488 0.137 #> 523         17         14   -3 2.688 -1.116 0.264 #> 524         13         13    0 2.688  0.000     1 #> 525         14         14    0 2.688  0.000     1 #> 526         16         12   -4 2.688 -1.488 0.137 #> 527         12         10   -2 2.688 -0.744 0.457 #> 528         15         16    1 2.688  0.372  0.71 #> 529         13         10   -3 2.688 -1.116 0.264 #> 530          9         10    1 2.688  0.372  0.71 #> 531         12          7   -5 2.688 -1.860 0.063 #> 532         20         20    0 2.688  0.000     1 #> 533         17         12   -5 2.688 -1.860 0.063 #> 534          6          8    2 2.688  0.744 0.457 #> 535         19         18   -1 2.688 -0.372  0.71 #> 536         12         12    0 2.688  0.000     1 #> 537         10          7   -3 2.688 -1.116 0.264 #> 538          6          4   -2 2.688 -0.744 0.457 #> 539          8          8    0 2.688  0.000     1 #> 540         10         12    2 2.688  0.744 0.457 #> 541          4          7    3 2.688  1.116 0.264 #> 542          2          2    0 2.688  0.000     1 #> 543          6          5   -1 2.688 -0.372  0.71 #> 544         12         10   -2 2.688 -0.744 0.457 #> 545          4          5    1 2.688  0.372  0.71 #> 546         11         10   -1 2.688 -0.372  0.71 #> 547         14         12   -2 2.688 -0.744 0.457 #> 548         13         15    2 2.688  0.744 0.457 #> 549         12          9   -3 2.688 -1.116 0.264 #> 550         11         11    0 2.688  0.000     1 #> 551          8          2   -6 2.688 -2.232 0.026 #> 552         14         15    1 2.688  0.372  0.71 #> 553         11         14    3 2.688  1.116 0.264 #> 554         13         12   -1 2.688 -0.372  0.71 #> 555          2          3    1 2.688  0.372  0.71 #> 556          9         13    4 2.688  1.488 0.137 #> 557         10         11    1 2.688  0.372  0.71 #> 558          8         12    4 2.688  1.488 0.137 #> 559         11         12    1 2.688  0.372  0.71 #> 560         19         18   -1 2.688 -0.372  0.71 #> 561         12         12    0 2.688  0.000     1 #> 562         12          8   -4 2.688 -1.488 0.137 #> 563          3          6    3 2.688  1.116 0.264 #> 564          4          0   -4 2.688 -1.488 0.137 #> 565         14         14    0 2.688  0.000     1 #> 566          3          4    1 2.688  0.372  0.71 #> 567         18         16   -2 2.688 -0.744 0.457 #> 568          3          2   -1 2.688 -0.372  0.71 #> 569         17         19    2 2.688  0.744 0.457 #> 570         10          8   -2 2.688 -0.744 0.457 #> 571         16         13   -3 2.688 -1.116 0.264 #> 572          8          8    0 2.688  0.000     1 #> 573         15         17    2 2.688  0.744 0.457 #> 574          7         12    5 2.688  1.860 0.063 #> 575          6          2   -4 2.688 -1.488 0.137 #> 576         11         14    3 2.688  1.116 0.264 #> 577         13         12   -1 2.688 -0.372  0.71 #> 578         17         14   -3 2.688 -1.116 0.264 #> 579          5          9    4 2.688  1.488 0.137 #> 580         12         17    5 2.688  1.860 0.063 #> 581         11         10   -1 2.688 -0.372  0.71 #> 582          6         12    6 2.688  2.232 0.026 #> 583         11         13    2 2.688  0.744 0.457 #> 584         16         18    2 2.688  0.744 0.457 #> 585          8          6   -2 2.688 -0.744 0.457 #> 586          7          9    2 2.688  0.744 0.457 #> 587         12         11   -1 2.688 -0.372  0.71 #> 588          9          7   -2 2.688 -0.744 0.457 #> 589          9          6   -3 2.688 -1.116 0.264 #> 590         14         13   -1 2.688 -0.372  0.71 #> 591         15         15    0 2.688  0.000     1 #> 592         19         15   -4 2.688 -1.488 0.137 #> 593          6          7    1 2.688  0.372  0.71 #> 594          4          3   -1 2.688 -0.372  0.71 #> 595          4          6    2 2.688  0.744 0.457 #> 596          4          3   -1 2.688 -0.372  0.71 #> 597          4          4    0 2.688  0.000     1 #> 598         10          6   -4 2.688 -1.488 0.137 #> 599          8         14    6 2.688  2.232 0.026 #> 600          9         12    3 2.688  1.116 0.264 #> 601         10         12    2 2.688  0.744 0.457 #> 602         12          9   -3 2.688 -1.116 0.264 #> 603         13          9   -4 2.688 -1.488 0.137 #> 604         11         11    0 2.688  0.000     1 #> 605          2          4    2 2.688  0.744 0.457 #> 606         16         14   -2 2.688 -0.744 0.457 #> 607          2          1   -1 2.688 -0.372  0.71 #> 608          3          2   -1 2.688 -0.372  0.71 #> 609          6          4   -2 2.688 -0.744 0.457 #> 610         15         11   -4 2.688 -1.488 0.137 #> 611          7          6   -1 2.688 -0.372  0.71 #> 612         14         18    4 2.688  1.488 0.137 #> 613          7         14    7 2.688  2.604 0.009 #> 614         18         14   -4 2.688 -1.488 0.137 #> 615          9          6   -3 2.688 -1.116 0.264 #> 616         11         11    0 2.688  0.000     1 #> 617          6          2   -4 2.688 -1.488 0.137 #> 618         10          7   -3 2.688 -1.116 0.264 #> 619          3          2   -1 2.688 -0.372  0.71 #> 620          8          4   -4 2.688 -1.488 0.137 #> 621          8         10    2 2.688  0.744 0.457 #> 622         16         16    0 2.688  0.000     1 #> 623          4          2   -2 2.688 -0.744 0.457 #> 624         13         15    2 2.688  0.744 0.457 #> 625         11         11    0 2.688  0.000     1 #> 626         14         13   -1 2.688 -0.372  0.71 #> 627          4          8    4 2.688  1.488 0.137 #> 628          6          8    2 2.688  0.744 0.457 #> 629         15          9   -6 2.688 -2.232 0.026 #> 630          2          3    1 2.688  0.372  0.71 #> 631          2          3    1 2.688  0.372  0.71 #> 632          8          6   -2 2.688 -0.744 0.457 #> 633          8          4   -4 2.688 -1.488 0.137 #> 634         12         18    6 2.688  2.232 0.026 #> 635         15         15    0 2.688  0.000     1 #> 636         10         10    0 2.688  0.000     1 #> 637          3          3    0 2.688  0.000     1 #> 638         14         15    1 2.688  0.372  0.71 #> 639          9          6   -3 2.688 -1.116 0.264 #> 640          2          5    3 2.688  1.116 0.264 #> 641         14         17    3 2.688  1.116 0.264 #> 642          4          2   -2 2.688 -0.744 0.457 #> 643         12         13    1 2.688  0.372  0.71 #> 644         10          7   -3 2.688 -1.116 0.264 #> 645          3          4    1 2.688  0.372  0.71 #> 646          4          2   -2 2.688 -0.744 0.457 #> 647          2          6    4 2.688  1.488 0.137 #> 648         11          8   -3 2.688 -1.116 0.264 #> 649         10         10    0 2.688  0.000     1 #> 650         17         17    0 2.688  0.000     1 #> 651          8         10    2 2.688  0.744 0.457 #> 652          8          9    1 2.688  0.372  0.71 #> 653         17         17    0 2.688  0.000     1 #> 654         15         13   -2 2.688 -0.744 0.457 #> 655         14         19    5 2.688  1.860 0.063 #> 656         10         14    4 2.688  1.488 0.137 #> 657         12         13    1 2.688  0.372  0.71 #> 658          7         12    5 2.688  1.860 0.063 #> 659         11         12    1 2.688  0.372  0.71 #> 660         13         10   -3 2.688 -1.116 0.264 #> 661          7          7    0 2.688  0.000     1 #> 662          8          6   -2 2.688 -0.744 0.457 #> 663          7          5   -2 2.688 -0.744 0.457 #> 664         14         10   -4 2.688 -1.488 0.137 #> 665         17         19    2 2.688  0.744 0.457 #> 666          9          6   -3 2.688 -1.116 0.264 #> 667          3          3    0 2.688  0.000     1 #> 668         15         11   -4 2.688 -1.488 0.137 #> 669          7          8    1 2.688  0.372  0.71 #> 670         12         12    0 2.688  0.000     1 #> 671         13         13    0 2.688  0.000     1 #> 672         16         20    4 2.688  1.488 0.137 #> 673         13          9   -4 2.688 -1.488 0.137 #> 674         14         16    2 2.688  0.744 0.457 #> 675          7          2   -5 2.688 -1.860 0.063 #> 676         10          6   -4 2.688 -1.488 0.137 #> 677         10         12    2 2.688  0.744 0.457 #> 678          8          9    1 2.688  0.372  0.71 #> 679          4          7    3 2.688  1.116 0.264 #> 680          2          4    2 2.688  0.744 0.457 #> 681         13         10   -3 2.688 -1.116 0.264 #> 682          5         12    7 2.688  2.604 0.009 #> 683          5          6    1 2.688  0.372  0.71 #> 684         10          7   -3 2.688 -1.116 0.264 #> 685         13         12   -1 2.688 -0.372  0.71 #> 686         17         19    2 2.688  0.744 0.457 #> 687         11         12    1 2.688  0.372  0.71 #> 688          4         10    6 2.688  2.232 0.026 #> 689          6          4   -2 2.688 -0.744 0.457 #> 690          3          5    2 2.688  0.744 0.457 #> 691         11         14    3 2.688  1.116 0.264 #> 692          7          2   -5 2.688 -1.860 0.063 #> 693          8         10    2 2.688  0.744 0.457 #> 694         13         11   -2 2.688 -0.744 0.457 #> 695         13         16    3 2.688  1.116 0.264 #> 696         16         15   -1 2.688 -0.372  0.71 #> 697         16         12   -4 2.688 -1.488 0.137 #> 698          3          3    0 2.688  0.000     1 #> 699         12         15    3 2.688  1.116 0.264 #> 700         12         16    4 2.688  1.488 0.137 #> 701          3          3    0 2.688  0.000     1 #> 702         20         20    0 2.688  0.000     1 #> 703          7         10    3 2.688  1.116 0.264 #> 704          9         13    4 2.688  1.488 0.137 #> 705          5          7    2 2.688  0.744 0.457 #> 706          2          2    0 2.688  0.000     1 #> 707         13         16    3 2.688  1.116 0.264 #> 708          5          7    2 2.688  0.744 0.457 #> 709          8          7   -1 2.688 -0.372  0.71 #> 710         15         18    3 2.688  1.116 0.264 #> 711          3          1   -2 2.688 -0.744 0.457 #> 712          5          5    0 2.688  0.000     1 #> 713          5          3   -2 2.688 -0.744 0.457 #> 714         15         16    1 2.688  0.372  0.71 #> 715         12         10   -2 2.688 -0.744 0.457 #> 716          9          6   -3 2.688 -1.116 0.264 #> 717          5          2   -3 2.688 -1.116 0.264 #> 718          3          4    1 2.688  0.372  0.71 #> 719          2          6    4 2.688  1.488 0.137 #> 720          4          6    2 2.688  0.744 0.457 #> 721         10         12    2 2.688  0.744 0.457 #> 722         16         14   -2 2.688 -0.744 0.457 #> 723          3          2   -1 2.688 -0.372  0.71 #> 724         13          8   -5 2.688 -1.860 0.063 #> 725         17         15   -2 2.688 -0.744 0.457 #> 726          8          8    0 2.688  0.000     1 #> 727          8         10    2 2.688  0.744 0.457 #> 728         16         12   -4 2.688 -1.488 0.137 #> 729         11         15    4 2.688  1.488 0.137 #> 730          4          8    4 2.688  1.488 0.137 #> 731          5          6    1 2.688  0.372  0.71 #> 732          4          3   -1 2.688 -0.372  0.71 #> 733          8          6   -2 2.688 -0.744 0.457 #> 734         18         19    1 2.688  0.372  0.71 #> 735         10         11    1 2.688  0.372  0.71 #> 736         10         12    2 2.688  0.744 0.457 #> 737         18         20    2 2.688  0.744 0.457 #> 738         11          5   -6 2.688 -2.232 0.026 #> 739         17         17    0 2.688  0.000     1 #> 740          3          5    2 2.688  0.744 0.457 #> 741         15         15    0 2.688  0.000     1 #> 742          8          9    1 2.688  0.372  0.71 #> 743          9          5   -4 2.688 -1.488 0.137 #> 744         16         13   -3 2.688 -1.116 0.264 #> 745         14         13   -1 2.688 -0.372  0.71 #> 746          8          6   -2 2.688 -0.744 0.457 #> 747          5          9    4 2.688  1.488 0.137 #> 748          3          1   -2 2.688 -0.744 0.457 #> 749          6          7    1 2.688  0.372  0.71 #> 750         17         13   -4 2.688 -1.488 0.137 #> 751         15         15    0 2.688  0.000     1 #> 752          5          6    1 2.688  0.372  0.71 #> 753          9         11    2 2.688  0.744 0.457 #> 754         16         14   -2 2.688 -0.744 0.457 #> 755         12         12    0 2.688  0.000     1 #> 756         12         14    2 2.688  0.744 0.457 #> 757         14          9   -5 2.688 -1.860 0.063 #> 758         12         15    3 2.688  1.116 0.264 #> 759          1          0   -1 2.688 -0.372  0.71 #> 760         13         17    4 2.688  1.488 0.137 #> 761         17         19    2 2.688  0.744 0.457 #> 762          4          4    0 2.688  0.000     1 #> 763         10          7   -3 2.688 -1.116 0.264 #> 764         15         15    0 2.688  0.000     1 #> 765         10         12    2 2.688  0.744 0.457 #> 766          2          2    0 2.688  0.000     1 #> 767         16         16    0 2.688  0.000     1 #> 768         14         13   -1 2.688 -0.372  0.71 #> 769         15         15    0 2.688  0.000     1 #> 770          7          3   -4 2.688 -1.488 0.137 #> 771          7          3   -4 2.688 -1.488 0.137 #> 772         15         14   -1 2.688 -0.372  0.71 #> 773         11         12    1 2.688  0.372  0.71 #> 774          2          1   -1 2.688 -0.372  0.71 #> 775          3          7    4 2.688  1.488 0.137 #> 776         16         16    0 2.688  0.000     1 #> 777         14          9   -5 2.688 -1.860 0.063 #> 778         14         14    0 2.688  0.000     1 #> 779         14         13   -1 2.688 -0.372  0.71 #> 780         13          9   -4 2.688 -1.488 0.137 #> 781         13         11   -2 2.688 -0.744 0.457 #> 782          5         13    8 2.688  2.976 0.003 #> 783         13         12   -1 2.688 -0.372  0.71 #> 784          8          7   -1 2.688 -0.372  0.71 #> 785         17         16   -1 2.688 -0.372  0.71 #> 786         10         11    1 2.688  0.372  0.71 #> 787         12         10   -2 2.688 -0.744 0.457 #> 788          7          9    2 2.688  0.744 0.457 #> 789          2          2    0 2.688  0.000     1 #> 790          1          3    2 2.688  0.744 0.457 #> 791          3          8    5 2.688  1.860 0.063 #> 792         14         16    2 2.688  0.744 0.457 #> 793          4          7    3 2.688  1.116 0.264 #> 794         15         17    2 2.688  0.744 0.457 #> 795         15         13   -2 2.688 -0.744 0.457 #> 796          7          8    1 2.688  0.372  0.71 #> 797          6          4   -2 2.688 -0.744 0.457 #> 798          7          6   -1 2.688 -0.372  0.71 #> 799         11          8   -3 2.688 -1.116 0.264 #> 800          8         12    4 2.688  1.488 0.137 #> 801          6          3   -3 2.688 -1.116 0.264 #> 802          7          2   -5 2.688 -1.860 0.063 #> 803          9          9    0 2.688  0.000     1 #> 804         17         14   -3 2.688 -1.116 0.264 #> 805          6          7    1 2.688  0.372  0.71 #> 806         14         13   -1 2.688 -0.372  0.71 #> 807          6         13    7 2.688  2.604 0.009 #> 808          7          9    2 2.688  0.744 0.457 #> 809         17         17    0 2.688  0.000     1 #> 810          3          6    3 2.688  1.116 0.264 #> 811         15         18    3 2.688  1.116 0.264 #> 812         10         10    0 2.688  0.000     1 #> 813          7          2   -5 2.688 -1.860 0.063 #> 814         13         14    1 2.688  0.372  0.71 #> 815          8         10    2 2.688  0.744 0.457 #> 816          7          7    0 2.688  0.000     1 #> 817         15          5  -10 2.688 -3.721     0 #> 818         11         11    0 2.688  0.000     1 #> 819          8         14    6 2.688  2.232 0.026 #> 820          7          5   -2 2.688 -0.744 0.457 #> 821         12         12    0 2.688  0.000     1 #> 822         10         13    3 2.688  1.116 0.264 #> 823          3          3    0 2.688  0.000     1 #> 824         17         18    1 2.688  0.372  0.71 #> 825          7          6   -1 2.688 -0.372  0.71 #> 826          5          7    2 2.688  0.744 0.457 #> 827         15         14   -1 2.688 -0.372  0.71 #> 828          3          7    4 2.688  1.488 0.137 #> 829          4          3   -1 2.688 -0.372  0.71 #> 830         20         17   -3 2.688 -1.116 0.264 #> 831          8          5   -3 2.688 -1.116 0.264 #> 832         13         18    5 2.688  1.860 0.063 #> 833         15         15    0 2.688  0.000     1 #> 834         16         17    1 2.688  0.372  0.71 #> 835          6          6    0 2.688  0.000     1 #> 836         16         16    0 2.688  0.000     1 #> 837          9          9    0 2.688  0.000     1 #> 838         10         16    6 2.688  2.232 0.026 #> 839         10         11    1 2.688  0.372  0.71 #> 840         16         17    1 2.688  0.372  0.71 #> 841         15         15    0 2.688  0.000     1 #> 842         13         13    0 2.688  0.000     1 #> 843         15         16    1 2.688  0.372  0.71 #> 844         10          7   -3 2.688 -1.116 0.264 #> 845         12          9   -3 2.688 -1.116 0.264 #> 846         12         12    0 2.688  0.000     1 #> 847          8          7   -1 2.688 -0.372  0.71 #> 848          7          3   -4 2.688 -1.488 0.137 #> 849          5          5    0 2.688  0.000     1 #> 850         19         16   -3 2.688 -1.116 0.264 #> 851         15         15    0 2.688  0.000     1 #> 852         13          8   -5 2.688 -1.860 0.063 #> 853          9         10    1 2.688  0.372  0.71 #> 854          8          8    0 2.688  0.000     1 #> 855          9          9    0 2.688  0.000     1 #> 856         12         13    1 2.688  0.372  0.71 #> 857         10          7   -3 2.688 -1.116 0.264 #> 858         13         10   -3 2.688 -1.116 0.264 #> 859         10          9   -1 2.688 -0.372  0.71 #> 860          5          8    3 2.688  1.116 0.264 #> 861          5          3   -2 2.688 -0.744 0.457 #> 862         13         14    1 2.688  0.372  0.71 #> 863          3          6    3 2.688  1.116 0.264 #> 864          8          4   -4 2.688 -1.488 0.137 #> 865         10         13    3 2.688  1.116 0.264 #> 866         12         12    0 2.688  0.000     1 #> 867          9         10    1 2.688  0.372  0.71 #> 868         11         13    2 2.688  0.744 0.457 #> 869         10          7   -3 2.688 -1.116 0.264 #> 870         13         13    0 2.688  0.000     1 #> 871         14         13   -1 2.688 -0.372  0.71 #> 872          8         10    2 2.688  0.744 0.457 #> 873          1          1    0 2.688  0.000     1 #> 874          7         13    6 2.688  2.232 0.026 #> 875         14         16    2 2.688  0.744 0.457 #> 876          9          8   -1 2.688 -0.372  0.71 #> 877         16         16    0 2.688  0.000     1 #> 878         14         15    1 2.688  0.372  0.71 #> 879          8         10    2 2.688  0.744 0.457 #> 880          6          2   -4 2.688 -1.488 0.137 #> 881          5          2   -3 2.688 -1.116 0.264 #> 882          6         10    4 2.688  1.488 0.137 #> 883         11         11    0 2.688  0.000     1 #> 884          6          5   -1 2.688 -0.372  0.71 #> 885         14         14    0 2.688  0.000     1 #> 886          3          7    4 2.688  1.488 0.137 #> 887          3          9    6 2.688  2.232 0.026 #> 888         10          7   -3 2.688 -1.116 0.264 #> 889          2          6    4 2.688  1.488 0.137 #> 890         15         11   -4 2.688 -1.488 0.137 #> 891         10          6   -4 2.688 -1.488 0.137 #> 892         10         10    0 2.688  0.000     1 #> 893         17         16   -1 2.688 -0.372  0.71 #> 894         11         12    1 2.688  0.372  0.71 #> 895          9         11    2 2.688  0.744 0.457 #> 896         15         13   -2 2.688 -0.744 0.457 #> 897         17         16   -1 2.688 -0.372  0.71 #> 898          7          9    2 2.688  0.744 0.457 #> 899         10          8   -2 2.688 -0.744 0.457 #> 900          6          5   -1 2.688 -0.372  0.71 #> 901          7          6   -1 2.688 -0.372  0.71 #> 902         16         19    3 2.688  1.116 0.264 #> 903         16         19    3 2.688  1.116 0.264 #> 904         12          9   -3 2.688 -1.116 0.264 #> 905          6          7    1 2.688  0.372  0.71 #> 906         19         20    1 2.688  0.372  0.71 #> 907         15         11   -4 2.688 -1.488 0.137 #> 908         10          5   -5 2.688 -1.860 0.063 #> 909          2          0   -2 2.688 -0.744 0.457 #> 910         18         10   -8 2.688 -2.976 0.003 #> 911          2          0   -2 2.688 -0.744 0.457 #> 912         20         17   -3 2.688 -1.116 0.264 #> 913          4          2   -2 2.688 -0.744 0.457 #> 914         16         17    1 2.688  0.372  0.71 #> 915         14         15    1 2.688  0.372  0.71 #> 916         18         13   -5 2.688 -1.860 0.063 #> 917         16         17    1 2.688  0.372  0.71 #> 918         15         18    3 2.688  1.116 0.264 #> 919         13         10   -3 2.688 -1.116 0.264 #> 920         11          8   -3 2.688 -1.116 0.264 #> 921          4          2   -2 2.688 -0.744 0.457 #> 922          6         10    4 2.688  1.488 0.137 #> 923         12         11   -1 2.688 -0.372  0.71 #> 924         18         18    0 2.688  0.000     1 #> 925          5          5    0 2.688  0.000     1 #> 926         19         19    0 2.688  0.000     1 #> 927          7          5   -2 2.688 -0.744 0.457 #> 928          9          3   -6 2.688 -2.232 0.026 #> 929         15         19    4 2.688  1.488 0.137 #> 930         15          9   -6 2.688 -2.232 0.026 #> 931         11         11    0 2.688  0.000     1 #> 932         12         10   -2 2.688 -0.744 0.457 #> 933         12         13    1 2.688  0.372  0.71 #> 934          9          6   -3 2.688 -1.116 0.264 #> 935         14         14    0 2.688  0.000     1 #> 936          6          7    1 2.688  0.372  0.71 #> 937          6          6    0 2.688  0.000     1 #> 938          8         10    2 2.688  0.744 0.457 #> 939          3          2   -1 2.688 -0.372  0.71 #> 940         11         10   -1 2.688 -0.372  0.71 #> 941         12         15    3 2.688  1.116 0.264 #> 942         13         14    1 2.688  0.372  0.71 #> 943         12          8   -4 2.688 -1.488 0.137 #> 944         15         13   -2 2.688 -0.744 0.457 #> 945         11         12    1 2.688  0.372  0.71 #> 946         11         11    0 2.688  0.000     1 #> 947         11         10   -1 2.688 -0.372  0.71 #> 948         10         13    3 2.688  1.116 0.264 #> 949          1          2    1 2.688  0.372  0.71 #> 950          7         12    5 2.688  1.860 0.063 #> 951          8          6   -2 2.688 -0.744 0.457 #> 952         15         12   -3 2.688 -1.116 0.264 #> 953          7          4   -3 2.688 -1.116 0.264 #> 954          2          6    4 2.688  1.488 0.137 #> 955          6          5   -1 2.688 -0.372  0.71 #> 956          3          3    0 2.688  0.000     1 #> 957          5          5    0 2.688  0.000     1 #> 958          6          6    0 2.688  0.000     1 #> 959         13         17    4 2.688  1.488 0.137 #> 960          6          7    1 2.688  0.372  0.71 #> 961          3          2   -1 2.688 -0.372  0.71 #> 962         12         11   -1 2.688 -0.372  0.71 #> 963          6          4   -2 2.688 -0.744 0.457 #> 964         17         12   -5 2.688 -1.860 0.063 #> 965          5          7    2 2.688  0.744 0.457 #> 966         13         16    3 2.688  1.116 0.264 #> 967         15         16    1 2.688  0.372  0.71 #> 968         12          9   -3 2.688 -1.116 0.264 #> 969         15         13   -2 2.688 -0.744 0.457 #> 970         14         16    2 2.688  0.744 0.457 #> 971          6          7    1 2.688  0.372  0.71 #> 972         16         16    0 2.688  0.000     1 #> 973          3          1   -2 2.688 -0.744 0.457 #> 974          5          5    0 2.688  0.000     1 #> 975          7          3   -4 2.688 -1.488 0.137 #> 976         13         13    0 2.688  0.000     1 #> 977         10         12    2 2.688  0.744 0.457 #> 978          2          4    2 2.688  0.744 0.457 #> 979          2          9    7 2.688  2.604 0.009 #> 980         10          9   -1 2.688 -0.372  0.71 #> 981          4          1   -3 2.688 -1.116 0.264 #> 982          7          4   -3 2.688 -1.116 0.264 #> 983         17         12   -5 2.688 -1.860 0.063 #> 984         18         16   -2 2.688 -0.744 0.457 #> 985         16         11   -5 2.688 -1.860 0.063 #> 986          5          3   -2 2.688 -0.744 0.457 #> 987         13         14    1 2.688  0.372  0.71 #> 988         11          8   -3 2.688 -1.116 0.264 #> 989          2         12   10 2.688  3.721     0 #> 990          9         11    2 2.688  0.744 0.457 #> 991         11          6   -5 2.688 -1.860 0.063 #> 992         11         10   -1 2.688 -0.372  0.71 #> 993          8          6   -2 2.688 -0.744 0.457 #> 994          1          4    3 2.688  1.116 0.264 #> 995         10          7   -3 2.688 -1.116 0.264 #> 996         11          5   -6 2.688 -2.232 0.026 #> 997          7          6   -1 2.688 -0.372  0.71 #> 998         10         12    2 2.688  0.744 0.457 #> 999         11          7   -4 2.688 -1.488 0.137 #> 1000         1          2    1 2.688  0.372  0.71  # include cutoffs RCI(predat = dat_pre, postdat = dat_post, SEM.pre=SEM.alpha,     cutoffs=c(-1.96, 1.96)) #>      pre.score post.score diff    SE      z     p cut_decision #> 1           18         19    1 2.688  0.372  0.71    unchanged #> 2           18          9   -9 2.688 -3.349 0.001    decreased #> 3           15          9   -6 2.688 -2.232 0.026    decreased #> 4           11         10   -1 2.688 -0.372  0.71    unchanged #> 5            4          5    1 2.688  0.372  0.71    unchanged #> 6            4          8    4 2.688  1.488 0.137    unchanged #> 7           11          8   -3 2.688 -1.116 0.264    unchanged #> 8           11         15    4 2.688  1.488 0.137    unchanged #> 9            3          3    0 2.688  0.000     1    unchanged #> 10           4          8    4 2.688  1.488 0.137    unchanged #> 11           1          5    4 2.688  1.488 0.137    unchanged #> 12          16         14   -2 2.688 -0.744 0.457    unchanged #> 13          12         10   -2 2.688 -0.744 0.457    unchanged #> 14          11         10   -1 2.688 -0.372  0.71    unchanged #> 15          17         18    1 2.688  0.372  0.71    unchanged #> 16           1          4    3 2.688  1.116 0.264    unchanged #> 17          10          8   -2 2.688 -0.744 0.457    unchanged #> 18          12         11   -1 2.688 -0.372  0.71    unchanged #> 19          15         12   -3 2.688 -1.116 0.264    unchanged #> 20          16         10   -6 2.688 -2.232 0.026    decreased #> 21           7          6   -1 2.688 -0.372  0.71    unchanged #> 22           7         12    5 2.688  1.860 0.063    unchanged #> 23           2          4    2 2.688  0.744 0.457    unchanged #> 24           5          7    2 2.688  0.744 0.457    unchanged #> 25          14         15    1 2.688  0.372  0.71    unchanged #> 26           9          6   -3 2.688 -1.116 0.264    unchanged #> 27          17         17    0 2.688  0.000     1    unchanged #> 28           4          9    5 2.688  1.860 0.063    unchanged #> 29          14         16    2 2.688  0.744 0.457    unchanged #> 30           4          7    3 2.688  1.116 0.264    unchanged #> 31           2          0   -2 2.688 -0.744 0.457    unchanged #> 32           9          6   -3 2.688 -1.116 0.264    unchanged #> 33          20         20    0 2.688  0.000     1    unchanged #> 34           9          6   -3 2.688 -1.116 0.264    unchanged #> 35           3          4    1 2.688  0.372  0.71    unchanged #> 36          14         15    1 2.688  0.372  0.71    unchanged #> 37           8          9    1 2.688  0.372  0.71    unchanged #> 38          15         13   -2 2.688 -0.744 0.457    unchanged #> 39           9         12    3 2.688  1.116 0.264    unchanged #> 40          18         18    0 2.688  0.000     1    unchanged #> 41          11         10   -1 2.688 -0.372  0.71    unchanged #> 42          12          9   -3 2.688 -1.116 0.264    unchanged #> 43           8          7   -1 2.688 -0.372  0.71    unchanged #> 44          10         11    1 2.688  0.372  0.71    unchanged #> 45           7         10    3 2.688  1.116 0.264    unchanged #> 46           8          9    1 2.688  0.372  0.71    unchanged #> 47           6          8    2 2.688  0.744 0.457    unchanged #> 48           6          7    1 2.688  0.372  0.71    unchanged #> 49           6          8    2 2.688  0.744 0.457    unchanged #> 50           8         11    3 2.688  1.116 0.264    unchanged #> 51          13         17    4 2.688  1.488 0.137    unchanged #> 52           6          6    0 2.688  0.000     1    unchanged #> 53          19         13   -6 2.688 -2.232 0.026    decreased #> 54           6         11    5 2.688  1.860 0.063    unchanged #> 55           9          8   -1 2.688 -0.372  0.71    unchanged #> 56           7          8    1 2.688  0.372  0.71    unchanged #> 57           9          6   -3 2.688 -1.116 0.264    unchanged #> 58           3          3    0 2.688  0.000     1    unchanged #> 59          10          8   -2 2.688 -0.744 0.457    unchanged #> 60          14         14    0 2.688  0.000     1    unchanged #> 61          12         12    0 2.688  0.000     1    unchanged #> 62          15         14   -1 2.688 -0.372  0.71    unchanged #> 63          13         12   -1 2.688 -0.372  0.71    unchanged #> 64           5          5    0 2.688  0.000     1    unchanged #> 65           5          4   -1 2.688 -0.372  0.71    unchanged #> 66           5          4   -1 2.688 -0.372  0.71    unchanged #> 67          18         14   -4 2.688 -1.488 0.137    unchanged #> 68           9          8   -1 2.688 -0.372  0.71    unchanged #> 69          11          9   -2 2.688 -0.744 0.457    unchanged #> 70          19         17   -2 2.688 -0.744 0.457    unchanged #> 71           9          5   -4 2.688 -1.488 0.137    unchanged #> 72          16         15   -1 2.688 -0.372  0.71    unchanged #> 73          10          9   -1 2.688 -0.372  0.71    unchanged #> 74          11         11    0 2.688  0.000     1    unchanged #> 75          14         10   -4 2.688 -1.488 0.137    unchanged #> 76          14         15    1 2.688  0.372  0.71    unchanged #> 77           5          4   -1 2.688 -0.372  0.71    unchanged #> 78          11          9   -2 2.688 -0.744 0.457    unchanged #> 79          15         10   -5 2.688 -1.860 0.063    unchanged #> 80          11         11    0 2.688  0.000     1    unchanged #> 81          10          8   -2 2.688 -0.744 0.457    unchanged #> 82          12         12    0 2.688  0.000     1    unchanged #> 83          11         11    0 2.688  0.000     1    unchanged #> 84           5          1   -4 2.688 -1.488 0.137    unchanged #> 85           7          9    2 2.688  0.744 0.457    unchanged #> 86           7         10    3 2.688  1.116 0.264    unchanged #> 87           3          7    4 2.688  1.488 0.137    unchanged #> 88           9         11    2 2.688  0.744 0.457    unchanged #> 89           8          9    1 2.688  0.372  0.71    unchanged #> 90          12         11   -1 2.688 -0.372  0.71    unchanged #> 91           6          1   -5 2.688 -1.860 0.063    unchanged #> 92           6          8    2 2.688  0.744 0.457    unchanged #> 93           3          5    2 2.688  0.744 0.457    unchanged #> 94          12         12    0 2.688  0.000     1    unchanged #> 95          18         16   -2 2.688 -0.744 0.457    unchanged #> 96           9          7   -2 2.688 -0.744 0.457    unchanged #> 97           8         11    3 2.688  1.116 0.264    unchanged #> 98           7          7    0 2.688  0.000     1    unchanged #> 99          12         11   -1 2.688 -0.372  0.71    unchanged #> 100         10         10    0 2.688  0.000     1    unchanged #> 101          5          5    0 2.688  0.000     1    unchanged #> 102         14         15    1 2.688  0.372  0.71    unchanged #> 103          9          9    0 2.688  0.000     1    unchanged #> 104          8         15    7 2.688  2.604 0.009    increased #> 105          2          3    1 2.688  0.372  0.71    unchanged #> 106          7         10    3 2.688  1.116 0.264    unchanged #> 107         12         12    0 2.688  0.000     1    unchanged #> 108          2          2    0 2.688  0.000     1    unchanged #> 109         14         13   -1 2.688 -0.372  0.71    unchanged #> 110          6          4   -2 2.688 -0.744 0.457    unchanged #> 111         15         10   -5 2.688 -1.860 0.063    unchanged #> 112          5          5    0 2.688  0.000     1    unchanged #> 113         15         18    3 2.688  1.116 0.264    unchanged #> 114          2          0   -2 2.688 -0.744 0.457    unchanged #> 115          9         12    3 2.688  1.116 0.264    unchanged #> 116         14         14    0 2.688  0.000     1    unchanged #> 117         10          7   -3 2.688 -1.116 0.264    unchanged #> 118          6          5   -1 2.688 -0.372  0.71    unchanged #> 119         12          9   -3 2.688 -1.116 0.264    unchanged #> 120          7          3   -4 2.688 -1.488 0.137    unchanged #> 121          9         12    3 2.688  1.116 0.264    unchanged #> 122          2          6    4 2.688  1.488 0.137    unchanged #> 123          9          6   -3 2.688 -1.116 0.264    unchanged #> 124          2          5    3 2.688  1.116 0.264    unchanged #> 125         12         12    0 2.688  0.000     1    unchanged #> 126         16         19    3 2.688  1.116 0.264    unchanged #> 127         13         14    1 2.688  0.372  0.71    unchanged #> 128         13         14    1 2.688  0.372  0.71    unchanged #> 129         14         15    1 2.688  0.372  0.71    unchanged #> 130          7         14    7 2.688  2.604 0.009    increased #> 131         10         11    1 2.688  0.372  0.71    unchanged #> 132          3          3    0 2.688  0.000     1    unchanged #> 133         15         15    0 2.688  0.000     1    unchanged #> 134         18         19    1 2.688  0.372  0.71    unchanged #> 135          2          5    3 2.688  1.116 0.264    unchanged #> 136         12         10   -2 2.688 -0.744 0.457    unchanged #> 137         12         14    2 2.688  0.744 0.457    unchanged #> 138          6          3   -3 2.688 -1.116 0.264    unchanged #> 139         13          9   -4 2.688 -1.488 0.137    unchanged #> 140          8          5   -3 2.688 -1.116 0.264    unchanged #> 141         18         17   -1 2.688 -0.372  0.71    unchanged #> 142         15         15    0 2.688  0.000     1    unchanged #> 143          7          9    2 2.688  0.744 0.457    unchanged #> 144         14         10   -4 2.688 -1.488 0.137    unchanged #> 145          3          5    2 2.688  0.744 0.457    unchanged #> 146          1          2    1 2.688  0.372  0.71    unchanged #> 147          5          6    1 2.688  0.372  0.71    unchanged #> 148          8          8    0 2.688  0.000     1    unchanged #> 149         13         15    2 2.688  0.744 0.457    unchanged #> 150          9          9    0 2.688  0.000     1    unchanged #> 151          8          9    1 2.688  0.372  0.71    unchanged #> 152          2          1   -1 2.688 -0.372  0.71    unchanged #> 153          3          3    0 2.688  0.000     1    unchanged #> 154          7          5   -2 2.688 -0.744 0.457    unchanged #> 155         16         13   -3 2.688 -1.116 0.264    unchanged #> 156          9         12    3 2.688  1.116 0.264    unchanged #> 157         15         17    2 2.688  0.744 0.457    unchanged #> 158         10          5   -5 2.688 -1.860 0.063    unchanged #> 159          8         10    2 2.688  0.744 0.457    unchanged #> 160         17         11   -6 2.688 -2.232 0.026    decreased #> 161         14          8   -6 2.688 -2.232 0.026    decreased #> 162          8          8    0 2.688  0.000     1    unchanged #> 163          3          5    2 2.688  0.744 0.457    unchanged #> 164         16          8   -8 2.688 -2.976 0.003    decreased #> 165          9          7   -2 2.688 -0.744 0.457    unchanged #> 166          7          8    1 2.688  0.372  0.71    unchanged #> 167         15         15    0 2.688  0.000     1    unchanged #> 168         15         18    3 2.688  1.116 0.264    unchanged #> 169          3          2   -1 2.688 -0.372  0.71    unchanged #> 170          1          2    1 2.688  0.372  0.71    unchanged #> 171          2          0   -2 2.688 -0.744 0.457    unchanged #> 172         20         15   -5 2.688 -1.860 0.063    unchanged #> 173         10         12    2 2.688  0.744 0.457    unchanged #> 174          9          3   -6 2.688 -2.232 0.026    decreased #> 175          5         15   10 2.688  3.721     0    increased #> 176          9          7   -2 2.688 -0.744 0.457    unchanged #> 177         15         16    1 2.688  0.372  0.71    unchanged #> 178          2          5    3 2.688  1.116 0.264    unchanged #> 179         18         20    2 2.688  0.744 0.457    unchanged #> 180         10          8   -2 2.688 -0.744 0.457    unchanged #> 181          6          6    0 2.688  0.000     1    unchanged #> 182          3          5    2 2.688  0.744 0.457    unchanged #> 183          9          7   -2 2.688 -0.744 0.457    unchanged #> 184          7         10    3 2.688  1.116 0.264    unchanged #> 185          6          3   -3 2.688 -1.116 0.264    unchanged #> 186          7          5   -2 2.688 -0.744 0.457    unchanged #> 187          7          4   -3 2.688 -1.116 0.264    unchanged #> 188         10          9   -1 2.688 -0.372  0.71    unchanged #> 189         17         12   -5 2.688 -1.860 0.063    unchanged #> 190          2          4    2 2.688  0.744 0.457    unchanged #> 191         16         15   -1 2.688 -0.372  0.71    unchanged #> 192          6          9    3 2.688  1.116 0.264    unchanged #> 193         10         13    3 2.688  1.116 0.264    unchanged #> 194          2          7    5 2.688  1.860 0.063    unchanged #> 195          5          3   -2 2.688 -0.744 0.457    unchanged #> 196         12          8   -4 2.688 -1.488 0.137    unchanged #> 197          5          1   -4 2.688 -1.488 0.137    unchanged #> 198          5          2   -3 2.688 -1.116 0.264    unchanged #> 199         17         17    0 2.688  0.000     1    unchanged #> 200          4          2   -2 2.688 -0.744 0.457    unchanged #> 201         13         13    0 2.688  0.000     1    unchanged #> 202         14         12   -2 2.688 -0.744 0.457    unchanged #> 203          2          2    0 2.688  0.000     1    unchanged #> 204         11          9   -2 2.688 -0.744 0.457    unchanged #> 205         10         11    1 2.688  0.372  0.71    unchanged #> 206         13         11   -2 2.688 -0.744 0.457    unchanged #> 207         17         18    1 2.688  0.372  0.71    unchanged #> 208         14         15    1 2.688  0.372  0.71    unchanged #> 209         18         18    0 2.688  0.000     1    unchanged #> 210          2          0   -2 2.688 -0.744 0.457    unchanged #> 211          9         11    2 2.688  0.744 0.457    unchanged #> 212         10         12    2 2.688  0.744 0.457    unchanged #> 213         16         14   -2 2.688 -0.744 0.457    unchanged #> 214          2          2    0 2.688  0.000     1    unchanged #> 215          3          4    1 2.688  0.372  0.71    unchanged #> 216         15         17    2 2.688  0.744 0.457    unchanged #> 217         14         12   -2 2.688 -0.744 0.457    unchanged #> 218          3          5    2 2.688  0.744 0.457    unchanged #> 219          9          8   -1 2.688 -0.372  0.71    unchanged #> 220          0          1    1 2.688  0.372  0.71    unchanged #> 221         14         12   -2 2.688 -0.744 0.457    unchanged #> 222          2          1   -1 2.688 -0.372  0.71    unchanged #> 223          5         10    5 2.688  1.860 0.063    unchanged #> 224          8         15    7 2.688  2.604 0.009    increased #> 225         12         14    2 2.688  0.744 0.457    unchanged #> 226         14         14    0 2.688  0.000     1    unchanged #> 227         11         11    0 2.688  0.000     1    unchanged #> 228          9          9    0 2.688  0.000     1    unchanged #> 229         17         15   -2 2.688 -0.744 0.457    unchanged #> 230          2          2    0 2.688  0.000     1    unchanged #> 231          6          9    3 2.688  1.116 0.264    unchanged #> 232          9         14    5 2.688  1.860 0.063    unchanged #> 233         13         13    0 2.688  0.000     1    unchanged #> 234         13         17    4 2.688  1.488 0.137    unchanged #> 235         13          6   -7 2.688 -2.604 0.009    decreased #> 236          8          8    0 2.688  0.000     1    unchanged #> 237          8          9    1 2.688  0.372  0.71    unchanged #> 238          6         12    6 2.688  2.232 0.026    increased #> 239          9          9    0 2.688  0.000     1    unchanged #> 240          7         12    5 2.688  1.860 0.063    unchanged #> 241         18         18    0 2.688  0.000     1    unchanged #> 242          4          3   -1 2.688 -0.372  0.71    unchanged #> 243          1          2    1 2.688  0.372  0.71    unchanged #> 244          3          1   -2 2.688 -0.744 0.457    unchanged #> 245          6          5   -1 2.688 -0.372  0.71    unchanged #> 246          4          4    0 2.688  0.000     1    unchanged #> 247         17         17    0 2.688  0.000     1    unchanged #> 248         20         18   -2 2.688 -0.744 0.457    unchanged #> 249          8         10    2 2.688  0.744 0.457    unchanged #> 250         15         18    3 2.688  1.116 0.264    unchanged #> 251         15         13   -2 2.688 -0.744 0.457    unchanged #> 252          8          8    0 2.688  0.000     1    unchanged #> 253          8          8    0 2.688  0.000     1    unchanged #> 254         11         13    2 2.688  0.744 0.457    unchanged #> 255         18         16   -2 2.688 -0.744 0.457    unchanged #> 256         10         11    1 2.688  0.372  0.71    unchanged #> 257         18         16   -2 2.688 -0.744 0.457    unchanged #> 258         10         11    1 2.688  0.372  0.71    unchanged #> 259          4          3   -1 2.688 -0.372  0.71    unchanged #> 260         11         14    3 2.688  1.116 0.264    unchanged #> 261         14         11   -3 2.688 -1.116 0.264    unchanged #> 262         14         13   -1 2.688 -0.372  0.71    unchanged #> 263         19         17   -2 2.688 -0.744 0.457    unchanged #> 264          4          6    2 2.688  0.744 0.457    unchanged #> 265         17         17    0 2.688  0.000     1    unchanged #> 266          9         12    3 2.688  1.116 0.264    unchanged #> 267          4          7    3 2.688  1.116 0.264    unchanged #> 268         15         12   -3 2.688 -1.116 0.264    unchanged #> 269          7          7    0 2.688  0.000     1    unchanged #> 270          8         11    3 2.688  1.116 0.264    unchanged #> 271          1          2    1 2.688  0.372  0.71    unchanged #> 272          8          6   -2 2.688 -0.744 0.457    unchanged #> 273          6          6    0 2.688  0.000     1    unchanged #> 274         17         16   -1 2.688 -0.372  0.71    unchanged #> 275         13         11   -2 2.688 -0.744 0.457    unchanged #> 276          2          1   -1 2.688 -0.372  0.71    unchanged #> 277          9         10    1 2.688  0.372  0.71    unchanged #> 278          2          0   -2 2.688 -0.744 0.457    unchanged #> 279         11         13    2 2.688  0.744 0.457    unchanged #> 280         17         17    0 2.688  0.000     1    unchanged #> 281         16         16    0 2.688  0.000     1    unchanged #> 282         14         15    1 2.688  0.372  0.71    unchanged #> 283         15         16    1 2.688  0.372  0.71    unchanged #> 284          4          1   -3 2.688 -1.116 0.264    unchanged #> 285         17         18    1 2.688  0.372  0.71    unchanged #> 286         10          7   -3 2.688 -1.116 0.264    unchanged #> 287         12         15    3 2.688  1.116 0.264    unchanged #> 288         15         17    2 2.688  0.744 0.457    unchanged #> 289         17         15   -2 2.688 -0.744 0.457    unchanged #> 290         14         11   -3 2.688 -1.116 0.264    unchanged #> 291         15         12   -3 2.688 -1.116 0.264    unchanged #> 292         10         10    0 2.688  0.000     1    unchanged #> 293          0          2    2 2.688  0.744 0.457    unchanged #> 294         12          8   -4 2.688 -1.488 0.137    unchanged #> 295          4          7    3 2.688  1.116 0.264    unchanged #> 296         15         15    0 2.688  0.000     1    unchanged #> 297         18         17   -1 2.688 -0.372  0.71    unchanged #> 298          9          7   -2 2.688 -0.744 0.457    unchanged #> 299         18         12   -6 2.688 -2.232 0.026    decreased #> 300          0          1    1 2.688  0.372  0.71    unchanged #> 301          4         11    7 2.688  2.604 0.009    increased #> 302         10          8   -2 2.688 -0.744 0.457    unchanged #> 303          5          2   -3 2.688 -1.116 0.264    unchanged #> 304         19         17   -2 2.688 -0.744 0.457    unchanged #> 305         11          6   -5 2.688 -1.860 0.063    unchanged #> 306         15         15    0 2.688  0.000     1    unchanged #> 307         10         12    2 2.688  0.744 0.457    unchanged #> 308         11          8   -3 2.688 -1.116 0.264    unchanged #> 309         10          7   -3 2.688 -1.116 0.264    unchanged #> 310          8          6   -2 2.688 -0.744 0.457    unchanged #> 311         14         15    1 2.688  0.372  0.71    unchanged #> 312         16         11   -5 2.688 -1.860 0.063    unchanged #> 313          6          4   -2 2.688 -0.744 0.457    unchanged #> 314         11         11    0 2.688  0.000     1    unchanged #> 315          7          7    0 2.688  0.000     1    unchanged #> 316          9         11    2 2.688  0.744 0.457    unchanged #> 317          7         11    4 2.688  1.488 0.137    unchanged #> 318          1          5    4 2.688  1.488 0.137    unchanged #> 319         10          9   -1 2.688 -0.372  0.71    unchanged #> 320         13         10   -3 2.688 -1.116 0.264    unchanged #> 321         13         10   -3 2.688 -1.116 0.264    unchanged #> 322         13          9   -4 2.688 -1.488 0.137    unchanged #> 323          1          2    1 2.688  0.372  0.71    unchanged #> 324         13         13    0 2.688  0.000     1    unchanged #> 325         13         13    0 2.688  0.000     1    unchanged #> 326         13         13    0 2.688  0.000     1    unchanged #> 327          7          6   -1 2.688 -0.372  0.71    unchanged #> 328          9         12    3 2.688  1.116 0.264    unchanged #> 329         13         13    0 2.688  0.000     1    unchanged #> 330          6         14    8 2.688  2.976 0.003    increased #> 331         12         14    2 2.688  0.744 0.457    unchanged #> 332          9          5   -4 2.688 -1.488 0.137    unchanged #> 333         13         12   -1 2.688 -0.372  0.71    unchanged #> 334         13         14    1 2.688  0.372  0.71    unchanged #> 335          9         11    2 2.688  0.744 0.457    unchanged #> 336         10          9   -1 2.688 -0.372  0.71    unchanged #> 337         12         13    1 2.688  0.372  0.71    unchanged #> 338         16         14   -2 2.688 -0.744 0.457    unchanged #> 339          6         10    4 2.688  1.488 0.137    unchanged #> 340         17         15   -2 2.688 -0.744 0.457    unchanged #> 341         12         14    2 2.688  0.744 0.457    unchanged #> 342          6          5   -1 2.688 -0.372  0.71    unchanged #> 343          5          9    4 2.688  1.488 0.137    unchanged #> 344          5          4   -1 2.688 -0.372  0.71    unchanged #> 345          6          9    3 2.688  1.116 0.264    unchanged #> 346         12          8   -4 2.688 -1.488 0.137    unchanged #> 347         12         13    1 2.688  0.372  0.71    unchanged #> 348          8         11    3 2.688  1.116 0.264    unchanged #> 349          5          6    1 2.688  0.372  0.71    unchanged #> 350         11         12    1 2.688  0.372  0.71    unchanged #> 351          9          7   -2 2.688 -0.744 0.457    unchanged #> 352         18         16   -2 2.688 -0.744 0.457    unchanged #> 353          9         11    2 2.688  0.744 0.457    unchanged #> 354          4          3   -1 2.688 -0.372  0.71    unchanged #> 355         12         17    5 2.688  1.860 0.063    unchanged #> 356         16         15   -1 2.688 -0.372  0.71    unchanged #> 357          9         13    4 2.688  1.488 0.137    unchanged #> 358         10          7   -3 2.688 -1.116 0.264    unchanged #> 359          1          3    2 2.688  0.744 0.457    unchanged #> 360         10         12    2 2.688  0.744 0.457    unchanged #> 361          5          5    0 2.688  0.000     1    unchanged #> 362         13         15    2 2.688  0.744 0.457    unchanged #> 363          9         12    3 2.688  1.116 0.264    unchanged #> 364         13         14    1 2.688  0.372  0.71    unchanged #> 365          9          5   -4 2.688 -1.488 0.137    unchanged #> 366         17         17    0 2.688  0.000     1    unchanged #> 367          4          2   -2 2.688 -0.744 0.457    unchanged #> 368         12          9   -3 2.688 -1.116 0.264    unchanged #> 369          3         10    7 2.688  2.604 0.009    increased #> 370         12         12    0 2.688  0.000     1    unchanged #> 371         14         18    4 2.688  1.488 0.137    unchanged #> 372         10         11    1 2.688  0.372  0.71    unchanged #> 373          7          9    2 2.688  0.744 0.457    unchanged #> 374          4          6    2 2.688  0.744 0.457    unchanged #> 375         10          5   -5 2.688 -1.860 0.063    unchanged #> 376         16         14   -2 2.688 -0.744 0.457    unchanged #> 377         15         15    0 2.688  0.000     1    unchanged #> 378         13         12   -1 2.688 -0.372  0.71    unchanged #> 379          0          3    3 2.688  1.116 0.264    unchanged #> 380          7          8    1 2.688  0.372  0.71    unchanged #> 381          6          7    1 2.688  0.372  0.71    unchanged #> 382          6          6    0 2.688  0.000     1    unchanged #> 383          6          8    2 2.688  0.744 0.457    unchanged #> 384          4          4    0 2.688  0.000     1    unchanged #> 385          3          4    1 2.688  0.372  0.71    unchanged #> 386          2          7    5 2.688  1.860 0.063    unchanged #> 387          9          9    0 2.688  0.000     1    unchanged #> 388         19         14   -5 2.688 -1.860 0.063    unchanged #> 389          3          6    3 2.688  1.116 0.264    unchanged #> 390          0          2    2 2.688  0.744 0.457    unchanged #> 391         15         14   -1 2.688 -0.372  0.71    unchanged #> 392         11          4   -7 2.688 -2.604 0.009    decreased #> 393          5          6    1 2.688  0.372  0.71    unchanged #> 394          2          1   -1 2.688 -0.372  0.71    unchanged #> 395          7         13    6 2.688  2.232 0.026    increased #> 396         13         11   -2 2.688 -0.744 0.457    unchanged #> 397         15         14   -1 2.688 -0.372  0.71    unchanged #> 398          2          4    2 2.688  0.744 0.457    unchanged #> 399         13          6   -7 2.688 -2.604 0.009    decreased #> 400         15          9   -6 2.688 -2.232 0.026    decreased #> 401          7          8    1 2.688  0.372  0.71    unchanged #> 402          3          3    0 2.688  0.000     1    unchanged #> 403          9         12    3 2.688  1.116 0.264    unchanged #> 404         17         17    0 2.688  0.000     1    unchanged #> 405          1          4    3 2.688  1.116 0.264    unchanged #> 406          4          2   -2 2.688 -0.744 0.457    unchanged #> 407          7         10    3 2.688  1.116 0.264    unchanged #> 408          7         11    4 2.688  1.488 0.137    unchanged #> 409         12         12    0 2.688  0.000     1    unchanged #> 410          8          6   -2 2.688 -0.744 0.457    unchanged #> 411          8          4   -4 2.688 -1.488 0.137    unchanged #> 412         14         11   -3 2.688 -1.116 0.264    unchanged #> 413          5          3   -2 2.688 -0.744 0.457    unchanged #> 414         16         17    1 2.688  0.372  0.71    unchanged #> 415         11         15    4 2.688  1.488 0.137    unchanged #> 416         15         12   -3 2.688 -1.116 0.264    unchanged #> 417         14         15    1 2.688  0.372  0.71    unchanged #> 418          5          6    1 2.688  0.372  0.71    unchanged #> 419          5         10    5 2.688  1.860 0.063    unchanged #> 420         10         13    3 2.688  1.116 0.264    unchanged #> 421          3          2   -1 2.688 -0.372  0.71    unchanged #> 422         17         17    0 2.688  0.000     1    unchanged #> 423         11         11    0 2.688  0.000     1    unchanged #> 424         14         13   -1 2.688 -0.372  0.71    unchanged #> 425         16          9   -7 2.688 -2.604 0.009    decreased #> 426         15         16    1 2.688  0.372  0.71    unchanged #> 427         11          7   -4 2.688 -1.488 0.137    unchanged #> 428          8         11    3 2.688  1.116 0.264    unchanged #> 429         13         13    0 2.688  0.000     1    unchanged #> 430         10         10    0 2.688  0.000     1    unchanged #> 431         15         14   -1 2.688 -0.372  0.71    unchanged #> 432          1          4    3 2.688  1.116 0.264    unchanged #> 433          3          3    0 2.688  0.000     1    unchanged #> 434         11         15    4 2.688  1.488 0.137    unchanged #> 435          3          4    1 2.688  0.372  0.71    unchanged #> 436          6         11    5 2.688  1.860 0.063    unchanged #> 437          2          0   -2 2.688 -0.744 0.457    unchanged #> 438         13         14    1 2.688  0.372  0.71    unchanged #> 439         18         14   -4 2.688 -1.488 0.137    unchanged #> 440          6         13    7 2.688  2.604 0.009    increased #> 441         14         12   -2 2.688 -0.744 0.457    unchanged #> 442          4          5    1 2.688  0.372  0.71    unchanged #> 443         10          9   -1 2.688 -0.372  0.71    unchanged #> 444         18         18    0 2.688  0.000     1    unchanged #> 445         17         16   -1 2.688 -0.372  0.71    unchanged #> 446         16         17    1 2.688  0.372  0.71    unchanged #> 447          0          0    0 2.688  0.000     1    unchanged #> 448         12         10   -2 2.688 -0.744 0.457    unchanged #> 449          4          7    3 2.688  1.116 0.264    unchanged #> 450          1          4    3 2.688  1.116 0.264    unchanged #> 451         19         18   -1 2.688 -0.372  0.71    unchanged #> 452          8          5   -3 2.688 -1.116 0.264    unchanged #> 453          8         11    3 2.688  1.116 0.264    unchanged #> 454          5          9    4 2.688  1.488 0.137    unchanged #> 455         18         17   -1 2.688 -0.372  0.71    unchanged #> 456         12         11   -1 2.688 -0.372  0.71    unchanged #> 457          5          9    4 2.688  1.488 0.137    unchanged #> 458          2          5    3 2.688  1.116 0.264    unchanged #> 459          1          2    1 2.688  0.372  0.71    unchanged #> 460         19         18   -1 2.688 -0.372  0.71    unchanged #> 461         15         17    2 2.688  0.744 0.457    unchanged #> 462         17         13   -4 2.688 -1.488 0.137    unchanged #> 463         13         15    2 2.688  0.744 0.457    unchanged #> 464         14         14    0 2.688  0.000     1    unchanged #> 465          6          9    3 2.688  1.116 0.264    unchanged #> 466          9          5   -4 2.688 -1.488 0.137    unchanged #> 467         16         15   -1 2.688 -0.372  0.71    unchanged #> 468          3          2   -1 2.688 -0.372  0.71    unchanged #> 469          1          7    6 2.688  2.232 0.026    increased #> 470         13         10   -3 2.688 -1.116 0.264    unchanged #> 471          5          4   -1 2.688 -0.372  0.71    unchanged #> 472          6          7    1 2.688  0.372  0.71    unchanged #> 473         20         19   -1 2.688 -0.372  0.71    unchanged #> 474          7          9    2 2.688  0.744 0.457    unchanged #> 475          1          1    0 2.688  0.000     1    unchanged #> 476         15         13   -2 2.688 -0.744 0.457    unchanged #> 477         16         11   -5 2.688 -1.860 0.063    unchanged #> 478         16         12   -4 2.688 -1.488 0.137    unchanged #> 479         11         10   -1 2.688 -0.372  0.71    unchanged #> 480         15         16    1 2.688  0.372  0.71    unchanged #> 481          7          8    1 2.688  0.372  0.71    unchanged #> 482         15         12   -3 2.688 -1.116 0.264    unchanged #> 483         15         16    1 2.688  0.372  0.71    unchanged #> 484         12         11   -1 2.688 -0.372  0.71    unchanged #> 485         12         10   -2 2.688 -0.744 0.457    unchanged #> 486          5          8    3 2.688  1.116 0.264    unchanged #> 487          8         12    4 2.688  1.488 0.137    unchanged #> 488         11         13    2 2.688  0.744 0.457    unchanged #> 489         16         17    1 2.688  0.372  0.71    unchanged #> 490          7          8    1 2.688  0.372  0.71    unchanged #> 491         19         18   -1 2.688 -0.372  0.71    unchanged #> 492          4          5    1 2.688  0.372  0.71    unchanged #> 493         19         16   -3 2.688 -1.116 0.264    unchanged #> 494          8          9    1 2.688  0.372  0.71    unchanged #> 495         10         15    5 2.688  1.860 0.063    unchanged #> 496          6          7    1 2.688  0.372  0.71    unchanged #> 497         11          8   -3 2.688 -1.116 0.264    unchanged #> 498          3          9    6 2.688  2.232 0.026    increased #> 499          8          8    0 2.688  0.000     1    unchanged #> 500          7         11    4 2.688  1.488 0.137    unchanged #> 501         13         16    3 2.688  1.116 0.264    unchanged #> 502         11         10   -1 2.688 -0.372  0.71    unchanged #> 503          0          1    1 2.688  0.372  0.71    unchanged #> 504          4          5    1 2.688  0.372  0.71    unchanged #> 505          4          6    2 2.688  0.744 0.457    unchanged #> 506         12         10   -2 2.688 -0.744 0.457    unchanged #> 507         18         16   -2 2.688 -0.744 0.457    unchanged #> 508         13         14    1 2.688  0.372  0.71    unchanged #> 509          5          7    2 2.688  0.744 0.457    unchanged #> 510          8         10    2 2.688  0.744 0.457    unchanged #> 511          6         10    4 2.688  1.488 0.137    unchanged #> 512          7          9    2 2.688  0.744 0.457    unchanged #> 513          5          5    0 2.688  0.000     1    unchanged #> 514          5         10    5 2.688  1.860 0.063    unchanged #> 515          9         11    2 2.688  0.744 0.457    unchanged #> 516         17         17    0 2.688  0.000     1    unchanged #> 517         14         13   -1 2.688 -0.372  0.71    unchanged #> 518          8         15    7 2.688  2.604 0.009    increased #> 519         14         14    0 2.688  0.000     1    unchanged #> 520         13          8   -5 2.688 -1.860 0.063    unchanged #> 521         14         12   -2 2.688 -0.744 0.457    unchanged #> 522          6          2   -4 2.688 -1.488 0.137    unchanged #> 523         17         14   -3 2.688 -1.116 0.264    unchanged #> 524         13         13    0 2.688  0.000     1    unchanged #> 525         14         14    0 2.688  0.000     1    unchanged #> 526         16         12   -4 2.688 -1.488 0.137    unchanged #> 527         12         10   -2 2.688 -0.744 0.457    unchanged #> 528         15         16    1 2.688  0.372  0.71    unchanged #> 529         13         10   -3 2.688 -1.116 0.264    unchanged #> 530          9         10    1 2.688  0.372  0.71    unchanged #> 531         12          7   -5 2.688 -1.860 0.063    unchanged #> 532         20         20    0 2.688  0.000     1    unchanged #> 533         17         12   -5 2.688 -1.860 0.063    unchanged #> 534          6          8    2 2.688  0.744 0.457    unchanged #> 535         19         18   -1 2.688 -0.372  0.71    unchanged #> 536         12         12    0 2.688  0.000     1    unchanged #> 537         10          7   -3 2.688 -1.116 0.264    unchanged #> 538          6          4   -2 2.688 -0.744 0.457    unchanged #> 539          8          8    0 2.688  0.000     1    unchanged #> 540         10         12    2 2.688  0.744 0.457    unchanged #> 541          4          7    3 2.688  1.116 0.264    unchanged #> 542          2          2    0 2.688  0.000     1    unchanged #> 543          6          5   -1 2.688 -0.372  0.71    unchanged #> 544         12         10   -2 2.688 -0.744 0.457    unchanged #> 545          4          5    1 2.688  0.372  0.71    unchanged #> 546         11         10   -1 2.688 -0.372  0.71    unchanged #> 547         14         12   -2 2.688 -0.744 0.457    unchanged #> 548         13         15    2 2.688  0.744 0.457    unchanged #> 549         12          9   -3 2.688 -1.116 0.264    unchanged #> 550         11         11    0 2.688  0.000     1    unchanged #> 551          8          2   -6 2.688 -2.232 0.026    decreased #> 552         14         15    1 2.688  0.372  0.71    unchanged #> 553         11         14    3 2.688  1.116 0.264    unchanged #> 554         13         12   -1 2.688 -0.372  0.71    unchanged #> 555          2          3    1 2.688  0.372  0.71    unchanged #> 556          9         13    4 2.688  1.488 0.137    unchanged #> 557         10         11    1 2.688  0.372  0.71    unchanged #> 558          8         12    4 2.688  1.488 0.137    unchanged #> 559         11         12    1 2.688  0.372  0.71    unchanged #> 560         19         18   -1 2.688 -0.372  0.71    unchanged #> 561         12         12    0 2.688  0.000     1    unchanged #> 562         12          8   -4 2.688 -1.488 0.137    unchanged #> 563          3          6    3 2.688  1.116 0.264    unchanged #> 564          4          0   -4 2.688 -1.488 0.137    unchanged #> 565         14         14    0 2.688  0.000     1    unchanged #> 566          3          4    1 2.688  0.372  0.71    unchanged #> 567         18         16   -2 2.688 -0.744 0.457    unchanged #> 568          3          2   -1 2.688 -0.372  0.71    unchanged #> 569         17         19    2 2.688  0.744 0.457    unchanged #> 570         10          8   -2 2.688 -0.744 0.457    unchanged #> 571         16         13   -3 2.688 -1.116 0.264    unchanged #> 572          8          8    0 2.688  0.000     1    unchanged #> 573         15         17    2 2.688  0.744 0.457    unchanged #> 574          7         12    5 2.688  1.860 0.063    unchanged #> 575          6          2   -4 2.688 -1.488 0.137    unchanged #> 576         11         14    3 2.688  1.116 0.264    unchanged #> 577         13         12   -1 2.688 -0.372  0.71    unchanged #> 578         17         14   -3 2.688 -1.116 0.264    unchanged #> 579          5          9    4 2.688  1.488 0.137    unchanged #> 580         12         17    5 2.688  1.860 0.063    unchanged #> 581         11         10   -1 2.688 -0.372  0.71    unchanged #> 582          6         12    6 2.688  2.232 0.026    increased #> 583         11         13    2 2.688  0.744 0.457    unchanged #> 584         16         18    2 2.688  0.744 0.457    unchanged #> 585          8          6   -2 2.688 -0.744 0.457    unchanged #> 586          7          9    2 2.688  0.744 0.457    unchanged #> 587         12         11   -1 2.688 -0.372  0.71    unchanged #> 588          9          7   -2 2.688 -0.744 0.457    unchanged #> 589          9          6   -3 2.688 -1.116 0.264    unchanged #> 590         14         13   -1 2.688 -0.372  0.71    unchanged #> 591         15         15    0 2.688  0.000     1    unchanged #> 592         19         15   -4 2.688 -1.488 0.137    unchanged #> 593          6          7    1 2.688  0.372  0.71    unchanged #> 594          4          3   -1 2.688 -0.372  0.71    unchanged #> 595          4          6    2 2.688  0.744 0.457    unchanged #> 596          4          3   -1 2.688 -0.372  0.71    unchanged #> 597          4          4    0 2.688  0.000     1    unchanged #> 598         10          6   -4 2.688 -1.488 0.137    unchanged #> 599          8         14    6 2.688  2.232 0.026    increased #> 600          9         12    3 2.688  1.116 0.264    unchanged #> 601         10         12    2 2.688  0.744 0.457    unchanged #> 602         12          9   -3 2.688 -1.116 0.264    unchanged #> 603         13          9   -4 2.688 -1.488 0.137    unchanged #> 604         11         11    0 2.688  0.000     1    unchanged #> 605          2          4    2 2.688  0.744 0.457    unchanged #> 606         16         14   -2 2.688 -0.744 0.457    unchanged #> 607          2          1   -1 2.688 -0.372  0.71    unchanged #> 608          3          2   -1 2.688 -0.372  0.71    unchanged #> 609          6          4   -2 2.688 -0.744 0.457    unchanged #> 610         15         11   -4 2.688 -1.488 0.137    unchanged #> 611          7          6   -1 2.688 -0.372  0.71    unchanged #> 612         14         18    4 2.688  1.488 0.137    unchanged #> 613          7         14    7 2.688  2.604 0.009    increased #> 614         18         14   -4 2.688 -1.488 0.137    unchanged #> 615          9          6   -3 2.688 -1.116 0.264    unchanged #> 616         11         11    0 2.688  0.000     1    unchanged #> 617          6          2   -4 2.688 -1.488 0.137    unchanged #> 618         10          7   -3 2.688 -1.116 0.264    unchanged #> 619          3          2   -1 2.688 -0.372  0.71    unchanged #> 620          8          4   -4 2.688 -1.488 0.137    unchanged #> 621          8         10    2 2.688  0.744 0.457    unchanged #> 622         16         16    0 2.688  0.000     1    unchanged #> 623          4          2   -2 2.688 -0.744 0.457    unchanged #> 624         13         15    2 2.688  0.744 0.457    unchanged #> 625         11         11    0 2.688  0.000     1    unchanged #> 626         14         13   -1 2.688 -0.372  0.71    unchanged #> 627          4          8    4 2.688  1.488 0.137    unchanged #> 628          6          8    2 2.688  0.744 0.457    unchanged #> 629         15          9   -6 2.688 -2.232 0.026    decreased #> 630          2          3    1 2.688  0.372  0.71    unchanged #> 631          2          3    1 2.688  0.372  0.71    unchanged #> 632          8          6   -2 2.688 -0.744 0.457    unchanged #> 633          8          4   -4 2.688 -1.488 0.137    unchanged #> 634         12         18    6 2.688  2.232 0.026    increased #> 635         15         15    0 2.688  0.000     1    unchanged #> 636         10         10    0 2.688  0.000     1    unchanged #> 637          3          3    0 2.688  0.000     1    unchanged #> 638         14         15    1 2.688  0.372  0.71    unchanged #> 639          9          6   -3 2.688 -1.116 0.264    unchanged #> 640          2          5    3 2.688  1.116 0.264    unchanged #> 641         14         17    3 2.688  1.116 0.264    unchanged #> 642          4          2   -2 2.688 -0.744 0.457    unchanged #> 643         12         13    1 2.688  0.372  0.71    unchanged #> 644         10          7   -3 2.688 -1.116 0.264    unchanged #> 645          3          4    1 2.688  0.372  0.71    unchanged #> 646          4          2   -2 2.688 -0.744 0.457    unchanged #> 647          2          6    4 2.688  1.488 0.137    unchanged #> 648         11          8   -3 2.688 -1.116 0.264    unchanged #> 649         10         10    0 2.688  0.000     1    unchanged #> 650         17         17    0 2.688  0.000     1    unchanged #> 651          8         10    2 2.688  0.744 0.457    unchanged #> 652          8          9    1 2.688  0.372  0.71    unchanged #> 653         17         17    0 2.688  0.000     1    unchanged #> 654         15         13   -2 2.688 -0.744 0.457    unchanged #> 655         14         19    5 2.688  1.860 0.063    unchanged #> 656         10         14    4 2.688  1.488 0.137    unchanged #> 657         12         13    1 2.688  0.372  0.71    unchanged #> 658          7         12    5 2.688  1.860 0.063    unchanged #> 659         11         12    1 2.688  0.372  0.71    unchanged #> 660         13         10   -3 2.688 -1.116 0.264    unchanged #> 661          7          7    0 2.688  0.000     1    unchanged #> 662          8          6   -2 2.688 -0.744 0.457    unchanged #> 663          7          5   -2 2.688 -0.744 0.457    unchanged #> 664         14         10   -4 2.688 -1.488 0.137    unchanged #> 665         17         19    2 2.688  0.744 0.457    unchanged #> 666          9          6   -3 2.688 -1.116 0.264    unchanged #> 667          3          3    0 2.688  0.000     1    unchanged #> 668         15         11   -4 2.688 -1.488 0.137    unchanged #> 669          7          8    1 2.688  0.372  0.71    unchanged #> 670         12         12    0 2.688  0.000     1    unchanged #> 671         13         13    0 2.688  0.000     1    unchanged #> 672         16         20    4 2.688  1.488 0.137    unchanged #> 673         13          9   -4 2.688 -1.488 0.137    unchanged #> 674         14         16    2 2.688  0.744 0.457    unchanged #> 675          7          2   -5 2.688 -1.860 0.063    unchanged #> 676         10          6   -4 2.688 -1.488 0.137    unchanged #> 677         10         12    2 2.688  0.744 0.457    unchanged #> 678          8          9    1 2.688  0.372  0.71    unchanged #> 679          4          7    3 2.688  1.116 0.264    unchanged #> 680          2          4    2 2.688  0.744 0.457    unchanged #> 681         13         10   -3 2.688 -1.116 0.264    unchanged #> 682          5         12    7 2.688  2.604 0.009    increased #> 683          5          6    1 2.688  0.372  0.71    unchanged #> 684         10          7   -3 2.688 -1.116 0.264    unchanged #> 685         13         12   -1 2.688 -0.372  0.71    unchanged #> 686         17         19    2 2.688  0.744 0.457    unchanged #> 687         11         12    1 2.688  0.372  0.71    unchanged #> 688          4         10    6 2.688  2.232 0.026    increased #> 689          6          4   -2 2.688 -0.744 0.457    unchanged #> 690          3          5    2 2.688  0.744 0.457    unchanged #> 691         11         14    3 2.688  1.116 0.264    unchanged #> 692          7          2   -5 2.688 -1.860 0.063    unchanged #> 693          8         10    2 2.688  0.744 0.457    unchanged #> 694         13         11   -2 2.688 -0.744 0.457    unchanged #> 695         13         16    3 2.688  1.116 0.264    unchanged #> 696         16         15   -1 2.688 -0.372  0.71    unchanged #> 697         16         12   -4 2.688 -1.488 0.137    unchanged #> 698          3          3    0 2.688  0.000     1    unchanged #> 699         12         15    3 2.688  1.116 0.264    unchanged #> 700         12         16    4 2.688  1.488 0.137    unchanged #> 701          3          3    0 2.688  0.000     1    unchanged #> 702         20         20    0 2.688  0.000     1    unchanged #> 703          7         10    3 2.688  1.116 0.264    unchanged #> 704          9         13    4 2.688  1.488 0.137    unchanged #> 705          5          7    2 2.688  0.744 0.457    unchanged #> 706          2          2    0 2.688  0.000     1    unchanged #> 707         13         16    3 2.688  1.116 0.264    unchanged #> 708          5          7    2 2.688  0.744 0.457    unchanged #> 709          8          7   -1 2.688 -0.372  0.71    unchanged #> 710         15         18    3 2.688  1.116 0.264    unchanged #> 711          3          1   -2 2.688 -0.744 0.457    unchanged #> 712          5          5    0 2.688  0.000     1    unchanged #> 713          5          3   -2 2.688 -0.744 0.457    unchanged #> 714         15         16    1 2.688  0.372  0.71    unchanged #> 715         12         10   -2 2.688 -0.744 0.457    unchanged #> 716          9          6   -3 2.688 -1.116 0.264    unchanged #> 717          5          2   -3 2.688 -1.116 0.264    unchanged #> 718          3          4    1 2.688  0.372  0.71    unchanged #> 719          2          6    4 2.688  1.488 0.137    unchanged #> 720          4          6    2 2.688  0.744 0.457    unchanged #> 721         10         12    2 2.688  0.744 0.457    unchanged #> 722         16         14   -2 2.688 -0.744 0.457    unchanged #> 723          3          2   -1 2.688 -0.372  0.71    unchanged #> 724         13          8   -5 2.688 -1.860 0.063    unchanged #> 725         17         15   -2 2.688 -0.744 0.457    unchanged #> 726          8          8    0 2.688  0.000     1    unchanged #> 727          8         10    2 2.688  0.744 0.457    unchanged #> 728         16         12   -4 2.688 -1.488 0.137    unchanged #> 729         11         15    4 2.688  1.488 0.137    unchanged #> 730          4          8    4 2.688  1.488 0.137    unchanged #> 731          5          6    1 2.688  0.372  0.71    unchanged #> 732          4          3   -1 2.688 -0.372  0.71    unchanged #> 733          8          6   -2 2.688 -0.744 0.457    unchanged #> 734         18         19    1 2.688  0.372  0.71    unchanged #> 735         10         11    1 2.688  0.372  0.71    unchanged #> 736         10         12    2 2.688  0.744 0.457    unchanged #> 737         18         20    2 2.688  0.744 0.457    unchanged #> 738         11          5   -6 2.688 -2.232 0.026    decreased #> 739         17         17    0 2.688  0.000     1    unchanged #> 740          3          5    2 2.688  0.744 0.457    unchanged #> 741         15         15    0 2.688  0.000     1    unchanged #> 742          8          9    1 2.688  0.372  0.71    unchanged #> 743          9          5   -4 2.688 -1.488 0.137    unchanged #> 744         16         13   -3 2.688 -1.116 0.264    unchanged #> 745         14         13   -1 2.688 -0.372  0.71    unchanged #> 746          8          6   -2 2.688 -0.744 0.457    unchanged #> 747          5          9    4 2.688  1.488 0.137    unchanged #> 748          3          1   -2 2.688 -0.744 0.457    unchanged #> 749          6          7    1 2.688  0.372  0.71    unchanged #> 750         17         13   -4 2.688 -1.488 0.137    unchanged #> 751         15         15    0 2.688  0.000     1    unchanged #> 752          5          6    1 2.688  0.372  0.71    unchanged #> 753          9         11    2 2.688  0.744 0.457    unchanged #> 754         16         14   -2 2.688 -0.744 0.457    unchanged #> 755         12         12    0 2.688  0.000     1    unchanged #> 756         12         14    2 2.688  0.744 0.457    unchanged #> 757         14          9   -5 2.688 -1.860 0.063    unchanged #> 758         12         15    3 2.688  1.116 0.264    unchanged #> 759          1          0   -1 2.688 -0.372  0.71    unchanged #> 760         13         17    4 2.688  1.488 0.137    unchanged #> 761         17         19    2 2.688  0.744 0.457    unchanged #> 762          4          4    0 2.688  0.000     1    unchanged #> 763         10          7   -3 2.688 -1.116 0.264    unchanged #> 764         15         15    0 2.688  0.000     1    unchanged #> 765         10         12    2 2.688  0.744 0.457    unchanged #> 766          2          2    0 2.688  0.000     1    unchanged #> 767         16         16    0 2.688  0.000     1    unchanged #> 768         14         13   -1 2.688 -0.372  0.71    unchanged #> 769         15         15    0 2.688  0.000     1    unchanged #> 770          7          3   -4 2.688 -1.488 0.137    unchanged #> 771          7          3   -4 2.688 -1.488 0.137    unchanged #> 772         15         14   -1 2.688 -0.372  0.71    unchanged #> 773         11         12    1 2.688  0.372  0.71    unchanged #> 774          2          1   -1 2.688 -0.372  0.71    unchanged #> 775          3          7    4 2.688  1.488 0.137    unchanged #> 776         16         16    0 2.688  0.000     1    unchanged #> 777         14          9   -5 2.688 -1.860 0.063    unchanged #> 778         14         14    0 2.688  0.000     1    unchanged #> 779         14         13   -1 2.688 -0.372  0.71    unchanged #> 780         13          9   -4 2.688 -1.488 0.137    unchanged #> 781         13         11   -2 2.688 -0.744 0.457    unchanged #> 782          5         13    8 2.688  2.976 0.003    increased #> 783         13         12   -1 2.688 -0.372  0.71    unchanged #> 784          8          7   -1 2.688 -0.372  0.71    unchanged #> 785         17         16   -1 2.688 -0.372  0.71    unchanged #> 786         10         11    1 2.688  0.372  0.71    unchanged #> 787         12         10   -2 2.688 -0.744 0.457    unchanged #> 788          7          9    2 2.688  0.744 0.457    unchanged #> 789          2          2    0 2.688  0.000     1    unchanged #> 790          1          3    2 2.688  0.744 0.457    unchanged #> 791          3          8    5 2.688  1.860 0.063    unchanged #> 792         14         16    2 2.688  0.744 0.457    unchanged #> 793          4          7    3 2.688  1.116 0.264    unchanged #> 794         15         17    2 2.688  0.744 0.457    unchanged #> 795         15         13   -2 2.688 -0.744 0.457    unchanged #> 796          7          8    1 2.688  0.372  0.71    unchanged #> 797          6          4   -2 2.688 -0.744 0.457    unchanged #> 798          7          6   -1 2.688 -0.372  0.71    unchanged #> 799         11          8   -3 2.688 -1.116 0.264    unchanged #> 800          8         12    4 2.688  1.488 0.137    unchanged #> 801          6          3   -3 2.688 -1.116 0.264    unchanged #> 802          7          2   -5 2.688 -1.860 0.063    unchanged #> 803          9          9    0 2.688  0.000     1    unchanged #> 804         17         14   -3 2.688 -1.116 0.264    unchanged #> 805          6          7    1 2.688  0.372  0.71    unchanged #> 806         14         13   -1 2.688 -0.372  0.71    unchanged #> 807          6         13    7 2.688  2.604 0.009    increased #> 808          7          9    2 2.688  0.744 0.457    unchanged #> 809         17         17    0 2.688  0.000     1    unchanged #> 810          3          6    3 2.688  1.116 0.264    unchanged #> 811         15         18    3 2.688  1.116 0.264    unchanged #> 812         10         10    0 2.688  0.000     1    unchanged #> 813          7          2   -5 2.688 -1.860 0.063    unchanged #> 814         13         14    1 2.688  0.372  0.71    unchanged #> 815          8         10    2 2.688  0.744 0.457    unchanged #> 816          7          7    0 2.688  0.000     1    unchanged #> 817         15          5  -10 2.688 -3.721     0    decreased #> 818         11         11    0 2.688  0.000     1    unchanged #> 819          8         14    6 2.688  2.232 0.026    increased #> 820          7          5   -2 2.688 -0.744 0.457    unchanged #> 821         12         12    0 2.688  0.000     1    unchanged #> 822         10         13    3 2.688  1.116 0.264    unchanged #> 823          3          3    0 2.688  0.000     1    unchanged #> 824         17         18    1 2.688  0.372  0.71    unchanged #> 825          7          6   -1 2.688 -0.372  0.71    unchanged #> 826          5          7    2 2.688  0.744 0.457    unchanged #> 827         15         14   -1 2.688 -0.372  0.71    unchanged #> 828          3          7    4 2.688  1.488 0.137    unchanged #> 829          4          3   -1 2.688 -0.372  0.71    unchanged #> 830         20         17   -3 2.688 -1.116 0.264    unchanged #> 831          8          5   -3 2.688 -1.116 0.264    unchanged #> 832         13         18    5 2.688  1.860 0.063    unchanged #> 833         15         15    0 2.688  0.000     1    unchanged #> 834         16         17    1 2.688  0.372  0.71    unchanged #> 835          6          6    0 2.688  0.000     1    unchanged #> 836         16         16    0 2.688  0.000     1    unchanged #> 837          9          9    0 2.688  0.000     1    unchanged #> 838         10         16    6 2.688  2.232 0.026    increased #> 839         10         11    1 2.688  0.372  0.71    unchanged #> 840         16         17    1 2.688  0.372  0.71    unchanged #> 841         15         15    0 2.688  0.000     1    unchanged #> 842         13         13    0 2.688  0.000     1    unchanged #> 843         15         16    1 2.688  0.372  0.71    unchanged #> 844         10          7   -3 2.688 -1.116 0.264    unchanged #> 845         12          9   -3 2.688 -1.116 0.264    unchanged #> 846         12         12    0 2.688  0.000     1    unchanged #> 847          8          7   -1 2.688 -0.372  0.71    unchanged #> 848          7          3   -4 2.688 -1.488 0.137    unchanged #> 849          5          5    0 2.688  0.000     1    unchanged #> 850         19         16   -3 2.688 -1.116 0.264    unchanged #> 851         15         15    0 2.688  0.000     1    unchanged #> 852         13          8   -5 2.688 -1.860 0.063    unchanged #> 853          9         10    1 2.688  0.372  0.71    unchanged #> 854          8          8    0 2.688  0.000     1    unchanged #> 855          9          9    0 2.688  0.000     1    unchanged #> 856         12         13    1 2.688  0.372  0.71    unchanged #> 857         10          7   -3 2.688 -1.116 0.264    unchanged #> 858         13         10   -3 2.688 -1.116 0.264    unchanged #> 859         10          9   -1 2.688 -0.372  0.71    unchanged #> 860          5          8    3 2.688  1.116 0.264    unchanged #> 861          5          3   -2 2.688 -0.744 0.457    unchanged #> 862         13         14    1 2.688  0.372  0.71    unchanged #> 863          3          6    3 2.688  1.116 0.264    unchanged #> 864          8          4   -4 2.688 -1.488 0.137    unchanged #> 865         10         13    3 2.688  1.116 0.264    unchanged #> 866         12         12    0 2.688  0.000     1    unchanged #> 867          9         10    1 2.688  0.372  0.71    unchanged #> 868         11         13    2 2.688  0.744 0.457    unchanged #> 869         10          7   -3 2.688 -1.116 0.264    unchanged #> 870         13         13    0 2.688  0.000     1    unchanged #> 871         14         13   -1 2.688 -0.372  0.71    unchanged #> 872          8         10    2 2.688  0.744 0.457    unchanged #> 873          1          1    0 2.688  0.000     1    unchanged #> 874          7         13    6 2.688  2.232 0.026    increased #> 875         14         16    2 2.688  0.744 0.457    unchanged #> 876          9          8   -1 2.688 -0.372  0.71    unchanged #> 877         16         16    0 2.688  0.000     1    unchanged #> 878         14         15    1 2.688  0.372  0.71    unchanged #> 879          8         10    2 2.688  0.744 0.457    unchanged #> 880          6          2   -4 2.688 -1.488 0.137    unchanged #> 881          5          2   -3 2.688 -1.116 0.264    unchanged #> 882          6         10    4 2.688  1.488 0.137    unchanged #> 883         11         11    0 2.688  0.000     1    unchanged #> 884          6          5   -1 2.688 -0.372  0.71    unchanged #> 885         14         14    0 2.688  0.000     1    unchanged #> 886          3          7    4 2.688  1.488 0.137    unchanged #> 887          3          9    6 2.688  2.232 0.026    increased #> 888         10          7   -3 2.688 -1.116 0.264    unchanged #> 889          2          6    4 2.688  1.488 0.137    unchanged #> 890         15         11   -4 2.688 -1.488 0.137    unchanged #> 891         10          6   -4 2.688 -1.488 0.137    unchanged #> 892         10         10    0 2.688  0.000     1    unchanged #> 893         17         16   -1 2.688 -0.372  0.71    unchanged #> 894         11         12    1 2.688  0.372  0.71    unchanged #> 895          9         11    2 2.688  0.744 0.457    unchanged #> 896         15         13   -2 2.688 -0.744 0.457    unchanged #> 897         17         16   -1 2.688 -0.372  0.71    unchanged #> 898          7          9    2 2.688  0.744 0.457    unchanged #> 899         10          8   -2 2.688 -0.744 0.457    unchanged #> 900          6          5   -1 2.688 -0.372  0.71    unchanged #> 901          7          6   -1 2.688 -0.372  0.71    unchanged #> 902         16         19    3 2.688  1.116 0.264    unchanged #> 903         16         19    3 2.688  1.116 0.264    unchanged #> 904         12          9   -3 2.688 -1.116 0.264    unchanged #> 905          6          7    1 2.688  0.372  0.71    unchanged #> 906         19         20    1 2.688  0.372  0.71    unchanged #> 907         15         11   -4 2.688 -1.488 0.137    unchanged #> 908         10          5   -5 2.688 -1.860 0.063    unchanged #> 909          2          0   -2 2.688 -0.744 0.457    unchanged #> 910         18         10   -8 2.688 -2.976 0.003    decreased #> 911          2          0   -2 2.688 -0.744 0.457    unchanged #> 912         20         17   -3 2.688 -1.116 0.264    unchanged #> 913          4          2   -2 2.688 -0.744 0.457    unchanged #> 914         16         17    1 2.688  0.372  0.71    unchanged #> 915         14         15    1 2.688  0.372  0.71    unchanged #> 916         18         13   -5 2.688 -1.860 0.063    unchanged #> 917         16         17    1 2.688  0.372  0.71    unchanged #> 918         15         18    3 2.688  1.116 0.264    unchanged #> 919         13         10   -3 2.688 -1.116 0.264    unchanged #> 920         11          8   -3 2.688 -1.116 0.264    unchanged #> 921          4          2   -2 2.688 -0.744 0.457    unchanged #> 922          6         10    4 2.688  1.488 0.137    unchanged #> 923         12         11   -1 2.688 -0.372  0.71    unchanged #> 924         18         18    0 2.688  0.000     1    unchanged #> 925          5          5    0 2.688  0.000     1    unchanged #> 926         19         19    0 2.688  0.000     1    unchanged #> 927          7          5   -2 2.688 -0.744 0.457    unchanged #> 928          9          3   -6 2.688 -2.232 0.026    decreased #> 929         15         19    4 2.688  1.488 0.137    unchanged #> 930         15          9   -6 2.688 -2.232 0.026    decreased #> 931         11         11    0 2.688  0.000     1    unchanged #> 932         12         10   -2 2.688 -0.744 0.457    unchanged #> 933         12         13    1 2.688  0.372  0.71    unchanged #> 934          9          6   -3 2.688 -1.116 0.264    unchanged #> 935         14         14    0 2.688  0.000     1    unchanged #> 936          6          7    1 2.688  0.372  0.71    unchanged #> 937          6          6    0 2.688  0.000     1    unchanged #> 938          8         10    2 2.688  0.744 0.457    unchanged #> 939          3          2   -1 2.688 -0.372  0.71    unchanged #> 940         11         10   -1 2.688 -0.372  0.71    unchanged #> 941         12         15    3 2.688  1.116 0.264    unchanged #> 942         13         14    1 2.688  0.372  0.71    unchanged #> 943         12          8   -4 2.688 -1.488 0.137    unchanged #> 944         15         13   -2 2.688 -0.744 0.457    unchanged #> 945         11         12    1 2.688  0.372  0.71    unchanged #> 946         11         11    0 2.688  0.000     1    unchanged #> 947         11         10   -1 2.688 -0.372  0.71    unchanged #> 948         10         13    3 2.688  1.116 0.264    unchanged #> 949          1          2    1 2.688  0.372  0.71    unchanged #> 950          7         12    5 2.688  1.860 0.063    unchanged #> 951          8          6   -2 2.688 -0.744 0.457    unchanged #> 952         15         12   -3 2.688 -1.116 0.264    unchanged #> 953          7          4   -3 2.688 -1.116 0.264    unchanged #> 954          2          6    4 2.688  1.488 0.137    unchanged #> 955          6          5   -1 2.688 -0.372  0.71    unchanged #> 956          3          3    0 2.688  0.000     1    unchanged #> 957          5          5    0 2.688  0.000     1    unchanged #> 958          6          6    0 2.688  0.000     1    unchanged #> 959         13         17    4 2.688  1.488 0.137    unchanged #> 960          6          7    1 2.688  0.372  0.71    unchanged #> 961          3          2   -1 2.688 -0.372  0.71    unchanged #> 962         12         11   -1 2.688 -0.372  0.71    unchanged #> 963          6          4   -2 2.688 -0.744 0.457    unchanged #> 964         17         12   -5 2.688 -1.860 0.063    unchanged #> 965          5          7    2 2.688  0.744 0.457    unchanged #> 966         13         16    3 2.688  1.116 0.264    unchanged #> 967         15         16    1 2.688  0.372  0.71    unchanged #> 968         12          9   -3 2.688 -1.116 0.264    unchanged #> 969         15         13   -2 2.688 -0.744 0.457    unchanged #> 970         14         16    2 2.688  0.744 0.457    unchanged #> 971          6          7    1 2.688  0.372  0.71    unchanged #> 972         16         16    0 2.688  0.000     1    unchanged #> 973          3          1   -2 2.688 -0.744 0.457    unchanged #> 974          5          5    0 2.688  0.000     1    unchanged #> 975          7          3   -4 2.688 -1.488 0.137    unchanged #> 976         13         13    0 2.688  0.000     1    unchanged #> 977         10         12    2 2.688  0.744 0.457    unchanged #> 978          2          4    2 2.688  0.744 0.457    unchanged #> 979          2          9    7 2.688  2.604 0.009    increased #> 980         10          9   -1 2.688 -0.372  0.71    unchanged #> 981          4          1   -3 2.688 -1.116 0.264    unchanged #> 982          7          4   -3 2.688 -1.116 0.264    unchanged #> 983         17         12   -5 2.688 -1.860 0.063    unchanged #> 984         18         16   -2 2.688 -0.744 0.457    unchanged #> 985         16         11   -5 2.688 -1.860 0.063    unchanged #> 986          5          3   -2 2.688 -0.744 0.457    unchanged #> 987         13         14    1 2.688  0.372  0.71    unchanged #> 988         11          8   -3 2.688 -1.116 0.264    unchanged #> 989          2         12   10 2.688  3.721     0    increased #> 990          9         11    2 2.688  0.744 0.457    unchanged #> 991         11          6   -5 2.688 -1.860 0.063    unchanged #> 992         11         10   -1 2.688 -0.372  0.71    unchanged #> 993          8          6   -2 2.688 -0.744 0.457    unchanged #> 994          1          4    3 2.688  1.116 0.264    unchanged #> 995         10          7   -3 2.688 -1.116 0.264    unchanged #> 996         11          5   -6 2.688 -2.232 0.026    decreased #> 997          7          6   -1 2.688 -0.372  0.71    unchanged #> 998         10         12    2 2.688  0.744 0.457    unchanged #> 999         11          7   -4 2.688 -1.488 0.137    unchanged #> 1000         1          2    1 2.688  0.372  0.71    unchanged  # allows SEM.post != SEM.pre (istats.post <- itemstats(dat_post)$overall) #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            9.745          4.774 0.206 0.063  0.84      1.91 SEM.alpha.post <- istats.post$SEM.alpha  RCI(predat = dat_pre, postdat = dat_post,    SEM.pre=SEM.alpha, SEM.post=SEM.alpha.post) #>      pre.score post.score diff    SE      z     p #> 1           18         19    1 2.694  0.371 0.711 #> 2           18          9   -9 2.694 -3.340 0.001 #> 3           15          9   -6 2.694 -2.227 0.026 #> 4           11         10   -1 2.694 -0.371 0.711 #> 5            4          5    1 2.694  0.371 0.711 #> 6            4          8    4 2.694  1.485 0.138 #> 7           11          8   -3 2.694 -1.113 0.266 #> 8           11         15    4 2.694  1.485 0.138 #> 9            3          3    0 2.694  0.000     1 #> 10           4          8    4 2.694  1.485 0.138 #> 11           1          5    4 2.694  1.485 0.138 #> 12          16         14   -2 2.694 -0.742 0.458 #> 13          12         10   -2 2.694 -0.742 0.458 #> 14          11         10   -1 2.694 -0.371 0.711 #> 15          17         18    1 2.694  0.371 0.711 #> 16           1          4    3 2.694  1.113 0.266 #> 17          10          8   -2 2.694 -0.742 0.458 #> 18          12         11   -1 2.694 -0.371 0.711 #> 19          15         12   -3 2.694 -1.113 0.266 #> 20          16         10   -6 2.694 -2.227 0.026 #> 21           7          6   -1 2.694 -0.371 0.711 #> 22           7         12    5 2.694  1.856 0.063 #> 23           2          4    2 2.694  0.742 0.458 #> 24           5          7    2 2.694  0.742 0.458 #> 25          14         15    1 2.694  0.371 0.711 #> 26           9          6   -3 2.694 -1.113 0.266 #> 27          17         17    0 2.694  0.000     1 #> 28           4          9    5 2.694  1.856 0.063 #> 29          14         16    2 2.694  0.742 0.458 #> 30           4          7    3 2.694  1.113 0.266 #> 31           2          0   -2 2.694 -0.742 0.458 #> 32           9          6   -3 2.694 -1.113 0.266 #> 33          20         20    0 2.694  0.000     1 #> 34           9          6   -3 2.694 -1.113 0.266 #> 35           3          4    1 2.694  0.371 0.711 #> 36          14         15    1 2.694  0.371 0.711 #> 37           8          9    1 2.694  0.371 0.711 #> 38          15         13   -2 2.694 -0.742 0.458 #> 39           9         12    3 2.694  1.113 0.266 #> 40          18         18    0 2.694  0.000     1 #> 41          11         10   -1 2.694 -0.371 0.711 #> 42          12          9   -3 2.694 -1.113 0.266 #> 43           8          7   -1 2.694 -0.371 0.711 #> 44          10         11    1 2.694  0.371 0.711 #> 45           7         10    3 2.694  1.113 0.266 #> 46           8          9    1 2.694  0.371 0.711 #> 47           6          8    2 2.694  0.742 0.458 #> 48           6          7    1 2.694  0.371 0.711 #> 49           6          8    2 2.694  0.742 0.458 #> 50           8         11    3 2.694  1.113 0.266 #> 51          13         17    4 2.694  1.485 0.138 #> 52           6          6    0 2.694  0.000     1 #> 53          19         13   -6 2.694 -2.227 0.026 #> 54           6         11    5 2.694  1.856 0.063 #> 55           9          8   -1 2.694 -0.371 0.711 #> 56           7          8    1 2.694  0.371 0.711 #> 57           9          6   -3 2.694 -1.113 0.266 #> 58           3          3    0 2.694  0.000     1 #> 59          10          8   -2 2.694 -0.742 0.458 #> 60          14         14    0 2.694  0.000     1 #> 61          12         12    0 2.694  0.000     1 #> 62          15         14   -1 2.694 -0.371 0.711 #> 63          13         12   -1 2.694 -0.371 0.711 #> 64           5          5    0 2.694  0.000     1 #> 65           5          4   -1 2.694 -0.371 0.711 #> 66           5          4   -1 2.694 -0.371 0.711 #> 67          18         14   -4 2.694 -1.485 0.138 #> 68           9          8   -1 2.694 -0.371 0.711 #> 69          11          9   -2 2.694 -0.742 0.458 #> 70          19         17   -2 2.694 -0.742 0.458 #> 71           9          5   -4 2.694 -1.485 0.138 #> 72          16         15   -1 2.694 -0.371 0.711 #> 73          10          9   -1 2.694 -0.371 0.711 #> 74          11         11    0 2.694  0.000     1 #> 75          14         10   -4 2.694 -1.485 0.138 #> 76          14         15    1 2.694  0.371 0.711 #> 77           5          4   -1 2.694 -0.371 0.711 #> 78          11          9   -2 2.694 -0.742 0.458 #> 79          15         10   -5 2.694 -1.856 0.063 #> 80          11         11    0 2.694  0.000     1 #> 81          10          8   -2 2.694 -0.742 0.458 #> 82          12         12    0 2.694  0.000     1 #> 83          11         11    0 2.694  0.000     1 #> 84           5          1   -4 2.694 -1.485 0.138 #> 85           7          9    2 2.694  0.742 0.458 #> 86           7         10    3 2.694  1.113 0.266 #> 87           3          7    4 2.694  1.485 0.138 #> 88           9         11    2 2.694  0.742 0.458 #> 89           8          9    1 2.694  0.371 0.711 #> 90          12         11   -1 2.694 -0.371 0.711 #> 91           6          1   -5 2.694 -1.856 0.063 #> 92           6          8    2 2.694  0.742 0.458 #> 93           3          5    2 2.694  0.742 0.458 #> 94          12         12    0 2.694  0.000     1 #> 95          18         16   -2 2.694 -0.742 0.458 #> 96           9          7   -2 2.694 -0.742 0.458 #> 97           8         11    3 2.694  1.113 0.266 #> 98           7          7    0 2.694  0.000     1 #> 99          12         11   -1 2.694 -0.371 0.711 #> 100         10         10    0 2.694  0.000     1 #> 101          5          5    0 2.694  0.000     1 #> 102         14         15    1 2.694  0.371 0.711 #> 103          9          9    0 2.694  0.000     1 #> 104          8         15    7 2.694  2.598 0.009 #> 105          2          3    1 2.694  0.371 0.711 #> 106          7         10    3 2.694  1.113 0.266 #> 107         12         12    0 2.694  0.000     1 #> 108          2          2    0 2.694  0.000     1 #> 109         14         13   -1 2.694 -0.371 0.711 #> 110          6          4   -2 2.694 -0.742 0.458 #> 111         15         10   -5 2.694 -1.856 0.063 #> 112          5          5    0 2.694  0.000     1 #> 113         15         18    3 2.694  1.113 0.266 #> 114          2          0   -2 2.694 -0.742 0.458 #> 115          9         12    3 2.694  1.113 0.266 #> 116         14         14    0 2.694  0.000     1 #> 117         10          7   -3 2.694 -1.113 0.266 #> 118          6          5   -1 2.694 -0.371 0.711 #> 119         12          9   -3 2.694 -1.113 0.266 #> 120          7          3   -4 2.694 -1.485 0.138 #> 121          9         12    3 2.694  1.113 0.266 #> 122          2          6    4 2.694  1.485 0.138 #> 123          9          6   -3 2.694 -1.113 0.266 #> 124          2          5    3 2.694  1.113 0.266 #> 125         12         12    0 2.694  0.000     1 #> 126         16         19    3 2.694  1.113 0.266 #> 127         13         14    1 2.694  0.371 0.711 #> 128         13         14    1 2.694  0.371 0.711 #> 129         14         15    1 2.694  0.371 0.711 #> 130          7         14    7 2.694  2.598 0.009 #> 131         10         11    1 2.694  0.371 0.711 #> 132          3          3    0 2.694  0.000     1 #> 133         15         15    0 2.694  0.000     1 #> 134         18         19    1 2.694  0.371 0.711 #> 135          2          5    3 2.694  1.113 0.266 #> 136         12         10   -2 2.694 -0.742 0.458 #> 137         12         14    2 2.694  0.742 0.458 #> 138          6          3   -3 2.694 -1.113 0.266 #> 139         13          9   -4 2.694 -1.485 0.138 #> 140          8          5   -3 2.694 -1.113 0.266 #> 141         18         17   -1 2.694 -0.371 0.711 #> 142         15         15    0 2.694  0.000     1 #> 143          7          9    2 2.694  0.742 0.458 #> 144         14         10   -4 2.694 -1.485 0.138 #> 145          3          5    2 2.694  0.742 0.458 #> 146          1          2    1 2.694  0.371 0.711 #> 147          5          6    1 2.694  0.371 0.711 #> 148          8          8    0 2.694  0.000     1 #> 149         13         15    2 2.694  0.742 0.458 #> 150          9          9    0 2.694  0.000     1 #> 151          8          9    1 2.694  0.371 0.711 #> 152          2          1   -1 2.694 -0.371 0.711 #> 153          3          3    0 2.694  0.000     1 #> 154          7          5   -2 2.694 -0.742 0.458 #> 155         16         13   -3 2.694 -1.113 0.266 #> 156          9         12    3 2.694  1.113 0.266 #> 157         15         17    2 2.694  0.742 0.458 #> 158         10          5   -5 2.694 -1.856 0.063 #> 159          8         10    2 2.694  0.742 0.458 #> 160         17         11   -6 2.694 -2.227 0.026 #> 161         14          8   -6 2.694 -2.227 0.026 #> 162          8          8    0 2.694  0.000     1 #> 163          3          5    2 2.694  0.742 0.458 #> 164         16          8   -8 2.694 -2.969 0.003 #> 165          9          7   -2 2.694 -0.742 0.458 #> 166          7          8    1 2.694  0.371 0.711 #> 167         15         15    0 2.694  0.000     1 #> 168         15         18    3 2.694  1.113 0.266 #> 169          3          2   -1 2.694 -0.371 0.711 #> 170          1          2    1 2.694  0.371 0.711 #> 171          2          0   -2 2.694 -0.742 0.458 #> 172         20         15   -5 2.694 -1.856 0.063 #> 173         10         12    2 2.694  0.742 0.458 #> 174          9          3   -6 2.694 -2.227 0.026 #> 175          5         15   10 2.694  3.712     0 #> 176          9          7   -2 2.694 -0.742 0.458 #> 177         15         16    1 2.694  0.371 0.711 #> 178          2          5    3 2.694  1.113 0.266 #> 179         18         20    2 2.694  0.742 0.458 #> 180         10          8   -2 2.694 -0.742 0.458 #> 181          6          6    0 2.694  0.000     1 #> 182          3          5    2 2.694  0.742 0.458 #> 183          9          7   -2 2.694 -0.742 0.458 #> 184          7         10    3 2.694  1.113 0.266 #> 185          6          3   -3 2.694 -1.113 0.266 #> 186          7          5   -2 2.694 -0.742 0.458 #> 187          7          4   -3 2.694 -1.113 0.266 #> 188         10          9   -1 2.694 -0.371 0.711 #> 189         17         12   -5 2.694 -1.856 0.063 #> 190          2          4    2 2.694  0.742 0.458 #> 191         16         15   -1 2.694 -0.371 0.711 #> 192          6          9    3 2.694  1.113 0.266 #> 193         10         13    3 2.694  1.113 0.266 #> 194          2          7    5 2.694  1.856 0.063 #> 195          5          3   -2 2.694 -0.742 0.458 #> 196         12          8   -4 2.694 -1.485 0.138 #> 197          5          1   -4 2.694 -1.485 0.138 #> 198          5          2   -3 2.694 -1.113 0.266 #> 199         17         17    0 2.694  0.000     1 #> 200          4          2   -2 2.694 -0.742 0.458 #> 201         13         13    0 2.694  0.000     1 #> 202         14         12   -2 2.694 -0.742 0.458 #> 203          2          2    0 2.694  0.000     1 #> 204         11          9   -2 2.694 -0.742 0.458 #> 205         10         11    1 2.694  0.371 0.711 #> 206         13         11   -2 2.694 -0.742 0.458 #> 207         17         18    1 2.694  0.371 0.711 #> 208         14         15    1 2.694  0.371 0.711 #> 209         18         18    0 2.694  0.000     1 #> 210          2          0   -2 2.694 -0.742 0.458 #> 211          9         11    2 2.694  0.742 0.458 #> 212         10         12    2 2.694  0.742 0.458 #> 213         16         14   -2 2.694 -0.742 0.458 #> 214          2          2    0 2.694  0.000     1 #> 215          3          4    1 2.694  0.371 0.711 #> 216         15         17    2 2.694  0.742 0.458 #> 217         14         12   -2 2.694 -0.742 0.458 #> 218          3          5    2 2.694  0.742 0.458 #> 219          9          8   -1 2.694 -0.371 0.711 #> 220          0          1    1 2.694  0.371 0.711 #> 221         14         12   -2 2.694 -0.742 0.458 #> 222          2          1   -1 2.694 -0.371 0.711 #> 223          5         10    5 2.694  1.856 0.063 #> 224          8         15    7 2.694  2.598 0.009 #> 225         12         14    2 2.694  0.742 0.458 #> 226         14         14    0 2.694  0.000     1 #> 227         11         11    0 2.694  0.000     1 #> 228          9          9    0 2.694  0.000     1 #> 229         17         15   -2 2.694 -0.742 0.458 #> 230          2          2    0 2.694  0.000     1 #> 231          6          9    3 2.694  1.113 0.266 #> 232          9         14    5 2.694  1.856 0.063 #> 233         13         13    0 2.694  0.000     1 #> 234         13         17    4 2.694  1.485 0.138 #> 235         13          6   -7 2.694 -2.598 0.009 #> 236          8          8    0 2.694  0.000     1 #> 237          8          9    1 2.694  0.371 0.711 #> 238          6         12    6 2.694  2.227 0.026 #> 239          9          9    0 2.694  0.000     1 #> 240          7         12    5 2.694  1.856 0.063 #> 241         18         18    0 2.694  0.000     1 #> 242          4          3   -1 2.694 -0.371 0.711 #> 243          1          2    1 2.694  0.371 0.711 #> 244          3          1   -2 2.694 -0.742 0.458 #> 245          6          5   -1 2.694 -0.371 0.711 #> 246          4          4    0 2.694  0.000     1 #> 247         17         17    0 2.694  0.000     1 #> 248         20         18   -2 2.694 -0.742 0.458 #> 249          8         10    2 2.694  0.742 0.458 #> 250         15         18    3 2.694  1.113 0.266 #> 251         15         13   -2 2.694 -0.742 0.458 #> 252          8          8    0 2.694  0.000     1 #> 253          8          8    0 2.694  0.000     1 #> 254         11         13    2 2.694  0.742 0.458 #> 255         18         16   -2 2.694 -0.742 0.458 #> 256         10         11    1 2.694  0.371 0.711 #> 257         18         16   -2 2.694 -0.742 0.458 #> 258         10         11    1 2.694  0.371 0.711 #> 259          4          3   -1 2.694 -0.371 0.711 #> 260         11         14    3 2.694  1.113 0.266 #> 261         14         11   -3 2.694 -1.113 0.266 #> 262         14         13   -1 2.694 -0.371 0.711 #> 263         19         17   -2 2.694 -0.742 0.458 #> 264          4          6    2 2.694  0.742 0.458 #> 265         17         17    0 2.694  0.000     1 #> 266          9         12    3 2.694  1.113 0.266 #> 267          4          7    3 2.694  1.113 0.266 #> 268         15         12   -3 2.694 -1.113 0.266 #> 269          7          7    0 2.694  0.000     1 #> 270          8         11    3 2.694  1.113 0.266 #> 271          1          2    1 2.694  0.371 0.711 #> 272          8          6   -2 2.694 -0.742 0.458 #> 273          6          6    0 2.694  0.000     1 #> 274         17         16   -1 2.694 -0.371 0.711 #> 275         13         11   -2 2.694 -0.742 0.458 #> 276          2          1   -1 2.694 -0.371 0.711 #> 277          9         10    1 2.694  0.371 0.711 #> 278          2          0   -2 2.694 -0.742 0.458 #> 279         11         13    2 2.694  0.742 0.458 #> 280         17         17    0 2.694  0.000     1 #> 281         16         16    0 2.694  0.000     1 #> 282         14         15    1 2.694  0.371 0.711 #> 283         15         16    1 2.694  0.371 0.711 #> 284          4          1   -3 2.694 -1.113 0.266 #> 285         17         18    1 2.694  0.371 0.711 #> 286         10          7   -3 2.694 -1.113 0.266 #> 287         12         15    3 2.694  1.113 0.266 #> 288         15         17    2 2.694  0.742 0.458 #> 289         17         15   -2 2.694 -0.742 0.458 #> 290         14         11   -3 2.694 -1.113 0.266 #> 291         15         12   -3 2.694 -1.113 0.266 #> 292         10         10    0 2.694  0.000     1 #> 293          0          2    2 2.694  0.742 0.458 #> 294         12          8   -4 2.694 -1.485 0.138 #> 295          4          7    3 2.694  1.113 0.266 #> 296         15         15    0 2.694  0.000     1 #> 297         18         17   -1 2.694 -0.371 0.711 #> 298          9          7   -2 2.694 -0.742 0.458 #> 299         18         12   -6 2.694 -2.227 0.026 #> 300          0          1    1 2.694  0.371 0.711 #> 301          4         11    7 2.694  2.598 0.009 #> 302         10          8   -2 2.694 -0.742 0.458 #> 303          5          2   -3 2.694 -1.113 0.266 #> 304         19         17   -2 2.694 -0.742 0.458 #> 305         11          6   -5 2.694 -1.856 0.063 #> 306         15         15    0 2.694  0.000     1 #> 307         10         12    2 2.694  0.742 0.458 #> 308         11          8   -3 2.694 -1.113 0.266 #> 309         10          7   -3 2.694 -1.113 0.266 #> 310          8          6   -2 2.694 -0.742 0.458 #> 311         14         15    1 2.694  0.371 0.711 #> 312         16         11   -5 2.694 -1.856 0.063 #> 313          6          4   -2 2.694 -0.742 0.458 #> 314         11         11    0 2.694  0.000     1 #> 315          7          7    0 2.694  0.000     1 #> 316          9         11    2 2.694  0.742 0.458 #> 317          7         11    4 2.694  1.485 0.138 #> 318          1          5    4 2.694  1.485 0.138 #> 319         10          9   -1 2.694 -0.371 0.711 #> 320         13         10   -3 2.694 -1.113 0.266 #> 321         13         10   -3 2.694 -1.113 0.266 #> 322         13          9   -4 2.694 -1.485 0.138 #> 323          1          2    1 2.694  0.371 0.711 #> 324         13         13    0 2.694  0.000     1 #> 325         13         13    0 2.694  0.000     1 #> 326         13         13    0 2.694  0.000     1 #> 327          7          6   -1 2.694 -0.371 0.711 #> 328          9         12    3 2.694  1.113 0.266 #> 329         13         13    0 2.694  0.000     1 #> 330          6         14    8 2.694  2.969 0.003 #> 331         12         14    2 2.694  0.742 0.458 #> 332          9          5   -4 2.694 -1.485 0.138 #> 333         13         12   -1 2.694 -0.371 0.711 #> 334         13         14    1 2.694  0.371 0.711 #> 335          9         11    2 2.694  0.742 0.458 #> 336         10          9   -1 2.694 -0.371 0.711 #> 337         12         13    1 2.694  0.371 0.711 #> 338         16         14   -2 2.694 -0.742 0.458 #> 339          6         10    4 2.694  1.485 0.138 #> 340         17         15   -2 2.694 -0.742 0.458 #> 341         12         14    2 2.694  0.742 0.458 #> 342          6          5   -1 2.694 -0.371 0.711 #> 343          5          9    4 2.694  1.485 0.138 #> 344          5          4   -1 2.694 -0.371 0.711 #> 345          6          9    3 2.694  1.113 0.266 #> 346         12          8   -4 2.694 -1.485 0.138 #> 347         12         13    1 2.694  0.371 0.711 #> 348          8         11    3 2.694  1.113 0.266 #> 349          5          6    1 2.694  0.371 0.711 #> 350         11         12    1 2.694  0.371 0.711 #> 351          9          7   -2 2.694 -0.742 0.458 #> 352         18         16   -2 2.694 -0.742 0.458 #> 353          9         11    2 2.694  0.742 0.458 #> 354          4          3   -1 2.694 -0.371 0.711 #> 355         12         17    5 2.694  1.856 0.063 #> 356         16         15   -1 2.694 -0.371 0.711 #> 357          9         13    4 2.694  1.485 0.138 #> 358         10          7   -3 2.694 -1.113 0.266 #> 359          1          3    2 2.694  0.742 0.458 #> 360         10         12    2 2.694  0.742 0.458 #> 361          5          5    0 2.694  0.000     1 #> 362         13         15    2 2.694  0.742 0.458 #> 363          9         12    3 2.694  1.113 0.266 #> 364         13         14    1 2.694  0.371 0.711 #> 365          9          5   -4 2.694 -1.485 0.138 #> 366         17         17    0 2.694  0.000     1 #> 367          4          2   -2 2.694 -0.742 0.458 #> 368         12          9   -3 2.694 -1.113 0.266 #> 369          3         10    7 2.694  2.598 0.009 #> 370         12         12    0 2.694  0.000     1 #> 371         14         18    4 2.694  1.485 0.138 #> 372         10         11    1 2.694  0.371 0.711 #> 373          7          9    2 2.694  0.742 0.458 #> 374          4          6    2 2.694  0.742 0.458 #> 375         10          5   -5 2.694 -1.856 0.063 #> 376         16         14   -2 2.694 -0.742 0.458 #> 377         15         15    0 2.694  0.000     1 #> 378         13         12   -1 2.694 -0.371 0.711 #> 379          0          3    3 2.694  1.113 0.266 #> 380          7          8    1 2.694  0.371 0.711 #> 381          6          7    1 2.694  0.371 0.711 #> 382          6          6    0 2.694  0.000     1 #> 383          6          8    2 2.694  0.742 0.458 #> 384          4          4    0 2.694  0.000     1 #> 385          3          4    1 2.694  0.371 0.711 #> 386          2          7    5 2.694  1.856 0.063 #> 387          9          9    0 2.694  0.000     1 #> 388         19         14   -5 2.694 -1.856 0.063 #> 389          3          6    3 2.694  1.113 0.266 #> 390          0          2    2 2.694  0.742 0.458 #> 391         15         14   -1 2.694 -0.371 0.711 #> 392         11          4   -7 2.694 -2.598 0.009 #> 393          5          6    1 2.694  0.371 0.711 #> 394          2          1   -1 2.694 -0.371 0.711 #> 395          7         13    6 2.694  2.227 0.026 #> 396         13         11   -2 2.694 -0.742 0.458 #> 397         15         14   -1 2.694 -0.371 0.711 #> 398          2          4    2 2.694  0.742 0.458 #> 399         13          6   -7 2.694 -2.598 0.009 #> 400         15          9   -6 2.694 -2.227 0.026 #> 401          7          8    1 2.694  0.371 0.711 #> 402          3          3    0 2.694  0.000     1 #> 403          9         12    3 2.694  1.113 0.266 #> 404         17         17    0 2.694  0.000     1 #> 405          1          4    3 2.694  1.113 0.266 #> 406          4          2   -2 2.694 -0.742 0.458 #> 407          7         10    3 2.694  1.113 0.266 #> 408          7         11    4 2.694  1.485 0.138 #> 409         12         12    0 2.694  0.000     1 #> 410          8          6   -2 2.694 -0.742 0.458 #> 411          8          4   -4 2.694 -1.485 0.138 #> 412         14         11   -3 2.694 -1.113 0.266 #> 413          5          3   -2 2.694 -0.742 0.458 #> 414         16         17    1 2.694  0.371 0.711 #> 415         11         15    4 2.694  1.485 0.138 #> 416         15         12   -3 2.694 -1.113 0.266 #> 417         14         15    1 2.694  0.371 0.711 #> 418          5          6    1 2.694  0.371 0.711 #> 419          5         10    5 2.694  1.856 0.063 #> 420         10         13    3 2.694  1.113 0.266 #> 421          3          2   -1 2.694 -0.371 0.711 #> 422         17         17    0 2.694  0.000     1 #> 423         11         11    0 2.694  0.000     1 #> 424         14         13   -1 2.694 -0.371 0.711 #> 425         16          9   -7 2.694 -2.598 0.009 #> 426         15         16    1 2.694  0.371 0.711 #> 427         11          7   -4 2.694 -1.485 0.138 #> 428          8         11    3 2.694  1.113 0.266 #> 429         13         13    0 2.694  0.000     1 #> 430         10         10    0 2.694  0.000     1 #> 431         15         14   -1 2.694 -0.371 0.711 #> 432          1          4    3 2.694  1.113 0.266 #> 433          3          3    0 2.694  0.000     1 #> 434         11         15    4 2.694  1.485 0.138 #> 435          3          4    1 2.694  0.371 0.711 #> 436          6         11    5 2.694  1.856 0.063 #> 437          2          0   -2 2.694 -0.742 0.458 #> 438         13         14    1 2.694  0.371 0.711 #> 439         18         14   -4 2.694 -1.485 0.138 #> 440          6         13    7 2.694  2.598 0.009 #> 441         14         12   -2 2.694 -0.742 0.458 #> 442          4          5    1 2.694  0.371 0.711 #> 443         10          9   -1 2.694 -0.371 0.711 #> 444         18         18    0 2.694  0.000     1 #> 445         17         16   -1 2.694 -0.371 0.711 #> 446         16         17    1 2.694  0.371 0.711 #> 447          0          0    0 2.694  0.000     1 #> 448         12         10   -2 2.694 -0.742 0.458 #> 449          4          7    3 2.694  1.113 0.266 #> 450          1          4    3 2.694  1.113 0.266 #> 451         19         18   -1 2.694 -0.371 0.711 #> 452          8          5   -3 2.694 -1.113 0.266 #> 453          8         11    3 2.694  1.113 0.266 #> 454          5          9    4 2.694  1.485 0.138 #> 455         18         17   -1 2.694 -0.371 0.711 #> 456         12         11   -1 2.694 -0.371 0.711 #> 457          5          9    4 2.694  1.485 0.138 #> 458          2          5    3 2.694  1.113 0.266 #> 459          1          2    1 2.694  0.371 0.711 #> 460         19         18   -1 2.694 -0.371 0.711 #> 461         15         17    2 2.694  0.742 0.458 #> 462         17         13   -4 2.694 -1.485 0.138 #> 463         13         15    2 2.694  0.742 0.458 #> 464         14         14    0 2.694  0.000     1 #> 465          6          9    3 2.694  1.113 0.266 #> 466          9          5   -4 2.694 -1.485 0.138 #> 467         16         15   -1 2.694 -0.371 0.711 #> 468          3          2   -1 2.694 -0.371 0.711 #> 469          1          7    6 2.694  2.227 0.026 #> 470         13         10   -3 2.694 -1.113 0.266 #> 471          5          4   -1 2.694 -0.371 0.711 #> 472          6          7    1 2.694  0.371 0.711 #> 473         20         19   -1 2.694 -0.371 0.711 #> 474          7          9    2 2.694  0.742 0.458 #> 475          1          1    0 2.694  0.000     1 #> 476         15         13   -2 2.694 -0.742 0.458 #> 477         16         11   -5 2.694 -1.856 0.063 #> 478         16         12   -4 2.694 -1.485 0.138 #> 479         11         10   -1 2.694 -0.371 0.711 #> 480         15         16    1 2.694  0.371 0.711 #> 481          7          8    1 2.694  0.371 0.711 #> 482         15         12   -3 2.694 -1.113 0.266 #> 483         15         16    1 2.694  0.371 0.711 #> 484         12         11   -1 2.694 -0.371 0.711 #> 485         12         10   -2 2.694 -0.742 0.458 #> 486          5          8    3 2.694  1.113 0.266 #> 487          8         12    4 2.694  1.485 0.138 #> 488         11         13    2 2.694  0.742 0.458 #> 489         16         17    1 2.694  0.371 0.711 #> 490          7          8    1 2.694  0.371 0.711 #> 491         19         18   -1 2.694 -0.371 0.711 #> 492          4          5    1 2.694  0.371 0.711 #> 493         19         16   -3 2.694 -1.113 0.266 #> 494          8          9    1 2.694  0.371 0.711 #> 495         10         15    5 2.694  1.856 0.063 #> 496          6          7    1 2.694  0.371 0.711 #> 497         11          8   -3 2.694 -1.113 0.266 #> 498          3          9    6 2.694  2.227 0.026 #> 499          8          8    0 2.694  0.000     1 #> 500          7         11    4 2.694  1.485 0.138 #> 501         13         16    3 2.694  1.113 0.266 #> 502         11         10   -1 2.694 -0.371 0.711 #> 503          0          1    1 2.694  0.371 0.711 #> 504          4          5    1 2.694  0.371 0.711 #> 505          4          6    2 2.694  0.742 0.458 #> 506         12         10   -2 2.694 -0.742 0.458 #> 507         18         16   -2 2.694 -0.742 0.458 #> 508         13         14    1 2.694  0.371 0.711 #> 509          5          7    2 2.694  0.742 0.458 #> 510          8         10    2 2.694  0.742 0.458 #> 511          6         10    4 2.694  1.485 0.138 #> 512          7          9    2 2.694  0.742 0.458 #> 513          5          5    0 2.694  0.000     1 #> 514          5         10    5 2.694  1.856 0.063 #> 515          9         11    2 2.694  0.742 0.458 #> 516         17         17    0 2.694  0.000     1 #> 517         14         13   -1 2.694 -0.371 0.711 #> 518          8         15    7 2.694  2.598 0.009 #> 519         14         14    0 2.694  0.000     1 #> 520         13          8   -5 2.694 -1.856 0.063 #> 521         14         12   -2 2.694 -0.742 0.458 #> 522          6          2   -4 2.694 -1.485 0.138 #> 523         17         14   -3 2.694 -1.113 0.266 #> 524         13         13    0 2.694  0.000     1 #> 525         14         14    0 2.694  0.000     1 #> 526         16         12   -4 2.694 -1.485 0.138 #> 527         12         10   -2 2.694 -0.742 0.458 #> 528         15         16    1 2.694  0.371 0.711 #> 529         13         10   -3 2.694 -1.113 0.266 #> 530          9         10    1 2.694  0.371 0.711 #> 531         12          7   -5 2.694 -1.856 0.063 #> 532         20         20    0 2.694  0.000     1 #> 533         17         12   -5 2.694 -1.856 0.063 #> 534          6          8    2 2.694  0.742 0.458 #> 535         19         18   -1 2.694 -0.371 0.711 #> 536         12         12    0 2.694  0.000     1 #> 537         10          7   -3 2.694 -1.113 0.266 #> 538          6          4   -2 2.694 -0.742 0.458 #> 539          8          8    0 2.694  0.000     1 #> 540         10         12    2 2.694  0.742 0.458 #> 541          4          7    3 2.694  1.113 0.266 #> 542          2          2    0 2.694  0.000     1 #> 543          6          5   -1 2.694 -0.371 0.711 #> 544         12         10   -2 2.694 -0.742 0.458 #> 545          4          5    1 2.694  0.371 0.711 #> 546         11         10   -1 2.694 -0.371 0.711 #> 547         14         12   -2 2.694 -0.742 0.458 #> 548         13         15    2 2.694  0.742 0.458 #> 549         12          9   -3 2.694 -1.113 0.266 #> 550         11         11    0 2.694  0.000     1 #> 551          8          2   -6 2.694 -2.227 0.026 #> 552         14         15    1 2.694  0.371 0.711 #> 553         11         14    3 2.694  1.113 0.266 #> 554         13         12   -1 2.694 -0.371 0.711 #> 555          2          3    1 2.694  0.371 0.711 #> 556          9         13    4 2.694  1.485 0.138 #> 557         10         11    1 2.694  0.371 0.711 #> 558          8         12    4 2.694  1.485 0.138 #> 559         11         12    1 2.694  0.371 0.711 #> 560         19         18   -1 2.694 -0.371 0.711 #> 561         12         12    0 2.694  0.000     1 #> 562         12          8   -4 2.694 -1.485 0.138 #> 563          3          6    3 2.694  1.113 0.266 #> 564          4          0   -4 2.694 -1.485 0.138 #> 565         14         14    0 2.694  0.000     1 #> 566          3          4    1 2.694  0.371 0.711 #> 567         18         16   -2 2.694 -0.742 0.458 #> 568          3          2   -1 2.694 -0.371 0.711 #> 569         17         19    2 2.694  0.742 0.458 #> 570         10          8   -2 2.694 -0.742 0.458 #> 571         16         13   -3 2.694 -1.113 0.266 #> 572          8          8    0 2.694  0.000     1 #> 573         15         17    2 2.694  0.742 0.458 #> 574          7         12    5 2.694  1.856 0.063 #> 575          6          2   -4 2.694 -1.485 0.138 #> 576         11         14    3 2.694  1.113 0.266 #> 577         13         12   -1 2.694 -0.371 0.711 #> 578         17         14   -3 2.694 -1.113 0.266 #> 579          5          9    4 2.694  1.485 0.138 #> 580         12         17    5 2.694  1.856 0.063 #> 581         11         10   -1 2.694 -0.371 0.711 #> 582          6         12    6 2.694  2.227 0.026 #> 583         11         13    2 2.694  0.742 0.458 #> 584         16         18    2 2.694  0.742 0.458 #> 585          8          6   -2 2.694 -0.742 0.458 #> 586          7          9    2 2.694  0.742 0.458 #> 587         12         11   -1 2.694 -0.371 0.711 #> 588          9          7   -2 2.694 -0.742 0.458 #> 589          9          6   -3 2.694 -1.113 0.266 #> 590         14         13   -1 2.694 -0.371 0.711 #> 591         15         15    0 2.694  0.000     1 #> 592         19         15   -4 2.694 -1.485 0.138 #> 593          6          7    1 2.694  0.371 0.711 #> 594          4          3   -1 2.694 -0.371 0.711 #> 595          4          6    2 2.694  0.742 0.458 #> 596          4          3   -1 2.694 -0.371 0.711 #> 597          4          4    0 2.694  0.000     1 #> 598         10          6   -4 2.694 -1.485 0.138 #> 599          8         14    6 2.694  2.227 0.026 #> 600          9         12    3 2.694  1.113 0.266 #> 601         10         12    2 2.694  0.742 0.458 #> 602         12          9   -3 2.694 -1.113 0.266 #> 603         13          9   -4 2.694 -1.485 0.138 #> 604         11         11    0 2.694  0.000     1 #> 605          2          4    2 2.694  0.742 0.458 #> 606         16         14   -2 2.694 -0.742 0.458 #> 607          2          1   -1 2.694 -0.371 0.711 #> 608          3          2   -1 2.694 -0.371 0.711 #> 609          6          4   -2 2.694 -0.742 0.458 #> 610         15         11   -4 2.694 -1.485 0.138 #> 611          7          6   -1 2.694 -0.371 0.711 #> 612         14         18    4 2.694  1.485 0.138 #> 613          7         14    7 2.694  2.598 0.009 #> 614         18         14   -4 2.694 -1.485 0.138 #> 615          9          6   -3 2.694 -1.113 0.266 #> 616         11         11    0 2.694  0.000     1 #> 617          6          2   -4 2.694 -1.485 0.138 #> 618         10          7   -3 2.694 -1.113 0.266 #> 619          3          2   -1 2.694 -0.371 0.711 #> 620          8          4   -4 2.694 -1.485 0.138 #> 621          8         10    2 2.694  0.742 0.458 #> 622         16         16    0 2.694  0.000     1 #> 623          4          2   -2 2.694 -0.742 0.458 #> 624         13         15    2 2.694  0.742 0.458 #> 625         11         11    0 2.694  0.000     1 #> 626         14         13   -1 2.694 -0.371 0.711 #> 627          4          8    4 2.694  1.485 0.138 #> 628          6          8    2 2.694  0.742 0.458 #> 629         15          9   -6 2.694 -2.227 0.026 #> 630          2          3    1 2.694  0.371 0.711 #> 631          2          3    1 2.694  0.371 0.711 #> 632          8          6   -2 2.694 -0.742 0.458 #> 633          8          4   -4 2.694 -1.485 0.138 #> 634         12         18    6 2.694  2.227 0.026 #> 635         15         15    0 2.694  0.000     1 #> 636         10         10    0 2.694  0.000     1 #> 637          3          3    0 2.694  0.000     1 #> 638         14         15    1 2.694  0.371 0.711 #> 639          9          6   -3 2.694 -1.113 0.266 #> 640          2          5    3 2.694  1.113 0.266 #> 641         14         17    3 2.694  1.113 0.266 #> 642          4          2   -2 2.694 -0.742 0.458 #> 643         12         13    1 2.694  0.371 0.711 #> 644         10          7   -3 2.694 -1.113 0.266 #> 645          3          4    1 2.694  0.371 0.711 #> 646          4          2   -2 2.694 -0.742 0.458 #> 647          2          6    4 2.694  1.485 0.138 #> 648         11          8   -3 2.694 -1.113 0.266 #> 649         10         10    0 2.694  0.000     1 #> 650         17         17    0 2.694  0.000     1 #> 651          8         10    2 2.694  0.742 0.458 #> 652          8          9    1 2.694  0.371 0.711 #> 653         17         17    0 2.694  0.000     1 #> 654         15         13   -2 2.694 -0.742 0.458 #> 655         14         19    5 2.694  1.856 0.063 #> 656         10         14    4 2.694  1.485 0.138 #> 657         12         13    1 2.694  0.371 0.711 #> 658          7         12    5 2.694  1.856 0.063 #> 659         11         12    1 2.694  0.371 0.711 #> 660         13         10   -3 2.694 -1.113 0.266 #> 661          7          7    0 2.694  0.000     1 #> 662          8          6   -2 2.694 -0.742 0.458 #> 663          7          5   -2 2.694 -0.742 0.458 #> 664         14         10   -4 2.694 -1.485 0.138 #> 665         17         19    2 2.694  0.742 0.458 #> 666          9          6   -3 2.694 -1.113 0.266 #> 667          3          3    0 2.694  0.000     1 #> 668         15         11   -4 2.694 -1.485 0.138 #> 669          7          8    1 2.694  0.371 0.711 #> 670         12         12    0 2.694  0.000     1 #> 671         13         13    0 2.694  0.000     1 #> 672         16         20    4 2.694  1.485 0.138 #> 673         13          9   -4 2.694 -1.485 0.138 #> 674         14         16    2 2.694  0.742 0.458 #> 675          7          2   -5 2.694 -1.856 0.063 #> 676         10          6   -4 2.694 -1.485 0.138 #> 677         10         12    2 2.694  0.742 0.458 #> 678          8          9    1 2.694  0.371 0.711 #> 679          4          7    3 2.694  1.113 0.266 #> 680          2          4    2 2.694  0.742 0.458 #> 681         13         10   -3 2.694 -1.113 0.266 #> 682          5         12    7 2.694  2.598 0.009 #> 683          5          6    1 2.694  0.371 0.711 #> 684         10          7   -3 2.694 -1.113 0.266 #> 685         13         12   -1 2.694 -0.371 0.711 #> 686         17         19    2 2.694  0.742 0.458 #> 687         11         12    1 2.694  0.371 0.711 #> 688          4         10    6 2.694  2.227 0.026 #> 689          6          4   -2 2.694 -0.742 0.458 #> 690          3          5    2 2.694  0.742 0.458 #> 691         11         14    3 2.694  1.113 0.266 #> 692          7          2   -5 2.694 -1.856 0.063 #> 693          8         10    2 2.694  0.742 0.458 #> 694         13         11   -2 2.694 -0.742 0.458 #> 695         13         16    3 2.694  1.113 0.266 #> 696         16         15   -1 2.694 -0.371 0.711 #> 697         16         12   -4 2.694 -1.485 0.138 #> 698          3          3    0 2.694  0.000     1 #> 699         12         15    3 2.694  1.113 0.266 #> 700         12         16    4 2.694  1.485 0.138 #> 701          3          3    0 2.694  0.000     1 #> 702         20         20    0 2.694  0.000     1 #> 703          7         10    3 2.694  1.113 0.266 #> 704          9         13    4 2.694  1.485 0.138 #> 705          5          7    2 2.694  0.742 0.458 #> 706          2          2    0 2.694  0.000     1 #> 707         13         16    3 2.694  1.113 0.266 #> 708          5          7    2 2.694  0.742 0.458 #> 709          8          7   -1 2.694 -0.371 0.711 #> 710         15         18    3 2.694  1.113 0.266 #> 711          3          1   -2 2.694 -0.742 0.458 #> 712          5          5    0 2.694  0.000     1 #> 713          5          3   -2 2.694 -0.742 0.458 #> 714         15         16    1 2.694  0.371 0.711 #> 715         12         10   -2 2.694 -0.742 0.458 #> 716          9          6   -3 2.694 -1.113 0.266 #> 717          5          2   -3 2.694 -1.113 0.266 #> 718          3          4    1 2.694  0.371 0.711 #> 719          2          6    4 2.694  1.485 0.138 #> 720          4          6    2 2.694  0.742 0.458 #> 721         10         12    2 2.694  0.742 0.458 #> 722         16         14   -2 2.694 -0.742 0.458 #> 723          3          2   -1 2.694 -0.371 0.711 #> 724         13          8   -5 2.694 -1.856 0.063 #> 725         17         15   -2 2.694 -0.742 0.458 #> 726          8          8    0 2.694  0.000     1 #> 727          8         10    2 2.694  0.742 0.458 #> 728         16         12   -4 2.694 -1.485 0.138 #> 729         11         15    4 2.694  1.485 0.138 #> 730          4          8    4 2.694  1.485 0.138 #> 731          5          6    1 2.694  0.371 0.711 #> 732          4          3   -1 2.694 -0.371 0.711 #> 733          8          6   -2 2.694 -0.742 0.458 #> 734         18         19    1 2.694  0.371 0.711 #> 735         10         11    1 2.694  0.371 0.711 #> 736         10         12    2 2.694  0.742 0.458 #> 737         18         20    2 2.694  0.742 0.458 #> 738         11          5   -6 2.694 -2.227 0.026 #> 739         17         17    0 2.694  0.000     1 #> 740          3          5    2 2.694  0.742 0.458 #> 741         15         15    0 2.694  0.000     1 #> 742          8          9    1 2.694  0.371 0.711 #> 743          9          5   -4 2.694 -1.485 0.138 #> 744         16         13   -3 2.694 -1.113 0.266 #> 745         14         13   -1 2.694 -0.371 0.711 #> 746          8          6   -2 2.694 -0.742 0.458 #> 747          5          9    4 2.694  1.485 0.138 #> 748          3          1   -2 2.694 -0.742 0.458 #> 749          6          7    1 2.694  0.371 0.711 #> 750         17         13   -4 2.694 -1.485 0.138 #> 751         15         15    0 2.694  0.000     1 #> 752          5          6    1 2.694  0.371 0.711 #> 753          9         11    2 2.694  0.742 0.458 #> 754         16         14   -2 2.694 -0.742 0.458 #> 755         12         12    0 2.694  0.000     1 #> 756         12         14    2 2.694  0.742 0.458 #> 757         14          9   -5 2.694 -1.856 0.063 #> 758         12         15    3 2.694  1.113 0.266 #> 759          1          0   -1 2.694 -0.371 0.711 #> 760         13         17    4 2.694  1.485 0.138 #> 761         17         19    2 2.694  0.742 0.458 #> 762          4          4    0 2.694  0.000     1 #> 763         10          7   -3 2.694 -1.113 0.266 #> 764         15         15    0 2.694  0.000     1 #> 765         10         12    2 2.694  0.742 0.458 #> 766          2          2    0 2.694  0.000     1 #> 767         16         16    0 2.694  0.000     1 #> 768         14         13   -1 2.694 -0.371 0.711 #> 769         15         15    0 2.694  0.000     1 #> 770          7          3   -4 2.694 -1.485 0.138 #> 771          7          3   -4 2.694 -1.485 0.138 #> 772         15         14   -1 2.694 -0.371 0.711 #> 773         11         12    1 2.694  0.371 0.711 #> 774          2          1   -1 2.694 -0.371 0.711 #> 775          3          7    4 2.694  1.485 0.138 #> 776         16         16    0 2.694  0.000     1 #> 777         14          9   -5 2.694 -1.856 0.063 #> 778         14         14    0 2.694  0.000     1 #> 779         14         13   -1 2.694 -0.371 0.711 #> 780         13          9   -4 2.694 -1.485 0.138 #> 781         13         11   -2 2.694 -0.742 0.458 #> 782          5         13    8 2.694  2.969 0.003 #> 783         13         12   -1 2.694 -0.371 0.711 #> 784          8          7   -1 2.694 -0.371 0.711 #> 785         17         16   -1 2.694 -0.371 0.711 #> 786         10         11    1 2.694  0.371 0.711 #> 787         12         10   -2 2.694 -0.742 0.458 #> 788          7          9    2 2.694  0.742 0.458 #> 789          2          2    0 2.694  0.000     1 #> 790          1          3    2 2.694  0.742 0.458 #> 791          3          8    5 2.694  1.856 0.063 #> 792         14         16    2 2.694  0.742 0.458 #> 793          4          7    3 2.694  1.113 0.266 #> 794         15         17    2 2.694  0.742 0.458 #> 795         15         13   -2 2.694 -0.742 0.458 #> 796          7          8    1 2.694  0.371 0.711 #> 797          6          4   -2 2.694 -0.742 0.458 #> 798          7          6   -1 2.694 -0.371 0.711 #> 799         11          8   -3 2.694 -1.113 0.266 #> 800          8         12    4 2.694  1.485 0.138 #> 801          6          3   -3 2.694 -1.113 0.266 #> 802          7          2   -5 2.694 -1.856 0.063 #> 803          9          9    0 2.694  0.000     1 #> 804         17         14   -3 2.694 -1.113 0.266 #> 805          6          7    1 2.694  0.371 0.711 #> 806         14         13   -1 2.694 -0.371 0.711 #> 807          6         13    7 2.694  2.598 0.009 #> 808          7          9    2 2.694  0.742 0.458 #> 809         17         17    0 2.694  0.000     1 #> 810          3          6    3 2.694  1.113 0.266 #> 811         15         18    3 2.694  1.113 0.266 #> 812         10         10    0 2.694  0.000     1 #> 813          7          2   -5 2.694 -1.856 0.063 #> 814         13         14    1 2.694  0.371 0.711 #> 815          8         10    2 2.694  0.742 0.458 #> 816          7          7    0 2.694  0.000     1 #> 817         15          5  -10 2.694 -3.712     0 #> 818         11         11    0 2.694  0.000     1 #> 819          8         14    6 2.694  2.227 0.026 #> 820          7          5   -2 2.694 -0.742 0.458 #> 821         12         12    0 2.694  0.000     1 #> 822         10         13    3 2.694  1.113 0.266 #> 823          3          3    0 2.694  0.000     1 #> 824         17         18    1 2.694  0.371 0.711 #> 825          7          6   -1 2.694 -0.371 0.711 #> 826          5          7    2 2.694  0.742 0.458 #> 827         15         14   -1 2.694 -0.371 0.711 #> 828          3          7    4 2.694  1.485 0.138 #> 829          4          3   -1 2.694 -0.371 0.711 #> 830         20         17   -3 2.694 -1.113 0.266 #> 831          8          5   -3 2.694 -1.113 0.266 #> 832         13         18    5 2.694  1.856 0.063 #> 833         15         15    0 2.694  0.000     1 #> 834         16         17    1 2.694  0.371 0.711 #> 835          6          6    0 2.694  0.000     1 #> 836         16         16    0 2.694  0.000     1 #> 837          9          9    0 2.694  0.000     1 #> 838         10         16    6 2.694  2.227 0.026 #> 839         10         11    1 2.694  0.371 0.711 #> 840         16         17    1 2.694  0.371 0.711 #> 841         15         15    0 2.694  0.000     1 #> 842         13         13    0 2.694  0.000     1 #> 843         15         16    1 2.694  0.371 0.711 #> 844         10          7   -3 2.694 -1.113 0.266 #> 845         12          9   -3 2.694 -1.113 0.266 #> 846         12         12    0 2.694  0.000     1 #> 847          8          7   -1 2.694 -0.371 0.711 #> 848          7          3   -4 2.694 -1.485 0.138 #> 849          5          5    0 2.694  0.000     1 #> 850         19         16   -3 2.694 -1.113 0.266 #> 851         15         15    0 2.694  0.000     1 #> 852         13          8   -5 2.694 -1.856 0.063 #> 853          9         10    1 2.694  0.371 0.711 #> 854          8          8    0 2.694  0.000     1 #> 855          9          9    0 2.694  0.000     1 #> 856         12         13    1 2.694  0.371 0.711 #> 857         10          7   -3 2.694 -1.113 0.266 #> 858         13         10   -3 2.694 -1.113 0.266 #> 859         10          9   -1 2.694 -0.371 0.711 #> 860          5          8    3 2.694  1.113 0.266 #> 861          5          3   -2 2.694 -0.742 0.458 #> 862         13         14    1 2.694  0.371 0.711 #> 863          3          6    3 2.694  1.113 0.266 #> 864          8          4   -4 2.694 -1.485 0.138 #> 865         10         13    3 2.694  1.113 0.266 #> 866         12         12    0 2.694  0.000     1 #> 867          9         10    1 2.694  0.371 0.711 #> 868         11         13    2 2.694  0.742 0.458 #> 869         10          7   -3 2.694 -1.113 0.266 #> 870         13         13    0 2.694  0.000     1 #> 871         14         13   -1 2.694 -0.371 0.711 #> 872          8         10    2 2.694  0.742 0.458 #> 873          1          1    0 2.694  0.000     1 #> 874          7         13    6 2.694  2.227 0.026 #> 875         14         16    2 2.694  0.742 0.458 #> 876          9          8   -1 2.694 -0.371 0.711 #> 877         16         16    0 2.694  0.000     1 #> 878         14         15    1 2.694  0.371 0.711 #> 879          8         10    2 2.694  0.742 0.458 #> 880          6          2   -4 2.694 -1.485 0.138 #> 881          5          2   -3 2.694 -1.113 0.266 #> 882          6         10    4 2.694  1.485 0.138 #> 883         11         11    0 2.694  0.000     1 #> 884          6          5   -1 2.694 -0.371 0.711 #> 885         14         14    0 2.694  0.000     1 #> 886          3          7    4 2.694  1.485 0.138 #> 887          3          9    6 2.694  2.227 0.026 #> 888         10          7   -3 2.694 -1.113 0.266 #> 889          2          6    4 2.694  1.485 0.138 #> 890         15         11   -4 2.694 -1.485 0.138 #> 891         10          6   -4 2.694 -1.485 0.138 #> 892         10         10    0 2.694  0.000     1 #> 893         17         16   -1 2.694 -0.371 0.711 #> 894         11         12    1 2.694  0.371 0.711 #> 895          9         11    2 2.694  0.742 0.458 #> 896         15         13   -2 2.694 -0.742 0.458 #> 897         17         16   -1 2.694 -0.371 0.711 #> 898          7          9    2 2.694  0.742 0.458 #> 899         10          8   -2 2.694 -0.742 0.458 #> 900          6          5   -1 2.694 -0.371 0.711 #> 901          7          6   -1 2.694 -0.371 0.711 #> 902         16         19    3 2.694  1.113 0.266 #> 903         16         19    3 2.694  1.113 0.266 #> 904         12          9   -3 2.694 -1.113 0.266 #> 905          6          7    1 2.694  0.371 0.711 #> 906         19         20    1 2.694  0.371 0.711 #> 907         15         11   -4 2.694 -1.485 0.138 #> 908         10          5   -5 2.694 -1.856 0.063 #> 909          2          0   -2 2.694 -0.742 0.458 #> 910         18         10   -8 2.694 -2.969 0.003 #> 911          2          0   -2 2.694 -0.742 0.458 #> 912         20         17   -3 2.694 -1.113 0.266 #> 913          4          2   -2 2.694 -0.742 0.458 #> 914         16         17    1 2.694  0.371 0.711 #> 915         14         15    1 2.694  0.371 0.711 #> 916         18         13   -5 2.694 -1.856 0.063 #> 917         16         17    1 2.694  0.371 0.711 #> 918         15         18    3 2.694  1.113 0.266 #> 919         13         10   -3 2.694 -1.113 0.266 #> 920         11          8   -3 2.694 -1.113 0.266 #> 921          4          2   -2 2.694 -0.742 0.458 #> 922          6         10    4 2.694  1.485 0.138 #> 923         12         11   -1 2.694 -0.371 0.711 #> 924         18         18    0 2.694  0.000     1 #> 925          5          5    0 2.694  0.000     1 #> 926         19         19    0 2.694  0.000     1 #> 927          7          5   -2 2.694 -0.742 0.458 #> 928          9          3   -6 2.694 -2.227 0.026 #> 929         15         19    4 2.694  1.485 0.138 #> 930         15          9   -6 2.694 -2.227 0.026 #> 931         11         11    0 2.694  0.000     1 #> 932         12         10   -2 2.694 -0.742 0.458 #> 933         12         13    1 2.694  0.371 0.711 #> 934          9          6   -3 2.694 -1.113 0.266 #> 935         14         14    0 2.694  0.000     1 #> 936          6          7    1 2.694  0.371 0.711 #> 937          6          6    0 2.694  0.000     1 #> 938          8         10    2 2.694  0.742 0.458 #> 939          3          2   -1 2.694 -0.371 0.711 #> 940         11         10   -1 2.694 -0.371 0.711 #> 941         12         15    3 2.694  1.113 0.266 #> 942         13         14    1 2.694  0.371 0.711 #> 943         12          8   -4 2.694 -1.485 0.138 #> 944         15         13   -2 2.694 -0.742 0.458 #> 945         11         12    1 2.694  0.371 0.711 #> 946         11         11    0 2.694  0.000     1 #> 947         11         10   -1 2.694 -0.371 0.711 #> 948         10         13    3 2.694  1.113 0.266 #> 949          1          2    1 2.694  0.371 0.711 #> 950          7         12    5 2.694  1.856 0.063 #> 951          8          6   -2 2.694 -0.742 0.458 #> 952         15         12   -3 2.694 -1.113 0.266 #> 953          7          4   -3 2.694 -1.113 0.266 #> 954          2          6    4 2.694  1.485 0.138 #> 955          6          5   -1 2.694 -0.371 0.711 #> 956          3          3    0 2.694  0.000     1 #> 957          5          5    0 2.694  0.000     1 #> 958          6          6    0 2.694  0.000     1 #> 959         13         17    4 2.694  1.485 0.138 #> 960          6          7    1 2.694  0.371 0.711 #> 961          3          2   -1 2.694 -0.371 0.711 #> 962         12         11   -1 2.694 -0.371 0.711 #> 963          6          4   -2 2.694 -0.742 0.458 #> 964         17         12   -5 2.694 -1.856 0.063 #> 965          5          7    2 2.694  0.742 0.458 #> 966         13         16    3 2.694  1.113 0.266 #> 967         15         16    1 2.694  0.371 0.711 #> 968         12          9   -3 2.694 -1.113 0.266 #> 969         15         13   -2 2.694 -0.742 0.458 #> 970         14         16    2 2.694  0.742 0.458 #> 971          6          7    1 2.694  0.371 0.711 #> 972         16         16    0 2.694  0.000     1 #> 973          3          1   -2 2.694 -0.742 0.458 #> 974          5          5    0 2.694  0.000     1 #> 975          7          3   -4 2.694 -1.485 0.138 #> 976         13         13    0 2.694  0.000     1 #> 977         10         12    2 2.694  0.742 0.458 #> 978          2          4    2 2.694  0.742 0.458 #> 979          2          9    7 2.694  2.598 0.009 #> 980         10          9   -1 2.694 -0.371 0.711 #> 981          4          1   -3 2.694 -1.113 0.266 #> 982          7          4   -3 2.694 -1.113 0.266 #> 983         17         12   -5 2.694 -1.856 0.063 #> 984         18         16   -2 2.694 -0.742 0.458 #> 985         16         11   -5 2.694 -1.856 0.063 #> 986          5          3   -2 2.694 -0.742 0.458 #> 987         13         14    1 2.694  0.371 0.711 #> 988         11          8   -3 2.694 -1.113 0.266 #> 989          2         12   10 2.694  3.712     0 #> 990          9         11    2 2.694  0.742 0.458 #> 991         11          6   -5 2.694 -1.856 0.063 #> 992         11         10   -1 2.694 -0.371 0.711 #> 993          8          6   -2 2.694 -0.742 0.458 #> 994          1          4    3 2.694  1.113 0.266 #> 995         10          7   -3 2.694 -1.113 0.266 #> 996         11          5   -6 2.694 -2.227 0.026 #> 997          7          6   -1 2.694 -0.371 0.711 #> 998         10         12    2 2.694  0.742 0.458 #> 999         11          7   -4 2.694 -1.485 0.138 #> 1000         1          2    1 2.694  0.371 0.711  # Supplying only the total scores TS_pre <- matrix(rowSums(dat_pre)) TS_post <- matrix(rowSums(dat_post)) RCI(predat = TS_pre, postdat = TS_post,    SEM.pre=SEM.alpha, SEM.post=SEM.alpha.post) #>      pre.score post.score diff    SE      z     p #> 1           18         19    1 2.694  0.371 0.711 #> 2           18          9   -9 2.694 -3.340 0.001 #> 3           15          9   -6 2.694 -2.227 0.026 #> 4           11         10   -1 2.694 -0.371 0.711 #> 5            4          5    1 2.694  0.371 0.711 #> 6            4          8    4 2.694  1.485 0.138 #> 7           11          8   -3 2.694 -1.113 0.266 #> 8           11         15    4 2.694  1.485 0.138 #> 9            3          3    0 2.694  0.000     1 #> 10           4          8    4 2.694  1.485 0.138 #> 11           1          5    4 2.694  1.485 0.138 #> 12          16         14   -2 2.694 -0.742 0.458 #> 13          12         10   -2 2.694 -0.742 0.458 #> 14          11         10   -1 2.694 -0.371 0.711 #> 15          17         18    1 2.694  0.371 0.711 #> 16           1          4    3 2.694  1.113 0.266 #> 17          10          8   -2 2.694 -0.742 0.458 #> 18          12         11   -1 2.694 -0.371 0.711 #> 19          15         12   -3 2.694 -1.113 0.266 #> 20          16         10   -6 2.694 -2.227 0.026 #> 21           7          6   -1 2.694 -0.371 0.711 #> 22           7         12    5 2.694  1.856 0.063 #> 23           2          4    2 2.694  0.742 0.458 #> 24           5          7    2 2.694  0.742 0.458 #> 25          14         15    1 2.694  0.371 0.711 #> 26           9          6   -3 2.694 -1.113 0.266 #> 27          17         17    0 2.694  0.000     1 #> 28           4          9    5 2.694  1.856 0.063 #> 29          14         16    2 2.694  0.742 0.458 #> 30           4          7    3 2.694  1.113 0.266 #> 31           2          0   -2 2.694 -0.742 0.458 #> 32           9          6   -3 2.694 -1.113 0.266 #> 33          20         20    0 2.694  0.000     1 #> 34           9          6   -3 2.694 -1.113 0.266 #> 35           3          4    1 2.694  0.371 0.711 #> 36          14         15    1 2.694  0.371 0.711 #> 37           8          9    1 2.694  0.371 0.711 #> 38          15         13   -2 2.694 -0.742 0.458 #> 39           9         12    3 2.694  1.113 0.266 #> 40          18         18    0 2.694  0.000     1 #> 41          11         10   -1 2.694 -0.371 0.711 #> 42          12          9   -3 2.694 -1.113 0.266 #> 43           8          7   -1 2.694 -0.371 0.711 #> 44          10         11    1 2.694  0.371 0.711 #> 45           7         10    3 2.694  1.113 0.266 #> 46           8          9    1 2.694  0.371 0.711 #> 47           6          8    2 2.694  0.742 0.458 #> 48           6          7    1 2.694  0.371 0.711 #> 49           6          8    2 2.694  0.742 0.458 #> 50           8         11    3 2.694  1.113 0.266 #> 51          13         17    4 2.694  1.485 0.138 #> 52           6          6    0 2.694  0.000     1 #> 53          19         13   -6 2.694 -2.227 0.026 #> 54           6         11    5 2.694  1.856 0.063 #> 55           9          8   -1 2.694 -0.371 0.711 #> 56           7          8    1 2.694  0.371 0.711 #> 57           9          6   -3 2.694 -1.113 0.266 #> 58           3          3    0 2.694  0.000     1 #> 59          10          8   -2 2.694 -0.742 0.458 #> 60          14         14    0 2.694  0.000     1 #> 61          12         12    0 2.694  0.000     1 #> 62          15         14   -1 2.694 -0.371 0.711 #> 63          13         12   -1 2.694 -0.371 0.711 #> 64           5          5    0 2.694  0.000     1 #> 65           5          4   -1 2.694 -0.371 0.711 #> 66           5          4   -1 2.694 -0.371 0.711 #> 67          18         14   -4 2.694 -1.485 0.138 #> 68           9          8   -1 2.694 -0.371 0.711 #> 69          11          9   -2 2.694 -0.742 0.458 #> 70          19         17   -2 2.694 -0.742 0.458 #> 71           9          5   -4 2.694 -1.485 0.138 #> 72          16         15   -1 2.694 -0.371 0.711 #> 73          10          9   -1 2.694 -0.371 0.711 #> 74          11         11    0 2.694  0.000     1 #> 75          14         10   -4 2.694 -1.485 0.138 #> 76          14         15    1 2.694  0.371 0.711 #> 77           5          4   -1 2.694 -0.371 0.711 #> 78          11          9   -2 2.694 -0.742 0.458 #> 79          15         10   -5 2.694 -1.856 0.063 #> 80          11         11    0 2.694  0.000     1 #> 81          10          8   -2 2.694 -0.742 0.458 #> 82          12         12    0 2.694  0.000     1 #> 83          11         11    0 2.694  0.000     1 #> 84           5          1   -4 2.694 -1.485 0.138 #> 85           7          9    2 2.694  0.742 0.458 #> 86           7         10    3 2.694  1.113 0.266 #> 87           3          7    4 2.694  1.485 0.138 #> 88           9         11    2 2.694  0.742 0.458 #> 89           8          9    1 2.694  0.371 0.711 #> 90          12         11   -1 2.694 -0.371 0.711 #> 91           6          1   -5 2.694 -1.856 0.063 #> 92           6          8    2 2.694  0.742 0.458 #> 93           3          5    2 2.694  0.742 0.458 #> 94          12         12    0 2.694  0.000     1 #> 95          18         16   -2 2.694 -0.742 0.458 #> 96           9          7   -2 2.694 -0.742 0.458 #> 97           8         11    3 2.694  1.113 0.266 #> 98           7          7    0 2.694  0.000     1 #> 99          12         11   -1 2.694 -0.371 0.711 #> 100         10         10    0 2.694  0.000     1 #> 101          5          5    0 2.694  0.000     1 #> 102         14         15    1 2.694  0.371 0.711 #> 103          9          9    0 2.694  0.000     1 #> 104          8         15    7 2.694  2.598 0.009 #> 105          2          3    1 2.694  0.371 0.711 #> 106          7         10    3 2.694  1.113 0.266 #> 107         12         12    0 2.694  0.000     1 #> 108          2          2    0 2.694  0.000     1 #> 109         14         13   -1 2.694 -0.371 0.711 #> 110          6          4   -2 2.694 -0.742 0.458 #> 111         15         10   -5 2.694 -1.856 0.063 #> 112          5          5    0 2.694  0.000     1 #> 113         15         18    3 2.694  1.113 0.266 #> 114          2          0   -2 2.694 -0.742 0.458 #> 115          9         12    3 2.694  1.113 0.266 #> 116         14         14    0 2.694  0.000     1 #> 117         10          7   -3 2.694 -1.113 0.266 #> 118          6          5   -1 2.694 -0.371 0.711 #> 119         12          9   -3 2.694 -1.113 0.266 #> 120          7          3   -4 2.694 -1.485 0.138 #> 121          9         12    3 2.694  1.113 0.266 #> 122          2          6    4 2.694  1.485 0.138 #> 123          9          6   -3 2.694 -1.113 0.266 #> 124          2          5    3 2.694  1.113 0.266 #> 125         12         12    0 2.694  0.000     1 #> 126         16         19    3 2.694  1.113 0.266 #> 127         13         14    1 2.694  0.371 0.711 #> 128         13         14    1 2.694  0.371 0.711 #> 129         14         15    1 2.694  0.371 0.711 #> 130          7         14    7 2.694  2.598 0.009 #> 131         10         11    1 2.694  0.371 0.711 #> 132          3          3    0 2.694  0.000     1 #> 133         15         15    0 2.694  0.000     1 #> 134         18         19    1 2.694  0.371 0.711 #> 135          2          5    3 2.694  1.113 0.266 #> 136         12         10   -2 2.694 -0.742 0.458 #> 137         12         14    2 2.694  0.742 0.458 #> 138          6          3   -3 2.694 -1.113 0.266 #> 139         13          9   -4 2.694 -1.485 0.138 #> 140          8          5   -3 2.694 -1.113 0.266 #> 141         18         17   -1 2.694 -0.371 0.711 #> 142         15         15    0 2.694  0.000     1 #> 143          7          9    2 2.694  0.742 0.458 #> 144         14         10   -4 2.694 -1.485 0.138 #> 145          3          5    2 2.694  0.742 0.458 #> 146          1          2    1 2.694  0.371 0.711 #> 147          5          6    1 2.694  0.371 0.711 #> 148          8          8    0 2.694  0.000     1 #> 149         13         15    2 2.694  0.742 0.458 #> 150          9          9    0 2.694  0.000     1 #> 151          8          9    1 2.694  0.371 0.711 #> 152          2          1   -1 2.694 -0.371 0.711 #> 153          3          3    0 2.694  0.000     1 #> 154          7          5   -2 2.694 -0.742 0.458 #> 155         16         13   -3 2.694 -1.113 0.266 #> 156          9         12    3 2.694  1.113 0.266 #> 157         15         17    2 2.694  0.742 0.458 #> 158         10          5   -5 2.694 -1.856 0.063 #> 159          8         10    2 2.694  0.742 0.458 #> 160         17         11   -6 2.694 -2.227 0.026 #> 161         14          8   -6 2.694 -2.227 0.026 #> 162          8          8    0 2.694  0.000     1 #> 163          3          5    2 2.694  0.742 0.458 #> 164         16          8   -8 2.694 -2.969 0.003 #> 165          9          7   -2 2.694 -0.742 0.458 #> 166          7          8    1 2.694  0.371 0.711 #> 167         15         15    0 2.694  0.000     1 #> 168         15         18    3 2.694  1.113 0.266 #> 169          3          2   -1 2.694 -0.371 0.711 #> 170          1          2    1 2.694  0.371 0.711 #> 171          2          0   -2 2.694 -0.742 0.458 #> 172         20         15   -5 2.694 -1.856 0.063 #> 173         10         12    2 2.694  0.742 0.458 #> 174          9          3   -6 2.694 -2.227 0.026 #> 175          5         15   10 2.694  3.712     0 #> 176          9          7   -2 2.694 -0.742 0.458 #> 177         15         16    1 2.694  0.371 0.711 #> 178          2          5    3 2.694  1.113 0.266 #> 179         18         20    2 2.694  0.742 0.458 #> 180         10          8   -2 2.694 -0.742 0.458 #> 181          6          6    0 2.694  0.000     1 #> 182          3          5    2 2.694  0.742 0.458 #> 183          9          7   -2 2.694 -0.742 0.458 #> 184          7         10    3 2.694  1.113 0.266 #> 185          6          3   -3 2.694 -1.113 0.266 #> 186          7          5   -2 2.694 -0.742 0.458 #> 187          7          4   -3 2.694 -1.113 0.266 #> 188         10          9   -1 2.694 -0.371 0.711 #> 189         17         12   -5 2.694 -1.856 0.063 #> 190          2          4    2 2.694  0.742 0.458 #> 191         16         15   -1 2.694 -0.371 0.711 #> 192          6          9    3 2.694  1.113 0.266 #> 193         10         13    3 2.694  1.113 0.266 #> 194          2          7    5 2.694  1.856 0.063 #> 195          5          3   -2 2.694 -0.742 0.458 #> 196         12          8   -4 2.694 -1.485 0.138 #> 197          5          1   -4 2.694 -1.485 0.138 #> 198          5          2   -3 2.694 -1.113 0.266 #> 199         17         17    0 2.694  0.000     1 #> 200          4          2   -2 2.694 -0.742 0.458 #> 201         13         13    0 2.694  0.000     1 #> 202         14         12   -2 2.694 -0.742 0.458 #> 203          2          2    0 2.694  0.000     1 #> 204         11          9   -2 2.694 -0.742 0.458 #> 205         10         11    1 2.694  0.371 0.711 #> 206         13         11   -2 2.694 -0.742 0.458 #> 207         17         18    1 2.694  0.371 0.711 #> 208         14         15    1 2.694  0.371 0.711 #> 209         18         18    0 2.694  0.000     1 #> 210          2          0   -2 2.694 -0.742 0.458 #> 211          9         11    2 2.694  0.742 0.458 #> 212         10         12    2 2.694  0.742 0.458 #> 213         16         14   -2 2.694 -0.742 0.458 #> 214          2          2    0 2.694  0.000     1 #> 215          3          4    1 2.694  0.371 0.711 #> 216         15         17    2 2.694  0.742 0.458 #> 217         14         12   -2 2.694 -0.742 0.458 #> 218          3          5    2 2.694  0.742 0.458 #> 219          9          8   -1 2.694 -0.371 0.711 #> 220          0          1    1 2.694  0.371 0.711 #> 221         14         12   -2 2.694 -0.742 0.458 #> 222          2          1   -1 2.694 -0.371 0.711 #> 223          5         10    5 2.694  1.856 0.063 #> 224          8         15    7 2.694  2.598 0.009 #> 225         12         14    2 2.694  0.742 0.458 #> 226         14         14    0 2.694  0.000     1 #> 227         11         11    0 2.694  0.000     1 #> 228          9          9    0 2.694  0.000     1 #> 229         17         15   -2 2.694 -0.742 0.458 #> 230          2          2    0 2.694  0.000     1 #> 231          6          9    3 2.694  1.113 0.266 #> 232          9         14    5 2.694  1.856 0.063 #> 233         13         13    0 2.694  0.000     1 #> 234         13         17    4 2.694  1.485 0.138 #> 235         13          6   -7 2.694 -2.598 0.009 #> 236          8          8    0 2.694  0.000     1 #> 237          8          9    1 2.694  0.371 0.711 #> 238          6         12    6 2.694  2.227 0.026 #> 239          9          9    0 2.694  0.000     1 #> 240          7         12    5 2.694  1.856 0.063 #> 241         18         18    0 2.694  0.000     1 #> 242          4          3   -1 2.694 -0.371 0.711 #> 243          1          2    1 2.694  0.371 0.711 #> 244          3          1   -2 2.694 -0.742 0.458 #> 245          6          5   -1 2.694 -0.371 0.711 #> 246          4          4    0 2.694  0.000     1 #> 247         17         17    0 2.694  0.000     1 #> 248         20         18   -2 2.694 -0.742 0.458 #> 249          8         10    2 2.694  0.742 0.458 #> 250         15         18    3 2.694  1.113 0.266 #> 251         15         13   -2 2.694 -0.742 0.458 #> 252          8          8    0 2.694  0.000     1 #> 253          8          8    0 2.694  0.000     1 #> 254         11         13    2 2.694  0.742 0.458 #> 255         18         16   -2 2.694 -0.742 0.458 #> 256         10         11    1 2.694  0.371 0.711 #> 257         18         16   -2 2.694 -0.742 0.458 #> 258         10         11    1 2.694  0.371 0.711 #> 259          4          3   -1 2.694 -0.371 0.711 #> 260         11         14    3 2.694  1.113 0.266 #> 261         14         11   -3 2.694 -1.113 0.266 #> 262         14         13   -1 2.694 -0.371 0.711 #> 263         19         17   -2 2.694 -0.742 0.458 #> 264          4          6    2 2.694  0.742 0.458 #> 265         17         17    0 2.694  0.000     1 #> 266          9         12    3 2.694  1.113 0.266 #> 267          4          7    3 2.694  1.113 0.266 #> 268         15         12   -3 2.694 -1.113 0.266 #> 269          7          7    0 2.694  0.000     1 #> 270          8         11    3 2.694  1.113 0.266 #> 271          1          2    1 2.694  0.371 0.711 #> 272          8          6   -2 2.694 -0.742 0.458 #> 273          6          6    0 2.694  0.000     1 #> 274         17         16   -1 2.694 -0.371 0.711 #> 275         13         11   -2 2.694 -0.742 0.458 #> 276          2          1   -1 2.694 -0.371 0.711 #> 277          9         10    1 2.694  0.371 0.711 #> 278          2          0   -2 2.694 -0.742 0.458 #> 279         11         13    2 2.694  0.742 0.458 #> 280         17         17    0 2.694  0.000     1 #> 281         16         16    0 2.694  0.000     1 #> 282         14         15    1 2.694  0.371 0.711 #> 283         15         16    1 2.694  0.371 0.711 #> 284          4          1   -3 2.694 -1.113 0.266 #> 285         17         18    1 2.694  0.371 0.711 #> 286         10          7   -3 2.694 -1.113 0.266 #> 287         12         15    3 2.694  1.113 0.266 #> 288         15         17    2 2.694  0.742 0.458 #> 289         17         15   -2 2.694 -0.742 0.458 #> 290         14         11   -3 2.694 -1.113 0.266 #> 291         15         12   -3 2.694 -1.113 0.266 #> 292         10         10    0 2.694  0.000     1 #> 293          0          2    2 2.694  0.742 0.458 #> 294         12          8   -4 2.694 -1.485 0.138 #> 295          4          7    3 2.694  1.113 0.266 #> 296         15         15    0 2.694  0.000     1 #> 297         18         17   -1 2.694 -0.371 0.711 #> 298          9          7   -2 2.694 -0.742 0.458 #> 299         18         12   -6 2.694 -2.227 0.026 #> 300          0          1    1 2.694  0.371 0.711 #> 301          4         11    7 2.694  2.598 0.009 #> 302         10          8   -2 2.694 -0.742 0.458 #> 303          5          2   -3 2.694 -1.113 0.266 #> 304         19         17   -2 2.694 -0.742 0.458 #> 305         11          6   -5 2.694 -1.856 0.063 #> 306         15         15    0 2.694  0.000     1 #> 307         10         12    2 2.694  0.742 0.458 #> 308         11          8   -3 2.694 -1.113 0.266 #> 309         10          7   -3 2.694 -1.113 0.266 #> 310          8          6   -2 2.694 -0.742 0.458 #> 311         14         15    1 2.694  0.371 0.711 #> 312         16         11   -5 2.694 -1.856 0.063 #> 313          6          4   -2 2.694 -0.742 0.458 #> 314         11         11    0 2.694  0.000     1 #> 315          7          7    0 2.694  0.000     1 #> 316          9         11    2 2.694  0.742 0.458 #> 317          7         11    4 2.694  1.485 0.138 #> 318          1          5    4 2.694  1.485 0.138 #> 319         10          9   -1 2.694 -0.371 0.711 #> 320         13         10   -3 2.694 -1.113 0.266 #> 321         13         10   -3 2.694 -1.113 0.266 #> 322         13          9   -4 2.694 -1.485 0.138 #> 323          1          2    1 2.694  0.371 0.711 #> 324         13         13    0 2.694  0.000     1 #> 325         13         13    0 2.694  0.000     1 #> 326         13         13    0 2.694  0.000     1 #> 327          7          6   -1 2.694 -0.371 0.711 #> 328          9         12    3 2.694  1.113 0.266 #> 329         13         13    0 2.694  0.000     1 #> 330          6         14    8 2.694  2.969 0.003 #> 331         12         14    2 2.694  0.742 0.458 #> 332          9          5   -4 2.694 -1.485 0.138 #> 333         13         12   -1 2.694 -0.371 0.711 #> 334         13         14    1 2.694  0.371 0.711 #> 335          9         11    2 2.694  0.742 0.458 #> 336         10          9   -1 2.694 -0.371 0.711 #> 337         12         13    1 2.694  0.371 0.711 #> 338         16         14   -2 2.694 -0.742 0.458 #> 339          6         10    4 2.694  1.485 0.138 #> 340         17         15   -2 2.694 -0.742 0.458 #> 341         12         14    2 2.694  0.742 0.458 #> 342          6          5   -1 2.694 -0.371 0.711 #> 343          5          9    4 2.694  1.485 0.138 #> 344          5          4   -1 2.694 -0.371 0.711 #> 345          6          9    3 2.694  1.113 0.266 #> 346         12          8   -4 2.694 -1.485 0.138 #> 347         12         13    1 2.694  0.371 0.711 #> 348          8         11    3 2.694  1.113 0.266 #> 349          5          6    1 2.694  0.371 0.711 #> 350         11         12    1 2.694  0.371 0.711 #> 351          9          7   -2 2.694 -0.742 0.458 #> 352         18         16   -2 2.694 -0.742 0.458 #> 353          9         11    2 2.694  0.742 0.458 #> 354          4          3   -1 2.694 -0.371 0.711 #> 355         12         17    5 2.694  1.856 0.063 #> 356         16         15   -1 2.694 -0.371 0.711 #> 357          9         13    4 2.694  1.485 0.138 #> 358         10          7   -3 2.694 -1.113 0.266 #> 359          1          3    2 2.694  0.742 0.458 #> 360         10         12    2 2.694  0.742 0.458 #> 361          5          5    0 2.694  0.000     1 #> 362         13         15    2 2.694  0.742 0.458 #> 363          9         12    3 2.694  1.113 0.266 #> 364         13         14    1 2.694  0.371 0.711 #> 365          9          5   -4 2.694 -1.485 0.138 #> 366         17         17    0 2.694  0.000     1 #> 367          4          2   -2 2.694 -0.742 0.458 #> 368         12          9   -3 2.694 -1.113 0.266 #> 369          3         10    7 2.694  2.598 0.009 #> 370         12         12    0 2.694  0.000     1 #> 371         14         18    4 2.694  1.485 0.138 #> 372         10         11    1 2.694  0.371 0.711 #> 373          7          9    2 2.694  0.742 0.458 #> 374          4          6    2 2.694  0.742 0.458 #> 375         10          5   -5 2.694 -1.856 0.063 #> 376         16         14   -2 2.694 -0.742 0.458 #> 377         15         15    0 2.694  0.000     1 #> 378         13         12   -1 2.694 -0.371 0.711 #> 379          0          3    3 2.694  1.113 0.266 #> 380          7          8    1 2.694  0.371 0.711 #> 381          6          7    1 2.694  0.371 0.711 #> 382          6          6    0 2.694  0.000     1 #> 383          6          8    2 2.694  0.742 0.458 #> 384          4          4    0 2.694  0.000     1 #> 385          3          4    1 2.694  0.371 0.711 #> 386          2          7    5 2.694  1.856 0.063 #> 387          9          9    0 2.694  0.000     1 #> 388         19         14   -5 2.694 -1.856 0.063 #> 389          3          6    3 2.694  1.113 0.266 #> 390          0          2    2 2.694  0.742 0.458 #> 391         15         14   -1 2.694 -0.371 0.711 #> 392         11          4   -7 2.694 -2.598 0.009 #> 393          5          6    1 2.694  0.371 0.711 #> 394          2          1   -1 2.694 -0.371 0.711 #> 395          7         13    6 2.694  2.227 0.026 #> 396         13         11   -2 2.694 -0.742 0.458 #> 397         15         14   -1 2.694 -0.371 0.711 #> 398          2          4    2 2.694  0.742 0.458 #> 399         13          6   -7 2.694 -2.598 0.009 #> 400         15          9   -6 2.694 -2.227 0.026 #> 401          7          8    1 2.694  0.371 0.711 #> 402          3          3    0 2.694  0.000     1 #> 403          9         12    3 2.694  1.113 0.266 #> 404         17         17    0 2.694  0.000     1 #> 405          1          4    3 2.694  1.113 0.266 #> 406          4          2   -2 2.694 -0.742 0.458 #> 407          7         10    3 2.694  1.113 0.266 #> 408          7         11    4 2.694  1.485 0.138 #> 409         12         12    0 2.694  0.000     1 #> 410          8          6   -2 2.694 -0.742 0.458 #> 411          8          4   -4 2.694 -1.485 0.138 #> 412         14         11   -3 2.694 -1.113 0.266 #> 413          5          3   -2 2.694 -0.742 0.458 #> 414         16         17    1 2.694  0.371 0.711 #> 415         11         15    4 2.694  1.485 0.138 #> 416         15         12   -3 2.694 -1.113 0.266 #> 417         14         15    1 2.694  0.371 0.711 #> 418          5          6    1 2.694  0.371 0.711 #> 419          5         10    5 2.694  1.856 0.063 #> 420         10         13    3 2.694  1.113 0.266 #> 421          3          2   -1 2.694 -0.371 0.711 #> 422         17         17    0 2.694  0.000     1 #> 423         11         11    0 2.694  0.000     1 #> 424         14         13   -1 2.694 -0.371 0.711 #> 425         16          9   -7 2.694 -2.598 0.009 #> 426         15         16    1 2.694  0.371 0.711 #> 427         11          7   -4 2.694 -1.485 0.138 #> 428          8         11    3 2.694  1.113 0.266 #> 429         13         13    0 2.694  0.000     1 #> 430         10         10    0 2.694  0.000     1 #> 431         15         14   -1 2.694 -0.371 0.711 #> 432          1          4    3 2.694  1.113 0.266 #> 433          3          3    0 2.694  0.000     1 #> 434         11         15    4 2.694  1.485 0.138 #> 435          3          4    1 2.694  0.371 0.711 #> 436          6         11    5 2.694  1.856 0.063 #> 437          2          0   -2 2.694 -0.742 0.458 #> 438         13         14    1 2.694  0.371 0.711 #> 439         18         14   -4 2.694 -1.485 0.138 #> 440          6         13    7 2.694  2.598 0.009 #> 441         14         12   -2 2.694 -0.742 0.458 #> 442          4          5    1 2.694  0.371 0.711 #> 443         10          9   -1 2.694 -0.371 0.711 #> 444         18         18    0 2.694  0.000     1 #> 445         17         16   -1 2.694 -0.371 0.711 #> 446         16         17    1 2.694  0.371 0.711 #> 447          0          0    0 2.694  0.000     1 #> 448         12         10   -2 2.694 -0.742 0.458 #> 449          4          7    3 2.694  1.113 0.266 #> 450          1          4    3 2.694  1.113 0.266 #> 451         19         18   -1 2.694 -0.371 0.711 #> 452          8          5   -3 2.694 -1.113 0.266 #> 453          8         11    3 2.694  1.113 0.266 #> 454          5          9    4 2.694  1.485 0.138 #> 455         18         17   -1 2.694 -0.371 0.711 #> 456         12         11   -1 2.694 -0.371 0.711 #> 457          5          9    4 2.694  1.485 0.138 #> 458          2          5    3 2.694  1.113 0.266 #> 459          1          2    1 2.694  0.371 0.711 #> 460         19         18   -1 2.694 -0.371 0.711 #> 461         15         17    2 2.694  0.742 0.458 #> 462         17         13   -4 2.694 -1.485 0.138 #> 463         13         15    2 2.694  0.742 0.458 #> 464         14         14    0 2.694  0.000     1 #> 465          6          9    3 2.694  1.113 0.266 #> 466          9          5   -4 2.694 -1.485 0.138 #> 467         16         15   -1 2.694 -0.371 0.711 #> 468          3          2   -1 2.694 -0.371 0.711 #> 469          1          7    6 2.694  2.227 0.026 #> 470         13         10   -3 2.694 -1.113 0.266 #> 471          5          4   -1 2.694 -0.371 0.711 #> 472          6          7    1 2.694  0.371 0.711 #> 473         20         19   -1 2.694 -0.371 0.711 #> 474          7          9    2 2.694  0.742 0.458 #> 475          1          1    0 2.694  0.000     1 #> 476         15         13   -2 2.694 -0.742 0.458 #> 477         16         11   -5 2.694 -1.856 0.063 #> 478         16         12   -4 2.694 -1.485 0.138 #> 479         11         10   -1 2.694 -0.371 0.711 #> 480         15         16    1 2.694  0.371 0.711 #> 481          7          8    1 2.694  0.371 0.711 #> 482         15         12   -3 2.694 -1.113 0.266 #> 483         15         16    1 2.694  0.371 0.711 #> 484         12         11   -1 2.694 -0.371 0.711 #> 485         12         10   -2 2.694 -0.742 0.458 #> 486          5          8    3 2.694  1.113 0.266 #> 487          8         12    4 2.694  1.485 0.138 #> 488         11         13    2 2.694  0.742 0.458 #> 489         16         17    1 2.694  0.371 0.711 #> 490          7          8    1 2.694  0.371 0.711 #> 491         19         18   -1 2.694 -0.371 0.711 #> 492          4          5    1 2.694  0.371 0.711 #> 493         19         16   -3 2.694 -1.113 0.266 #> 494          8          9    1 2.694  0.371 0.711 #> 495         10         15    5 2.694  1.856 0.063 #> 496          6          7    1 2.694  0.371 0.711 #> 497         11          8   -3 2.694 -1.113 0.266 #> 498          3          9    6 2.694  2.227 0.026 #> 499          8          8    0 2.694  0.000     1 #> 500          7         11    4 2.694  1.485 0.138 #> 501         13         16    3 2.694  1.113 0.266 #> 502         11         10   -1 2.694 -0.371 0.711 #> 503          0          1    1 2.694  0.371 0.711 #> 504          4          5    1 2.694  0.371 0.711 #> 505          4          6    2 2.694  0.742 0.458 #> 506         12         10   -2 2.694 -0.742 0.458 #> 507         18         16   -2 2.694 -0.742 0.458 #> 508         13         14    1 2.694  0.371 0.711 #> 509          5          7    2 2.694  0.742 0.458 #> 510          8         10    2 2.694  0.742 0.458 #> 511          6         10    4 2.694  1.485 0.138 #> 512          7          9    2 2.694  0.742 0.458 #> 513          5          5    0 2.694  0.000     1 #> 514          5         10    5 2.694  1.856 0.063 #> 515          9         11    2 2.694  0.742 0.458 #> 516         17         17    0 2.694  0.000     1 #> 517         14         13   -1 2.694 -0.371 0.711 #> 518          8         15    7 2.694  2.598 0.009 #> 519         14         14    0 2.694  0.000     1 #> 520         13          8   -5 2.694 -1.856 0.063 #> 521         14         12   -2 2.694 -0.742 0.458 #> 522          6          2   -4 2.694 -1.485 0.138 #> 523         17         14   -3 2.694 -1.113 0.266 #> 524         13         13    0 2.694  0.000     1 #> 525         14         14    0 2.694  0.000     1 #> 526         16         12   -4 2.694 -1.485 0.138 #> 527         12         10   -2 2.694 -0.742 0.458 #> 528         15         16    1 2.694  0.371 0.711 #> 529         13         10   -3 2.694 -1.113 0.266 #> 530          9         10    1 2.694  0.371 0.711 #> 531         12          7   -5 2.694 -1.856 0.063 #> 532         20         20    0 2.694  0.000     1 #> 533         17         12   -5 2.694 -1.856 0.063 #> 534          6          8    2 2.694  0.742 0.458 #> 535         19         18   -1 2.694 -0.371 0.711 #> 536         12         12    0 2.694  0.000     1 #> 537         10          7   -3 2.694 -1.113 0.266 #> 538          6          4   -2 2.694 -0.742 0.458 #> 539          8          8    0 2.694  0.000     1 #> 540         10         12    2 2.694  0.742 0.458 #> 541          4          7    3 2.694  1.113 0.266 #> 542          2          2    0 2.694  0.000     1 #> 543          6          5   -1 2.694 -0.371 0.711 #> 544         12         10   -2 2.694 -0.742 0.458 #> 545          4          5    1 2.694  0.371 0.711 #> 546         11         10   -1 2.694 -0.371 0.711 #> 547         14         12   -2 2.694 -0.742 0.458 #> 548         13         15    2 2.694  0.742 0.458 #> 549         12          9   -3 2.694 -1.113 0.266 #> 550         11         11    0 2.694  0.000     1 #> 551          8          2   -6 2.694 -2.227 0.026 #> 552         14         15    1 2.694  0.371 0.711 #> 553         11         14    3 2.694  1.113 0.266 #> 554         13         12   -1 2.694 -0.371 0.711 #> 555          2          3    1 2.694  0.371 0.711 #> 556          9         13    4 2.694  1.485 0.138 #> 557         10         11    1 2.694  0.371 0.711 #> 558          8         12    4 2.694  1.485 0.138 #> 559         11         12    1 2.694  0.371 0.711 #> 560         19         18   -1 2.694 -0.371 0.711 #> 561         12         12    0 2.694  0.000     1 #> 562         12          8   -4 2.694 -1.485 0.138 #> 563          3          6    3 2.694  1.113 0.266 #> 564          4          0   -4 2.694 -1.485 0.138 #> 565         14         14    0 2.694  0.000     1 #> 566          3          4    1 2.694  0.371 0.711 #> 567         18         16   -2 2.694 -0.742 0.458 #> 568          3          2   -1 2.694 -0.371 0.711 #> 569         17         19    2 2.694  0.742 0.458 #> 570         10          8   -2 2.694 -0.742 0.458 #> 571         16         13   -3 2.694 -1.113 0.266 #> 572          8          8    0 2.694  0.000     1 #> 573         15         17    2 2.694  0.742 0.458 #> 574          7         12    5 2.694  1.856 0.063 #> 575          6          2   -4 2.694 -1.485 0.138 #> 576         11         14    3 2.694  1.113 0.266 #> 577         13         12   -1 2.694 -0.371 0.711 #> 578         17         14   -3 2.694 -1.113 0.266 #> 579          5          9    4 2.694  1.485 0.138 #> 580         12         17    5 2.694  1.856 0.063 #> 581         11         10   -1 2.694 -0.371 0.711 #> 582          6         12    6 2.694  2.227 0.026 #> 583         11         13    2 2.694  0.742 0.458 #> 584         16         18    2 2.694  0.742 0.458 #> 585          8          6   -2 2.694 -0.742 0.458 #> 586          7          9    2 2.694  0.742 0.458 #> 587         12         11   -1 2.694 -0.371 0.711 #> 588          9          7   -2 2.694 -0.742 0.458 #> 589          9          6   -3 2.694 -1.113 0.266 #> 590         14         13   -1 2.694 -0.371 0.711 #> 591         15         15    0 2.694  0.000     1 #> 592         19         15   -4 2.694 -1.485 0.138 #> 593          6          7    1 2.694  0.371 0.711 #> 594          4          3   -1 2.694 -0.371 0.711 #> 595          4          6    2 2.694  0.742 0.458 #> 596          4          3   -1 2.694 -0.371 0.711 #> 597          4          4    0 2.694  0.000     1 #> 598         10          6   -4 2.694 -1.485 0.138 #> 599          8         14    6 2.694  2.227 0.026 #> 600          9         12    3 2.694  1.113 0.266 #> 601         10         12    2 2.694  0.742 0.458 #> 602         12          9   -3 2.694 -1.113 0.266 #> 603         13          9   -4 2.694 -1.485 0.138 #> 604         11         11    0 2.694  0.000     1 #> 605          2          4    2 2.694  0.742 0.458 #> 606         16         14   -2 2.694 -0.742 0.458 #> 607          2          1   -1 2.694 -0.371 0.711 #> 608          3          2   -1 2.694 -0.371 0.711 #> 609          6          4   -2 2.694 -0.742 0.458 #> 610         15         11   -4 2.694 -1.485 0.138 #> 611          7          6   -1 2.694 -0.371 0.711 #> 612         14         18    4 2.694  1.485 0.138 #> 613          7         14    7 2.694  2.598 0.009 #> 614         18         14   -4 2.694 -1.485 0.138 #> 615          9          6   -3 2.694 -1.113 0.266 #> 616         11         11    0 2.694  0.000     1 #> 617          6          2   -4 2.694 -1.485 0.138 #> 618         10          7   -3 2.694 -1.113 0.266 #> 619          3          2   -1 2.694 -0.371 0.711 #> 620          8          4   -4 2.694 -1.485 0.138 #> 621          8         10    2 2.694  0.742 0.458 #> 622         16         16    0 2.694  0.000     1 #> 623          4          2   -2 2.694 -0.742 0.458 #> 624         13         15    2 2.694  0.742 0.458 #> 625         11         11    0 2.694  0.000     1 #> 626         14         13   -1 2.694 -0.371 0.711 #> 627          4          8    4 2.694  1.485 0.138 #> 628          6          8    2 2.694  0.742 0.458 #> 629         15          9   -6 2.694 -2.227 0.026 #> 630          2          3    1 2.694  0.371 0.711 #> 631          2          3    1 2.694  0.371 0.711 #> 632          8          6   -2 2.694 -0.742 0.458 #> 633          8          4   -4 2.694 -1.485 0.138 #> 634         12         18    6 2.694  2.227 0.026 #> 635         15         15    0 2.694  0.000     1 #> 636         10         10    0 2.694  0.000     1 #> 637          3          3    0 2.694  0.000     1 #> 638         14         15    1 2.694  0.371 0.711 #> 639          9          6   -3 2.694 -1.113 0.266 #> 640          2          5    3 2.694  1.113 0.266 #> 641         14         17    3 2.694  1.113 0.266 #> 642          4          2   -2 2.694 -0.742 0.458 #> 643         12         13    1 2.694  0.371 0.711 #> 644         10          7   -3 2.694 -1.113 0.266 #> 645          3          4    1 2.694  0.371 0.711 #> 646          4          2   -2 2.694 -0.742 0.458 #> 647          2          6    4 2.694  1.485 0.138 #> 648         11          8   -3 2.694 -1.113 0.266 #> 649         10         10    0 2.694  0.000     1 #> 650         17         17    0 2.694  0.000     1 #> 651          8         10    2 2.694  0.742 0.458 #> 652          8          9    1 2.694  0.371 0.711 #> 653         17         17    0 2.694  0.000     1 #> 654         15         13   -2 2.694 -0.742 0.458 #> 655         14         19    5 2.694  1.856 0.063 #> 656         10         14    4 2.694  1.485 0.138 #> 657         12         13    1 2.694  0.371 0.711 #> 658          7         12    5 2.694  1.856 0.063 #> 659         11         12    1 2.694  0.371 0.711 #> 660         13         10   -3 2.694 -1.113 0.266 #> 661          7          7    0 2.694  0.000     1 #> 662          8          6   -2 2.694 -0.742 0.458 #> 663          7          5   -2 2.694 -0.742 0.458 #> 664         14         10   -4 2.694 -1.485 0.138 #> 665         17         19    2 2.694  0.742 0.458 #> 666          9          6   -3 2.694 -1.113 0.266 #> 667          3          3    0 2.694  0.000     1 #> 668         15         11   -4 2.694 -1.485 0.138 #> 669          7          8    1 2.694  0.371 0.711 #> 670         12         12    0 2.694  0.000     1 #> 671         13         13    0 2.694  0.000     1 #> 672         16         20    4 2.694  1.485 0.138 #> 673         13          9   -4 2.694 -1.485 0.138 #> 674         14         16    2 2.694  0.742 0.458 #> 675          7          2   -5 2.694 -1.856 0.063 #> 676         10          6   -4 2.694 -1.485 0.138 #> 677         10         12    2 2.694  0.742 0.458 #> 678          8          9    1 2.694  0.371 0.711 #> 679          4          7    3 2.694  1.113 0.266 #> 680          2          4    2 2.694  0.742 0.458 #> 681         13         10   -3 2.694 -1.113 0.266 #> 682          5         12    7 2.694  2.598 0.009 #> 683          5          6    1 2.694  0.371 0.711 #> 684         10          7   -3 2.694 -1.113 0.266 #> 685         13         12   -1 2.694 -0.371 0.711 #> 686         17         19    2 2.694  0.742 0.458 #> 687         11         12    1 2.694  0.371 0.711 #> 688          4         10    6 2.694  2.227 0.026 #> 689          6          4   -2 2.694 -0.742 0.458 #> 690          3          5    2 2.694  0.742 0.458 #> 691         11         14    3 2.694  1.113 0.266 #> 692          7          2   -5 2.694 -1.856 0.063 #> 693          8         10    2 2.694  0.742 0.458 #> 694         13         11   -2 2.694 -0.742 0.458 #> 695         13         16    3 2.694  1.113 0.266 #> 696         16         15   -1 2.694 -0.371 0.711 #> 697         16         12   -4 2.694 -1.485 0.138 #> 698          3          3    0 2.694  0.000     1 #> 699         12         15    3 2.694  1.113 0.266 #> 700         12         16    4 2.694  1.485 0.138 #> 701          3          3    0 2.694  0.000     1 #> 702         20         20    0 2.694  0.000     1 #> 703          7         10    3 2.694  1.113 0.266 #> 704          9         13    4 2.694  1.485 0.138 #> 705          5          7    2 2.694  0.742 0.458 #> 706          2          2    0 2.694  0.000     1 #> 707         13         16    3 2.694  1.113 0.266 #> 708          5          7    2 2.694  0.742 0.458 #> 709          8          7   -1 2.694 -0.371 0.711 #> 710         15         18    3 2.694  1.113 0.266 #> 711          3          1   -2 2.694 -0.742 0.458 #> 712          5          5    0 2.694  0.000     1 #> 713          5          3   -2 2.694 -0.742 0.458 #> 714         15         16    1 2.694  0.371 0.711 #> 715         12         10   -2 2.694 -0.742 0.458 #> 716          9          6   -3 2.694 -1.113 0.266 #> 717          5          2   -3 2.694 -1.113 0.266 #> 718          3          4    1 2.694  0.371 0.711 #> 719          2          6    4 2.694  1.485 0.138 #> 720          4          6    2 2.694  0.742 0.458 #> 721         10         12    2 2.694  0.742 0.458 #> 722         16         14   -2 2.694 -0.742 0.458 #> 723          3          2   -1 2.694 -0.371 0.711 #> 724         13          8   -5 2.694 -1.856 0.063 #> 725         17         15   -2 2.694 -0.742 0.458 #> 726          8          8    0 2.694  0.000     1 #> 727          8         10    2 2.694  0.742 0.458 #> 728         16         12   -4 2.694 -1.485 0.138 #> 729         11         15    4 2.694  1.485 0.138 #> 730          4          8    4 2.694  1.485 0.138 #> 731          5          6    1 2.694  0.371 0.711 #> 732          4          3   -1 2.694 -0.371 0.711 #> 733          8          6   -2 2.694 -0.742 0.458 #> 734         18         19    1 2.694  0.371 0.711 #> 735         10         11    1 2.694  0.371 0.711 #> 736         10         12    2 2.694  0.742 0.458 #> 737         18         20    2 2.694  0.742 0.458 #> 738         11          5   -6 2.694 -2.227 0.026 #> 739         17         17    0 2.694  0.000     1 #> 740          3          5    2 2.694  0.742 0.458 #> 741         15         15    0 2.694  0.000     1 #> 742          8          9    1 2.694  0.371 0.711 #> 743          9          5   -4 2.694 -1.485 0.138 #> 744         16         13   -3 2.694 -1.113 0.266 #> 745         14         13   -1 2.694 -0.371 0.711 #> 746          8          6   -2 2.694 -0.742 0.458 #> 747          5          9    4 2.694  1.485 0.138 #> 748          3          1   -2 2.694 -0.742 0.458 #> 749          6          7    1 2.694  0.371 0.711 #> 750         17         13   -4 2.694 -1.485 0.138 #> 751         15         15    0 2.694  0.000     1 #> 752          5          6    1 2.694  0.371 0.711 #> 753          9         11    2 2.694  0.742 0.458 #> 754         16         14   -2 2.694 -0.742 0.458 #> 755         12         12    0 2.694  0.000     1 #> 756         12         14    2 2.694  0.742 0.458 #> 757         14          9   -5 2.694 -1.856 0.063 #> 758         12         15    3 2.694  1.113 0.266 #> 759          1          0   -1 2.694 -0.371 0.711 #> 760         13         17    4 2.694  1.485 0.138 #> 761         17         19    2 2.694  0.742 0.458 #> 762          4          4    0 2.694  0.000     1 #> 763         10          7   -3 2.694 -1.113 0.266 #> 764         15         15    0 2.694  0.000     1 #> 765         10         12    2 2.694  0.742 0.458 #> 766          2          2    0 2.694  0.000     1 #> 767         16         16    0 2.694  0.000     1 #> 768         14         13   -1 2.694 -0.371 0.711 #> 769         15         15    0 2.694  0.000     1 #> 770          7          3   -4 2.694 -1.485 0.138 #> 771          7          3   -4 2.694 -1.485 0.138 #> 772         15         14   -1 2.694 -0.371 0.711 #> 773         11         12    1 2.694  0.371 0.711 #> 774          2          1   -1 2.694 -0.371 0.711 #> 775          3          7    4 2.694  1.485 0.138 #> 776         16         16    0 2.694  0.000     1 #> 777         14          9   -5 2.694 -1.856 0.063 #> 778         14         14    0 2.694  0.000     1 #> 779         14         13   -1 2.694 -0.371 0.711 #> 780         13          9   -4 2.694 -1.485 0.138 #> 781         13         11   -2 2.694 -0.742 0.458 #> 782          5         13    8 2.694  2.969 0.003 #> 783         13         12   -1 2.694 -0.371 0.711 #> 784          8          7   -1 2.694 -0.371 0.711 #> 785         17         16   -1 2.694 -0.371 0.711 #> 786         10         11    1 2.694  0.371 0.711 #> 787         12         10   -2 2.694 -0.742 0.458 #> 788          7          9    2 2.694  0.742 0.458 #> 789          2          2    0 2.694  0.000     1 #> 790          1          3    2 2.694  0.742 0.458 #> 791          3          8    5 2.694  1.856 0.063 #> 792         14         16    2 2.694  0.742 0.458 #> 793          4          7    3 2.694  1.113 0.266 #> 794         15         17    2 2.694  0.742 0.458 #> 795         15         13   -2 2.694 -0.742 0.458 #> 796          7          8    1 2.694  0.371 0.711 #> 797          6          4   -2 2.694 -0.742 0.458 #> 798          7          6   -1 2.694 -0.371 0.711 #> 799         11          8   -3 2.694 -1.113 0.266 #> 800          8         12    4 2.694  1.485 0.138 #> 801          6          3   -3 2.694 -1.113 0.266 #> 802          7          2   -5 2.694 -1.856 0.063 #> 803          9          9    0 2.694  0.000     1 #> 804         17         14   -3 2.694 -1.113 0.266 #> 805          6          7    1 2.694  0.371 0.711 #> 806         14         13   -1 2.694 -0.371 0.711 #> 807          6         13    7 2.694  2.598 0.009 #> 808          7          9    2 2.694  0.742 0.458 #> 809         17         17    0 2.694  0.000     1 #> 810          3          6    3 2.694  1.113 0.266 #> 811         15         18    3 2.694  1.113 0.266 #> 812         10         10    0 2.694  0.000     1 #> 813          7          2   -5 2.694 -1.856 0.063 #> 814         13         14    1 2.694  0.371 0.711 #> 815          8         10    2 2.694  0.742 0.458 #> 816          7          7    0 2.694  0.000     1 #> 817         15          5  -10 2.694 -3.712     0 #> 818         11         11    0 2.694  0.000     1 #> 819          8         14    6 2.694  2.227 0.026 #> 820          7          5   -2 2.694 -0.742 0.458 #> 821         12         12    0 2.694  0.000     1 #> 822         10         13    3 2.694  1.113 0.266 #> 823          3          3    0 2.694  0.000     1 #> 824         17         18    1 2.694  0.371 0.711 #> 825          7          6   -1 2.694 -0.371 0.711 #> 826          5          7    2 2.694  0.742 0.458 #> 827         15         14   -1 2.694 -0.371 0.711 #> 828          3          7    4 2.694  1.485 0.138 #> 829          4          3   -1 2.694 -0.371 0.711 #> 830         20         17   -3 2.694 -1.113 0.266 #> 831          8          5   -3 2.694 -1.113 0.266 #> 832         13         18    5 2.694  1.856 0.063 #> 833         15         15    0 2.694  0.000     1 #> 834         16         17    1 2.694  0.371 0.711 #> 835          6          6    0 2.694  0.000     1 #> 836         16         16    0 2.694  0.000     1 #> 837          9          9    0 2.694  0.000     1 #> 838         10         16    6 2.694  2.227 0.026 #> 839         10         11    1 2.694  0.371 0.711 #> 840         16         17    1 2.694  0.371 0.711 #> 841         15         15    0 2.694  0.000     1 #> 842         13         13    0 2.694  0.000     1 #> 843         15         16    1 2.694  0.371 0.711 #> 844         10          7   -3 2.694 -1.113 0.266 #> 845         12          9   -3 2.694 -1.113 0.266 #> 846         12         12    0 2.694  0.000     1 #> 847          8          7   -1 2.694 -0.371 0.711 #> 848          7          3   -4 2.694 -1.485 0.138 #> 849          5          5    0 2.694  0.000     1 #> 850         19         16   -3 2.694 -1.113 0.266 #> 851         15         15    0 2.694  0.000     1 #> 852         13          8   -5 2.694 -1.856 0.063 #> 853          9         10    1 2.694  0.371 0.711 #> 854          8          8    0 2.694  0.000     1 #> 855          9          9    0 2.694  0.000     1 #> 856         12         13    1 2.694  0.371 0.711 #> 857         10          7   -3 2.694 -1.113 0.266 #> 858         13         10   -3 2.694 -1.113 0.266 #> 859         10          9   -1 2.694 -0.371 0.711 #> 860          5          8    3 2.694  1.113 0.266 #> 861          5          3   -2 2.694 -0.742 0.458 #> 862         13         14    1 2.694  0.371 0.711 #> 863          3          6    3 2.694  1.113 0.266 #> 864          8          4   -4 2.694 -1.485 0.138 #> 865         10         13    3 2.694  1.113 0.266 #> 866         12         12    0 2.694  0.000     1 #> 867          9         10    1 2.694  0.371 0.711 #> 868         11         13    2 2.694  0.742 0.458 #> 869         10          7   -3 2.694 -1.113 0.266 #> 870         13         13    0 2.694  0.000     1 #> 871         14         13   -1 2.694 -0.371 0.711 #> 872          8         10    2 2.694  0.742 0.458 #> 873          1          1    0 2.694  0.000     1 #> 874          7         13    6 2.694  2.227 0.026 #> 875         14         16    2 2.694  0.742 0.458 #> 876          9          8   -1 2.694 -0.371 0.711 #> 877         16         16    0 2.694  0.000     1 #> 878         14         15    1 2.694  0.371 0.711 #> 879          8         10    2 2.694  0.742 0.458 #> 880          6          2   -4 2.694 -1.485 0.138 #> 881          5          2   -3 2.694 -1.113 0.266 #> 882          6         10    4 2.694  1.485 0.138 #> 883         11         11    0 2.694  0.000     1 #> 884          6          5   -1 2.694 -0.371 0.711 #> 885         14         14    0 2.694  0.000     1 #> 886          3          7    4 2.694  1.485 0.138 #> 887          3          9    6 2.694  2.227 0.026 #> 888         10          7   -3 2.694 -1.113 0.266 #> 889          2          6    4 2.694  1.485 0.138 #> 890         15         11   -4 2.694 -1.485 0.138 #> 891         10          6   -4 2.694 -1.485 0.138 #> 892         10         10    0 2.694  0.000     1 #> 893         17         16   -1 2.694 -0.371 0.711 #> 894         11         12    1 2.694  0.371 0.711 #> 895          9         11    2 2.694  0.742 0.458 #> 896         15         13   -2 2.694 -0.742 0.458 #> 897         17         16   -1 2.694 -0.371 0.711 #> 898          7          9    2 2.694  0.742 0.458 #> 899         10          8   -2 2.694 -0.742 0.458 #> 900          6          5   -1 2.694 -0.371 0.711 #> 901          7          6   -1 2.694 -0.371 0.711 #> 902         16         19    3 2.694  1.113 0.266 #> 903         16         19    3 2.694  1.113 0.266 #> 904         12          9   -3 2.694 -1.113 0.266 #> 905          6          7    1 2.694  0.371 0.711 #> 906         19         20    1 2.694  0.371 0.711 #> 907         15         11   -4 2.694 -1.485 0.138 #> 908         10          5   -5 2.694 -1.856 0.063 #> 909          2          0   -2 2.694 -0.742 0.458 #> 910         18         10   -8 2.694 -2.969 0.003 #> 911          2          0   -2 2.694 -0.742 0.458 #> 912         20         17   -3 2.694 -1.113 0.266 #> 913          4          2   -2 2.694 -0.742 0.458 #> 914         16         17    1 2.694  0.371 0.711 #> 915         14         15    1 2.694  0.371 0.711 #> 916         18         13   -5 2.694 -1.856 0.063 #> 917         16         17    1 2.694  0.371 0.711 #> 918         15         18    3 2.694  1.113 0.266 #> 919         13         10   -3 2.694 -1.113 0.266 #> 920         11          8   -3 2.694 -1.113 0.266 #> 921          4          2   -2 2.694 -0.742 0.458 #> 922          6         10    4 2.694  1.485 0.138 #> 923         12         11   -1 2.694 -0.371 0.711 #> 924         18         18    0 2.694  0.000     1 #> 925          5          5    0 2.694  0.000     1 #> 926         19         19    0 2.694  0.000     1 #> 927          7          5   -2 2.694 -0.742 0.458 #> 928          9          3   -6 2.694 -2.227 0.026 #> 929         15         19    4 2.694  1.485 0.138 #> 930         15          9   -6 2.694 -2.227 0.026 #> 931         11         11    0 2.694  0.000     1 #> 932         12         10   -2 2.694 -0.742 0.458 #> 933         12         13    1 2.694  0.371 0.711 #> 934          9          6   -3 2.694 -1.113 0.266 #> 935         14         14    0 2.694  0.000     1 #> 936          6          7    1 2.694  0.371 0.711 #> 937          6          6    0 2.694  0.000     1 #> 938          8         10    2 2.694  0.742 0.458 #> 939          3          2   -1 2.694 -0.371 0.711 #> 940         11         10   -1 2.694 -0.371 0.711 #> 941         12         15    3 2.694  1.113 0.266 #> 942         13         14    1 2.694  0.371 0.711 #> 943         12          8   -4 2.694 -1.485 0.138 #> 944         15         13   -2 2.694 -0.742 0.458 #> 945         11         12    1 2.694  0.371 0.711 #> 946         11         11    0 2.694  0.000     1 #> 947         11         10   -1 2.694 -0.371 0.711 #> 948         10         13    3 2.694  1.113 0.266 #> 949          1          2    1 2.694  0.371 0.711 #> 950          7         12    5 2.694  1.856 0.063 #> 951          8          6   -2 2.694 -0.742 0.458 #> 952         15         12   -3 2.694 -1.113 0.266 #> 953          7          4   -3 2.694 -1.113 0.266 #> 954          2          6    4 2.694  1.485 0.138 #> 955          6          5   -1 2.694 -0.371 0.711 #> 956          3          3    0 2.694  0.000     1 #> 957          5          5    0 2.694  0.000     1 #> 958          6          6    0 2.694  0.000     1 #> 959         13         17    4 2.694  1.485 0.138 #> 960          6          7    1 2.694  0.371 0.711 #> 961          3          2   -1 2.694 -0.371 0.711 #> 962         12         11   -1 2.694 -0.371 0.711 #> 963          6          4   -2 2.694 -0.742 0.458 #> 964         17         12   -5 2.694 -1.856 0.063 #> 965          5          7    2 2.694  0.742 0.458 #> 966         13         16    3 2.694  1.113 0.266 #> 967         15         16    1 2.694  0.371 0.711 #> 968         12          9   -3 2.694 -1.113 0.266 #> 969         15         13   -2 2.694 -0.742 0.458 #> 970         14         16    2 2.694  0.742 0.458 #> 971          6          7    1 2.694  0.371 0.711 #> 972         16         16    0 2.694  0.000     1 #> 973          3          1   -2 2.694 -0.742 0.458 #> 974          5          5    0 2.694  0.000     1 #> 975          7          3   -4 2.694 -1.485 0.138 #> 976         13         13    0 2.694  0.000     1 #> 977         10         12    2 2.694  0.742 0.458 #> 978          2          4    2 2.694  0.742 0.458 #> 979          2          9    7 2.694  2.598 0.009 #> 980         10          9   -1 2.694 -0.371 0.711 #> 981          4          1   -3 2.694 -1.113 0.266 #> 982          7          4   -3 2.694 -1.113 0.266 #> 983         17         12   -5 2.694 -1.856 0.063 #> 984         18         16   -2 2.694 -0.742 0.458 #> 985         16         11   -5 2.694 -1.856 0.063 #> 986          5          3   -2 2.694 -0.742 0.458 #> 987         13         14    1 2.694  0.371 0.711 #> 988         11          8   -3 2.694 -1.113 0.266 #> 989          2         12   10 2.694  3.712     0 #> 990          9         11    2 2.694  0.742 0.458 #> 991         11          6   -5 2.694 -1.856 0.063 #> 992         11         10   -1 2.694 -0.371 0.711 #> 993          8          6   -2 2.694 -0.742 0.458 #> 994          1          4    3 2.694  1.113 0.266 #> 995         10          7   -3 2.694 -1.113 0.266 #> 996         11          5   -6 2.694 -2.227 0.026 #> 997          7          6   -1 2.694 -0.371 0.711 #> 998         10         12    2 2.694  0.742 0.458 #> 999         11          7   -4 2.694 -1.485 0.138 #> 1000         1          2    1 2.694  0.371 0.711  ######  # interactive shiny interfaces for live scoring mod_pre <- mirt(Science) #>   # (optional) setup mod_post to have medium effect size change (d = 0.5) sv <- mod2values(mod_pre) sv$value[sv$name == 'MEAN_1'] <- 0.5 mod_post <- mirt(Science, pars=sv, TOL=NA)  # only use pre-test model for scoring if(interactive()){     RCI(mod_pre=mod_pre, shiny=TRUE)      # use both pre-test and post-test models for including empirical priors     RCI(mod_pre=mod_pre, mod_post=mod_post, shiny=TRUE,         main='Perceptions of Science and Technology')  }   ############################ # Example where individuals take completely different item set pre-post #   but prior calibration has been performed to equate the items  dat <- key2binary(SAT12,   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  mod <- mirt(dat) #>   # with N=5 individuals under investigation predat <- postdat <- dat[1:5,] predat[, 17:32] <- NA postdat[, 1:16] <- NA  head(predat) #>      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> [1,]      1      1      1      1      1      1      1      1      1       1 #> [2,]      0      1      0      0      1      0      1      0      1       1 #> [3,]      1      1      1      0      1      0      1      0      1       0 #> [4,]      0      1      0      1      1      0      1      0      1       0 #> [5,]      0      1      1      1      1      0      1      1      0       0 #>      Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> [1,]       1       1       1       1       1       1      NA      NA      NA #> [2,]       1       0       1       1       1       0      NA      NA      NA #> [3,]       1       0       0       1       1       0      NA      NA      NA #> [4,]       1       1       1       1       1       0      NA      NA      NA #> [5,]       1       1       1       1       1       0      NA      NA      NA #>      Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> [1,]      NA      NA      NA      NA      NA      NA      NA      NA      NA #> [2,]      NA      NA      NA      NA      NA      NA      NA      NA      NA #> [3,]      NA      NA      NA      NA      NA      NA      NA      NA      NA #> [4,]      NA      NA      NA      NA      NA      NA      NA      NA      NA #> [5,]      NA      NA      NA      NA      NA      NA      NA      NA      NA #>      Item.29 Item.30 Item.31 Item.32 #> [1,]      NA      NA      NA      NA #> [2,]      NA      NA      NA      NA #> [3,]      NA      NA      NA      NA #> [4,]      NA      NA      NA      NA #> [5,]      NA      NA      NA      NA head(postdat) #>      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> [1,]     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> [2,]     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> [3,]     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> [4,]     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #> [5,]     NA     NA     NA     NA     NA     NA     NA     NA     NA      NA #>      Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> [1,]      NA      NA      NA      NA      NA      NA       1       1       1 #> [2,]      NA      NA      NA      NA      NA      NA       1       0       1 #> [3,]      NA      NA      NA      NA      NA      NA       1       0       0 #> [4,]      NA      NA      NA      NA      NA      NA       1       0       0 #> [5,]      NA      NA      NA      NA      NA      NA       1       0       1 #>      Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       1       1       0       1       0       0       1       0 #> [3,]       1       1       1       0       1       1       0       1       1 #> [4,]       1       1       0       0       0       0       0       1       1 #> [5,]       1       1       1       0       1       0       1       1       1 #>      Item.29 Item.30 Item.31 Item.32 #> [1,]       1       1       1       1 #> [2,]       0       0       1       0 #> [3,]       0       0       1       0 #> [4,]       0       0       1       0 #> [5,]       1       0       1       0  RCI(mod, predat, postdat) #>   pre.score post.score converged   diff    SE      z     p #> 1     2.206      1.808      TRUE -0.398 0.951 -0.419 0.675 #> 2     0.373     -0.344      TRUE -0.717 0.720 -0.995  0.32 #> 3     0.303     -0.115      TRUE -0.419 0.728 -0.575 0.566 #> 4     0.295     -0.864      TRUE -1.159 0.699 -1.658 0.097 #> 5     0.670      0.513      TRUE -0.157 0.772 -0.203 0.839  ###### # Two-dimensional IRT model for each time point, 20 items (no DIF)  J <- 20 N <- 500 slopes <- rlnorm(J, .2, .2) a <- matrix(c(slopes, numeric(J*2), slopes),J*2) ints <- rnorm(J) d <- matrix(c(ints, ints), ncol=1) data.frame(a=a, d=d) #>          a.1       a.2           d #> 1  1.1552393 0.0000000 -0.63265649 #> 2  0.7725387 0.0000000 -0.23498495 #> 3  1.1911807 0.0000000 -0.23365145 #> 4  1.5201541 0.0000000 -0.09858223 #> 5  1.1752077 0.0000000  0.83519448 #> 6  1.0858223 0.0000000 -0.43051228 #> 7  1.6628731 0.0000000  0.41443651 #> 8  1.1012075 0.0000000  1.41245283 #> 9  1.0354140 0.0000000  0.84976955 #> 10 1.3580607 0.0000000  0.17070288 #> 11 0.9164153 0.0000000 -0.24230045 #> 12 1.1904205 0.0000000 -1.66708924 #> 13 1.5486689 0.0000000 -1.74009514 #> 14 1.1839185 0.0000000  0.84319987 #> 15 1.2910372 0.0000000 -1.96094872 #> 16 1.3247273 0.0000000 -0.33889244 #> 17 1.3673442 0.0000000  1.84475886 #> 18 1.2868859 0.0000000  0.51631728 #> 19 0.9999844 0.0000000 -0.73065644 #> 20 1.1269914 0.0000000  1.68359583 #> 21 0.0000000 1.1552393 -0.63265649 #> 22 0.0000000 0.7725387 -0.23498495 #> 23 0.0000000 1.1911807 -0.23365145 #> 24 0.0000000 1.5201541 -0.09858223 #> 25 0.0000000 1.1752077  0.83519448 #> 26 0.0000000 1.0858223 -0.43051228 #> 27 0.0000000 1.6628731  0.41443651 #> 28 0.0000000 1.1012075  1.41245283 #> 29 0.0000000 1.0354140  0.84976955 #> 30 0.0000000 1.3580607  0.17070288 #> 31 0.0000000 0.9164153 -0.24230045 #> 32 0.0000000 1.1904205 -1.66708924 #> 33 0.0000000 1.5486689 -1.74009514 #> 34 0.0000000 1.1839185  0.84319987 #> 35 0.0000000 1.2910372 -1.96094872 #> 36 0.0000000 1.3247273 -0.33889244 #> 37 0.0000000 1.3673442  1.84475886 #> 38 0.0000000 1.2868859  0.51631728 #> 39 0.0000000 0.9999844 -0.73065644 #> 40 0.0000000 1.1269914  1.68359583  # mean effects across time mu <- c(0, -1/2) sigma <- matrix(c(1, .7, .7, 1), 2,2)  dat <- simdata(a, d, N, mu=mu, sigma=sigma, itemtype = '2PL')  # build equality constraints across time points constr <- NULL for(i in (1:J)){     constr <- c(constr, paste0(\"(\", i, ',', i+J, \",a1,a2)\"))     constr <- c(constr, paste0(\"(\", i, ',', i+J, \",d)\")) } constr <- paste0(constr, collapse=',')  # define model where item parameters constrained over time, and # latent trait has potential scale-location changes (e.g., regression to the # mean effects) model <- sprintf(\"                   thetapre = 1-%i,                   thetapost = %i-%i,                   COV = thetapre*thetapost, thetapost*thetapost                   MEAN = thetapost                   CONSTRAIN = %s\", J, J+1, 2*J, constr) cat(model) #>  #>                   thetapre = 1-20, #>                   thetapost = 21-40, #>                   COV = thetapre*thetapost, thetapost*thetapost #>                   MEAN = thetapost #>                   CONSTRAIN = (1,21,a1,a2),(1,21,d),(2,22,a1,a2),(2,22,d),(3,23,a1,a2),(3,23,d),(4,24,a1,a2),(4,24,d),(5,25,a1,a2),(5,25,d),(6,26,a1,a2),(6,26,d),(7,27,a1,a2),(7,27,d),(8,28,a1,a2),(8,28,d),(9,29,a1,a2),(9,29,d),(10,30,a1,a2),(10,30,d),(11,31,a1,a2),(11,31,d),(12,32,a1,a2),(12,32,d),(13,33,a1,a2),(13,33,d),(14,34,a1,a2),(14,34,d),(15,35,a1,a2),(15,35,d),(16,36,a1,a2),(16,36,d),(17,37,a1,a2),(17,37,d),(18,38,a1,a2),(18,38,d),(19,39,a1,a2),(19,39,d),(20,40,a1,a2),(20,40,d)  # fit the model to calibration data mod <- mirt(dat, model = model, SE=TRUE) #>  #>  #> Calculating information matrix... coef(mod, printSE=TRUE) #> $Item_1 #>        a1 a2      d logit(g) logit(u) #> par 1.252  0 -0.639     -999      999 #> SE  0.117 NA  0.097       NA       NA #>  #> $Item_2 #>        a1 a2      d logit(g) logit(u) #> par 0.702  0 -0.268     -999      999 #> SE  0.084 NA  0.077       NA       NA #>  #> $Item_3 #>        a1 a2      d logit(g) logit(u) #> par 1.210  0 -0.210     -999      999 #> SE  0.112 NA  0.094       NA       NA #>  #> $Item_4 #>        a1 a2      d logit(g) logit(u) #> par 1.608  0 -0.178     -999      999 #> SE  0.140 NA  0.110       NA       NA #>  #> $Item_5 #>        a1 a2     d logit(g) logit(u) #> par 1.237  0 0.770     -999      999 #> SE  0.116 NA 0.103       NA       NA #>  #> $Item_6 #>        a1 a2      d logit(g) logit(u) #> par 1.296  0 -0.445     -999      999 #> SE  0.118 NA  0.097       NA       NA #>  #> $Item_7 #>        a1 a2     d logit(g) logit(u) #> par 1.856  0 0.377     -999      999 #> SE  0.161 NA 0.124       NA       NA #>  #> $Item_8 #>        a1 a2     d logit(g) logit(u) #> par 1.125  0 1.368     -999      999 #> SE  0.115 NA 0.113       NA       NA #>  #> $Item_9 #>        a1 a2     d logit(g) logit(u) #> par 0.961  0 0.717     -999      999 #> SE  0.099 NA 0.092       NA       NA #>  #> $Item_10 #>        a1 a2     d logit(g) logit(u) #> par 1.517  0 0.150     -999      999 #> SE  0.133 NA 0.107       NA       NA #>  #> $Item_11 #>        a1 a2      d logit(g) logit(u) #> par 0.855  0 -0.271     -999      999 #> SE  0.092 NA  0.081       NA       NA #>  #> $Item_12 #>        a1 a2      d logit(g) logit(u) #> par 1.056  0 -1.475     -999      999 #> SE  0.115 NA  0.104       NA       NA #>  #> $Item_13 #>        a1 a2      d logit(g) logit(u) #> par 1.745  0 -2.061     -999      999 #> SE  0.173 NA  0.157       NA       NA #>  #> $Item_14 #>        a1 a2     d logit(g) logit(u) #> par 1.333  0 0.860     -999      999 #> SE  0.123 NA 0.109       NA       NA #>  #> $Item_15 #>        a1 a2      d logit(g) logit(u) #> par 1.488  0 -2.028     -999      999 #> SE  0.153 NA  0.142       NA       NA #>  #> $Item_16 #>        a1 a2      d logit(g) logit(u) #> par 1.409  0 -0.359     -999      999 #> SE  0.125 NA  0.102       NA       NA #>  #> $Item_17 #>        a1 a2     d logit(g) logit(u) #> par 1.378  0 1.715     -999      999 #> SE  0.136 NA 0.135       NA       NA #>  #> $Item_18 #>        a1 a2     d logit(g) logit(u) #> par 1.202  0 0.321     -999      999 #> SE  0.111 NA 0.096       NA       NA #>  #> $Item_19 #>        a1 a2      d logit(g) logit(u) #> par 1.061  0 -0.807     -999      999 #> SE  0.106 NA  0.092       NA       NA #>  #> $Item_20 #>        a1 a2     d logit(g) logit(u) #> par 1.146  0 1.724     -999      999 #> SE  0.121 NA 0.126       NA       NA #>  #> $Item_21 #>     a1    a2      d logit(g) logit(u) #> par  0 1.252 -0.639     -999      999 #> SE  NA 0.117  0.097       NA       NA #>  #> $Item_22 #>     a1    a2      d logit(g) logit(u) #> par  0 0.702 -0.268     -999      999 #> SE  NA 0.084  0.077       NA       NA #>  #> $Item_23 #>     a1    a2      d logit(g) logit(u) #> par  0 1.210 -0.210     -999      999 #> SE  NA 0.112  0.094       NA       NA #>  #> $Item_24 #>     a1    a2      d logit(g) logit(u) #> par  0 1.608 -0.178     -999      999 #> SE  NA 0.140  0.110       NA       NA #>  #> $Item_25 #>     a1    a2     d logit(g) logit(u) #> par  0 1.237 0.770     -999      999 #> SE  NA 0.116 0.103       NA       NA #>  #> $Item_26 #>     a1    a2      d logit(g) logit(u) #> par  0 1.296 -0.445     -999      999 #> SE  NA 0.118  0.097       NA       NA #>  #> $Item_27 #>     a1    a2     d logit(g) logit(u) #> par  0 1.856 0.377     -999      999 #> SE  NA 0.161 0.124       NA       NA #>  #> $Item_28 #>     a1    a2     d logit(g) logit(u) #> par  0 1.125 1.368     -999      999 #> SE  NA 0.115 0.113       NA       NA #>  #> $Item_29 #>     a1    a2     d logit(g) logit(u) #> par  0 0.961 0.717     -999      999 #> SE  NA 0.099 0.092       NA       NA #>  #> $Item_30 #>     a1    a2     d logit(g) logit(u) #> par  0 1.517 0.150     -999      999 #> SE  NA 0.133 0.107       NA       NA #>  #> $Item_31 #>     a1    a2      d logit(g) logit(u) #> par  0 0.855 -0.271     -999      999 #> SE  NA 0.092  0.081       NA       NA #>  #> $Item_32 #>     a1    a2      d logit(g) logit(u) #> par  0 1.056 -1.475     -999      999 #> SE  NA 0.115  0.104       NA       NA #>  #> $Item_33 #>     a1    a2      d logit(g) logit(u) #> par  0 1.745 -2.061     -999      999 #> SE  NA 0.173  0.157       NA       NA #>  #> $Item_34 #>     a1    a2     d logit(g) logit(u) #> par  0 1.333 0.860     -999      999 #> SE  NA 0.123 0.109       NA       NA #>  #> $Item_35 #>     a1    a2      d logit(g) logit(u) #> par  0 1.488 -2.028     -999      999 #> SE  NA 0.153  0.142       NA       NA #>  #> $Item_36 #>     a1    a2      d logit(g) logit(u) #> par  0 1.409 -0.359     -999      999 #> SE  NA 0.125  0.102       NA       NA #>  #> $Item_37 #>     a1    a2     d logit(g) logit(u) #> par  0 1.378 1.715     -999      999 #> SE  NA 0.136 0.135       NA       NA #>  #> $Item_38 #>     a1    a2     d logit(g) logit(u) #> par  0 1.202 0.321     -999      999 #> SE  NA 0.111 0.096       NA       NA #>  #> $Item_39 #>     a1    a2      d logit(g) logit(u) #> par  0 1.061 -0.807     -999      999 #> SE  NA 0.106  0.092       NA       NA #>  #> $Item_40 #>     a1    a2     d logit(g) logit(u) #> par  0 1.146 1.724     -999      999 #> SE  NA 0.121 0.126       NA       NA #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0 -0.519      1  0.691  0.971 #> SE      NA  0.049     NA  0.047  0.096 #>  coef(mod, simplify=TRUE) #> $items #>            a1    a2      d g u #> Item_1  1.252 0.000 -0.639 0 1 #> Item_2  0.702 0.000 -0.268 0 1 #> Item_3  1.210 0.000 -0.210 0 1 #> Item_4  1.608 0.000 -0.178 0 1 #> Item_5  1.237 0.000  0.770 0 1 #> Item_6  1.296 0.000 -0.445 0 1 #> Item_7  1.856 0.000  0.377 0 1 #> Item_8  1.125 0.000  1.368 0 1 #> Item_9  0.961 0.000  0.717 0 1 #> Item_10 1.517 0.000  0.150 0 1 #> Item_11 0.855 0.000 -0.271 0 1 #> Item_12 1.056 0.000 -1.475 0 1 #> Item_13 1.745 0.000 -2.061 0 1 #> Item_14 1.333 0.000  0.860 0 1 #> Item_15 1.488 0.000 -2.028 0 1 #> Item_16 1.409 0.000 -0.359 0 1 #> Item_17 1.378 0.000  1.715 0 1 #> Item_18 1.202 0.000  0.321 0 1 #> Item_19 1.061 0.000 -0.807 0 1 #> Item_20 1.146 0.000  1.724 0 1 #> Item_21 0.000 1.252 -0.639 0 1 #> Item_22 0.000 0.702 -0.268 0 1 #> Item_23 0.000 1.210 -0.210 0 1 #> Item_24 0.000 1.608 -0.178 0 1 #> Item_25 0.000 1.237  0.770 0 1 #> Item_26 0.000 1.296 -0.445 0 1 #> Item_27 0.000 1.856  0.377 0 1 #> Item_28 0.000 1.125  1.368 0 1 #> Item_29 0.000 0.961  0.717 0 1 #> Item_30 0.000 1.517  0.150 0 1 #> Item_31 0.000 0.855 -0.271 0 1 #> Item_32 0.000 1.056 -1.475 0 1 #> Item_33 0.000 1.745 -2.061 0 1 #> Item_34 0.000 1.333  0.860 0 1 #> Item_35 0.000 1.488 -2.028 0 1 #> Item_36 0.000 1.409 -0.359 0 1 #> Item_37 0.000 1.378  1.715 0 1 #> Item_38 0.000 1.202  0.321 0 1 #> Item_39 0.000 1.061 -0.807 0 1 #> Item_40 0.000 1.146  1.724 0 1 #>  #> $means #>  thetapre thetapost  #>     0.000    -0.519  #>  #> $cov #>           thetapre thetapost #> thetapre     1.000     0.691 #> thetapost    0.691     0.971 #>  summary(mod) #>         thetapre thetapost    h2 #> Item_1     0.592           0.351 #> Item_2     0.381           0.145 #> Item_3     0.579           0.336 #> Item_4     0.687           0.472 #> Item_5     0.588           0.346 #> Item_6     0.606           0.367 #> Item_7     0.737           0.543 #> Item_8     0.551           0.304 #> Item_9     0.492           0.242 #> Item_10    0.665           0.443 #> Item_11    0.449           0.202 #> Item_12    0.527           0.278 #> Item_13    0.716           0.512 #> Item_14    0.617           0.380 #> Item_15    0.658           0.433 #> Item_16    0.638           0.407 #> Item_17    0.629           0.396 #> Item_18    0.577           0.333 #> Item_19    0.529           0.280 #> Item_20    0.558           0.312 #> Item_21              0.587 0.344 #> Item_22              0.377 0.142 #> Item_23              0.574 0.329 #> Item_24              0.682 0.465 #> Item_25              0.582 0.339 #> Item_26              0.600 0.360 #> Item_27              0.732 0.536 #> Item_28              0.546 0.298 #> Item_29              0.486 0.236 #> Item_30              0.660 0.435 #> Item_31              0.444 0.197 #> Item_32              0.522 0.272 #> Item_33              0.711 0.505 #> Item_34              0.611 0.374 #> Item_35              0.653 0.426 #> Item_36              0.632 0.400 #> Item_37              0.624 0.389 #> Item_38              0.571 0.326 #> Item_39              0.524 0.274 #> Item_40              0.553 0.306 #>  #>         SE.thetapre SE.thetapost #> Item_1        0.036              #> Item_2        0.039              #> Item_3        0.036              #> Item_4        0.032              #> Item_5        0.036              #> Item_6        0.035              #> Item_7        0.029              #> Item_8        0.039              #> Item_9        0.038              #> Item_10       0.033              #> Item_11       0.039              #> Item_12       0.041              #> Item_13       0.035              #> Item_14       0.035              #> Item_15       0.038              #> Item_16       0.034              #> Item_17       0.037              #> Item_18       0.036              #> Item_19       0.038              #> Item_20       0.041              #> Item_21                    0.036 #> Item_22                    0.039 #> Item_23                    0.036 #> Item_24                    0.032 #> Item_25                    0.036 #> Item_26                    0.035 #> Item_27                    0.029 #> Item_28                    0.039 #> Item_29                    0.038 #> Item_30                    0.033 #> Item_31                    0.038 #> Item_32                    0.041 #> Item_33                    0.035 #> Item_34                    0.035 #> Item_35                    0.038 #> Item_36                    0.034 #> Item_37                    0.038 #> Item_38                    0.036 #> Item_39                    0.038 #> Item_40                    0.041 #>  #> SS loadings:  7.081 6.954  #> Proportion Var:  0.177 0.174  #>  #> Factor correlations:  #>  #>           thetapre thetapost #> thetapre     1.000           #> thetapost    0.701         1  # test data Theta <- cbind(c(0, 1, 2), c(0,1,2)) nochange <- simdata(a, d, itemtype = '2PL', Theta = Theta) change <- simdata(a, d, itemtype = '2PL', Theta = Theta +                       cbind(0, c(-1, -1, -1)))  # total score differences data.frame(pre=rowSums(nochange[,1:J]),            post=rowSums(nochange[,1:J + J])) #>   pre post #> 1  10    8 #> 2  12   15 #> 3  18   18 data.frame(pre=rowSums(change[,1:J]),            post=rowSums(change[,1:J + J])) #>   pre post #> 1  12    5 #> 2  14   10 #> 3  19   17   RCI(mod, predat = nochange) #>   pre.score post.score converged   diff    SE      z     p #> 1    -0.052     -0.483      TRUE -0.431 0.524 -0.822 0.411 #> 2     0.412      0.943      TRUE  0.531 0.542  0.978 0.328 #> 3     1.673      1.367      TRUE -0.306 0.641 -0.478 0.633 RCI(mod, predat = change) #>   pre.score post.score converged   diff    SE      z     p #> 1     0.215     -1.063      TRUE -1.278 0.554 -2.305 0.021 #> 2     0.871     -0.080      TRUE -0.951 0.536 -1.776 0.076 #> 3     1.867      1.210      TRUE -0.657 0.651 -1.009 0.313  # }"},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":null,"dir":"Reference","previous_headings":"","what":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"function computes set RMSD \"badness--fit\" statistics investing DIF across set grouping variables. first step, (potentially highly constrained) multiple group model fitted, second step item (person) parameters estimated based examines across groups. Category level DIF assessed based well pseudo-table counts match (constrained) probability functions implied original multiple group model (also weighing across implied density function latent traits). RSMD fit poor, indicating non-ignorable DIF, multiple-group model adjusted better account large response bias due using pooled model. See Lee von Davier (2020) Buchholz Hartig (2019) details.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"","code":"RMSD_DIF(pooled_mod, flag = 0, probfun = TRUE, dentype = \"norm\")"},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"pooled_mod multiple-group model (used compute model-implied probability goodness--fit test) single-group model computing RMSD goodness--fit values relative model-implied information flag numeric value used cut-help flag larger RMSD values (e.g., flag = .03 highlight categories RMSD values greater .03) probfun logical; use probability functions compute RMSD? FALSE, expected score functions integrated instead, may useful collapsing across categories polytomous items dentype density use latent trait. Can 'norm' use normal Gaussian density mean/variance extracted model object(default), 'snorm' standard normal distribution, 'empirical' use density estimate obtained via E-table","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"function generally designed work multiple-group models, however single-group model passed return RMSD information regarding observed vs expected response functions.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"Buchholz, J., Hartig, J. (2019). Comparing Attitudes Across Groups: IRT-Based Item-Fit Statistic   Analysis Measurement Invariance. Applied Psychological Measurement, 43(3), 241-250.   doi:10.1177/0146621617748323 Lee, S. S., von Davier, M. (2020). Improving measurement properties PISA home   possessions scale partial invariance modeling.   Psychological test assessment modeling, 62(1):55-83.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/RMSD_DIF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RMSD effect size statistic to quantify category-level DIF — RMSD_DIF","text":"","code":"# \\donttest{  #----- generate some data set.seed(12345) a <- a2 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- d2 <- matrix(rnorm(15,0,.7),ncol=1)  # item 1 has DIF d2[1] <- d[1] - .5 a2[1] <- a[1] + 1  itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  #-----  # fully pooled model pooled_mod <- multipleGroup(dat, 1, group=group,    invariance = c(colnames(dat), 'free_mean', 'free_var')) #>  coef(pooled_mod, simplify=TRUE) #> $D1 #> $items #>            a1      d g u #> Item_1  1.440  0.358 0 1 #> Item_2  1.136 -0.590 0 1 #> Item_3  0.996 -0.237 0 1 #> Item_4  0.902  0.921 0 1 #> Item_5  1.060  0.153 0 1 #> Item_6  0.440  0.637 0 1 #> Item_7  1.170  1.023 0 1 #> Item_8  0.904 -0.353 0 1 #> Item_9  0.875 -0.978 0 1 #> Item_10 0.665 -1.120 0 1 #> Item_11 0.939  1.243 0 1 #> Item_12 1.336 -0.194 0 1 #> Item_13 1.249  0.481 0 1 #> Item_14 1.050  0.444 0 1 #> Item_15 0.778 -0.064 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1      d g u #> Item_1  1.440  0.358 0 1 #> Item_2  1.136 -0.590 0 1 #> Item_3  0.996 -0.237 0 1 #> Item_4  0.902  0.921 0 1 #> Item_5  1.060  0.153 0 1 #> Item_6  0.440  0.637 0 1 #> Item_7  1.170  1.023 0 1 #> Item_8  0.904 -0.353 0 1 #> Item_9  0.875 -0.978 0 1 #> Item_10 0.665 -1.120 0 1 #> Item_11 0.939  1.243 0 1 #> Item_12 1.336 -0.194 0 1 #> Item_13 1.249  0.481 0 1 #> Item_14 1.050  0.444 0 1 #> Item_15 0.778 -0.064 0 1 #>  #> $means #>    F1  #> -0.08  #>  #> $cov #>       F1 #> F1 1.167 #>  #>   RMSD_DIF(pooled_mod) #>  #>  #> $D1 #>           P.0   P.1 #> Item_1  0.056 0.056 #> Item_2  0.018 0.018 #> Item_3  0.014 0.014 #> Item_4  0.019 0.019 #> Item_5  0.010 0.010 #> Item_6  0.021 0.021 #> Item_7  0.016 0.016 #> Item_8  0.017 0.017 #> Item_9  0.019 0.019 #> Item_10 0.018 0.018 #> Item_11 0.013 0.013 #> Item_12 0.014 0.014 #> Item_13 0.018 0.018 #> Item_14 0.009 0.009 #> Item_15 0.011 0.011 #>  #> $D2 #>           P.0   P.1 #> Item_1  0.053 0.053 #> Item_2  0.021 0.021 #> Item_3  0.013 0.013 #> Item_4  0.016 0.016 #> Item_5  0.008 0.008 #> Item_6  0.022 0.022 #> Item_7  0.017 0.017 #> Item_8  0.016 0.016 #> Item_9  0.017 0.017 #> Item_10 0.014 0.014 #> Item_11 0.021 0.021 #> Item_12 0.013 0.013 #> Item_13 0.011 0.011 #> Item_14 0.004 0.004 #> Item_15 0.014 0.014 #>  RMSD_DIF(pooled_mod, dentype = 'empirical') #>  #>  #> $D1 #>           P.0   P.1 #> Item_1  0.056 0.056 #> Item_2  0.018 0.018 #> Item_3  0.014 0.014 #> Item_4  0.019 0.019 #> Item_5  0.010 0.010 #> Item_6  0.021 0.021 #> Item_7  0.016 0.016 #> Item_8  0.017 0.017 #> Item_9  0.019 0.019 #> Item_10 0.018 0.018 #> Item_11 0.013 0.013 #> Item_12 0.014 0.014 #> Item_13 0.018 0.018 #> Item_14 0.009 0.009 #> Item_15 0.011 0.011 #>  #> $D2 #>           P.0   P.1 #> Item_1  0.052 0.052 #> Item_2  0.021 0.021 #> Item_3  0.013 0.013 #> Item_4  0.016 0.016 #> Item_5  0.009 0.009 #> Item_6  0.022 0.022 #> Item_7  0.017 0.017 #> Item_8  0.016 0.016 #> Item_9  0.017 0.017 #> Item_10 0.014 0.014 #> Item_11 0.021 0.021 #> Item_12 0.013 0.013 #> Item_13 0.011 0.011 #> Item_14 0.004 0.004 #> Item_15 0.014 0.014 #>  RMSD_DIF(pooled_mod, flag = .03) #>  #>  #> $D1 #>           P.0   P.1 #> Item_1  0.056 0.056 #> Item_2     NA    NA #> Item_3     NA    NA #> Item_4     NA    NA #> Item_5     NA    NA #> Item_6     NA    NA #> Item_7     NA    NA #> Item_8     NA    NA #> Item_9     NA    NA #> Item_10    NA    NA #> Item_11    NA    NA #> Item_12    NA    NA #> Item_13    NA    NA #> Item_14    NA    NA #> Item_15    NA    NA #>  #> $D2 #>           P.0   P.1 #> Item_1  0.053 0.053 #> Item_2     NA    NA #> Item_3     NA    NA #> Item_4     NA    NA #> Item_5     NA    NA #> Item_6     NA    NA #> Item_7     NA    NA #> Item_8     NA    NA #> Item_9     NA    NA #> Item_10    NA    NA #> Item_11    NA    NA #> Item_12    NA    NA #> Item_13    NA    NA #> Item_14    NA    NA #> Item_15    NA    NA #>   # more freely estimated model (item 1 has 2 parameters estimated) MGmod <- multipleGroup(dat, 1, group=group,                        invariance = c(colnames(dat)[-1], 'free_mean', 'free_var')) #>  coef(MGmod, simplify=TRUE) #> $D1 #> $items #>            a1      d g u #> Item_1  1.071  0.525 0 1 #> Item_2  1.178 -0.615 0 1 #> Item_3  1.031 -0.258 0 1 #> Item_4  0.933  0.902 0 1 #> Item_5  1.099  0.130 0 1 #> Item_6  0.455  0.627 0 1 #> Item_7  1.217  1.001 0 1 #> Item_8  0.926 -0.372 0 1 #> Item_9  0.905 -0.997 0 1 #> Item_10 0.692 -1.136 0 1 #> Item_11 0.967  1.222 0 1 #> Item_12 1.373 -0.222 0 1 #> Item_13 1.302  0.456 0 1 #> Item_14 1.079  0.421 0 1 #> Item_15 0.804 -0.080 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1      d g u #> Item_1  2.100  0.083 0 1 #> Item_2  1.178 -0.615 0 1 #> Item_3  1.031 -0.258 0 1 #> Item_4  0.933  0.902 0 1 #> Item_5  1.099  0.130 0 1 #> Item_6  0.455  0.627 0 1 #> Item_7  1.217  1.001 0 1 #> Item_8  0.926 -0.372 0 1 #> Item_9  0.905 -0.997 0 1 #> Item_10 0.692 -1.136 0 1 #> Item_11 0.967  1.222 0 1 #> Item_12 1.373 -0.222 0 1 #> Item_13 1.302  0.456 0 1 #> Item_14 1.079  0.421 0 1 #> Item_15 0.804 -0.080 0 1 #>  #> $means #>     F1  #> -0.036  #>  #> $cov #>       F1 #> F1 1.033 #>  #>   # RMSD in item.1 now reduced (MG model accounts for DIF) RMSD_DIF(MGmod) #>  #>  #> $D1 #>           P.0   P.1 #> Item_1  0.007 0.007 #> Item_2  0.015 0.015 #> Item_3  0.017 0.017 #> Item_4  0.015 0.015 #> Item_5  0.009 0.009 #> Item_6  0.020 0.020 #> Item_7  0.010 0.010 #> Item_8  0.020 0.020 #> Item_9  0.017 0.017 #> Item_10 0.018 0.018 #> Item_11 0.017 0.017 #> Item_12 0.010 0.010 #> Item_13 0.017 0.017 #> Item_14 0.013 0.013 #> Item_15 0.011 0.011 #>  #> $D2 #>           P.0   P.1 #> Item_1  0.005 0.005 #> Item_2  0.020 0.020 #> Item_3  0.018 0.018 #> Item_4  0.011 0.011 #> Item_5  0.007 0.007 #> Item_6  0.022 0.022 #> Item_7  0.011 0.011 #> Item_8  0.017 0.017 #> Item_9  0.016 0.016 #> Item_10 0.016 0.016 #> Item_11 0.022 0.022 #> Item_12 0.008 0.008 #> Item_13 0.006 0.006 #> Item_14 0.009 0.009 #> Item_15 0.014 0.014 #>  RMSD_DIF(MGmod, flag = .03) #>  #>  #> $D1 #>         P.0 P.1 #> Item_1   NA  NA #> Item_2   NA  NA #> Item_3   NA  NA #> Item_4   NA  NA #> Item_5   NA  NA #> Item_6   NA  NA #> Item_7   NA  NA #> Item_8   NA  NA #> Item_9   NA  NA #> Item_10  NA  NA #> Item_11  NA  NA #> Item_12  NA  NA #> Item_13  NA  NA #> Item_14  NA  NA #> Item_15  NA  NA #>  #> $D2 #>         P.0 P.1 #> Item_1   NA  NA #> Item_2   NA  NA #> Item_3   NA  NA #> Item_4   NA  NA #> Item_5   NA  NA #> Item_6   NA  NA #> Item_7   NA  NA #> Item_8   NA  NA #> Item_9   NA  NA #> Item_10  NA  NA #> Item_11  NA  NA #> Item_12  NA  NA #> Item_13  NA  NA #> Item_14  NA  NA #> Item_15  NA  NA #>   ################# # NA placeholders included when groups do not respond to specific items  a1 <- a2 <- rlnorm(20) d <- d2 <- rnorm(20) # item 5 contains DIF a2[5] <- a1[5] + 1 d2[5] <- d[5] - 1/2 g <- rbeta(20, 5, 17)  dat1 <- simdata(a1, d, guess = g, N=1000, itemtype = '3PL') dat1[, 11:13] <- NA  # items 11:13 items NA for g1 dat2 <- simdata(a2, d2, guess = g, N=1000, itemtype = '3PL',    mu=1/4, sigma=matrix(.75)) dat2[,1:3] <- NA # items 1:3 items NA for g2 dat <- rbind(dat1, dat2) group <- c(rep('g1', 1000), rep('g2', 1000))  mod <- multipleGroup(dat, \"Theta = 1-20                             PRIOR = (1-20, g, norm, -1, 0.5)\",                      group=group, itemtype='3PL',                      invariance = c(colnames(dat), 'free_mean', 'free_var')) #>  coef(mod, simplify = TRUE) #> $g1 #> $items #>             a1      d     g u #> Item_1   0.958  0.962 0.281 1 #> Item_2   0.476 -1.243 0.223 1 #> Item_3   1.459 -1.321 0.331 1 #> Item_4   1.685  0.851 0.227 1 #> Item_5   3.014 -0.148 0.264 1 #> Item_6   0.436 -1.155 0.254 1 #> Item_7   2.134 -2.246 0.145 1 #> Item_8   0.532  0.633 0.262 1 #> Item_9   1.011  0.449 0.258 1 #> Item_10  2.458 -0.681 0.176 1 #> Item_11  1.398 -0.124 0.252 1 #> Item_12  0.180  0.329 0.269 1 #> Item_13  0.809  0.736 0.292 1 #> Item_14  0.674  0.518 0.270 1 #> Item_15  2.931 -1.035 0.280 1 #> Item_16  0.418  0.595 0.256 1 #> Item_17  0.413 -0.241 0.253 1 #> Item_18  2.136  0.899 0.287 1 #> Item_19 -0.208 -2.328 0.277 1 #> Item_20  0.538 -0.132 0.262 1 #>  #> $means #> Theta  #>     0  #>  #> $cov #>       Theta #> Theta     1 #>  #>  #> $g2 #> $items #>             a1      d     g u #> Item_1   0.958  0.962 0.281 1 #> Item_2   0.476 -1.243 0.223 1 #> Item_3   1.459 -1.321 0.331 1 #> Item_4   1.685  0.851 0.227 1 #> Item_5   3.014 -0.148 0.264 1 #> Item_6   0.436 -1.155 0.254 1 #> Item_7   2.134 -2.246 0.145 1 #> Item_8   0.532  0.633 0.262 1 #> Item_9   1.011  0.449 0.258 1 #> Item_10  2.458 -0.681 0.176 1 #> Item_11  1.398 -0.124 0.252 1 #> Item_12  0.180  0.329 0.269 1 #> Item_13  0.809  0.736 0.292 1 #> Item_14  0.674  0.518 0.270 1 #> Item_15  2.931 -1.035 0.280 1 #> Item_16  0.418  0.595 0.256 1 #> Item_17  0.413 -0.241 0.253 1 #> Item_18  2.136  0.899 0.287 1 #> Item_19 -0.208 -2.328 0.277 1 #> Item_20  0.538 -0.132 0.262 1 #>  #> $means #> Theta  #> 0.294  #>  #> $cov #>       Theta #> Theta 0.744 #>  #>   RMSD_DIF(mod) #>  #>  #> $g1 #>           P.0   P.1 #> Item_1  0.004 0.004 #> Item_2  0.020 0.020 #> Item_3  0.009 0.009 #> Item_4  0.014 0.014 #> Item_5  0.028 0.028 #> Item_6  0.018 0.018 #> Item_7  0.019 0.019 #> Item_8  0.017 0.017 #> Item_9  0.016 0.016 #> Item_10 0.006 0.006 #> Item_11    NA    NA #> Item_12    NA    NA #> Item_13    NA    NA #> Item_14 0.009 0.009 #> Item_15 0.013 0.013 #> Item_16 0.020 0.020 #> Item_17 0.023 0.023 #> Item_18 0.004 0.004 #> Item_19 0.027 0.027 #> Item_20 0.009 0.009 #>  #> $g2 #>           P.0   P.1 #> Item_1     NA    NA #> Item_2     NA    NA #> Item_3     NA    NA #> Item_4  0.014 0.014 #> Item_5  0.029 0.029 #> Item_6  0.014 0.014 #> Item_7  0.020 0.020 #> Item_8  0.019 0.019 #> Item_9  0.018 0.018 #> Item_10 0.011 0.011 #> Item_11 0.005 0.005 #> Item_12 0.007 0.007 #> Item_13 0.014 0.014 #> Item_14 0.006 0.006 #> Item_15 0.014 0.014 #> Item_16 0.026 0.026 #> Item_17 0.023 0.023 #> Item_18 0.008 0.008 #> Item_19 0.014 0.014 #> Item_20 0.010 0.010 #>  RMSD_DIF(mod, flag = .03) #>  #>  #> $g1 #>         P.0 P.1 #> Item_1   NA  NA #> Item_2   NA  NA #> Item_3   NA  NA #> Item_4   NA  NA #> Item_5   NA  NA #> Item_6   NA  NA #> Item_7   NA  NA #> Item_8   NA  NA #> Item_9   NA  NA #> Item_10  NA  NA #> Item_11  NA  NA #> Item_12  NA  NA #> Item_13  NA  NA #> Item_14  NA  NA #> Item_15  NA  NA #> Item_16  NA  NA #> Item_17  NA  NA #> Item_18  NA  NA #> Item_19  NA  NA #> Item_20  NA  NA #>  #> $g2 #>         P.0 P.1 #> Item_1   NA  NA #> Item_2   NA  NA #> Item_3   NA  NA #> Item_4   NA  NA #> Item_5   NA  NA #> Item_6   NA  NA #> Item_7   NA  NA #> Item_8   NA  NA #> Item_9   NA  NA #> Item_10  NA  NA #> Item_11  NA  NA #> Item_12  NA  NA #> Item_13  NA  NA #> Item_14  NA  NA #> Item_15  NA  NA #> Item_16  NA  NA #> Item_17  NA  NA #> Item_18  NA  NA #> Item_19  NA  NA #> Item_20  NA  NA #>   ################# # Single group model (GOF only) mod <- mirt(dat) #>  RMSD_DIF(mod) #>  #>           P.0   P.1 #> Item_1  0.019 0.019 #> Item_2  0.014 0.014 #> Item_3  0.027 0.027 #> Item_4  0.009 0.009 #> Item_5  0.013 0.013 #> Item_6  0.004 0.004 #> Item_7  0.011 0.011 #> Item_8  0.005 0.005 #> Item_9  0.016 0.016 #> Item_10 0.013 0.013 #> Item_11 0.005 0.005 #> Item_12 0.014 0.014 #> Item_13 0.024 0.024 #> Item_14 0.006 0.006 #> Item_15 0.019 0.019 #> Item_16 0.010 0.010 #> Item_17 0.005 0.005 #> Item_18 0.013 0.013 #> Item_19 0.013 0.013 #> Item_20 0.003 0.003 RMSD_DIF(mod, probfun=FALSE) #>  #>         S(theta) #> Item_1     0.019 #> Item_2     0.014 #> Item_3     0.027 #> Item_4     0.009 #> Item_5     0.013 #> Item_6     0.004 #> Item_7     0.011 #> Item_8     0.005 #> Item_9     0.016 #> Item_10    0.013 #> Item_11    0.005 #> Item_12    0.014 #> Item_13    0.024 #> Item_14    0.006 #> Item_15    0.019 #> Item_16    0.010 #> Item_17    0.005 #> Item_18    0.013 #> Item_19    0.013 #> Item_20    0.003  # polytomous mod2 <- mirt(Science) #>  RMSD_DIF(mod2) #>  #>           P.1   P.2   P.3   P.4 #> Comfort 0.023 0.019 0.024 0.014 #> Work    0.019 0.014 0.026 0.028 #> Future  0.013 0.012 0.005 0.004 #> Benefit 0.033 0.038 0.026 0.021 RMSD_DIF(mod2, probfun=FALSE) #>  #>         S(theta) #> Comfort    0.042 #> Work       0.057 #> Future     0.015 #> Benefit    0.049  ################# # polytomous DIF example set.seed(12345) a <- a2 <- matrix(rlnorm(20,.2,.3))  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often (minimum distance of 0.3 here) diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- d2 <- diffs + rnorm(20)  # item 1 has slope + dif for first intercept parameter d2[1] <- d[1] - .5 a2[1] <- a[1] + 1  itemtype <- rep('graded', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  #-----  # fully pooled model pooled_mod <- multipleGroup(dat, 1, group=group,          invariance = c(colnames(dat), 'free_mean', 'free_var')) #>  coef(pooled_mod, simplify=TRUE) #> $D1 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  1.708  1.205  0.527 -0.453 -0.948 #> Item_2  1.517 -0.518 -0.992 -1.653 -2.434 #> Item_3  1.187  1.757  0.681  0.375 -0.638 #> Item_4  1.167  2.719  1.868  1.539  0.808 #> Item_5  1.410  0.485 -0.466 -0.867 -1.581 #> Item_6  0.683 -0.984 -1.396 -1.940 -2.910 #> Item_7  1.387  2.128  1.234  0.341 -0.386 #> Item_8  0.985  2.332  1.994  1.374  0.440 #> Item_9  1.043  1.597  0.850  0.024 -0.373 #> Item_10 0.906 -0.284 -1.281 -1.573 -2.038 #> Item_11 1.128  1.269  0.470 -0.460 -1.184 #> Item_12 2.016  0.268 -0.318 -1.128 -1.716 #> Item_13 1.356 -0.202 -0.835 -1.233 -2.016 #> Item_14 1.261  3.169  2.582  1.916  1.334 #> Item_15 0.928  2.307  1.957  1.151  0.268 #> Item_16 1.479  2.080  1.345  0.682 -0.305 #> Item_17 0.815  2.163  1.208  0.410 -0.557 #> Item_18 1.113  0.333 -0.481 -1.357 -2.072 #> Item_19 1.604  1.256  0.584  0.240 -0.145 #> Item_20 1.333  1.876  1.439  0.858  0.241 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  1.708  1.205  0.527 -0.453 -0.948 #> Item_2  1.517 -0.518 -0.992 -1.653 -2.434 #> Item_3  1.187  1.757  0.681  0.375 -0.638 #> Item_4  1.167  2.719  1.868  1.539  0.808 #> Item_5  1.410  0.485 -0.466 -0.867 -1.581 #> Item_6  0.683 -0.984 -1.396 -1.940 -2.910 #> Item_7  1.387  2.128  1.234  0.341 -0.386 #> Item_8  0.985  2.332  1.994  1.374  0.440 #> Item_9  1.043  1.597  0.850  0.024 -0.373 #> Item_10 0.906 -0.284 -1.281 -1.573 -2.038 #> Item_11 1.128  1.269  0.470 -0.460 -1.184 #> Item_12 2.016  0.268 -0.318 -1.128 -1.716 #> Item_13 1.356 -0.202 -0.835 -1.233 -2.016 #> Item_14 1.261  3.169  2.582  1.916  1.334 #> Item_15 0.928  2.307  1.957  1.151  0.268 #> Item_16 1.479  2.080  1.345  0.682 -0.305 #> Item_17 0.815  2.163  1.208  0.410 -0.557 #> Item_18 1.113  0.333 -0.481 -1.357 -2.072 #> Item_19 1.604  1.256  0.584  0.240 -0.145 #> Item_20 1.333  1.876  1.439  0.858  0.241 #>  #> $means #>     F1  #> -0.022  #>  #> $cov #>       F1 #> F1 1.182 #>  #>   # Item_1 fits poorly in several categories (RMSD > .05) RMSD_DIF(pooled_mod) #>  #>  #> $D1 #>           P.1   P.2   P.3   P.4   P.5 #> Item_1  0.088 0.057 0.024 0.023 0.037 #> Item_2  0.014 0.008 0.010 0.011 0.012 #> Item_3  0.019 0.019 0.015 0.017 0.027 #> Item_4  0.024 0.010 0.010 0.014 0.028 #> Item_5  0.030 0.017 0.006 0.023 0.021 #> Item_6  0.010 0.015 0.015 0.019 0.016 #> Item_7  0.016 0.015 0.020 0.015 0.019 #> Item_8  0.014 0.008 0.012 0.021 0.022 #> Item_9  0.019 0.031 0.022 0.014 0.028 #> Item_10 0.025 0.015 0.010 0.011 0.032 #> Item_11 0.012 0.017 0.015 0.011 0.015 #> Item_12 0.013 0.011 0.021 0.013 0.018 #> Item_13 0.023 0.013 0.018 0.021 0.014 #> Item_14 0.009 0.011 0.005 0.022 0.029 #> Item_15 0.015 0.011 0.016 0.010 0.028 #> Item_16 0.016 0.025 0.020 0.022 0.012 #> Item_17 0.025 0.015 0.020 0.023 0.031 #> Item_18 0.016 0.015 0.017 0.016 0.023 #> Item_19 0.019 0.022 0.016 0.013 0.013 #> Item_20 0.033 0.011 0.012 0.012 0.025 #>  #> $D2 #>           P.1   P.2   P.3   P.4   P.5 #> Item_1  0.101 0.059 0.036 0.018 0.040 #> Item_2  0.007 0.013 0.005 0.012 0.011 #> Item_3  0.035 0.028 0.017 0.030 0.016 #> Item_4  0.011 0.020 0.012 0.011 0.027 #> Item_5  0.017 0.017 0.010 0.013 0.016 #> Item_6  0.026 0.011 0.007 0.016 0.014 #> Item_7  0.017 0.013 0.017 0.019 0.020 #> Item_8  0.021 0.016 0.016 0.017 0.030 #> Item_9  0.019 0.016 0.014 0.015 0.020 #> Item_10 0.020 0.014 0.014 0.018 0.028 #> Item_11 0.018 0.021 0.017 0.013 0.019 #> Item_12 0.013 0.010 0.022 0.007 0.015 #> Item_13 0.018 0.013 0.013 0.012 0.017 #> Item_14 0.026 0.007 0.023 0.012 0.008 #> Item_15 0.019 0.010 0.014 0.017 0.023 #> Item_16 0.015 0.019 0.019 0.018 0.013 #> Item_17 0.017 0.018 0.028 0.024 0.012 #> Item_18 0.024 0.022 0.025 0.017 0.028 #> Item_19 0.027 0.017 0.014 0.009 0.024 #> Item_20 0.025 0.013 0.014 0.011 0.018 #>  RMSD_DIF(pooled_mod, flag = .05) #>  #>  #> $D1 #>           P.1   P.2 P.3 P.4 P.5 #> Item_1  0.088 0.057  NA  NA  NA #> Item_2     NA    NA  NA  NA  NA #> Item_3     NA    NA  NA  NA  NA #> Item_4     NA    NA  NA  NA  NA #> Item_5     NA    NA  NA  NA  NA #> Item_6     NA    NA  NA  NA  NA #> Item_7     NA    NA  NA  NA  NA #> Item_8     NA    NA  NA  NA  NA #> Item_9     NA    NA  NA  NA  NA #> Item_10    NA    NA  NA  NA  NA #> Item_11    NA    NA  NA  NA  NA #> Item_12    NA    NA  NA  NA  NA #> Item_13    NA    NA  NA  NA  NA #> Item_14    NA    NA  NA  NA  NA #> Item_15    NA    NA  NA  NA  NA #> Item_16    NA    NA  NA  NA  NA #> Item_17    NA    NA  NA  NA  NA #> Item_18    NA    NA  NA  NA  NA #> Item_19    NA    NA  NA  NA  NA #> Item_20    NA    NA  NA  NA  NA #>  #> $D2 #>           P.1   P.2 P.3 P.4 P.5 #> Item_1  0.101 0.059  NA  NA  NA #> Item_2     NA    NA  NA  NA  NA #> Item_3     NA    NA  NA  NA  NA #> Item_4     NA    NA  NA  NA  NA #> Item_5     NA    NA  NA  NA  NA #> Item_6     NA    NA  NA  NA  NA #> Item_7     NA    NA  NA  NA  NA #> Item_8     NA    NA  NA  NA  NA #> Item_9     NA    NA  NA  NA  NA #> Item_10    NA    NA  NA  NA  NA #> Item_11    NA    NA  NA  NA  NA #> Item_12    NA    NA  NA  NA  NA #> Item_13    NA    NA  NA  NA  NA #> Item_14    NA    NA  NA  NA  NA #> Item_15    NA    NA  NA  NA  NA #> Item_16    NA    NA  NA  NA  NA #> Item_17    NA    NA  NA  NA  NA #> Item_18    NA    NA  NA  NA  NA #> Item_19    NA    NA  NA  NA  NA #> Item_20    NA    NA  NA  NA  NA #>  RMSD_DIF(pooled_mod, flag = .1, probfun = FALSE) # use expected score function #>  #>  #> $D1 #>         S(theta) #> Item_1     0.184 #> Item_2        NA #> Item_3        NA #> Item_4     0.106 #> Item_5        NA #> Item_6        NA #> Item_7        NA #> Item_8        NA #> Item_9        NA #> Item_10       NA #> Item_11       NA #> Item_12       NA #> Item_13       NA #> Item_14       NA #> Item_15       NA #> Item_16       NA #> Item_17    0.101 #> Item_18       NA #> Item_19       NA #> Item_20    0.102 #>  #> $D2 #>         S(theta) #> Item_1     0.211 #> Item_2        NA #> Item_3        NA #> Item_4        NA #> Item_5        NA #> Item_6        NA #> Item_7        NA #> Item_8        NA #> Item_9        NA #> Item_10       NA #> Item_11       NA #> Item_12       NA #> Item_13       NA #> Item_14       NA #> Item_15       NA #> Item_16       NA #> Item_17       NA #> Item_18       NA #> Item_19       NA #> Item_20       NA #>   # more freely estimated model (item 1 has more parameters estimated) MGmod <- multipleGroup(dat, 1, group=group,                        invariance = c(colnames(dat)[-1], 'free_mean', 'free_var')) #>  coef(MGmod, simplify=TRUE) #> $D1 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  1.293  1.471  0.527 -0.408 -0.925 #> Item_2  1.553 -0.527 -1.000 -1.659 -2.439 #> Item_3  1.226  1.754  0.675  0.368 -0.647 #> Item_4  1.201  2.716  1.864  1.535  0.802 #> Item_5  1.447  0.476 -0.475 -0.876 -1.590 #> Item_6  0.702 -0.989 -1.400 -1.944 -2.915 #> Item_7  1.426  2.122  1.227  0.333 -0.395 #> Item_8  1.009  2.325  1.987  1.368  0.433 #> Item_9  1.076  1.593  0.846  0.018 -0.380 #> Item_10 0.936 -0.290 -1.289 -1.581 -2.047 #> Item_11 1.157  1.261  0.463 -0.467 -1.191 #> Item_12 2.070  0.255 -0.331 -1.141 -1.728 #> Item_13 1.392 -0.211 -0.844 -1.242 -2.025 #> Item_14 1.290  3.158  2.571  1.906  1.324 #> Item_15 0.952  2.301  1.951  1.145  0.262 #> Item_16 1.516  2.070  1.334  0.671 -0.314 #> Item_17 0.835  2.158  1.202  0.405 -0.562 #> Item_18 1.141  0.326 -0.487 -1.363 -2.078 #> Item_19 1.643  1.245  0.573  0.230 -0.155 #> Item_20 1.371  1.869  1.432  0.851  0.234 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  2.523  0.906  0.520 -0.587 -1.079 #> Item_2  1.553 -0.527 -1.000 -1.659 -2.439 #> Item_3  1.226  1.754  0.675  0.368 -0.647 #> Item_4  1.201  2.716  1.864  1.535  0.802 #> Item_5  1.447  0.476 -0.475 -0.876 -1.590 #> Item_6  0.702 -0.989 -1.400 -1.944 -2.915 #> Item_7  1.426  2.122  1.227  0.333 -0.395 #> Item_8  1.009  2.325  1.987  1.368  0.433 #> Item_9  1.076  1.593  0.846  0.018 -0.380 #> Item_10 0.936 -0.290 -1.289 -1.581 -2.047 #> Item_11 1.157  1.261  0.463 -0.467 -1.191 #> Item_12 2.070  0.255 -0.331 -1.141 -1.728 #> Item_13 1.392 -0.211 -0.844 -1.242 -2.025 #> Item_14 1.290  3.158  2.571  1.906  1.324 #> Item_15 0.952  2.301  1.951  1.145  0.262 #> Item_16 1.516  2.070  1.334  0.671 -0.314 #> Item_17 0.835  2.158  1.202  0.405 -0.562 #> Item_18 1.141  0.326 -0.487 -1.363 -2.078 #> Item_19 1.643  1.245  0.573  0.230 -0.155 #> Item_20 1.371  1.869  1.432  0.851  0.234 #>  #> $means #>     F1  #> -0.009  #>  #> $cov #>       F1 #> F1 1.071 #>  #>   # RMSDs in Item_1 now reduced (MG model better accounts for DIF) RMSD_DIF(MGmod) #>  #>  #> $D1 #>           P.1   P.2   P.3   P.4   P.5 #> Item_1  0.007 0.019 0.017 0.016 0.010 #> Item_2  0.016 0.009 0.009 0.011 0.015 #> Item_3  0.016 0.018 0.014 0.018 0.025 #> Item_4  0.021 0.010 0.010 0.014 0.022 #> Item_5  0.028 0.017 0.007 0.022 0.022 #> Item_6  0.009 0.016 0.015 0.018 0.015 #> Item_7  0.016 0.013 0.021 0.015 0.018 #> Item_8  0.012 0.008 0.012 0.022 0.021 #> Item_9  0.016 0.029 0.023 0.014 0.025 #> Item_10 0.023 0.015 0.010 0.011 0.031 #> Item_11 0.016 0.018 0.015 0.011 0.015 #> Item_12 0.010 0.010 0.022 0.012 0.020 #> Item_13 0.019 0.011 0.017 0.021 0.016 #> Item_14 0.012 0.010 0.005 0.023 0.032 #> Item_15 0.015 0.011 0.016 0.011 0.028 #> Item_16 0.013 0.024 0.020 0.022 0.015 #> Item_17 0.024 0.015 0.019 0.024 0.030 #> Item_18 0.019 0.016 0.017 0.016 0.020 #> Item_19 0.021 0.022 0.016 0.013 0.013 #> Item_20 0.029 0.011 0.012 0.012 0.022 #>  #> $D2 #>           P.1   P.2   P.3   P.4   P.5 #> Item_1  0.026 0.003 0.019 0.007 0.010 #> Item_2  0.008 0.013 0.004 0.012 0.014 #> Item_3  0.032 0.027 0.016 0.031 0.014 #> Item_4  0.009 0.019 0.011 0.011 0.023 #> Item_5  0.021 0.017 0.010 0.014 0.017 #> Item_6  0.026 0.012 0.007 0.016 0.014 #> Item_7  0.020 0.013 0.019 0.018 0.018 #> Item_8  0.021 0.015 0.017 0.017 0.026 #> Item_9  0.017 0.015 0.015 0.015 0.019 #> Item_10 0.018 0.014 0.014 0.018 0.027 #> Item_11 0.020 0.021 0.017 0.013 0.017 #> Item_12 0.010 0.010 0.022 0.007 0.017 #> Item_13 0.015 0.012 0.013 0.013 0.014 #> Item_14 0.028 0.007 0.022 0.013 0.009 #> Item_15 0.018 0.010 0.015 0.017 0.024 #> Item_16 0.014 0.019 0.018 0.017 0.016 #> Item_17 0.017 0.017 0.028 0.025 0.013 #> Item_18 0.029 0.022 0.025 0.019 0.025 #> Item_19 0.027 0.016 0.015 0.010 0.024 #> Item_20 0.019 0.013 0.014 0.012 0.014 #>  RMSD_DIF(MGmod, flag = .05) #>  #>  #> $D1 #>         P.1 P.2 P.3 P.4 P.5 #> Item_1   NA  NA  NA  NA  NA #> Item_2   NA  NA  NA  NA  NA #> Item_3   NA  NA  NA  NA  NA #> Item_4   NA  NA  NA  NA  NA #> Item_5   NA  NA  NA  NA  NA #> Item_6   NA  NA  NA  NA  NA #> Item_7   NA  NA  NA  NA  NA #> Item_8   NA  NA  NA  NA  NA #> Item_9   NA  NA  NA  NA  NA #> Item_10  NA  NA  NA  NA  NA #> Item_11  NA  NA  NA  NA  NA #> Item_12  NA  NA  NA  NA  NA #> Item_13  NA  NA  NA  NA  NA #> Item_14  NA  NA  NA  NA  NA #> Item_15  NA  NA  NA  NA  NA #> Item_16  NA  NA  NA  NA  NA #> Item_17  NA  NA  NA  NA  NA #> Item_18  NA  NA  NA  NA  NA #> Item_19  NA  NA  NA  NA  NA #> Item_20  NA  NA  NA  NA  NA #>  #> $D2 #>         P.1 P.2 P.3 P.4 P.5 #> Item_1   NA  NA  NA  NA  NA #> Item_2   NA  NA  NA  NA  NA #> Item_3   NA  NA  NA  NA  NA #> Item_4   NA  NA  NA  NA  NA #> Item_5   NA  NA  NA  NA  NA #> Item_6   NA  NA  NA  NA  NA #> Item_7   NA  NA  NA  NA  NA #> Item_8   NA  NA  NA  NA  NA #> Item_9   NA  NA  NA  NA  NA #> Item_10  NA  NA  NA  NA  NA #> Item_11  NA  NA  NA  NA  NA #> Item_12  NA  NA  NA  NA  NA #> Item_13  NA  NA  NA  NA  NA #> Item_14  NA  NA  NA  NA  NA #> Item_15  NA  NA  NA  NA  NA #> Item_16  NA  NA  NA  NA  NA #> Item_17  NA  NA  NA  NA  NA #> Item_18  NA  NA  NA  NA  NA #> Item_19  NA  NA  NA  NA  NA #> Item_20  NA  NA  NA  NA  NA #>  RMSD_DIF(MGmod, probfun = FALSE, flag = .1) # use expected score function #>  #>  #> $D1 #>         S(theta) #> Item_1        NA #> Item_2        NA #> Item_3        NA #> Item_4        NA #> Item_5        NA #> Item_6        NA #> Item_7        NA #> Item_8        NA #> Item_9        NA #> Item_10       NA #> Item_11       NA #> Item_12       NA #> Item_13       NA #> Item_14       NA #> Item_15       NA #> Item_16       NA #> Item_17    0.104 #> Item_18       NA #> Item_19       NA #> Item_20       NA #>  #> $D2 #>         S(theta) #> Item_1        NA #> Item_2        NA #> Item_3        NA #> Item_4        NA #> Item_5        NA #> Item_6        NA #> Item_7        NA #> Item_8        NA #> Item_9        NA #> Item_10       NA #> Item_11       NA #> Item_12       NA #> Item_13       NA #> Item_14       NA #> Item_15       NA #> Item_16       NA #> Item_17       NA #> Item_18       NA #> Item_19       NA #> Item_20       NA #>   # }"},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of SAT12 data — SAT12","title":"Description of SAT12 data — SAT12","text":"Data obtained TESTFACT (Woods et al., 2003) manual, 32 response pattern scored items grade 12 science assessment test (SAT) measuring topics chemistry, biology, physics. scoring key data [1, 4, 5, 2, 3, 1, 2, 1, 3, 1, 2, 4, 2, 1, 5, 3, 4, 4, 1, 4, 3, 3, 4, 1, 3, 5, 1, 3, 1, 5, 4, 5], respectively. However, careful analysis using nominal response model suggests scoring key item 32 may incorrect, changed 5 3.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of SAT12 data — SAT12","text":"Wood, R., Wilson, D. T., Gibbons, R. D., Schilling, S. G., Muraki, E., & Bock, R. D. (2003). TESTFACT 4 Windows: Test Scoring, Item Statistics, Full-information Item Factor Analysis [Computer software]. Lincolnwood, IL: Scientific Software International.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of SAT12 data — SAT12","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SAT12.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of SAT12 data — SAT12","text":"","code":"# \\donttest{  itemstats(SAT12, use_ts = FALSE) #> $overall #>     N #> 1 600 #>  #> $itemstats #>           N K  mean    sd #> Item.1  600 6 2.497 1.188 #> Item.2  600 6 3.385 1.356 #> Item.3  600 6 3.212 1.534 #> Item.4  600 6 2.762 1.370 #> Item.5  600 6 2.868 0.911 #> Item.6  600 5 2.358 1.135 #> Item.7  600 6 2.422 0.908 #> Item.8  600 6 2.925 1.370 #> Item.9  600 5 2.907 0.567 #> Item.10 600 6 2.320 1.490 #> Item.11 600 5 2.017 0.199 #> Item.12 600 6 3.642 1.184 #> Item.13 600 5 2.317 0.956 #> Item.14 600 6 1.798 1.432 #> Item.15 600 6 4.535 1.087 #> Item.16 600 6 3.368 1.135 #> Item.17 600 5 3.968 0.343 #> Item.18 600 6 3.020 1.514 #> Item.19 600 5 1.900 1.053 #> Item.20 600 6 3.870 0.483 #> Item.21 600 6 2.937 0.554 #> Item.22 600 5 2.985 0.442 #> Item.23 600 6 2.755 1.437 #> Item.24 600 6 1.502 1.037 #> Item.25 600 6 2.740 1.380 #> Item.26 600 6 3.923 1.265 #> Item.27 600 6 1.240 0.766 #> Item.28 600 6 3.262 0.937 #> Item.29 600 6 2.285 1.306 #> Item.30 600 6 3.703 1.553 #> Item.31 600 6 3.788 0.899 #> Item.32 600 6 3.023 1.303 #>  #> $proportions #>             1     2     3     4     5     8 #> Item.1  0.283 0.203 0.267 0.232 0.013 0.002 #> Item.2  0.212 0.022 0.070 0.568 0.127 0.002 #> Item.3  0.165 0.183 0.260 0.098 0.280 0.013 #> Item.4  0.165 0.378 0.148 0.172 0.128 0.008 #> Item.5  0.093 0.143 0.620 0.093 0.048 0.002 #> Item.6  0.160 0.582 0.107 0.043 0.108    NA #> Item.7  0.025 0.760 0.007 0.190 0.017 0.002 #> Item.8  0.202 0.205 0.207 0.250 0.133 0.003 #> Item.9  0.065 0.010 0.885 0.033 0.007    NA #> Item.10 0.422 0.215 0.165 0.028 0.167 0.003 #> Item.11 0.003 0.983 0.008 0.003 0.002    NA #> Item.12 0.072 0.082 0.218 0.415 0.205 0.008 #> Item.13 0.110 0.662 0.070 0.118 0.040    NA #> Item.14 0.723 0.027 0.108 0.022 0.117 0.003 #> Item.15 0.035 0.062 0.060 0.025 0.817 0.002 #> Item.16 0.070 0.105 0.413 0.215 0.195 0.002 #> Item.17 0.008 0.005 0.010 0.963 0.013    NA #> Item.18 0.303 0.033 0.165 0.352 0.142 0.005 #> Item.19 0.548 0.053 0.358 0.030 0.010    NA #> Item.20 0.012 0.002 0.105 0.873 0.007 0.002 #> Item.21 0.050 0.008 0.915 0.013 0.012 0.002 #> Item.22 0.028 0.005 0.935 0.017 0.015    NA #> Item.23 0.290 0.177 0.128 0.313 0.087 0.005 #> Item.24 0.728 0.162 0.042 0.022 0.045 0.002 #> Item.25 0.240 0.170 0.375 0.065 0.142 0.008 #> Item.26 0.020 0.227 0.030 0.262 0.460 0.002 #> Item.27 0.862 0.093 0.012 0.020 0.010 0.003 #> Item.28 0.082 0.010 0.530 0.337 0.037 0.005 #> Item.29 0.340 0.295 0.205 0.085 0.067 0.008 #> Item.30 0.150 0.110 0.107 0.183 0.440 0.010 #> Item.31 0.075 0.020 0.012 0.833 0.058 0.002 #> Item.32 0.125 0.183 0.443 0.075 0.162 0.012 #>   # score the data (missing scored as 0) head(SAT12) #>   Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> 1      1      4      5      2      3      1      2      1      3       1 #> 2      3      4      2      8      3      3      2      8      3       1 #> 3      1      4      5      4      3      2      2      3      3       2 #> 4      2      4      4      2      3      3      2      4      3       2 #> 5      2      4      5      2      3      2      2      1      1       2 #> 6      1      4      3      1      3      2      2      3      3       1 #>   Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> 1       2       4       2       1       5       3       4       4       1 #> 2       2       8       2       1       5       2       4       1       1 #> 3       2       1       3       1       5       5       4       1       3 #> 4       2       4       2       1       5       2       4       1       3 #> 5       2       4       2       1       5       4       4       5       1 #> 6       2       3       2       1       5       5       4       4       1 #>   Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> 1       4       3       3       4       1       3       5       1       3 #> 2       4       3       3       8       1       8       4       1       4 #> 3       4       3       3       1       1       3       4       1       3 #> 4       4       3       1       5       2       5       4       1       3 #> 5       4       3       3       3       1       1       5       1       3 #> 6       4       3       3       4       1       1       4       1       4 #>   Item.29 Item.30 Item.31 Item.32 #> 1       1       5       4       5 #> 2       5       8       4       8 #> 3       4       4       4       1 #> 4       4       2       4       2 #> 5       1       2       4       1 #> 6       2       3       4       3 dat <- key2binary(SAT12,     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) head(dat) #>      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> [1,]      1      1      1      1      1      1      1      1      1       1 #> [2,]      0      1      0      0      1      0      1      0      1       1 #> [3,]      1      1      1      0      1      0      1      0      1       0 #> [4,]      0      1      0      1      1      0      1      0      1       0 #> [5,]      0      1      1      1      1      0      1      1      0       0 #> [6,]      1      1      0      0      1      0      1      0      1       1 #>      Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       0       1       1       1       0       1       0       1 #> [3,]       1       0       0       1       1       0       1       0       0 #> [4,]       1       1       1       1       1       0       1       0       0 #> [5,]       1       1       1       1       1       0       1       0       1 #> [6,]       1       0       1       1       1       0       1       1       1 #>      Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       1       1       0       1       0       0       1       0 #> [3,]       1       1       1       0       1       1       0       1       1 #> [4,]       1       1       0       0       0       0       0       1       1 #> [5,]       1       1       1       0       1       0       1       1       1 #> [6,]       1       1       1       1       1       0       0       1       0 #>      Item.29 Item.30 Item.31 Item.32 #> [1,]       1       1       1       1 #> [2,]       0       0       1       0 #> [3,]       0       0       1       0 #> [4,]       0       0       1       0 #> [5,]       1       0       1       0 #> [6,]       0       0       1       0 itemstats(dat) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  600           18.202          5.054 0.108 0.075 0.798     2.272 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  600 2 0.283 0.451   0.380         0.300       0.793 #> Item.2  600 2 0.568 0.496   0.539         0.464       0.785 #> Item.3  600 2 0.280 0.449   0.446         0.371       0.789 #> Item.4  600 2 0.378 0.485   0.325         0.235       0.796 #> Item.5  600 2 0.620 0.486   0.424         0.340       0.791 #> Item.6  600 2 0.160 0.367   0.414         0.351       0.791 #> Item.7  600 2 0.760 0.427   0.366         0.289       0.793 #> Item.8  600 2 0.202 0.402   0.307         0.233       0.795 #> Item.9  600 2 0.885 0.319   0.189         0.127       0.798 #> Item.10 600 2 0.422 0.494   0.465         0.383       0.789 #> Item.11 600 2 0.983 0.128   0.181         0.156       0.797 #> Item.12 600 2 0.415 0.493   0.173         0.076       0.803 #> Item.13 600 2 0.662 0.474   0.438         0.358       0.790 #> Item.14 600 2 0.723 0.448   0.411         0.333       0.791 #> Item.15 600 2 0.817 0.387   0.393         0.325       0.792 #> Item.16 600 2 0.413 0.493   0.367         0.278       0.794 #> Item.17 600 2 0.963 0.188   0.238         0.202       0.796 #> Item.18 600 2 0.352 0.478   0.576         0.508       0.783 #> Item.19 600 2 0.548 0.498   0.401         0.314       0.792 #> Item.20 600 2 0.873 0.333   0.376         0.318       0.792 #> Item.21 600 2 0.915 0.279   0.190         0.136       0.798 #> Item.22 600 2 0.935 0.247   0.284         0.238       0.795 #> Item.23 600 2 0.313 0.464   0.338         0.253       0.795 #> Item.24 600 2 0.728 0.445   0.422         0.346       0.791 #> Item.25 600 2 0.375 0.485   0.383         0.297       0.793 #> Item.26 600 2 0.460 0.499   0.562         0.489       0.783 #> Item.27 600 2 0.862 0.346   0.425         0.367       0.791 #> Item.28 600 2 0.530 0.500   0.465         0.383       0.789 #> Item.29 600 2 0.340 0.474   0.407         0.324       0.791 #> Item.30 600 2 0.440 0.497   0.255         0.159       0.799 #> Item.31 600 2 0.833 0.373   0.479         0.419       0.788 #> Item.32 600 2 0.162 0.368   0.110         0.037       0.802 #>  #> $proportions #>             0     1 #> Item.1  0.717 0.283 #> Item.2  0.432 0.568 #> Item.3  0.720 0.280 #> Item.4  0.622 0.378 #> Item.5  0.380 0.620 #> Item.6  0.840 0.160 #> Item.7  0.240 0.760 #> Item.8  0.798 0.202 #> Item.9  0.115 0.885 #> Item.10 0.578 0.422 #> Item.11 0.017 0.983 #> Item.12 0.585 0.415 #> Item.13 0.338 0.662 #> Item.14 0.277 0.723 #> Item.15 0.183 0.817 #> Item.16 0.587 0.413 #> Item.17 0.037 0.963 #> Item.18 0.648 0.352 #> Item.19 0.452 0.548 #> Item.20 0.127 0.873 #> Item.21 0.085 0.915 #> Item.22 0.065 0.935 #> Item.23 0.687 0.313 #> Item.24 0.272 0.728 #> Item.25 0.625 0.375 #> Item.26 0.540 0.460 #> Item.27 0.138 0.862 #> Item.28 0.470 0.530 #> Item.29 0.660 0.340 #> Item.30 0.560 0.440 #> Item.31 0.167 0.833 #> Item.32 0.838 0.162 #>   # score the data, missing (value of 8) treated as NA SAT12missing <- SAT12 SAT12missing[SAT12missing == 8] <- NA dat <- key2binary(SAT12missing,     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) head(dat) #>      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> [1,]      1      1      1      1      1      1      1      1      1       1 #> [2,]      0      1      0     NA      1      0      1     NA      1       1 #> [3,]      1      1      1      0      1      0      1      0      1       0 #> [4,]      0      1      0      1      1      0      1      0      1       0 #> [5,]      0      1      1      1      1      0      1      1      0       0 #> [6,]      1      1      0      0      1      0      1      0      1       1 #>      Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1      NA       1       1       1       0       1       0       1 #> [3,]       1       0       0       1       1       0       1       0       0 #> [4,]       1       1       1       1       1       0       1       0       0 #> [5,]       1       1       1       1       1       0       1       0       1 #> [6,]       1       0       1       1       1       0       1       1       1 #>      Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       1       1      NA       1      NA       0       1       0 #> [3,]       1       1       1       0       1       1       0       1       1 #> [4,]       1       1       0       0       0       0       0       1       1 #> [5,]       1       1       1       0       1       0       1       1       1 #> [6,]       1       1       1       1       1       0       0       1       0 #>      Item.29 Item.30 Item.31 Item.32 #> [1,]       1       1       1       1 #> [2,]       0      NA       1      NA #> [3,]       0       0       1       0 #> [4,]       0       0       1       0 #> [5,]       1       0       1       0 #> [6,]       0       0       1       0  # potentially better scoring for item 32 (based on nominal model finding) dat <- key2binary(SAT12,     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,3)) # }"},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":null,"dir":"Reference","previous_headings":"","what":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"Classical test theory approach detecting unidirectional bidirectional (one crossing location) DIF. family statistics intended unidimensional tests, applies regression-corrected matched-total score approach quantify response bias two groups. Can used DIF, DBF, DTF testing two discrete groups.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"","code":"SIBTEST(   dat,   group,   suspect_set,   match_set,   focal_name = unique(group)[2],   guess_correction = 0,   Jmin = 5,   na.rm = FALSE,   randomize = FALSE,   C = cbind(1, -diag(length(unique(group)) - 1L)),   pairwise = FALSE,   DIF = FALSE,   p.adjust.method = \"none\",   permute = 1000,   pk_focal = FALSE,   correction = TRUE,   remove_cross = FALSE,   details = FALSE,   plot = \"none\",   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"dat integer-based dataset tested, containing dichotomous polytomous responses group (factor) vector indicating group membership length number rows dat suspect_set integer vector indicating items inspect SIBTEST. Including one value perform DIF test, including one perform simultaneous bundle test (DBF); including non-matched items perform DTF. missing, simultaneous test using items listed match_set used (.e., DTF) match_set integer vector indicating items use items matched (.e., contain DIF). analogous 'anchor' items likelihood method locate DIF. missing, items items found suspect_set used focal_name name focal group; e.g., 'focal'. specified one selected automatically using unique(group)[2] guess_correction vector numbers 0 1 indicating much correct items guessing. length ncol(dat) Jmin minimum number observations required splitting data focal reference groups conditioned matched set na.rm logical; remove rows dat missing values? TRUE, rows missing data removed, well corresponding elements group input randomize logical; perform crossing test non-compensatory bias using Li Stout's (1996) permutation approach? Default FALSE, uses ad-hoc mixed degrees freedom method suggested Chalmers (2018) C contrast matrix use pooled testing two groups. Default uses effects coding approach, last group (last column matrix) treated reference group, column associated respective name via unique(group) (.e., first column coefficient unique(group)[1], second column unique(group)[2], ) pairwise logical; perform pairwise comparisons multi-group applications? DIF logical; elements suspect_set treated one time test DIF? Use logical treat items part match_set unless input provided explicitly. Default FALSE allow DBF DTF tests p.adjust.method character input dictating method use p.adjust. studying two groups. Default present p-value adjustments permute number permutations perform randomize = TRUE. Default 1000 pk_focal logical; using group weights focal group instead total sample? Default FALSE per Shealy Stout's recommendation correction logical; apply composite correction difference focal composite scores using true-score regression technique? Default TRUE, reflecting Shealy Stout's linear extrapolation method remove_cross logical; remove subtest information associated approximate crossing location? TRUE reflects CSIBTEST definition Li Stout (1996); FALSE, reflects version CSIBTEST utilized Chalmers (2018). applicable two-group settings (multi-group fixed FALSE) details logical; return data.frame containing details required compute SIBTEST? plot character input indicating type plot construct. Options 'none' (default), 'observed' scaled focal subtest scores matched subtest scores, 'weights' proportion weights used (.e., proportion observations matched score), 'difference' difference scaled focal subtest scores matched subtest scores, 'wdifference' conditional differences multiplied respective weight. Note last plot reflects components used SIBTEST, therefore sum plotted observations equal beta coefficient SIBTEST ... additional plotting arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"data.frame type object containing SIBTEST results. Note   beta coefficient (G)CSIBTEST reported absolute values   reflect sum respective area information   estimated crossing locations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"SIBTEST similar Mantel-Haenszel approach detecting DIF uses regression correction based KR-20/coefficient alpha reliability index correct observed differences latent trait distributions equal. Function supports standard SIBTEST dichotomous polytomous data (compensatory) supports crossing DIF testing (.e., non-compensatory/non-uniform) using asymptotic sampling distribution version Crossing-SIBTEST (CSIBTEST) statistic described Chalmers (2018) permutation method described Li Stout (1996). function also supports multi-group generalizations (GSIBTEST GCSIBTEST) proposed Chalmers Zheng (2023), users may specify alternative contrast matrices evaluate specific comparisons groups well perform joint hypothesis tests.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"Chalmers, R. P. (2018). Improving Crossing-SIBTEST statistic detecting non-uniform DIF. Psychometrika, 83, 2, 376-386. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. & Zheng, G. (2023). Multi-group Generalizations SIBTEST Crossing-SIBTEST. Applied Measurement Education, 36(2), 171-191, doi:10.1080/08957347.2023.2201703 . Chang, H. H., Mazzeo, J. & Roussos, L. (1996). DIF Polytomously Scored Items: Adaptation   SIBTEST Procedure. Journal Educational Measurement, 33, 333-353. Li, H.-H. & Stout, W. (1996). new procedure detection crossing DIF. Psychometrika, 61, 647-677. Shealy, R. & Stout, W. (1993). model-based standardization approach separates true   bias/DIF group ability differences detect test bias/DTF well item bias/DIF.   Psychometrika, 58, 159-194.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SIBTEST.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Generalized) Simultaneous Item Bias Test (SIBTEST) — SIBTEST","text":"","code":"# \\donttest{  set.seed(1234) n <- 30 N <- 500 a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('reference', N), rep('focal', N*2))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N*2, itemtype = 'dich') dat <- rbind(dat1, dat2)  # DIF (all other items as anchors) SIBTEST(dat, group, suspect_set = 6) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.014 0.027 0.265  1 0.606 #> CSIBTEST       focal            29             1  0.015    NA 0.331  2 0.848  # Some plots depicting the above tests SIBTEST(dat, group, suspect_set = 6, plot = 'observed')  SIBTEST(dat, group, suspect_set = 6, plot = 'weights')  SIBTEST(dat, group, suspect_set = 6, plot = 'wdifference')   # Include CSIBTEST with randomization method SIBTEST(dat, group, suspect_set = 6, randomize = TRUE) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.014 0.027 0.265  1 0.606 #> CSIBTEST       focal            29             1  0.015 0.027          0.827  # remove crossing-location (identical to Li and Stout 1996 definition of CSIBTEST) SIBTEST(dat, group, suspect_set = 6, randomize = TRUE, remove_cross=TRUE) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.014 0.027 0.265  1 0.606 #> CSIBTEST       focal            29             1  0.016 0.026          0.781  # DIF (specific anchors) SIBTEST(dat, group, match_set = 1:5, suspect_set = 6) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.008 0.028 0.078  1 0.781 #> CSIBTEST       focal             5             1  0.004    NA 0.105  2 0.949 SIBTEST(dat, group, match_set = 1:5, suspect_set = 6, randomize=TRUE) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.008 0.028 0.078  1 0.781 #> CSIBTEST       focal             5             1  0.004 0.028              1  # DBF (all and specific anchors, respectively) SIBTEST(dat, group, suspect_set = 11:30) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST        focal            10            20 0.053 0.165 0.102  1 0.75 #> CSIBTEST       focal            10            20 0.053    NA 0.102  1 0.75 SIBTEST(dat, group, match_set = 1:5, suspect_set = 11:30) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df   p #> SIBTEST        focal             5            20 0.166 0.197 0.708  1 0.4 #> CSIBTEST       focal             5            20 0.166    NA 0.708  1 0.4  # DTF SIBTEST(dat, group, suspect_set = 11:30) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST        focal            10            20 0.053 0.165 0.102  1 0.75 #> CSIBTEST       focal            10            20 0.053    NA 0.102  1 0.75 SIBTEST(dat, group, match_set = 1:10) #equivalent #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST        focal            10            20 0.053 0.165 0.102  1 0.75 #> CSIBTEST       focal            10            20 0.053    NA 0.102  1 0.75  # different hyper pars dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N*2, itemtype = 'dich', mu = .5, sigma = matrix(1.5)) dat <- rbind(dat1, dat2) SIBTEST(dat, group, 6:30) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5            25 0.115 0.249 0.214  1 0.644 #> CSIBTEST       focal             5            25 0.419    NA 2.966  2 0.227 SIBTEST(dat, group, 11:30) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            10            20 0.098 0.171 0.333  1 0.564 #> CSIBTEST       focal            10            20 0.321    NA 3.603  2 0.165  # DIF testing with anchors 1 through 5 SIBTEST(dat, group, 6, match_set = 1:5) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.012 0.027  0.18  1 0.671 #> CSIBTEST       focal             5             1 0.030    NA 1.246  2 0.536 SIBTEST(dat, group, 7, match_set = 1:5) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.011 0.029 0.148  1   0.7 #> CSIBTEST       focal             5             1  0.038    NA 1.764  2 0.414 SIBTEST(dat, group, 8, match_set = 1:5) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.026 0.028 0.824  1 0.364 #> CSIBTEST       focal             5             1  0.026    NA 0.824  1 0.364  # DIF testing with all other items as anchors SIBTEST(dat, group, 6) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.003 0.027 0.012  1 0.913 #> CSIBTEST       focal            29             1  0.014    NA 0.261  2 0.878 SIBTEST(dat, group, 7) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.014 0.028 0.241  1 0.623 #> CSIBTEST       focal            29             1  0.032    NA 1.311  2 0.519 SIBTEST(dat, group, 8) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.045 0.026 2.883  1 0.089 #> CSIBTEST       focal            29             1  0.045    NA 2.883  1 0.089  ## ------------- ## systematic differing slopes and intercepts (clear DTF) dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, 1)),   N*2, itemtype = 'dich') dat <- rbind(dat1, dat2) SIBTEST(dat, group, 6:30) #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5            25 -2.334 0.264 78.065  1 0 #> CSIBTEST       focal             5            25  2.334    NA 78.065  1 0 SIBTEST(dat, group, 11:30) #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal            10            20 -2.376 0.179 176.396  1 0 #> CSIBTEST       focal            10            20  2.376    NA 176.396  1 0  # Some plots depicting the above tests SIBTEST(dat, group, suspect_set = 11:30, plot = 'observed')  SIBTEST(dat, group, suspect_set = 11:30, plot = 'weights')  SIBTEST(dat, group, suspect_set = 11:30, plot = 'wdifference')   # DIF testing using valid anchors SIBTEST(dat, group, suspect_set = 6, match_set = 1:5) #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.013 0.028 0.209  1 0.648 #> CSIBTEST       focal             5             1  0.060    NA 5.276  2 0.071 SIBTEST(dat, group, suspect_set = 7, match_set = 1:5) #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.011 0.027  0.17  1  0.68 #> CSIBTEST       focal             5             1 0.006    NA 0.173  2 0.917 SIBTEST(dat, group, suspect_set = 30, match_set = 1:5) #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal             5             1 -0.335 0.026 166.911  1 0 #> CSIBTEST       focal             5             1  0.335    NA 166.911  1 0  # test DIF using specific match_set SIBTEST(dat, group, suspect_set = 6:30, match_set = 1:5, DIF=TRUE) #> $Item_6 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.013 0.028 0.209  1 0.648 #> CSIBTEST       focal             5             1  0.060    NA 5.276  2 0.071 #>  #> $Item_7 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.011 0.027  0.17  1  0.68 #> CSIBTEST       focal             5             1 0.006    NA 0.173  2 0.917 #>  #> $Item_8 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST        focal             5             1 -0.007 0.028 0.071  1 0.79 #> CSIBTEST       focal             5             1  0.007    NA 0.071  1 0.79 #>  #> $Item_9 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.004 0.027 0.022  1 0.882 #> CSIBTEST       focal             5             1 0.020    NA 0.562  2 0.755 #>  #> $Item_10 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.031 0.027 1.309  1 0.253 #> CSIBTEST       focal             5             1 0.018    NA 1.314  2 0.518 #>  #> $Item_11 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.032 0.028 1.292  1 0.256 #> CSIBTEST       focal             5             1 0.032    NA 1.292  1 0.256 #>  #> $Item_12 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.018 0.026 0.448  1 0.503 #> CSIBTEST       focal             5             1 0.010    NA 0.457  2 0.796 #>  #> $Item_13 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.000 0.027     0  1  0.99 #> CSIBTEST       focal             5             1 0.029    NA 1.135  2 0.567 #>  #> $Item_14 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.004 0.028 0.024  1 0.876 #> CSIBTEST       focal             5             1 0.005    NA 0.032  2 0.984 #>  #> $Item_15 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST        focal             5             1 -0.008 0.027 0.091  1 0.763 #> CSIBTEST       focal             5             1  0.012    NA 1.273  2 0.529 #>  #> $Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5             1 -0.194 0.028 48.949  1 0 #> CSIBTEST       focal             5             1  0.194    NA 48.949  1 0 #>  #> $Item_17 #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal             5             1 -0.381 0.026 207.053  1 0 #> CSIBTEST       focal             5             1  0.381    NA 207.053  1 0 #>  #> $Item_18 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5             1 -0.122 0.027 20.077  1 0 #> CSIBTEST       focal             5             1  0.122    NA 20.077  1 0 #>  #> $Item_19 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal             5             1 0.206 0.025 67.462  1 0 #> CSIBTEST       focal             5             1 0.206    NA 67.462  1 0 #>  #> $Item_20 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.006 0.018 0.104  1 0.747 #> CSIBTEST       focal             5             1 0.010    NA  0.64  2 0.726 #>  #> $Item_21 #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal             5             1 -0.288 0.026 120.661  1 0 #> CSIBTEST       focal             5             1  0.288    NA 120.661  1 0 #>  #> $Item_22 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5             1 -0.259 0.027 89.969  1 0 #> CSIBTEST       focal             5             1  0.259    NA 89.969  1 0 #>  #> $Item_23 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5             1 -0.235 0.028 72.731  1 0 #> CSIBTEST       focal             5             1  0.235    NA 72.731  1 0 #>  #> $Item_24 #>          focal_group n_matched_set n_suspect_set beta    SE    X2 df     p #> SIBTEST        focal             5             1 0.06 0.027 4.759  1 0.029 #> CSIBTEST       focal             5             1 0.06    NA 4.759  1 0.029 #>  #> $Item_25 #>          focal_group n_matched_set n_suspect_set  beta    SE      X2 df p #> SIBTEST        focal             5             1 -0.38 0.026 209.695  1 0 #> CSIBTEST       focal             5             1  0.38    NA 209.695  1 0 #>  #> $Item_26 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5             1 -0.196 0.025 60.776  1 0 #> CSIBTEST       focal             5             1  0.196    NA 60.776  1 0 #>  #> $Item_27 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal             5             1 0.152 0.027 30.646  1 0 #> CSIBTEST       focal             5             1 0.152    NA 30.646  1 0 #>  #> $Item_28 #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal             5             1 -0.311 0.026 138.049  1 0 #> CSIBTEST       focal             5             1  0.311    NA 138.049  1 0 #>  #> $Item_29 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal             5             1 -0.129 0.027 22.567  1 0 #> CSIBTEST       focal             5             1  0.129    NA 22.567  1 0 #>  #> $Item_30 #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal             5             1 -0.335 0.026 166.911  1 0 #> CSIBTEST       focal             5             1  0.335    NA 166.911  1 0 #>   # test DIF using all-other-as-anchors method (not typically recommended) SIBTEST(dat, group, suspect_set = 1:30, DIF=TRUE) #> $Item_1 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal            29             1 0.127 0.028 20.939  1 0 #> CSIBTEST       focal            29             1 0.127    NA 20.939  1 0 #>  #> $Item_2 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.048 0.029 2.801  1 0.094 #> CSIBTEST       focal            29             1 0.089    NA 9.376  2 0.009 #>  #> $Item_3 #>          focal_group n_matched_set n_suspect_set  beta    SE   X2 df     p #> SIBTEST        focal            29             1 0.013 0.026 0.25  1 0.617 #> CSIBTEST       focal            29             1 0.013    NA 0.25  1 0.617 #>  #> $Item_4 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.067 0.023 8.472  1 0.004 #> CSIBTEST       focal            29             1 0.067    NA 8.472  1 0.004 #>  #> $Item_5 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.054 0.028  3.78  1 0.052 #> CSIBTEST       focal            29             1 0.071    NA 6.524  2 0.038 #>  #> $Item_6 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.045 0.027 2.839  1 0.092 #> CSIBTEST       focal            29             1 0.047    NA 3.679  2 0.159 #>  #> $Item_7 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.082 0.028 8.455  1 0.004 #> CSIBTEST       focal            29             1 0.085    NA 9.148  2  0.01 #>  #> $Item_8 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df     p #> SIBTEST        focal            29             1 0.088 0.028 10.042  1 0.002 #> CSIBTEST       focal            29             1 0.108    NA 15.424  2     0 #>  #> $Item_9 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df     p #> SIBTEST        focal            29             1 0.082 0.029  8.256  1 0.004 #> CSIBTEST       focal            29             1 0.099    NA 12.193  2 0.002 #>  #> $Item_10 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.076 0.028 7.264  1 0.007 #> CSIBTEST       focal            29             1 0.076    NA 7.264  1 0.007 #>  #> $Item_11 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df     p #> SIBTEST        focal            29             1 0.096 0.028 12.036  1 0.001 #> CSIBTEST       focal            29             1 0.114    NA 17.072  2     0 #>  #> $Item_12 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal            29             1 0.105 0.027 14.678  1 0 #> CSIBTEST       focal            29             1 0.105    NA 14.678  1 0 #>  #> $Item_13 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.057 0.028 4.098  1 0.043 #> CSIBTEST       focal            29             1 0.057    NA 4.098  1 0.043 #>  #> $Item_14 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.082 0.026 9.589  1 0.002 #> CSIBTEST       focal            29             1 0.082    NA 9.589  1 0.002 #>  #> $Item_15 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.023 0.026 0.779  1 0.378 #> CSIBTEST       focal            29             1 0.023    NA 0.779  1 0.378 #>  #> $Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df     p #> SIBTEST        focal            29             1 -0.092 0.028  10.83  1 0.001 #> CSIBTEST       focal            29             1  0.094    NA 11.373  2 0.003 #>  #> $Item_17 #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal            29             1 -0.328 0.028 137.581  1 0 #> CSIBTEST       focal            29             1  0.328    NA 137.581  1 0 #>  #> $Item_18 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df     p #> SIBTEST        focal            29             1 -0.037 0.026  2.017  1 0.155 #> CSIBTEST       focal            29             1  0.094    NA 14.977  2 0.001 #>  #> $Item_19 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal            29             1 0.315 0.033 93.742  1 0 #> CSIBTEST       focal            29             1 0.315    NA 93.742  1 0 #>  #> $Item_20 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 0.069 0.023 8.926  1 0.003 #> CSIBTEST       focal            29             1 0.069    NA 8.926  1 0.003 #>  #> $Item_21 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal            29             1 -0.225 0.025 80.654  1 0 #> CSIBTEST       focal            29             1  0.225    NA 80.654  1 0 #>  #> $Item_22 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df p #> SIBTEST        focal            29             1 -0.186 0.027 48.41  1 0 #> CSIBTEST       focal            29             1  0.186    NA 48.41  1 0 #>  #> $Item_23 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal            29             1 -0.14 0.028 24.643  1 0 #> CSIBTEST       focal            29             1  0.14    NA 24.643  1 0 #>  #> $Item_24 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal            29             1 0.146 0.026 30.882  1 0 #> CSIBTEST       focal            29             1 0.159    NA 40.395  2 0 #>  #> $Item_25 #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df p #> SIBTEST        focal            29             1 -0.311 0.027 133.904  1 0 #> CSIBTEST       focal            29             1  0.311    NA 133.904  1 0 #>  #> $Item_26 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST        focal            29             1 -0.07 0.025 8.026  1 0.005 #> CSIBTEST       focal            29             1  0.07    NA 8.026  1 0.005 #>  #> $Item_27 #>          focal_group n_matched_set n_suspect_set  beta    SE     X2 df p #> SIBTEST        focal            29             1 0.269 0.029 86.816  1 0 #> CSIBTEST       focal            29             1 0.269    NA 86.816  1 0 #>  #> $Item_28 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal            29             1 -0.237 0.027 74.759  1 0 #> CSIBTEST       focal            29             1  0.237    NA 74.759  1 0 #>  #> $Item_29 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df     p #> SIBTEST        focal            29             1 -0.036 0.027  1.744  1 0.187 #> CSIBTEST       focal            29             1  0.105    NA 14.901  2 0.001 #>  #> $Item_30 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal            29             1 -0.264 0.028 87.158  1 0 #> CSIBTEST       focal            29             1  0.264    NA 87.158  1 0 #>   # randomization method is fairly poor when smaller matched-set used SIBTEST(dat, group, suspect_set = 30, match_set = 1:5, randomize=TRUE) #>          focal_group n_matched_set n_suspect_set   beta    SE      X2 df     p #> SIBTEST        focal             5             1 -0.335 0.026 166.911  1     0 #> CSIBTEST       focal             5             1  0.335 0.026            0.253 SIBTEST(dat, group, suspect_set = 30, randomize=TRUE) #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST        focal            29             1 -0.264 0.028 87.158  1 0 #> CSIBTEST       focal            29             1  0.264 0.028           0  ## ---------------------------------- # three group SIBTEST test set.seed(1234) n <- 30 N <- 1000 a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('group1', N), rep('group2', N), rep('group3', N))  # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N, itemtype = 'dich') dat3 <- simdata(a, d, N, itemtype = 'dich') dat <- rbind(dat1, dat2, dat3)  # omnibus test using effects-coding contrast matrix (default) SIBTEST(dat, group, suspect_set = 6) #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.005 -0.005 0.084  2 0.959 #> GCSIBTEST            29             1  0.004  0.016 1.027          SIBTEST(dat, group, suspect_set = 6, randomize=TRUE) #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.005 -0.005 0.084  2 0.959 #> GCSIBTEST            29             1  0.004  0.016 1.027    0.847  # explicit contrasts SIBTEST(dat, group, suspect_set = 6, randomize=TRUE,         C = matrix(c(1,-1,0), 1)) #>           n_matched_set n_suspect_set   beta    X2 df     p #> GSIBTEST             29             1 -0.003  0.02  1 0.888 #> GCSIBTEST            29             1  0.002 0.009    0.957  # test all items for DIF SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE) #> $Item_1 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.017  0.001 1.008  2 0.604 #> GCSIBTEST            29             1  0.022  0.031 7.502          #>  #> $Item_2 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.046 -0.022 4.695  2 0.096 #> GCSIBTEST            29             1  0.038  0.026 3.452          #>  #> $Item_3 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.001 -0.002 0.009  2 0.996 #> GCSIBTEST            29             1  0.003  0.008 0.298          #>  #> $Item_4 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.002 -0.005 0.193  2 0.908 #> GCSIBTEST            29             1  0.012  0.006 0.609          #>  #> $Item_5 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.028  0.015 1.807  2 0.405 #> GCSIBTEST            29             1  0.028  0.029 7.164          #>  #> $Item_6 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.005 -0.005 0.084  2 0.959 #> GCSIBTEST            29             1  0.004  0.016 1.027          #>  #> $Item_7 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.007  0.015 1.134  2 0.567 #> GCSIBTEST            29             1  0.012  0.015 0.564          #>  #> $Item_8 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.001  0.007 0.147  2 0.929 #> GCSIBTEST            29             1  0.019  0.011 0.835          #>  #> $Item_9 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.046  0.002 6.347  2 0.042 #> GCSIBTEST            29             1  0.037  0.031 3.719          #>  #> $Item_10 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.004  0.002 0.084  2 0.959 #> GCSIBTEST            29             1  0.036  0.014 3.326          #>  #> $Item_11 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.017 -0.015 0.788  2 0.674 #> GCSIBTEST            29             1  0.017  0.017 2.736          #>  #> $Item_12 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.026  0.024  2.02  2 0.364 #> GCSIBTEST            29             1  0.035  0.023 3.074          #>  #> $Item_13 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.005      0 0.088  2 0.957 #> GCSIBTEST            29             1  0.016      0 0.769          #>  #> $Item_14 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.000  0.005 0.085  2 0.959 #> GCSIBTEST            29             1  0.022  0.031 2.229          #>  #> $Item_15 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.013  0.025 1.558  2 0.459 #> GCSIBTEST            29             1  0.011  0.041 4.631          #>  #> $Item_16 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.003 -0.033 2.934  2 0.231 #> GCSIBTEST            29             1  0.021  0.033 2.469          #>  #> $Item_17 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.001  0.001 0.002  2 0.999 #> GCSIBTEST            29             1  0.002  0.006 0.088          #>  #> $Item_18 #>           n_matched_set n_suspect_set beta_1 beta_2     X2 df     p #> GSIBTEST             29             1  -0.06 -0.023  8.761  2 0.013 #> GCSIBTEST            29             1   0.06  0.004 10.588          #>  #> $Item_19 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.005 -0.025 1.591  2 0.451 #> GCSIBTEST            29             1  0.029  0.010 4.078          #>  #> $Item_20 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.011  0.002 0.583  2 0.747 #> GCSIBTEST            29             1  0.011  0.014 2.621          #>  #> $Item_21 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.013  0.031 2.247  2 0.325 #> GCSIBTEST            29             1  0.032  0.031  8.87          #>  #> $Item_22 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.010 -0.019 1.868  2 0.393 #> GCSIBTEST            29             1  0.012  0.019 0.792          #>  #> $Item_23 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.007 -0.018 0.745  2 0.689 #> GCSIBTEST            29             1  0.030  0.018 5.375          #>  #> $Item_24 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.006  0.020 0.891  2 0.641 #> GCSIBTEST            29             1  0.016  0.025  3.57          #>  #> $Item_25 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.027  0.015 3.923  2 0.141 #> GCSIBTEST            29             1  0.027  0.019 1.697          #>  #> $Item_26 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.010  0.010 0.434  2 0.805 #> GCSIBTEST            29             1  0.017  0.005 1.637          #>  #> $Item_27 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.023  0.016 1.272  2 0.529 #> GCSIBTEST            29             1  0.023  0.017 1.288          #>  #> $Item_28 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1 -0.003  0.003 0.087  2 0.957 #> GCSIBTEST            29             1  0.001  0.016 0.844          #>  #> $Item_29 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df    p #> GSIBTEST             29             1 -0.007 -0.027  1.69  2 0.43 #> GCSIBTEST            29             1  0.031  0.027 2.472         #>  #> $Item_30 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.013 -0.011 1.391  2 0.499 #> GCSIBTEST            29             1  0.012  0.020 2.593          #>  SIBTEST(dat, group, suspect_set = 16:ncol(dat), DIF=TRUE,         match_set = 1:15) # specific anchors #> $Item_16 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1 -0.003 -0.035 3.407  2 0.182 #> GCSIBTEST            15             1  0.018  0.035 6.656          #>  #> $Item_17 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df p #> GSIBTEST             15             1  0.000   0.00     0  2 1 #> GCSIBTEST            15             1  0.019   0.03 2.148      #>  #> $Item_18 #>           n_matched_set n_suspect_set beta_1 beta_2     X2 df     p #> GSIBTEST             15             1 -0.064 -0.027 10.021  2 0.007 #> GCSIBTEST            15             1  0.064  0.010  11.28          #>  #> $Item_19 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1 -0.013 -0.029 1.915  2 0.384 #> GCSIBTEST            15             1  0.015  0.027 4.362          #>  #> $Item_20 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1   0.01 -0.002 0.817  2 0.665 #> GCSIBTEST            15             1   0.01  0.008  0.54          #>  #> $Item_21 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1  0.015  0.022 1.116  2 0.572 #> GCSIBTEST            15             1  0.035  0.022 2.729          #>  #> $Item_22 #>           n_matched_set n_suspect_set beta_1 beta_2   X2 df     p #> GSIBTEST             15             1  0.005 -0.026 2.51  2 0.285 #> GCSIBTEST            15             1  0.005  0.026 2.51          #>  #> $Item_23 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1 -0.008 -0.022 1.108  2 0.575 #> GCSIBTEST            15             1  0.007  0.022 2.045          #>  #> $Item_24 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df    p #> GSIBTEST             15             1  0.003  0.016 0.686  2 0.71 #> GCSIBTEST            15             1  0.018  0.023 3.804         #>  #> $Item_25 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1 -0.033  0.007 4.161  2 0.125 #> GCSIBTEST            15             1  0.033  0.007 4.161          #>  #> $Item_26 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1  0.011  0.007 0.338  2 0.845 #> GCSIBTEST            15             1  0.011  0.005 0.729          #>  #> $Item_27 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1  0.021  0.009  0.98  2 0.613 #> GCSIBTEST            15             1  0.023  0.018 1.286          #>  #> $Item_28 #>           n_matched_set n_suspect_set beta_1 beta_2     X2 df     p #> GSIBTEST             15             1 -0.009 -0.003  0.235  2 0.889 #> GCSIBTEST            15             1  0.035  0.028 10.697          #>  #> $Item_29 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1 -0.007 -0.032 2.394  2 0.302 #> GCSIBTEST            15             1  0.018  0.032 5.554          #>  #> $Item_30 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             15             1  0.013 -0.012 1.558  2 0.459 #> GCSIBTEST            15             1  0.013  0.028 1.872          #>   # post-hoc between two groups only pick <- group %in% c('group1', 'group2') SIBTEST(subset(dat, pick), group[pick], suspect_set = 1:ncol(dat), DIF=TRUE) #> $Item_1 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.023 0.02 1.399  1 0.237 #> CSIBTEST      group2            29             1 0.027   NA  1.95  2 0.377 #>  #> $Item_2 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.045 0.021 4.628  1 0.031 #> CSIBTEST      group2            29             1  0.041    NA 4.639  2 0.098 #>  #> $Item_3 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST       group2            29             1 0.003 0.021 0.027  1 0.87 #> CSIBTEST      group2            29             1 0.003    NA 0.027  1 0.87 #>  #> $Item_4 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.015 0.018  1 0.894 #> CSIBTEST      group2            29             1  0.015    NA 1.744  2 0.418 #>  #> $Item_5 #>          focal_group n_matched_set n_suspect_set beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.03 0.021 1.979  1 0.159 #> CSIBTEST      group2            29             1 0.03    NA 1.979  1 0.159 #>  #> $Item_6 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.021 0.005  1 0.942 #> CSIBTEST      group2            29             1  0.003    NA 0.029  2 0.986 #>  #> $Item_7 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.005 0.021  0.06  1 0.807 #> CSIBTEST      group2            29             1  0.012    NA 0.342  2 0.843 #>  #> $Item_8 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST       group2            29             1 -0.002 0.021  0.01  1 0.92 #> CSIBTEST      group2            29             1  0.019    NA 1.123  2 0.57 #>  #> $Item_9 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST       group2            29             1 0.045 0.021 4.696  1 0.03 #> CSIBTEST      group2            29             1 0.035    NA  4.82  2 0.09 #>  #> $Item_10 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.007 0.021 0.121  1 0.728 #> CSIBTEST      group2            29             1  0.036    NA 3.296  2 0.192 #>  #> $Item_11 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST       group2            29             1 -0.017 0.021 0.624  1 0.43 #> CSIBTEST      group2            29             1  0.017    NA 0.624  1 0.43 #>  #> $Item_12 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.026 0.02 1.733  1 0.188 #> CSIBTEST      group2            29             1 0.037   NA 3.391  2 0.183 #>  #> $Item_13 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.021 0.009  1 0.925 #> CSIBTEST      group2            29             1  0.019    NA 1.139  2 0.566 #>  #> $Item_14 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.001 0.022 0.001  1 0.973 #> CSIBTEST      group2            29             1  0.022    NA 1.108  2 0.575 #>  #> $Item_15 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.012 0.02 0.357  1  0.55 #> CSIBTEST      group2            29             1 0.010   NA 0.358  2 0.836 #>  #> $Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.005 0.022 0.064  1 0.801 #> CSIBTEST      group2            29             1  0.016    NA 0.547  2 0.761 #>  #> $Item_17 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.002 0.021 0.011  1 0.916 #> CSIBTEST      group2            29             1 0.003    NA 0.025  2 0.987 #>  #> $Item_18 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group2            29             1 -0.059 0.02 8.584  1 0.003 #> CSIBTEST      group2            29             1  0.059   NA 8.584  1 0.003 #>  #> $Item_19 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.01 0.021 0.248  1 0.619 #> CSIBTEST      group2            29             1  0.02    NA 1.031  2 0.597 #>  #> $Item_20 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.018 0.017 1.224  1 0.268 #> CSIBTEST      group2            29             1 0.018    NA 1.224  1 0.268 #>  #> $Item_21 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.012 0.021 0.338  1 0.561 #> CSIBTEST      group2            29             1 0.030    NA  2.06  2 0.357 #>  #> $Item_22 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.008 0.021 0.141  1 0.707 #> CSIBTEST      group2            29             1 0.008    NA 0.171  2 0.918 #>  #> $Item_23 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.007 0.021 0.126  1 0.723 #> CSIBTEST      group2            29             1  0.031    NA 2.224  2 0.329 #>  #> $Item_24 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.007 0.022 0.105  1 0.746 #> CSIBTEST      group2            29             1 0.012    NA 0.578  2 0.749 #>  #> $Item_25 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.026 0.021 1.468  1 0.226 #> CSIBTEST      group2            29             1  0.026    NA 1.468  1 0.226 #>  #> $Item_26 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.009 0.018 0.219  1  0.64 #> CSIBTEST      group2            29             1 0.019    NA 3.558  2 0.169 #>  #> $Item_27 #>          focal_group n_matched_set n_suspect_set  beta    SE   X2 df     p #> SIBTEST       group2            29             1 0.018 0.021 0.73  1 0.393 #> CSIBTEST      group2            29             1 0.018    NA 0.73  1 0.393 #>  #> $Item_28 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.019 0.015  1 0.903 #> CSIBTEST      group2            29             1  0.000    NA 0.017  2 0.991 #>  #> $Item_29 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST       group2            29             1 -0.010 0.021 0.206  1 0.65 #> CSIBTEST      group2            29             1  0.029    NA 1.883  2 0.39 #>  #> $Item_30 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.012 0.02 0.348  1 0.555 #> CSIBTEST      group2            29             1 0.012   NA 0.402  2 0.818 #>   # post-hoc pairwise comparison for all groups SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE, pairwise = TRUE) #> $group1_group2 #> $group1_group2$Item_1 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.023 0.02 1.399  1 0.237 #> CSIBTEST      group2            29             1 0.027   NA  1.95  2 0.377 #>  #> $group1_group2$Item_2 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.045 0.021 4.628  1 0.031 #> CSIBTEST      group2            29             1  0.041    NA 4.639  2 0.098 #>  #> $group1_group2$Item_3 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST       group2            29             1 0.003 0.021 0.027  1 0.87 #> CSIBTEST      group2            29             1 0.003    NA 0.027  1 0.87 #>  #> $group1_group2$Item_4 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.015 0.018  1 0.894 #> CSIBTEST      group2            29             1  0.015    NA 1.744  2 0.418 #>  #> $group1_group2$Item_5 #>          focal_group n_matched_set n_suspect_set beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.03 0.021 1.979  1 0.159 #> CSIBTEST      group2            29             1 0.03    NA 1.979  1 0.159 #>  #> $group1_group2$Item_6 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.021 0.005  1 0.942 #> CSIBTEST      group2            29             1  0.003    NA 0.029  2 0.986 #>  #> $group1_group2$Item_7 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.005 0.021  0.06  1 0.807 #> CSIBTEST      group2            29             1  0.012    NA 0.342  2 0.843 #>  #> $group1_group2$Item_8 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST       group2            29             1 -0.002 0.021  0.01  1 0.92 #> CSIBTEST      group2            29             1  0.019    NA 1.123  2 0.57 #>  #> $group1_group2$Item_9 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df    p #> SIBTEST       group2            29             1 0.045 0.021 4.696  1 0.03 #> CSIBTEST      group2            29             1 0.035    NA  4.82  2 0.09 #>  #> $group1_group2$Item_10 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.007 0.021 0.121  1 0.728 #> CSIBTEST      group2            29             1  0.036    NA 3.296  2 0.192 #>  #> $group1_group2$Item_11 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST       group2            29             1 -0.017 0.021 0.624  1 0.43 #> CSIBTEST      group2            29             1  0.017    NA 0.624  1 0.43 #>  #> $group1_group2$Item_12 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.026 0.02 1.733  1 0.188 #> CSIBTEST      group2            29             1 0.037   NA 3.391  2 0.183 #>  #> $group1_group2$Item_13 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.021 0.009  1 0.925 #> CSIBTEST      group2            29             1  0.019    NA 1.139  2 0.566 #>  #> $group1_group2$Item_14 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.001 0.022 0.001  1 0.973 #> CSIBTEST      group2            29             1  0.022    NA 1.108  2 0.575 #>  #> $group1_group2$Item_15 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.012 0.02 0.357  1  0.55 #> CSIBTEST      group2            29             1 0.010   NA 0.358  2 0.836 #>  #> $group1_group2$Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.005 0.022 0.064  1 0.801 #> CSIBTEST      group2            29             1  0.016    NA 0.547  2 0.761 #>  #> $group1_group2$Item_17 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.002 0.021 0.011  1 0.916 #> CSIBTEST      group2            29             1 0.003    NA 0.025  2 0.987 #>  #> $group1_group2$Item_18 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group2            29             1 -0.059 0.02 8.584  1 0.003 #> CSIBTEST      group2            29             1  0.059   NA 8.584  1 0.003 #>  #> $group1_group2$Item_19 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.01 0.021 0.248  1 0.619 #> CSIBTEST      group2            29             1  0.02    NA 1.031  2 0.597 #>  #> $group1_group2$Item_20 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.018 0.017 1.224  1 0.268 #> CSIBTEST      group2            29             1 0.018    NA 1.224  1 0.268 #>  #> $group1_group2$Item_21 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.012 0.021 0.338  1 0.561 #> CSIBTEST      group2            29             1 0.030    NA  2.06  2 0.357 #>  #> $group1_group2$Item_22 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.008 0.021 0.141  1 0.707 #> CSIBTEST      group2            29             1 0.008    NA 0.171  2 0.918 #>  #> $group1_group2$Item_23 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.007 0.021 0.126  1 0.723 #> CSIBTEST      group2            29             1  0.031    NA 2.224  2 0.329 #>  #> $group1_group2$Item_24 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.007 0.022 0.105  1 0.746 #> CSIBTEST      group2            29             1 0.012    NA 0.578  2 0.749 #>  #> $group1_group2$Item_25 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.026 0.021 1.468  1 0.226 #> CSIBTEST      group2            29             1  0.026    NA 1.468  1 0.226 #>  #> $group1_group2$Item_26 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.009 0.018 0.219  1  0.64 #> CSIBTEST      group2            29             1 0.019    NA 3.558  2 0.169 #>  #> $group1_group2$Item_27 #>          focal_group n_matched_set n_suspect_set  beta    SE   X2 df     p #> SIBTEST       group2            29             1 0.018 0.021 0.73  1 0.393 #> CSIBTEST      group2            29             1 0.018    NA 0.73  1 0.393 #>  #> $group1_group2$Item_28 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group2            29             1 -0.002 0.019 0.015  1 0.903 #> CSIBTEST      group2            29             1  0.000    NA 0.017  2 0.991 #>  #> $group1_group2$Item_29 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df    p #> SIBTEST       group2            29             1 -0.010 0.021 0.206  1 0.65 #> CSIBTEST      group2            29             1  0.029    NA 1.883  2 0.39 #>  #> $group1_group2$Item_30 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group2            29             1 0.012 0.02 0.348  1 0.555 #> CSIBTEST      group2            29             1 0.012   NA 0.402  2 0.818 #>  #>  #> $group1_group3 #> $group1_group3$Item_1 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.002 0.02 0.006  1 0.937 #> CSIBTEST      group3            29             1 0.032   NA 4.561  2 0.102 #>  #> $group1_group3$Item_2 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.022 0.021 1.079  1 0.299 #> CSIBTEST      group3            29             1  0.024    NA 1.265  2 0.531 #>  #> $group1_group3$Item_3 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.003 0.02 0.021  1 0.886 #> CSIBTEST      group3            29             1  0.009   NA  0.21  2   0.9 #>  #> $group1_group3$Item_4 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.003 0.016 0.043  1 0.836 #> CSIBTEST      group3            29             1  0.004    NA 0.079  2 0.961 #>  #> $group1_group3$Item_5 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.019 0.021 0.757  1 0.384 #> CSIBTEST      group3            29             1 0.033    NA  2.45  2 0.294 #>  #> $group1_group3$Item_6 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.006 0.021 0.079  1 0.779 #> CSIBTEST      group3            29             1  0.017    NA 0.819  2 0.664 #>  #> $group1_group3$Item_7 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.016 0.021 0.589  1 0.443 #> CSIBTEST      group3            29             1 0.016    NA 0.589  1 0.443 #>  #> $group1_group3$Item_8 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.007 0.021 0.103  1 0.748 #> CSIBTEST      group3            29             1 0.010    NA  0.26  2 0.878 #>  #> $group1_group3$Item_9 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.002 0.021 0.013  1 0.911 #> CSIBTEST      group3            29             1 0.032    NA   2.8  2 0.247 #>  #> $group1_group3$Item_10 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.002 0.02  0.01  1 0.919 #> CSIBTEST      group3            29             1 0.015   NA 0.974  2 0.615 #>  #> $group1_group3$Item_11 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.014 0.021 0.447  1 0.504 #> CSIBTEST      group3            29             1  0.014    NA 1.612  2 0.447 #>  #> $group1_group3$Item_12 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.024 0.02 1.397  1 0.237 #> CSIBTEST      group3            29             1 0.023   NA 1.453  2 0.484 #>  #> $group1_group3$Item_13 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.006 0.021 0.092  1 0.762 #> CSIBTEST      group3            29             1  0.000    NA 0.126  2 0.939 #>  #> $group1_group3$Item_14 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.004 0.021 0.032  1 0.859 #> CSIBTEST      group3            29             1 0.032    NA 2.534  2 0.282 #>  #> $group1_group3$Item_15 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.023 0.02 1.367  1 0.242 #> CSIBTEST      group3            29             1 0.040   NA 5.532  2 0.063 #>  #> $group1_group3$Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.034 0.021 2.489  1 0.115 #> CSIBTEST      group3            29             1  0.034    NA 2.489  1 0.115 #>  #> $group1_group3$Item_17 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.000 0.021     0  1 0.985 #> CSIBTEST      group3            29             1 0.007    NA 0.141  2 0.932 #>  #> $group1_group3$Item_18 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.022 0.02 1.216  1  0.27 #> CSIBTEST      group3            29             1  0.001   NA  2.58  2 0.275 #>  #> $group1_group3$Item_19 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.025 0.02 1.525  1 0.217 #> CSIBTEST      group3            29             1  0.010   NA 1.879  2 0.391 #>  #> $group1_group3$Item_20 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.003 0.015 0.034  1 0.854 #> CSIBTEST      group3            29             1 0.014    NA 1.113  2 0.573 #>  #> $group1_group3$Item_21 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.031 0.021 2.216  1 0.137 #> CSIBTEST      group3            29             1 0.031    NA 2.216  1 0.137 #>  #> $group1_group3$Item_22 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.018 0.021 0.676  1 0.411 #> CSIBTEST      group3            29             1  0.018    NA 0.676  1 0.411 #>  #> $group1_group3$Item_23 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.019 0.021 0.823  1 0.364 #> CSIBTEST      group3            29             1  0.019    NA 0.823  1 0.364 #>  #> $group1_group3$Item_24 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.018 0.021  0.75  1 0.386 #> CSIBTEST      group3            29             1 0.026    NA 1.727  2 0.422 #>  #> $group1_group3$Item_25 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.013 0.021 0.392  1 0.532 #> CSIBTEST      group3            29             1 0.018    NA 0.746  2 0.689 #>  #> $group1_group3$Item_26 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.010 0.018 0.304  1 0.581 #> CSIBTEST      group3            29             1 0.005    NA 0.325  2  0.85 #>  #> $group1_group3$Item_27 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.017 0.021 0.649  1 0.421 #> CSIBTEST      group3            29             1 0.025    NA 1.722  2 0.423 #>  #> $group1_group3$Item_28 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.001 0.02 0.003  1 0.954 #> CSIBTEST      group3            29             1 0.009   NA 0.349  2  0.84 #>  #> $group1_group3$Item_29 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.028 0.021 1.764  1 0.184 #> CSIBTEST      group3            29             1  0.028    NA 1.764  1 0.184 #>  #> $group1_group3$Item_30 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.011 0.02 0.316  1 0.574 #> CSIBTEST      group3            29             1  0.025   NA 1.705  2 0.426 #>  #>  #> $group2_group3 #> $group2_group3$Item_1 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.020 0.019 1.056  1 0.304 #> CSIBTEST      group3            29             1  0.003    NA 1.628  2 0.443 #>  #> $group2_group3$Item_2 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.023 0.021 1.233  1 0.267 #> CSIBTEST      group3            29             1 0.023    NA 1.233  1 0.267 #>  #> $group2_group3$Item_3 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.000 0.02     0  1 0.993 #> CSIBTEST      group3            29             1 0.003   NA 0.122  2 0.941 #>  #> $group2_group3$Item_4 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.005 0.015  0.12  1 0.729 #> CSIBTEST      group3            29             1 0.001    NA 0.339  2 0.844 #>  #> $group2_group3$Item_5 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.01 0.021  0.23  1 0.631 #> CSIBTEST      group3            29             1  0.00    NA 0.241  2 0.886 #>  #> $group2_group3$Item_6 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.006 0.021 0.078  1 0.779 #> CSIBTEST      group3            29             1  0.006    NA 0.078  1 0.779 #>  #> $group2_group3$Item_7 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.019 0.021 0.791  1 0.374 #> CSIBTEST      group3            29             1 0.019    NA 0.791  1 0.374 #>  #> $group2_group3$Item_8 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.007 0.021 0.102  1  0.75 #> CSIBTEST      group3            29             1 0.013    NA  0.84  2 0.657 #>  #> $group2_group3$Item_9 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.045 0.021 4.764  1 0.029 #> CSIBTEST      group3            29             1  0.045    NA 4.764  1 0.029 #>  #> $group2_group3$Item_10 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.008 0.021 0.139  1 0.709 #> CSIBTEST      group3            29             1 0.014    NA 0.468  2 0.791 #>  #> $group2_group3$Item_11 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.001 0.021 0.001  1 0.978 #> CSIBTEST      group3            29             1  0.017    NA 0.866  2 0.648 #>  #> $group2_group3$Item_12 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.000 0.02     0  1 0.991 #> CSIBTEST      group3            29             1 0.002   NA 0.007  2 0.996 #>  #> $group2_group3$Item_13 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.002 0.021 0.014  1 0.907 #> CSIBTEST      group3            29             1 0.008    NA 0.204  2 0.903 #>  #> $group2_group3$Item_14 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.005 0.021 0.051  1 0.822 #> CSIBTEST      group3            29             1 0.011    NA 1.915  2 0.384 #>  #> $group2_group3$Item_15 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.011 0.02 0.335  1 0.563 #> CSIBTEST      group3            29             1 0.049   NA 6.682  2 0.035 #>  #> $group2_group3$Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.031 0.021 2.131  1 0.144 #> CSIBTEST      group3            29             1  0.029    NA 2.194  2 0.334 #>  #> $group2_group3$Item_17 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.004 0.021 0.029  1 0.864 #> CSIBTEST      group3            29             1  0.001    NA  0.03  2 0.985 #>  #> $group2_group3$Item_18 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.038 0.021 3.351  1 0.067 #> CSIBTEST      group3            29             1 0.038    NA 3.351  1 0.067 #>  #> $group2_group3$Item_19 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.021 0.021  1.06  1 0.303 #> CSIBTEST      group3            29             1  0.006    NA 3.523  2 0.172 #>  #> $group2_group3$Item_20 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.017 0.017 0.992  1 0.319 #> CSIBTEST      group3            29             1  0.017    NA 0.992  1 0.319 #>  #> $group2_group3$Item_21 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.016 0.021 0.578  1 0.447 #> CSIBTEST      group3            29             1 0.034    NA 4.188  2 0.123 #>  #> $group2_group3$Item_22 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.033 0.021 2.372  1 0.124 #> CSIBTEST      group3            29             1  0.033    NA 2.372  1 0.124 #>  #> $group2_group3$Item_23 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.009 0.021 0.178  1 0.673 #> CSIBTEST      group3            29             1  0.024    NA 1.949  2 0.377 #>  #> $group2_group3$Item_24 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group3            29             1 0.008 0.022 0.151  1 0.698 #> CSIBTEST      group3            29             1 0.018    NA 0.683  2 0.711 #>  #> $group2_group3$Item_25 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.043 0.02 4.495  1 0.034 #> CSIBTEST      group3            29             1 0.043   NA 4.495  1 0.034 #>  #> $group2_group3$Item_26 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.003 0.019 0.025  1 0.875 #> CSIBTEST      group3            29             1  0.023    NA  3.11  2 0.211 #>  #> $group2_group3$Item_27 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.002 0.021 0.007  1 0.933 #> CSIBTEST      group3            29             1  0.013    NA 0.373  2  0.83 #>  #> $group2_group3$Item_28 #>          focal_group n_matched_set n_suspect_set  beta   SE    X2 df     p #> SIBTEST       group3            29             1 0.002 0.02 0.013  1 0.909 #> CSIBTEST      group3            29             1 0.008   NA 0.354  2 0.838 #>  #> $group2_group3$Item_29 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.018 0.022 0.722  1 0.395 #> CSIBTEST      group3            29             1  0.026    NA 1.466  2 0.481 #>  #> $group2_group3$Item_30 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.029 0.02 1.973  1  0.16 #> CSIBTEST      group3            29             1  0.032   NA 2.615  2 0.271 #>  #>   ## systematic differing slopes and intercepts dat2 <- simdata(a + c(numeric(15), .5,.5,.5,.5,.5, numeric(10)),         d + c(numeric(15), 0,.6,.7,.8,.9, numeric(10)),         N, itemtype = 'dich') dat <- rbind(dat1, dat2, dat3)  SIBTEST(dat, group, suspect_set = 16) #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.008 -0.034 4.642  2 0.098 #> GCSIBTEST            29             1  0.059  0.034 8.205          SIBTEST(dat, group, suspect_set = 16, randomize=TRUE) #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.008 -0.034 4.642  2 0.098 #> GCSIBTEST            29             1  0.059  0.034 8.205    0.125  SIBTEST(dat, group, suspect_set = 19) #>           n_matched_set n_suspect_set beta_1 beta_2     X2 df p #> GSIBTEST             29             1 -0.136 -0.025 52.967  2 0 #> GCSIBTEST            29             1  0.130  0.009 61.401      SIBTEST(dat, group, suspect_set = 19, randomize=TRUE) #>           n_matched_set n_suspect_set beta_1 beta_2     X2 df p #> GSIBTEST             29             1 -0.136 -0.025 52.967  2 0 #> GCSIBTEST            29             1  0.130  0.009 61.401    0  SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE) #> $Item_16 #>           n_matched_set n_suspect_set beta_1 beta_2    X2 df     p #> GSIBTEST             29             1  0.008 -0.034 4.642  2 0.098 #> GCSIBTEST            29             1  0.059  0.034 8.205          #>  #> $Item_19 #>           n_matched_set n_suspect_set beta_1 beta_2     X2 df p #> GSIBTEST             29             1 -0.136 -0.025 52.967  2 0 #> GCSIBTEST            29             1  0.130  0.009 61.401      #>  SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE, pairwise=TRUE) #> $group1_group2 #> $group1_group2$Item_16 #>          focal_group n_matched_set n_suspect_set  beta    SE    X2 df     p #> SIBTEST       group2            29             1 0.008 0.021 0.154  1 0.695 #> CSIBTEST      group2            29             1 0.057    NA 9.536  2 0.008 #>  #> $group1_group2$Item_19 #>          focal_group n_matched_set n_suspect_set   beta    SE     X2 df p #> SIBTEST       group2            29             1 -0.138 0.021 45.595  1 0 #> CSIBTEST      group2            29             1  0.141    NA 47.776  2 0 #>  #>  #> $group1_group3 #> $group1_group3$Item_16 #>          focal_group n_matched_set n_suspect_set   beta    SE    X2 df     p #> SIBTEST       group3            29             1 -0.034 0.021 2.489  1 0.115 #> CSIBTEST      group3            29             1  0.034    NA 2.489  1 0.115 #>  #> $group1_group3$Item_19 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.025 0.02 1.525  1 0.217 #> CSIBTEST      group3            29             1  0.010   NA 1.879  2 0.391 #>  #>  #> $group2_group3 #> $group2_group3$Item_16 #>          focal_group n_matched_set n_suspect_set   beta   SE    X2 df     p #> SIBTEST       group3            29             1 -0.039 0.02 3.721  1 0.054 #> CSIBTEST      group3            29             1  0.040   NA 4.185  2 0.123 #>  #> $group2_group3$Item_19 #>          focal_group n_matched_set n_suspect_set  beta   SE     X2 df p #> SIBTEST       group3            29             1 0.112 0.02 30.503  1 0 #> CSIBTEST      group3            29             1 0.118   NA 37.348  2 0 #>  #>    # }"},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":null,"dir":"Reference","previous_headings":"","what":"Social Life Feelings Data — SLF","title":"Social Life Feelings Data — SLF","text":"5-item data set analyzed Bartholomew (1998). Data contains dichotomous responses (endorsement vs non-endorsement) 1490 German respondents five statements perceptions social life.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Social Life Feelings Data — SLF","text":"Bartholomew, D., J. (1998). Scaling unobservable constructs social science. Journal Royal Statistical Society - Series C, 47, 1-13.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Social Life Feelings Data — SLF","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SLF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Social Life Feelings Data — SLF","text":"","code":"# \\donttest{ # tabular format data(SLF) SLF #>    social1 social2 social3 social4 social5 freq #> 1        0       0       0       0       0  156 #> 2        0       0       0       0       1   26 #> 3        0       0       0       1       0   14 #> 4        0       0       0       1       1    9 #> 5        0       0       1       0       0  127 #> 6        0       0       1       0       1   26 #> 7        0       0       1       1       0   66 #> 8        0       0       1       1       1   16 #> 9        0       1       0       0       0  174 #> 10       0       1       0       0       1   35 #> 11       0       1       0       1       0   36 #> 12       0       1       0       1       1   13 #> 13       0       1       1       0       0  208 #> 14       0       1       1       0       1   65 #> 15       0       1       1       1       0  195 #> 16       0       1       1       1       1  129 #> 17       1       0       0       0       0    8 #> 18       1       0       0       0       1    2 #> 19       1       0       0       1       0    1 #> 20       1       0       0       1       1    3 #> 21       1       0       1       0       0    4 #> 22       1       0       1       0       1    4 #> 23       1       0       1       1       0   18 #> 24       1       0       1       1       1    9 #> 25       1       1       0       0       0    8 #> 26       1       1       0       0       1    2 #> 27       1       1       0       1       0    5 #> 28       1       1       0       1       1    3 #> 29       1       1       1       0       0   19 #> 30       1       1       1       0       1   10 #> 31       1       1       1       1       0   31 #> 32       1       1       1       1       1   68  # full dataset full <- expand.table(SLF) itemstats(full) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1490            2.166          1.324 0.187 0.076 0.536     0.902 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> social1 1490 2 0.131 0.337   0.482         0.251       0.510 #> social2 1490 2 0.672 0.470   0.550         0.227       0.527 #> social3 1490 2 0.668 0.471   0.632         0.335       0.458 #> social4 1490 2 0.413 0.493   0.702         0.420       0.397 #> social5 1490 2 0.282 0.450   0.578         0.281       0.493 #>  #> $proportions #>             0     1 #> social1 0.869 0.131 #> social2 0.328 0.672 #> social3 0.332 0.668 #> social4 0.587 0.413 #> social5 0.718 0.282 #>   mod <- mirt(full) #>  plot(mod, type = 'trace')   # }"},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of Science data — Science","title":"Description of Science data — Science","text":"4-item data set borrowed ltm package R, first example grm() function. See complete documentation therein, well Karlheinz Melich (1992).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of Science data — Science","text":"Karlheinz, R. Melich, . (1992). Euro-Barometer 38.1: Consumer Protection Perceptions Science Technology. INRA (Europe), Brussels. [computer file]","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of Science data — Science","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/Science.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of Science data — Science","text":"","code":"# \\donttest{ itemstats(Science) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  392           11.668          2.003 0.275 0.098 0.598      1.27 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 392 4 3.120 0.588   0.596         0.352       0.552 #> Work    392 4 2.722 0.807   0.666         0.332       0.567 #> Future  392 4 2.990 0.757   0.748         0.488       0.437 #> Benefit 392 4 2.837 0.802   0.684         0.363       0.541 #>  #> $proportions #>             1     2     3     4 #> Comfort 0.013 0.082 0.679 0.227 #> Work    0.084 0.250 0.526 0.140 #> Future  0.036 0.184 0.536 0.245 #> Benefit 0.054 0.255 0.492 0.199 #>   mod <- mirt(Science, 1) #>  plot(mod, type = 'trace')  # }"},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"Defines object returned mirt model exploratory.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"Class ","text":"Call: function call Data: list data, sometimes different forms Options: list estimation options Fit: list fit information Model: list model-based information ParObjects: list S4 objects used estimation OptimInfo: list arguments optimization process Internals: list internal arguments secondary computations (inspecting       object generally required) vcov: matrix represented asymptotic covariance matrix parameter estimates time: data.frame indicating breakdown computation times seconds","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Class ","text":"anova signature(object = \"SingleGroupClass\") coef signature(object = \"SingleGroupClass\") plot signature(x = \"SingleGroupClass\", y = \"missing\") print signature(x = \"SingleGroupClass\") residuals signature(object = \"SingleGroupClass\") show signature(object = \"SingleGroupClass\") summary signature(object = \"SingleGroupClass\")","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Class ","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/SingleGroupClass-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Class ","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare nested models with likelihood-based statistics — anova-method","title":"Compare nested models with likelihood-based statistics — anova-method","text":"Compare nested models using likelihood ratio test (X2), Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), Sample-Size Adjusted BIC (SABIC), Hannan-Quinn (HQ) Criterion. given sequence objects, anova tests models one another order specified. Note object inputs ordered terms constrained model least constrained.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare nested models with likelihood-based statistics — anova-method","text":"","code":"# S4 method for class 'SingleGroupClass' anova(   object,   object2,   ...,   bounded = FALSE,   mix = 0.5,   frame = 1,   verbose = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare nested models with likelihood-based statistics — anova-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass, reflecting constrained model fitted object2 second model estimated mirt package estimation methods ... additional less constrained model objects compared sequentially previous model bounded logical; two models comparing bounded parameter (e.g., comparing single 2PL 3PL model 1 df)? TRUE 50:50 mix chi-squared distributions used obtain p-value mix proportion chi-squared mixtures. Default 0.5 frame (internal parameter standard use) verbose (deprecated argument)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare nested models with likelihood-based statistics — anova-method","text":"data.frame/mirt_df object","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compare nested models with likelihood-based statistics — anova-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/anova-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare nested models with likelihood-based statistics — anova-method","text":"","code":"# \\donttest{ x <- mirt(Science, 1) #>  x2 <- mirt(Science, 2) #>  anova(x, x2) #>         AIC    SABIC       HQ      BIC    logLik     X2 df     p #> x  3249.739 3262.512 3274.922 3313.279 -1608.870                 #> x2 3241.938 3257.106 3271.843 3317.392 -1601.969 13.801  3 0.003  # compare three models sequentially (X2 not always meaningful) x3 <- mirt(Science, 1, 'gpcm') #>  x4 <- mirt(Science, 1, 'nominal') #>  anova(x, x2, x3, x4) #>         AIC    SABIC       HQ      BIC    logLik      X2 df     p #> x  3249.739 3262.512 3274.922 3313.279 -1608.870                  #> x2 3241.938 3257.106 3271.843 3317.392 -1601.969  13.801  3 0.003 #> x3 3257.366 3270.139 3282.549 3320.906 -1612.683 -21.428 -3   NaN #> x4 3264.910 3284.069 3302.684 3360.220 -1608.455   8.456  8  0.39  # in isolation anova(x) #>        AIC    SABIC       HQ      BIC   logLik #> x 3249.739 3262.512 3274.922 3313.279 -1608.87  # with priors on first model model <- \"Theta = 1-4           PRIOR = (1-4, a1, lnorm, 0, 10)\" xp <- mirt(Science, model) #>  anova(xp, x2) #>         AIC    SABIC       HQ      BIC    logLik   logPost df #> xp 3249.829 3262.602 3275.012 3313.369 -1608.914 -1622.881 NA #> x2 3241.938 3257.106 3271.843 3317.392 -1601.969 -1601.969  3 anova(xp) #>         AIC    SABIC       HQ      BIC    logLik   logPost #> xp 3249.829 3262.602 3275.012 3313.369 -1608.914 -1622.881  # bounded parameter dat <- expand.table(LSAT7) mod <- mirt(dat, 1) #>  mod2 <- mirt(dat, 1, itemtype = c(rep('2PL', 4), '3PL')) #>  anova(mod, mod2) #unbounded test #>           AIC    SABIC       HQ      BIC    logLik    X2 df    p #> mod  5337.610 5354.927 5356.263 5386.688 -2658.805               #> mod2 5339.587 5358.636 5360.106 5393.573 -2658.794 0.023  1 0.88 anova(mod, mod2, bounded = TRUE) #bounded #>           AIC    SABIC       HQ      BIC    logLik    X2 df    p #> mod  5337.610 5354.927 5356.263 5386.688 -2658.805               #> mod2 5339.587 5358.636 5360.106 5393.573 -2658.794 0.023  1 0.44  # priors model <- 'F = 1-5           PRIOR = (5, g, norm, -1, 1)' mod1b <- mirt(dat, model, itemtype = c(rep('2PL', 4), '3PL')) #>  anova(mod1b) #>            AIC   SABIC       HQ      BIC    logLik   logPost #> mod1b 5339.571 5358.62 5360.089 5393.557 -2658.786 -2659.705  model2 <- 'F = 1-5           PRIOR = (1-5, g, norm, -1, 1)' mod2b <- mirt(dat, model2, itemtype = '3PL') #>  anova(mod1b, mod2b) #>            AIC    SABIC       HQ      BIC    logLik   logPost df #> mod1b 5339.571 5358.620 5360.089 5393.557 -2658.786 -2659.705 NA #> mod2b 5348.306 5374.282 5376.286 5421.923 -2659.153 -2664.008  4  # }"},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the area under a selection of information curves — areainfo","title":"Function to calculate the area under a selection of information curves — areainfo","text":"Compute area test item information function definite integral range.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the area under a selection of information curves — areainfo","text":"","code":"areainfo(   x,   theta_lim,   which.items = 1:extract.mirt(x, \"nitems\"),   group = NULL,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the area under a selection of information curves — areainfo","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied theta_lim range integration computed .items integer vector indicating items include expected information function. Default uses possible items group group argument pass extract.group function. Required input object multiple-group model ... additional arguments passed integrate","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to calculate the area under a selection of information curves — areainfo","text":"data.frame lower upper integration range, information area   within range (Info), information area range -10 10 (Total.Info), proportion   total information given integration range (Info.Proportion), number items included (nitems)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate the area under a selection of information curves — areainfo","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate the area under a selection of information curves — areainfo","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/areainfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate the area under a selection of information curves — areainfo","text":"","code":"dat <- expand.table(LSAT7) mod <- mirt(dat, 1) #>   areainfo(mod, c(-2,0), which.items = 1) #item 1 #>  LowerBound UpperBound      Info TotalInfo Proportion nitems #>          -2          0 0.3899825 0.9879254  0.3947489      1 # \\donttest{ areainfo(mod, c(-2,0), which.items = 1:3) #items 1 to 3 #>  LowerBound UpperBound     Info TotalInfo Proportion nitems #>          -2          0 2.095673  3.774611  0.5552023      3 areainfo(mod, c(-2,0)) # all items (total test information) #>  LowerBound UpperBound     Info TotalInfo Proportion nitems #>          -2          0 2.568988  5.275594  0.4869571      5  # plot the area area <- areainfo(mod, c(-2,0)) Theta <- matrix(seq(-3,3, length.out=1000)) info <- testinfo(mod, Theta) plot(info ~ Theta, type = 'l')  pick <- Theta >= -2 & Theta <=0 polygon(c(-2, Theta[pick], 0), c(0, info[pick], 0), col='lightblue') text(x = 2, y = 0.5, labels = paste(\"Total Information:\", round(area$TotalInfo, 3),            \"\\n\\nInformation in (-2, 0):\", round(area$Info, 3),            paste(\"(\", round(100 * area$Proportion, 2), \"%)\", sep = \"\")), cex = 1.2)   # }"},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse values from multiple imputation draws — averageMI","title":"Collapse values from multiple imputation draws — averageMI","text":"function computes updated parameter standard error estimates using multiple imputation methodology. Given set parameter estimates associated standard errors function returns weighted average overall within variability due multiple imputations according Rubin's (1987) methodology.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse values from multiple imputation draws — averageMI","text":"","code":"averageMI(par, SEpar, as.data.frame = TRUE)"},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse values from multiple imputation draws — averageMI","text":"par list containing parameter estimates computed imputed datasets SEpar list containing standard errors associated par .data.frame logical; return data.frame instead list? Default TRUE","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse values from multiple imputation draws — averageMI","text":"returns list data.frame containing updated averaged parameter estimates,   standard errors, t-values associated degrees freedom two tailed p-values","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Collapse values from multiple imputation draws — averageMI","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Rubin, D.B. (1987) Multiple Imputation Nonresponse Surveys. Wiley & Sons, New York.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Collapse values from multiple imputation draws — averageMI","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/averageMI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collapse values from multiple imputation draws — averageMI","text":"","code":"# \\donttest{  # simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  # items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  mod1 <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) #>  coef(mod1, simplify=TRUE) #> $items #>         a1      d g u #> Item_1   1 -0.409 0 1 #> Item_2   1  0.491 0 1 #> Item_3   1  0.313 0 1 #> Item_4   1  1.965 0 1 #> Item_5   1  1.753 0 1 #> Item_6   1 -0.246 0 1 #> Item_7   1 -1.077 0 1 #> Item_8   1  0.533 0 1 #> Item_9   1 -1.232 0 1 #> Item_10  1  0.603 0 1 #> Item_11  1 -0.404 0 1 #> Item_12  1  1.238 0 1 #> Item_13  1  1.033 0 1 #> Item_14  1  1.524 0 1 #> Item_15  1 -0.548 0 1 #> Item_16  1  2.075 0 1 #> Item_17  1 -0.695 0 1 #> Item_18  1 -1.200 0 1 #> Item_19  1  0.121 0 1 #> Item_20  1  0.523 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 0.215 #>  #> $lr.betas #>                 F1 #> (Intercept)  0.000 #> X1           0.527 #> X2          -1.036 #>   # draw plausible values for secondary analyses pv <- fscores(mod1, plausible.draws = 10) pvmods <- lapply(pv, function(x, covdata) lm(x ~ covdata$X1 + covdata$X2),                  covdata=covdata)  # compute Rubin's multiple imputation average so <- lapply(pvmods, summary) par <- lapply(so, function(x) x$coefficients[, 'Estimate']) SEpar <- lapply(so, function(x) x$coefficients[, 'Std. Error']) averageMI(par, SEpar) #>                par SEpar       t      df     p #> (Intercept)  0.003 0.016   0.209 198.552 0.209 #> covdata$X1   0.528 0.018  28.554  63.384     0 #> covdata$X2  -1.037 0.021 -49.311  35.705     0  # }"},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"bfactor fits confirmatory maximum likelihood two-tier/bifactor/testlet model dichotomous polytomous data item response theory paradigm. IRT models fit using dimensional reduction EM algorithm regardless number specific factors estimated model uses number factors second-tier structure plus 1. bifactor model maximum number dimensions 2 since second-tier consists ubiquitous unidimensional factor. See mirt appropriate methods used objects returned estimation.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"","code":"bfactor(   data,   model,   model2 = paste0(\"G = 1-\", ncol(data)),   group = NULL,   quadpts = NULL,   invariance = \"\",   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"data matrix data.frame consists numerically ordered data, organized form integers, missing data coded NA model numeric vector specifying factor loads   item. example, 4 item test two specific factors, first   specific factor loads first two items second specific factor   last two, vector c(1,1,2,2). items load   second-tier factors (specific component) NA values may   used place-holders. numbers translated format suitable   mirt.model(), combined definition model2, letter 'S'   added respective factor number Alternatively, input can specified using mirt.model syntax   restriction item must load exactly one specific factor (specific factors,   predicted general factor specified model2) model2 two-tier model specification object defined mirt.model() string passed mirt.model. default model fit unidimensional model second-tier, therefore equivalent bifactor model group factor variable indicating group membership used multiple group analyses quadpts number quadrature nodes use accounting reduced number dimensions. Scheme one used mirt, however regards reduced dimensions (e.g., bifactor model 2 dimensions integrated) invariance see multipleGroup details, however, specific factor variances means constrained according dimensional reduction algorithm ... additional arguments passed estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"function returns object class SingleGroupClass   (SingleGroupClass-class) MultipleGroupClass(MultipleGroupClass-class).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"bfactor follows item factor analysis strategy explicated Gibbons Hedeker (1992), Gibbons et al. (2007), Cai (2010). Nested models may compared via approximate chi-squared difference test reduction AIC BIC (accessible via anova). See mirt details regarding IRT estimation approach used package. two-tier model specific block diagonal covariance structure primary secondary latent traits. Namely, secondary latent traits assumed orthogonal traits fixed variance 1, primary traits can organized vary covary primary traits model. $$\\Sigma_{two-tier} = \\left(\\begin{array}{cc} G & 0 \\\\ 0 & diag(S) \\end{array} \\right)$$ bifactor model special case two-tier model \\(G\\) 1x1 matrix, therefore 1 primary factor modeled. Evaluation numerical integrals two-tier model requires \\(ncol(G) + 1\\) dimensions integration since \\(S\\) second order ('specific') factors require 1 integration grid due dimension reduction technique. Note: multiple group two-tier analyses second-tier means variances freed since specific factors treated independently due dimension reduction technique.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"Cai, L. (2010). two-tier full-information item factor analysis model applications. Psychometrika, 75, 581-612. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Bradlow, E.T., Wainer, H., & Wang, X. (1999). Bayesian random effects model testlets. Psychometrika, 64, 153-168. Gibbons, R. D., & Hedeker, D. R. (1992). Full-information Item Bi-Factor Analysis. Psychometrika, 57, 423-436. Gibbons, R. D., Darrell, R. B., Hedeker, D., Weiss, D. J., Segawa, E., Bhaumik, D. K., Kupfer, D. J., Frank, E., Grochocinski, V. J., & Stover, . (2007). Full-Information item bifactor analysis graded response data. Applied Psychological Measurement, 31, 4-19. Wainer, H., Bradlow, E.T., & Wang, X. (2007). Testlet response theory applications. New York, NY: Cambridge University Press.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/bfactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full-Information Item Bi-factor and Two-Tier Analysis — bfactor","text":"","code":"# \\donttest{  ### load SAT12 and compute bifactor model with 3 specific factors data(SAT12) data <- key2binary(SAT12,   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) specific <- c(2,3,2,3,3,2,1,2,1,1,1,3,1,3,1,2,1,1,3,3,1,1,3,1,3,3,1,3,2,3,1,2) mod1 <- bfactor(data, specific) #>  summary(mod1) #>              G      S1      S2      S3      h2 #> Item.1  0.4078          0.2273         0.21799 #> Item.2  0.6195                  0.3391 0.49881 #> Item.3  0.5573         -0.0744         0.31612 #> Item.4  0.2808                  0.3101 0.17503 #> Item.5  0.4779                  0.2544 0.29311 #> Item.6  0.5341          0.2724         0.35948 #> Item.7  0.4741  0.4210                 0.40199 #> Item.8  0.3537          0.2732         0.19971 #> Item.9  0.2181  0.5321                 0.33068 #> Item.10 0.4849  0.3792                 0.37895 #> Item.11 0.6442  0.3321                 0.52536 #> Item.12 0.0699                  0.1592 0.03023 #> Item.13 0.5219  0.2743                 0.34764 #> Item.14 0.4791                  0.4563 0.43776 #> Item.15 0.5985  0.2402                 0.41590 #> Item.16 0.3885          0.2049         0.19292 #> Item.17 0.6636  0.1177                 0.45423 #> Item.18 0.7163  0.0775                 0.51903 #> Item.19 0.4520                  0.0198 0.20466 #> Item.20 0.6578                  0.1792 0.46478 #> Item.21 0.2806  0.3451                 0.19787 #> Item.22 0.7025 -0.0281                 0.49425 #> Item.23 0.3236                  0.2657 0.17536 #> Item.24 0.5848  0.1030                 0.35266 #> Item.25 0.3732                  0.3297 0.24799 #> Item.26 0.6430                  0.2124 0.45854 #> Item.27 0.7374  0.1554                 0.56792 #> Item.28 0.5256                  0.0758 0.28199 #> Item.29 0.4185          0.7071         0.67516 #> Item.30 0.2455                 -0.0959 0.06946 #> Item.31 0.8333 -0.0872                 0.70202 #> Item.32 0.0780          0.0165         0.00635 #>  #> SS loadings:  8.435 1.03 0.748 0.781  #> Proportion Var:  0.264 0.032 0.023 0.024  #>  #> Factor correlations:  #>  #>    G S1 S2 S3 #> G  1          #> S1 0  1       #> S2 0  0  1    #> S3 0  0  0  1 itemplot(mod1, 18, drop.zeros = TRUE) #drop the zero slopes to allow plotting   # alternative model definition via ?mirt.model syntax specific2 <- \"S1 = 7,9,10,11,13,15,17,18,21,22,24,27,31               S2 = 1,3,6,8,16,29,32               S3 = 2,4,5,12,14,19,20,23,25,26,28,30\" mod2 <- bfactor(data, specific2) #>  anova(mod1, mod2) # same #>          AIC    SABIC       HQ      BIC    logLik X2 df   p #> mod1 19062.1 19179.44 19226.42 19484.21 -9435.052           #> mod2 19062.1 19179.44 19226.42 19484.21 -9435.052  0  0 NaN  # also equivalent using item names instead (not run) specific3 <- \"S1 = Item.7, Item.9, Item.10, Item.11, Item.13, Item.15,                 Item.17, Item.18, Item.21, Item.22, Item.24, Item.27, Item.31               S2 = Item.1, Item.3, Item.6, Item.8, Item.16, Item.29, Item.32               S3 = Item.2, Item.4, Item.5, Item.12, Item.14, Item.19,                 Item.20, Item.23, Item.25, Item.26, Item.28, Item.30\" # mod3 <- bfactor(data, specific3) # anova(mod1, mod2, mod3)  # all same  ### Try with fixed guessing parameters added guess <- rep(.1,32) mod2 <- bfactor(data, specific, guess = guess) #>  coef(mod2) #> $Item.1 #>        a1 a2    a3 a4      d   g u #> par 1.225  0 0.624  0 -1.822 0.1 1 #>  #> $Item.2 #>        a1 a2 a3    a4     d   g u #> par 1.721  0  0 0.954 0.171 0.1 1 #>  #> $Item.3 #>        a1 a2     a3 a4      d   g u #> par 2.415  0 -0.459  0 -2.602 0.1 1 #>  #> $Item.4 #>        a1 a2 a3    a4      d   g u #> par 0.745  0  0 0.695 -0.989 0.1 1 #>  #> $Item.5 #>        a1 a2 a3    a4     d   g u #> par 1.048  0  0 0.603 0.419 0.1 1 #>  #> $Item.6 #>       a1 a2    a3 a4      d   g u #> par 3.06  0 0.501  0 -5.002 0.1 1 #>  #> $Item.7 #>        a1    a2 a3 a4     d   g u #> par 1.121 0.839  0  0 1.373 0.1 1 #>  #> $Item.8 #>        a1 a2    a3 a4      d   g u #> par 1.956  0 1.443  0 -3.772 0.1 1 #>  #> $Item.9 #>        a1    a2 a3 a4     d   g u #> par 0.512 1.236  0  0 2.484 0.1 1 #>  #> $Item.10 #>       a1    a2 a3 a4      d   g u #> par 1.68 1.506  0  0 -1.031 0.1 1 #>  #> $Item.11 #>        a1    a2 a3 a4     d   g u #> par 1.655 0.842  0  0 5.441 0.1 1 #>  #> $Item.12 #>        a1 a2 a3    a4      d   g u #> par 0.129  0  0 0.364 -0.641 0.1 1 #>  #> $Item.13 #>        a1    a2 a3 a4     d   g u #> par 1.183 0.477  0  0 0.679 0.1 1 #>  #> $Item.14 #>        a1 a2 a3    a4     d   g u #> par 1.125  0  0 1.058 1.164 0.1 1 #>  #> $Item.15 #>        a1    a2 a3 a4     d   g u #> par 1.435 0.317  0  0 1.863 0.1 1 #>  #> $Item.16 #>       a1 a2    a3 a4      d   g u #> par 0.95  0 0.573  0 -0.783 0.1 1 #>  #> $Item.17 #>        a1    a2 a3 a4     d   g u #> par 1.547 0.059  0  0 4.112 0.1 1 #>  #> $Item.18 #>        a1    a2 a3 a4      d   g u #> par 2.731 0.094  0  0 -1.808 0.1 1 #>  #> $Item.19 #>        a1 a2 a3    a4      d   g u #> par 0.918  0  0 0.101 -0.001 0.1 1 #>  #> $Item.20 #>        a1 a2 a3    a4     d   g u #> par 1.456  0  0 0.593 2.501 0.1 1 #>  #> $Item.21 #>        a1    a2 a3 a4    d   g u #> par 0.596 0.493  0  0 2.49 0.1 1 #>  #> $Item.22 #>        a1     a2 a3 a4     d   g u #> par 1.554 -0.242  0  0 3.428 0.1 1 #>  #> $Item.23 #>        a1 a2 a3    a4      d   g u #> par 0.908  0  0 0.766 -1.488 0.1 1 #>  #> $Item.24 #>        a1    a2 a3 a4     d   g u #> par 1.379 0.001  0  0 1.132 0.1 1 #>  #> $Item.25 #>       a1 a2 a3    a4      d   g u #> par 1.03  0  0 1.094 -1.164 0.1 1 #>  #> $Item.26 #>        a1 a2 a3    a4      d   g u #> par 1.985  0  0 0.747 -0.663 0.1 1 #>  #> $Item.27 #>        a1    a2 a3 a4     d   g u #> par 1.909 0.348  0  0 2.642 0.1 1 #>  #> $Item.28 #>        a1 a2 a3    a4      d   g u #> par 1.213  0  0 0.142 -0.097 0.1 1 #>  #> $Item.29 #>        a1 a2    a3 a4      d   g u #> par 1.938  0 2.339  0 -2.209 0.1 1 #>  #> $Item.30 #>        a1 a2 a3     a4      d   g u #> par 0.479  0  0 -0.128 -0.527 0.1 1 #>  #> $Item.31 #>        a1    a2 a3 a4     d   g u #> par 3.173 -0.82  0  0 3.316 0.1 1 #>  #> $Item.32 #>        a1 a2     a3 a4      d   g u #> par 0.534  0 -0.053  0 -2.786 0.1 1 #>  #> $GroupPars #>     MEAN_1 MEAN_2 MEAN_3 MEAN_4 COV_11 COV_21 COV_31 COV_41 COV_22 COV_32 #> par      0      0      0      0      1      0      0      0      1      0 #>     COV_42 COV_33 COV_43 COV_44 #> par      0      1      0      1 #>  anova(mod1, mod2) #>           AIC    SABIC       HQ      BIC    logLik     X2 df   p #> mod1 19062.10 19179.44 19226.42 19484.21 -9435.052               #> mod2 19009.55 19126.88 19173.87 19431.65 -9408.775 52.553  0 NaN  ## don't estimate specific factor for item 32 specific[32] <- NA mod3 <- bfactor(data, specific) #>  anova(mod3, mod1) #>           AIC    SABIC       HQ      BIC    logLik   X2 df     p #> mod3 19060.12 19176.23 19222.73 19477.83 -9435.062               #> mod1 19062.10 19179.44 19226.42 19484.21 -9435.052 0.02  1 0.886  # same, but with syntax (not run) specific3 <- \"S1 = 7,9,10,11,13,15,17,18,21,22,24,27,31               S2 = 1,3,6,8,16,29               S3 = 2,4,5,12,14,19,20,23,25,26,28,30\" # mod3b <- bfactor(data, specific3) # anova(mod3b)   ######### # mixed itemtype example  # simulate data a <- matrix(c( 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,0.5,NA, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5, 1,NA,0.5),ncol=3,byrow=TRUE)  d <- matrix(c( -1.0,NA,NA, -1.5,NA,NA,  1.5,NA,NA,  0.0,NA,NA, 2.5,1.0,-1, 3.0,2.0,-0.5, 3.0,2.0,-0.5, 3.0,2.0,-0.5, 2.5,1.0,-1, 2.0,0.0,NA, -1.0,NA,NA, -1.5,NA,NA,  1.5,NA,NA,  0.0,NA,NA),ncol=3,byrow=TRUE) items <- rep('2PL', 14) items[5:10] <- 'graded'  sigma <- diag(3) dataset <- simdata(a,d,5000,itemtype=items,sigma=sigma) itemstats(dataset) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  5000           15.145           4.49 0.178 0.032 0.736     2.309 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  5000 2 0.306 0.461   0.436         0.347       0.723 #> Item_2  5000 2 0.232 0.422   0.403         0.320       0.725 #> Item_3  5000 2 0.771 0.420   0.376         0.291       0.727 #> Item_4  5000 2 0.498 0.500   0.478         0.385       0.719 #> Item_5  5000 4 1.896 0.963   0.571         0.398       0.717 #> Item_6  5000 4 2.147 0.880   0.549         0.389       0.717 #> Item_7  5000 4 2.171 0.863   0.540         0.382       0.717 #> Item_8  5000 4 2.133 0.890   0.551         0.389       0.717 #> Item_9  5000 4 1.858 0.988   0.575         0.398       0.717 #> Item_10 5000 3 1.332 0.736   0.528         0.394       0.715 #> Item_11 5000 2 0.299 0.458   0.438         0.351       0.723 #> Item_12 5000 2 0.233 0.423   0.390         0.306       0.726 #> Item_13 5000 2 0.764 0.424   0.410         0.326       0.725 #> Item_14 5000 2 0.504 0.500   0.473         0.379       0.720 #>  #> $proportions #>             0     1     2     3 #> Item_1  0.694 0.306    NA    NA #> Item_2  0.768 0.232    NA    NA #> Item_3  0.229 0.771    NA    NA #> Item_4  0.502 0.498    NA    NA #> Item_5  0.107 0.199 0.384 0.310 #> Item_6  0.081 0.082 0.447 0.390 #> Item_7  0.072 0.085 0.443 0.400 #> Item_8  0.082 0.091 0.438 0.389 #> Item_9  0.123 0.199 0.374 0.304 #> Item_10 0.160 0.348 0.492    NA #> Item_11 0.701 0.299    NA    NA #> Item_12 0.767 0.233    NA    NA #> Item_13 0.236 0.764    NA    NA #> Item_14 0.496 0.504    NA    NA #>   specific <- \"S1 = 1-7              S2 = 8-14\" simmod <- bfactor(dataset, specific) #>  coef(simmod, simplify=TRUE) #> $items #>            a1     a2    a3      d  g  u    d1     d2     d3 #> Item_1  1.145  0.392 0.000 -1.048  0  1    NA     NA     NA #> Item_2  1.146 -0.042 0.000 -1.496  0  1    NA     NA     NA #> Item_3  0.962  0.334 0.000  1.458  0  1    NA     NA     NA #> Item_4  1.247 -0.163 0.000 -0.008  0  1    NA     NA     NA #> Item_5  1.086  0.117 0.000     NA NA NA 2.543  1.012 -0.991 #> Item_6  1.149  0.462 0.000     NA NA NA 3.005  2.081 -0.577 #> Item_7  1.112  0.062 0.000     NA NA NA 3.039  2.056 -0.500 #> Item_8  0.939  0.000 0.674     NA NA NA 2.916  1.939 -0.568 #> Item_9  0.887  0.000 0.676     NA NA NA 2.381  0.925 -1.035 #> Item_10 0.928  0.000 0.655     NA NA NA 2.034 -0.044     NA #> Item_11 1.018  0.000 0.456 -1.063  0  1    NA     NA     NA #> Item_12 0.903  0.000 0.560 -1.448  0  1    NA     NA     NA #> Item_13 0.928  0.000 0.620  1.456  0  1    NA     NA     NA #> Item_14 0.974  0.000 0.663  0.022  0  1    NA     NA     NA #>  #> $means #>  G S1 S2  #>  0  0  0  #>  #> $cov #>    G S1 S2 #> G  1  0  0 #> S1 0  1  0 #> S2 0  0  1 #>    ######### # General testlet response model (Wainer, 2007)  # simulate data set.seed(1234) a <- matrix(0, 12, 4) a[,1] <- rlnorm(12, .2, .3) ind <- 1 for(i in 1:3){    a[ind:(ind+3),i+1] <- a[ind:(ind+3),1]    ind <- ind+4 } print(a) #>            [,1]      [,2]     [,3]      [,4] #>  [1,] 0.8503394 0.8503394 0.000000 0.0000000 #>  [2,] 1.3274088 1.3274088 0.000000 0.0000000 #>  [3,] 1.6910208 1.6910208 0.000000 0.0000000 #>  [4,] 0.6042850 0.6042850 0.000000 0.0000000 #>  [5,] 1.3892130 0.0000000 1.389213 0.0000000 #>  [6,] 1.4216480 0.0000000 1.421648 0.0000000 #>  [7,] 1.0279618 0.0000000 1.027962 0.0000000 #>  [8,] 1.0366667 0.0000000 1.036667 0.0000000 #>  [9,] 1.0311394 0.0000000 0.000000 1.0311394 #> [10,] 0.9351846 0.0000000 0.000000 0.9351846 #> [11,] 1.0584888 0.0000000 0.000000 1.0584888 #> [12,] 0.9052755 0.0000000 0.000000 0.9052755 d <- rnorm(12, 0, .5) sigma <- diag(c(1, .5, 1, .5)) dataset <- simdata(a,d,2000,itemtype=rep('2PL', 12),sigma=sigma) itemstats(dataset) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  2000                6          2.929 0.175 0.068 0.717     1.558 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  2000 2 0.426 0.495   0.438         0.287       0.708 #> Item_2  2000 2 0.502 0.500   0.560         0.425       0.689 #> Item_3  2000 2 0.571 0.495   0.575         0.445       0.686 #> Item_4  2000 2 0.502 0.500   0.383         0.224       0.716 #> Item_5  2000 2 0.464 0.499   0.549         0.413       0.690 #> Item_6  2000 2 0.436 0.496   0.561         0.428       0.688 #> Item_7  2000 2 0.440 0.497   0.500         0.356       0.698 #> Item_8  2000 2 0.693 0.462   0.474         0.339       0.701 #> Item_9  2000 2 0.511 0.500   0.481         0.334       0.701 #> Item_10 2000 2 0.456 0.498   0.465         0.316       0.704 #> Item_11 2000 2 0.458 0.498   0.459         0.309       0.705 #> Item_12 2000 2 0.540 0.498   0.475         0.327       0.702 #>  #> $proportions #>             0     1 #> Item_1  0.575 0.426 #> Item_2  0.498 0.502 #> Item_3  0.430 0.571 #> Item_4  0.498 0.502 #> Item_5  0.536 0.464 #> Item_6  0.564 0.436 #> Item_7  0.559 0.440 #> Item_8  0.308 0.693 #> Item_9  0.488 0.511 #> Item_10 0.543 0.456 #> Item_11 0.541 0.458 #> Item_12 0.460 0.540 #>   # estimate by applying constraints and freeing the latent variances specific <- \"S1 = 1-4              S2 = 5-8              S3 = 9-12\" model <- \"G = 1-12           CONSTRAIN = (1, a1, a2), (2, a1, a2), (3, a1, a2), (4, a1, a2),             (5, a1, a3), (6, a1, a3), (7, a1, a3), (8, a1, a3),             (9, a1, a4), (10, a1, a4), (11, a1, a4), (12, a1, a4)           COV = S1*S1, S2*S2, S3*S3\"  simmod <- bfactor(dataset, specific, model) #>  coef(simmod, simplify=TRUE) #> $items #>            a1    a2    a3    a4      d g u #> Item_1  0.794 0.794 0.000 0.000 -0.359 0 1 #> Item_2  1.544 1.544 0.000 0.000  0.011 0 1 #> Item_3  1.762 1.762 0.000 0.000  0.479 0 1 #> Item_4  0.544 0.544 0.000 0.000  0.011 0 1 #> Item_5  1.386 0.000 1.386 0.000 -0.244 0 1 #> Item_6  1.497 0.000 1.497 0.000 -0.449 0 1 #> Item_7  0.853 0.000 0.853 0.000 -0.312 0 1 #> Item_8  0.953 0.000 0.953 0.000  1.101 0 1 #> Item_9  0.981 0.000 0.000 0.981  0.058 0 1 #> Item_10 0.913 0.000 0.000 0.913 -0.217 0 1 #> Item_11 0.868 0.000 0.000 0.868 -0.204 0 1 #> Item_12 0.966 0.000 0.000 0.966  0.206 0 1 #>  #> $means #>  G S1 S2 S3  #>  0  0  0  0  #>  #> $cov #>    G    S1    S2    S3 #> G  1 0.000 0.000 0.000 #> S1 0 0.452 0.000 0.000 #> S2 0 0.000 1.135 0.000 #> S3 0 0.000 0.000 0.432 #>   # Constrained testlet model (Bradlow, 1999) model2 <- \"G = 1-12           CONSTRAIN = (1, a1, a2), (2, a1, a2), (3, a1, a2), (4, a1, a2),             (5, a1, a3), (6, a1, a3), (7, a1, a3), (8, a1, a3),             (9, a1, a4), (10, a1, a4), (11, a1, a4), (12, a1, a4),             (GROUP, COV_22, COV_33, COV_44)           COV = S1*S1, S2*S2, S3*S3\"  simmod2 <- bfactor(dataset, specific, model2) #>  coef(simmod2, simplify=TRUE) #> $items #>            a1    a2    a3    a4      d g u #> Item_1  0.744 0.744 0.000 0.000 -0.360 0 1 #> Item_2  1.453 1.453 0.000 0.000  0.010 0 1 #> Item_3  1.664 1.664 0.000 0.000  0.482 0 1 #> Item_4  0.509 0.509 0.000 0.000  0.011 0 1 #> Item_5  1.541 0.000 1.541 0.000 -0.241 0 1 #> Item_6  1.670 0.000 1.670 0.000 -0.445 0 1 #> Item_7  0.968 0.000 0.968 0.000 -0.313 0 1 #> Item_8  1.075 0.000 1.075 0.000  1.098 0 1 #> Item_9  0.927 0.000 0.000 0.927  0.059 0 1 #> Item_10 0.854 0.000 0.000 0.854 -0.218 0 1 #> Item_11 0.813 0.000 0.000 0.813 -0.205 0 1 #> Item_12 0.908 0.000 0.000 0.908  0.207 0 1 #>  #> $means #>  G S1 S2 S3  #>  0  0  0  0  #>  #> $cov #>    G    S1    S2    S3 #> G  1 0.000 0.000 0.000 #> S1 0 0.667 0.000 0.000 #> S2 0 0.000 0.667 0.000 #> S3 0 0.000 0.000 0.667 #>  anova(simmod2, simmod) #>              AIC    SABIC       HQ      BIC   logLik     X2 df     p #> simmod2 30256.59 30317.19 30308.00 30396.61 -15103.3                 #> simmod  30248.79 30314.24 30304.32 30400.02 -15097.4 11.795  2 0.003   ######### # Two-tier model  # simulate data set.seed(1234) a <- matrix(c(   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,0.5,NA,NA,   0,1,NA,0.5,NA,   0,1,NA,0.5,NA,   0,1,NA,0.5,NA,   1,0,NA,0.5,NA,   1,0,NA,0.5,NA,   1,0,NA,0.5,NA,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5,   1,0,NA,NA,0.5),ncol=5,byrow=TRUE)  d <- matrix(rnorm(16)) items <- rep('2PL', 16)  sigma <- diag(5) sigma[1,2] <- sigma[2,1] <- .4 dataset <- simdata(a,d,2000,itemtype=items,sigma=sigma) itemstats(dataset) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  2000            7.086          3.077 0.108 0.058 0.662      1.79 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  2000 2 0.288 0.453   0.378         0.241       0.650 #> Item_2  2000 2 0.571 0.495   0.422         0.276       0.646 #> Item_3  2000 2 0.705 0.456   0.381         0.245       0.650 #> Item_4  2000 2 0.133 0.340   0.289         0.183       0.656 #> Item_5  2000 2 0.601 0.490   0.393         0.246       0.650 #> Item_6  2000 2 0.587 0.492   0.419         0.274       0.646 #> Item_7  2000 2 0.379 0.485   0.444         0.304       0.642 #> Item_8  2000 2 0.378 0.485   0.400         0.256       0.649 #> Item_9  2000 2 0.386 0.487   0.392         0.246       0.650 #> Item_10 2000 2 0.322 0.467   0.400         0.261       0.648 #> Item_11 2000 2 0.402 0.490   0.455         0.315       0.640 #> Item_12 2000 2 0.318 0.466   0.414         0.278       0.646 #> Item_13 2000 2 0.368 0.482   0.423         0.281       0.645 #> Item_14 2000 2 0.498 0.500   0.424         0.277       0.646 #> Item_15 2000 2 0.669 0.471   0.394         0.254       0.649 #> Item_16 2000 2 0.482 0.500   0.444         0.300       0.642 #>  #> $proportions #>             0     1 #> Item_1  0.713 0.288 #> Item_2  0.430 0.571 #> Item_3  0.295 0.705 #> Item_4  0.867 0.133 #> Item_5  0.400 0.601 #> Item_6  0.413 0.587 #> Item_7  0.621 0.379 #> Item_8  0.622 0.378 #> Item_9  0.614 0.386 #> Item_10 0.678 0.322 #> Item_11 0.598 0.402 #> Item_12 0.681 0.318 #> Item_13 0.632 0.368 #> Item_14 0.502 0.498 #> Item_15 0.330 0.669 #> Item_16 0.518 0.482 #>   specific <- \"S1 = 1-5              S2 = 6-11              S3 = 12-16\" model <- '     G1 = 1-8     G2 = 9-16     COV = G1*G2'  # quadpts dropped for faster estimation, but not as precise simmod <- bfactor(dataset, specific, model, quadpts = 9, TOL = 1e-3) #>  coef(simmod, simplify=TRUE) #> $items #>            a1    a2    a3    a4    a5      d g u #> Item_1  0.965 0.000 0.385 0.000 0.000 -1.100 0 1 #> Item_2  1.076 0.000 0.550 0.000 0.000  0.363 0 1 #> Item_3  0.898 0.000 0.592 0.000 0.000  1.068 0 1 #> Item_4  0.896 0.000 0.710 0.000 0.000 -2.293 0 1 #> Item_5  0.892 0.000 0.848 0.000 0.000  0.526 0 1 #> Item_6  1.013 0.000 0.000 0.413 0.000  0.435 0 1 #> Item_7  1.162 0.000 0.000 0.451 0.000 -0.639 0 1 #> Item_8  0.945 0.000 0.000 0.609 0.000 -0.623 0 1 #> Item_9  0.000 0.831 0.000 0.371 0.000 -0.544 0 1 #> Item_10 0.000 0.925 0.000 0.610 0.000 -0.926 0 1 #> Item_11 0.000 1.142 0.000 0.495 0.000 -0.517 0 1 #> Item_12 0.000 0.978 0.000 0.000 0.634 -0.964 0 1 #> Item_13 0.000 1.108 0.000 0.000 0.437 -0.694 0 1 #> Item_14 0.000 1.004 0.000 0.000 0.321 -0.012 0 1 #> Item_15 0.000 0.916 0.000 0.000 0.758  0.897 0 1 #> Item_16 0.000 1.020 0.000 0.000 0.650 -0.096 0 1 #>  #> $means #> G1 G2 S1 S2 S3  #>  0  0  0  0  0  #>  #> $cov #>       G1    G2 S1 S2 S3 #> G1 1.000 0.412  0  0  0 #> G2 0.412 1.000  0  0  0 #> S1 0.000 0.000  1  0  0 #> S2 0.000 0.000  0  1  0 #> S3 0.000 0.000  0  0  1 #>  summary(simmod) #>            G1    G2    S1    S2    S3    h2 #> Item_1  0.484       0.193             0.271 #> Item_2  0.516       0.263             0.335 #> Item_3  0.446       0.294             0.285 #> Item_4  0.437       0.346             0.311 #> Item_5  0.425       0.404             0.343 #> Item_6  0.501             0.204       0.293 #> Item_7  0.551             0.214       0.349 #> Item_8  0.463             0.299       0.304 #> Item_9        0.431       0.192       0.222 #> Item_10       0.456       0.300       0.298 #> Item_11       0.541       0.235       0.348 #> Item_12       0.474             0.307 0.319 #> Item_13       0.533             0.210 0.329 #> Item_14       0.501             0.160 0.277 #> Item_15       0.441             0.365 0.328 #> Item_16       0.488             0.311 0.336 #>  #> SS loadings:  1.839 1.88 0.476 0.359 0.395  #> Proportion Var:  0.115 0.118 0.03 0.022 0.025  #>  #> Factor correlations:  #>  #>       G1 G2 S1 S2 S3 #> G1 1.000             #> G2 0.412  1          #> S1 0.000  0  1       #> S2 0.000  0  0  1    #> S3 0.000  0  0  0  1 itemfit(simmod, QMC=TRUE) #>       item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1  7.103       9      0.000  0.626 #> 2   Item_2 13.326      10      0.013  0.206 #> 3   Item_3  8.332       9      0.000  0.501 #> 4   Item_4  8.531      10      0.000  0.577 #> 5   Item_5  7.170      10      0.000  0.709 #> 6   Item_6  3.967      10      0.000  0.949 #> 7   Item_7  8.350      10      0.000  0.595 #> 8   Item_8 16.010      10      0.017  0.099 #> 9   Item_9 17.529      10      0.019  0.063 #> 10 Item_10 12.058      10      0.010  0.281 #> 11 Item_11 13.567      10      0.013  0.194 #> 12 Item_12 13.907       9      0.017  0.126 #> 13 Item_13 11.144      10      0.008  0.346 #> 14 Item_14  7.852      10      0.000  0.643 #> 15 Item_15 14.142       9      0.017  0.117 #> 16 Item_16  5.926      10      0.000  0.821 M2(simmod, QMC=TRUE) #>             M2 df         p RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI CFI #> stats 86.28163 87 0.5015988     0       0 0.01201603 0.01662365 1.000285   1 residuals(simmod, QMC=TRUE) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.046  -0.011  -0.002  -0.001   0.012   0.041  #>  #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1         -0.011 -0.015 -0.007  0.016  0.003  0.006 -0.002  0.004  -0.009 #> Item_2   0.263        -0.002  0.005 -0.001  0.016 -0.022  0.021 -0.003  -0.006 #> Item_3   0.441  0.008         0.014 -0.001  0.029 -0.017 -0.011 -0.021  -0.028 #> Item_4   0.086  0.054  0.376        -0.014 -0.023  0.021 -0.004  0.020  -0.040 #> Item_5   0.514  0.004  0.003  0.386        -0.028  0.011  0.014 -0.021   0.013 #> Item_6   0.015  0.483  1.630  1.038  1.588        -0.022 -0.009  0.031  -0.004 #> Item_7   0.077  0.996  0.590  0.852  0.258  0.992        -0.007 -0.004   0.013 #> Item_8   0.012  0.858  0.264  0.039  0.377  0.154  0.094        -0.020   0.008 #> Item_9   0.033  0.017  0.863  0.803  0.890  1.974  0.037  0.808          0.001 #> Item_10  0.157  0.084  1.528  3.158  0.360  0.038  0.330  0.128  0.001         #> Item_11  0.510  0.125  2.195  0.231  0.004  0.215  1.049  0.004  0.031   0.754 #> Item_12  2.017  0.253  1.865  0.388  0.005  0.417  0.074  0.090  0.443   0.042 #> Item_13  0.470  2.122  0.125  0.271  0.881  0.264  0.310  4.304  0.009   0.059 #> Item_14  0.101  1.546  0.165  0.006  0.296  0.004  1.672  0.765  3.341   0.066 #> Item_15  0.822  0.257  0.011  0.442  0.443  0.113  0.526  0.297  2.306   0.044 #> Item_16  0.097  0.627  1.486  0.127  0.445  0.011  0.732  0.061  0.007   0.944 #>         Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 #> Item_1   -0.016  -0.032   0.015  -0.007   0.020  -0.007 #> Item_2    0.008   0.011  -0.033  -0.028  -0.011   0.018 #> Item_3    0.033   0.031   0.008  -0.009  -0.002   0.027 #> Item_4   -0.011   0.014  -0.012  -0.002  -0.015  -0.008 #> Item_5   -0.001   0.002  -0.021  -0.012   0.015   0.015 #> Item_6    0.010   0.014  -0.011   0.001  -0.008   0.002 #> Item_7    0.023   0.006   0.012   0.029  -0.016   0.019 #> Item_8   -0.001   0.007  -0.046  -0.020   0.012   0.006 #> Item_9    0.004  -0.015  -0.002   0.041  -0.034  -0.002 #> Item_10  -0.019   0.005   0.005   0.006  -0.005   0.022 #> Item_11           0.009   0.000  -0.025   0.039  -0.011 #> Item_12   0.149          -0.008   0.013  -0.002  -0.009 #> Item_13   0.000   0.140           0.013  -0.012   0.003 #> Item_14   1.269   0.338   0.336          -0.007  -0.023 #> Item_15   3.061   0.010   0.284   0.086           0.010 #> Item_16   0.250   0.153   0.015   1.026   0.190          # }"},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric bootstrap likelihood-ratio test — boot.LR","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"Given two fitted models, compute parametric bootstrap test determine whether less restrictive models fits significantly better restricted model. Note hypothesis test also works prior parameter distributions included either model. Function can run parallel using suitable mirtCluster definition.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"","code":"boot.LR(mod, mod2, R = 1000, verbose = TRUE)"},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"mod estimated model object, constrained mod2 mod2 estimated model object R number parametric bootstraps use. verbose logical; include additional information console?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"p-value evaluating whether restrictive model fits significantly worse   less restrictive model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.LR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric bootstrap likelihood-ratio test — boot.LR","text":"","code":"# \\donttest{  # standard dat <- expand.table(LSAT7) mod1 <- mirt(dat, 1) #>  mod2 <- mirt(dat, 1, '3PL') #>   # standard LR test anova(mod1, mod2) #>          AIC    SABIC       HQ      BIC    logLik  X2 df     p #> mod1 5337.61 5354.927 5356.263 5386.688 -2658.805              #> mod2 5346.11 5372.085 5374.089 5419.726 -2658.055 1.5  5 0.913  # bootstrap LR test (run in parallel to save time) if(interactive()) mirtCluster() boot.LR(mod1, mod2, R=200) #> [1] 0.3084577  # }"},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate bootstrapped standard errors for estimated models — boot.mirt","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"Given internal mirt object estimate bootstrapped standard errors. may beneficial run computations using multi-core architecture (e.g., parallel package). Parameters organized freely estimated values mod2values(x) (equality constraints also returned bootstrapped estimates).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"","code":"boot.mirt(x, R = 100, boot.fun = NULL, technical = NULL, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"x estimated model object R number draws use (passed boot() function) boot.fun user-defined function used extract information bootstrap fitted models. Must form boot.fun(x), x bootstrap fitted model investigation, return must numeric vector. omitted default function defined internally returns estimated parameters mod object, resulting bootstrapped parameter estimate results technical technical arguments passed estimation engine. See mirt details ... additional arguments passed boot(...) mirt's estimation engine","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/boot.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate bootstrapped standard errors for estimated models — boot.mirt","text":"","code":"# \\donttest{  # standard mod <- mirt(Science, 1) #>  booted <- boot.mirt(mod, R=20) plot(booted)  booted #>  #> ORDINARY NONPARAMETRIC BOOTSTRAP #>  #>  #> Call: #> boot.mirt(x = mod, R = 20) #>  #>  #> Bootstrap Statistics : #>        original       bias    std. error #> t1*   1.0417547  0.039756609   0.2180908 #> t2*   4.8641542  0.107617991   0.4246238 #> t3*   2.6399417  0.008343677   0.2938708 #> t4*  -1.4660135 -0.044006228   0.1801285 #> t5*   1.2259618 -0.010737940   0.1673617 #> t6*   2.9240027  0.059797889   0.2816925 #> t7*   0.9011651 -0.011811056   0.1472792 #> t8*  -2.2665647  0.015599564   0.2175903 #> t9*   2.2933717 -0.001395176   0.4712084 #> t10*  5.2339928 -0.006057157   0.8133609 #> t11*  2.2137728 -0.016503240   0.4009882 #> t12* -1.9637062 -0.027397765   0.3737457 #> t13*  1.0949151  0.011490687   0.2112956 #> t14*  3.3479196 -0.042309791   0.3130434 #> t15*  0.9916289 -0.020381501   0.1864301 #> t16* -1.6882599 -0.013255970   0.1565944  if (FALSE) { # \\dontrun{ #run in parallel using snow back-end using all available cores mod <- mirt(Science, 1) booted <- boot.mirt(mod, parallel = 'snow', ncpus = parallel::detectCores()) booted } # }  #### # bootstrapped CIs for standardized factor loadings boot.fun <- function(mod){   so <- summary(mod, verbose=FALSE)   as.vector(so$rotF) }  # test to see if it works before running boot.fun(mod) #> [1] 0.5220496 0.5844686 0.8030199 0.5410276  # run booted.loads <- boot.mirt(mod, boot.fun=boot.fun) #> Warning: EM cycles terminated after 500 iterations. booted.loads #>  #> ORDINARY NONPARAMETRIC BOOTSTRAP #>  #>  #> Call: #> boot.mirt(x = mod, boot.fun = boot.fun) #>  #>  #> Bootstrap Statistics : #>      original       bias    std. error #> t1* 0.5220496  0.005643174  0.08294517 #> t2* 0.5844686 -0.006140366  0.06189828 #> t3* 0.8030199 -0.006557025  0.07143835 #> t4* 0.5410276  0.011377983  0.08396097  # }"},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract raw coefs from model object — coef-method","title":"Extract raw coefs from model object — coef-method","text":"Return list (data.frame) raw item group level coefficients. Note output console rounded three digits, returned list objects . Hence, elements cfs <- coef(mod); cfs[[1]] contain non-rounded results (useful simulations).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract raw coefs from model object — coef-method","text":"","code":"# S4 method for class 'SingleGroupClass' coef(   object,   CI = 0.95,   printSE = FALSE,   rotate = \"none\",   Target = NULL,   IRTpars = FALSE,   rawug = FALSE,   as.data.frame = FALSE,   simplify = FALSE,   unique = FALSE,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract raw coefs from model object — coef-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass CI amount converged used compute confidence intervals; default 95 percent confidence intervals printSE logical; print standard errors instead confidence intervals? IRTpars = TRUE delta method used compute associated standard errors mirt's default slope-intercept form rotate see summary method details. default rotation 'none' Target dummy variable matrix indicting target rotation pattern IRTpars logical; convert slope intercept parameters traditional IRT parameters? applicable unidimensional models models simple structure (.e., one non-zero slope). suitable ACOV estimate computed fitted model, printSE = FALSE, suitable CIs included based delta method (applicable) rawug logical; return untransformed internal g u parameters? FALSE, g u's converted original format along delta standard errors .data.frame logical; convert list output data.frame instead? simplify logical; items parameter names (indicating class) collapsed matrix, list length 2 returned containing matrix item parameters group-level estimates unique return vector uniquely estimated parameters verbose logical; allow information printed console? ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract raw coefs from model object — coef-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/coef-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract raw coefs from model object — coef-method","text":"","code":"# \\donttest{ dat <- expand.table(LSAT7) x <- mirt(dat, 1) #>  coef(x) #> $Item.1 #>        a1     d g u #> par 0.988 1.856 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.081 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.804 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.765 0.486 0 1 #>  #> $Item.5 #>        a1     d g u #> par 0.736 1.855 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  coef(x, IRTpars = TRUE) #> $Item.1 #>         a      b g u #> par 0.988 -1.879 0 1 #>  #> $Item.2 #>         a      b g u #> par 1.081 -0.748 0 1 #>  #> $Item.3 #>         a      b g u #> par 1.706 -1.058 0 1 #>  #> $Item.4 #>         a      b g u #> par 0.765 -0.635 0 1 #>  #> $Item.5 #>         a     b g u #> par 0.736 -2.52 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  coef(x, simplify = TRUE) #> $items #>           a1     d g u #> Item.1 0.988 1.856 0 1 #> Item.2 1.081 0.808 0 1 #> Item.3 1.706 1.804 0 1 #> Item.4 0.765 0.486 0 1 #> Item.5 0.736 1.855 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   #with computed information matrix x <- mirt(dat, 1, SE = TRUE) #>  #>  #> Calculating information matrix... coef(x) #> $Item.1 #>            a1     d  g  u #> par     0.988 1.856  0  1 #> CI_2.5  0.641 1.598 NA NA #> CI_97.5 1.335 2.114 NA NA #>  #> $Item.2 #>            a1     d  g  u #> par     1.081 0.808  0  1 #> CI_2.5  0.750 0.629 NA NA #> CI_97.5 1.412 0.987 NA NA #>  #> $Item.3 #>            a1     d  g  u #> par     1.706 1.804  0  1 #> CI_2.5  1.078 1.404 NA NA #> CI_97.5 2.334 2.205 NA NA #>  #> $Item.4 #>            a1     d  g  u #> par     0.765 0.486  0  1 #> CI_2.5  0.502 0.339 NA NA #> CI_97.5 1.028 0.633 NA NA #>  #> $Item.5 #>            a1     d  g  u #> par     0.736 1.855  0  1 #> CI_2.5  0.440 1.630 NA NA #> CI_97.5 1.032 2.079 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0      1 #> CI_2.5      NA     NA #> CI_97.5     NA     NA #>  coef(x, printSE = TRUE) #> $Item.1 #>        a1     d logit(g) logit(u) #> par 0.988 1.856     -999      999 #> SE  0.177 0.131       NA       NA #>  #> $Item.2 #>        a1     d logit(g) logit(u) #> par 1.081 0.808     -999      999 #> SE  0.169 0.091       NA       NA #>  #> $Item.3 #>        a1     d logit(g) logit(u) #> par 1.706 1.804     -999      999 #> SE  0.320 0.204       NA       NA #>  #> $Item.4 #>        a1     d logit(g) logit(u) #> par 0.765 0.486     -999      999 #> SE  0.134 0.075       NA       NA #>  #> $Item.5 #>        a1     d logit(g) logit(u) #> par 0.736 1.855     -999      999 #> SE  0.151 0.114       NA       NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #> SE      NA     NA #>  coef(x, as.data.frame = TRUE) #>                        par    CI_2.5   CI_97.5 #> Item.1.a1        0.9879254 0.6405319 1.3353189 #> Item.1.d         1.8560605 1.5983450 2.1137759 #> Item.1.g         0.0000000        NA        NA #> Item.1.u         1.0000000        NA        NA #> Item.2.a1        1.0808847 0.7500334 1.4117360 #> Item.2.d         0.8079786 0.6291264 0.9868309 #> Item.2.g         0.0000000        NA        NA #> Item.2.u         1.0000000        NA        NA #> Item.3.a1        1.7058006 1.0778209 2.3337803 #> Item.3.d         1.8042187 1.4035692 2.2048683 #> Item.3.g         0.0000000        NA        NA #> Item.3.u         1.0000000        NA        NA #> Item.4.a1        0.7651853 0.5022681 1.0281025 #> Item.4.d         0.4859966 0.3391601 0.6328331 #> Item.4.g         0.0000000        NA        NA #> Item.4.u         1.0000000        NA        NA #> Item.5.a1        0.7357980 0.4395386 1.0320574 #> Item.5.d         1.8545127 1.6302516 2.0787739 #> Item.5.g         0.0000000        NA        NA #> Item.5.u         1.0000000        NA        NA #> GroupPars.MEAN_1 0.0000000        NA        NA #> GroupPars.COV_11 1.0000000        NA        NA  #two factors x2 <- mirt(Science, 2) #>  coef(x2) #> $Comfort #>         a1    a2    d1    d2     d3 #> par -1.335 0.097 5.211 2.866 -1.603 #>  #> $Work #>         a1    a2    d1    d2     d3 #> par -0.879 1.853 3.704 1.153 -2.904 #>  #> $Future #>        a1    a2    d1    d2     d3 #> par -1.47 1.165 4.663 1.957 -1.736 #>  #> $Benefit #>         a1 a2    d1    d2     d3 #> par -1.722  0 3.989 1.195 -2.044 #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0      0      1      0      1 #>  coef(x2, rotate = 'varimax') #>  #> Rotation:  varimax  #>  #> $Comfort #>        a1    a2    d1    d2     d3 #> par 1.254 0.468 5.211 2.866 -1.603 #>  #> $Work #>        a1    a2    d1    d2     d3 #> par 0.323 2.025 3.704 1.153 -2.904 #>  #> $Future #>        a1    a2    d1    d2     d3 #> par 1.083 1.531 4.663 1.957 -1.736 #>  #> $Benefit #>        a1    a2    d1    d2     d3 #> par 1.653 0.484 3.989 1.195 -2.044 #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0      0      1      0      1 #>   # }"},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a user defined group-level object with correct generic functions — createGroup","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"Initializes proper S4 class methods necessary mirt functions use estimation defining customized group-level functions. use defined objects pass mirt(..., customGroup = OBJECT) command, ensure class parameters properly labelled.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"","code":"createGroup(   par,   est,   den,   nfact,   standardize = FALSE,   gr = NULL,   hss = NULL,   gen = NULL,   lbound = NULL,   ubound = NULL,   derivType = \"Richardson\" )"},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"par named vector starting values parameters est logical vector indicating parameters freely estimated default den probability density function given Theta/ability values. First input contains vector defined parameters second input must matrix called Theta. Function also must return numeric vector object corresponding associated densities row Theta input nfact number factors required model. E.g., unidimensional models one dimension integration nfact = 1 standardize logical; use standardization quadrature table method proposed Woods Thissen (2006)? TRUE, logical elements named 'MEAN_1' 'COV_11' can included parameter vector, values set FALSE est input E-table standardized fixed values (e.g., par <- c(a1=1, d=0, MEAN_1=0, COV_11=1) est <- c(TRUE, TRUE, FALSE, FALSE) standardize E-table 0 mean unit variance) gr gradient function (vector first derivatives) log-likelihood used estimation. function must form gr(x, Theta), x object defined createGroup() Theta matrix latent trait parameters hss Hessian function (matrix second derivatives) log-likelihood used estimation. specified numeric approximation used. input identical gr argument gen function used GenRandomPars = TRUE passed estimation function generate random starting values. Function must form function(object) ... must return vector properties equivalent par object. NULL, parameters remain defined starting values default lbound optional vector indicating lower bounds parameters. specified bounds set -Inf ubound optional vector indicating lower bounds parameters. specified bounds set Inf derivType gr hss terms specified type used obtain numerically. Default 'Richardson'","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createGroup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a user defined group-level object with correct generic functions — createGroup","text":"","code":"# normal density example, N(mu, sigma^2) den <- function(obj, Theta) dnorm(Theta, obj@par[1], sqrt(obj@par[2])) par <- c(mu = 0, sigma2 = .5) est <- c(FALSE, TRUE) lbound <- c(-Inf, 0) grp <- createGroup(par, est, den, nfact = 1, lbound=lbound)  dat <- expand.table(LSAT6) mod <- mirt(dat, 1, 'Rasch') #>  modcustom <- mirt(dat, 1, 'Rasch', customGroup=grp) #>   coef(mod) #> $Item_1 #>     a1     d g u #> par  1 2.731 0 1 #>  #> $Item_2 #>     a1     d g u #> par  1 0.999 0 1 #>  #> $Item_3 #>     a1    d g u #> par  1 0.24 0 1 #>  #> $Item_4 #>     a1     d g u #> par  1 1.307 0 1 #>  #> $Item_5 #>     a1   d g u #> par  1 2.1 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  0.572 #>  coef(modcustom) #> $Item_1 #>     a1     d g u #> par  1 2.729 0 1 #>  #> $Item_2 #>     a1     d g u #> par  1 0.998 0 1 #>  #> $Item_3 #>     a1    d g u #> par  1 0.24 0 1 #>  #> $Item_4 #>     a1     d g u #> par  1 1.306 0 1 #>  #> $Item_5 #>     a1     d g u #> par  1 2.099 0 1 #>  #> $GroupPars #>     mu sigma2 #> par  0  0.569 #>"},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a user defined item with correct generic functions — createItem","title":"Create a user defined item with correct generic functions — createItem","text":"Initializes proper S4 class methods necessary mirt functions use estimation. use defined objects pass mirt(..., customItems = list()) command, ensure classes properly labelled unique list. Additionally, input mirt(..., customItemsData = list()) can also included specify additional item-level information better recycle custom-item definitions (e.g., supplying varying Q-matrices), list input must length number items. examples regarding function can used fitting unfolding-type models see Liu Chalmers (2018).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a user defined item with correct generic functions — createItem","text":"","code":"createItem(   name,   par,   est,   P,   gr = NULL,   hss = NULL,   gen = NULL,   lbound = NULL,   ubound = NULL,   derivType = \"Richardson\",   derivType.hss = \"Richardson\",   bytecompile = TRUE )"},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a user defined item with correct generic functions — createItem","text":"name character indicating item class name defined par named vector starting values parameters est logical vector indicating parameters freely estimated default P probability trace function categories (first column category 1, second   category two, etc). First input contains vector item parameters, second input   must matrix called Theta, third input must number categories   called ncat, (optionally) fourth argument termed itemdata   may included containing  users specification information.   last optional input utilized within estimation functions   mirt via list input customItemsData   naturally recycle custom-item definitions. Therefore, inputs must form function(par, Theta, ncat){...} function(par, Theta, ncat, itemdata){...} valid; however, names arguements relavent. Finally, function must return matrix object category probabilities,   columns represent respective category gr gradient function (vector first derivatives) log-likelihood used estimation. function must form gr(x, Theta), x object defined createItem() Theta matrix latent trait parameters. Tabulated (EM) raw (MHRM) data located x@dat slot, used form complete data log-likelihood. specified numeric approximation used hss Hessian function (matrix second derivatives) log-likelihood used estimation. specified numeric approximation used (required MH-RM algorithm ). input identical gr argument gen function used GenRandomPars = TRUE passed estimation function generate random starting values. Function must form function(object) ... must return vector properties equivalent par object. NULL, parameters remain defined starting values default lbound optional vector indicating lower bounds parameters. specified bounds set -Inf ubound optional vector indicating lower bounds parameters. specified bounds set Inf derivType gr term specified type used obtain gradient numerically symbolically. Default 'Richardson' extrapolation method; see numerical_deriv details options. 'symbolic' supplied gradient computed using symbolical approach (potentially accurate method, though may fail depending P function defined) derivType.hss hss term specified type used obtain Hessian numerically. Default 'Richardson' extrapolation method; see numerical_deriv details options. 'symbolic' supplied Hessian computed using symbolical approach (potentially accurate method, though may fail depending P function defined) bytecompile logical; applicable, byte compile functions provided? Default TRUE provide","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a user defined item with correct generic functions — createItem","text":"summary() function return proper standardized loadings since function sure handle (slopes defined !). Instead loadings .001 filled place-holders.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a user defined item with correct generic functions — createItem","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Liu, C.-W. Chalmers, R. P. (2018). Fitting item response unfolding models   Likert-scale data using mirt R. PLoS ONE, 13, 5.   doi:10.1371/journal.pone.0196292","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a user defined item with correct generic functions — createItem","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/createItem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a user defined item with correct generic functions — createItem","text":"","code":"# \\donttest{  name <- 'old2PL' par <- c(a = .5, b = -2) est <- c(TRUE, TRUE) P.old2PL <- function(par,Theta, ncat){      a <- par[1]      b <- par[2]      P1 <- 1 / (1 + exp(-1*a*(Theta - b)))      cbind(1-P1, P1) }  x <- createItem(name, par=par, est=est, P=P.old2PL)  # So, let's estimate it! dat <- expand.table(LSAT7) sv <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x), pars = 'values') tail(sv) #looks good #>    group   item     class   name parnum value lbound ubound   est const nconst #> 15   all Item.4      dich      g     15   0.0      0      1 FALSE  none   none #> 16   all Item.4      dich      u     16   1.0      0      1 FALSE  none   none #> 17   all Item.5    custom      a     17   0.5   -Inf    Inf  TRUE  none   none #> 18   all Item.5    custom      b     18  -2.0   -Inf    Inf  TRUE  none   none #> 19   all  GROUP GroupPars MEAN_1     19   0.0   -Inf    Inf FALSE  none   none #> 20   all  GROUP GroupPars COV_11     20   1.0      0    Inf FALSE  none   none #>    prior.type prior_1 prior_2 #> 15       none     NaN     NaN #> 16       none     NaN     NaN #> 17       none     NaN     NaN #> 18       none     NaN     NaN #> 19       none     NaN     NaN #> 20       none     NaN     NaN mod <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x)) #>  coef(mod) #> $Item.1 #>        a1     d g u #> par 0.989 1.856 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.081 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.703 1.803 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.766 0.486 0 1 #>  #> $Item.5 #>         a      b #> par 0.737 -2.518 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  mod2 <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x), method = 'MHRM') #> , Max-Change = 0.2000, Max-Change = 0.1181, Max-Change = 0.0997, Max-Change = 0.0507, Max-Change = 0.0517, Max-Change = 0.0408, Max-Change = 0.0306, Max-Change = 0.0181, Max-Change = 0.0508, Max-Change = 0.0376, Max-Change = 0.0376, Max-Change = 0.0422, Max-Change = 0.0672, Max-Change = 0.0461, Max-Change = 0.0406, Max-Change = 0.0409, Max-Change = 0.0421, Max-Change = 0.0262, Max-Change = 0.0280, Max-Change = 0.0325, Max-Change = 0.0308, Max-Change = 0.0616, Max-Change = 0.1016, Max-Change = 0.1420, Max-Change = 0.0328, Max-Change = 0.0294, Max-Change = 0.0073, Max-Change = 0.0408, Max-Change = 0.0465, Max-Change = 0.0230, Max-Change = 0.0984, Max-Change = 0.0730, Max-Change = 0.0847, Max-Change = 0.0413, Max-Change = 0.0344, Max-Change = 0.0533, Max-Change = 0.0179, Max-Change = 0.0099, Max-Change = 0.0445, Max-Change = 0.0294, Max-Change = 0.0415, Max-Change = 0.0512, Max-Change = 0.0322, Max-Change = 0.0326, Max-Change = 0.0537, Max-Change = 0.0124, Max-Change = 0.0285, Max-Change = 0.0206, Max-Change = 0.0230, Max-Change = 0.0248, Max-Change = 0.1203, Max-Change = 0.0214, Max-Change = 0.0321, Max-Change = 0.1221, Max-Change = 0.0744, Max-Change = 0.0355, Max-Change = 0.0427, Max-Change = 0.0216, Max-Change = 0.0300, Max-Change = 0.0323, Max-Change = 0.0341, Max-Change = 0.0383, Max-Change = 0.0571, Max-Change = 0.0120, Max-Change = 0.0231, Max-Change = 0.0425, Max-Change = 0.0676, Max-Change = 0.0799, Max-Change = 0.0301, Max-Change = 0.0567, Max-Change = 0.0441, Max-Change = 0.0617, Max-Change = 0.0684, Max-Change = 0.0211, Max-Change = 0.1073, Max-Change = 0.0279, Max-Change = 0.0202, Max-Change = 0.0424, Max-Change = 0.0365, Max-Change = 0.0259, Max-Change = 0.0489, Max-Change = 0.0694, Max-Change = 0.0689, Max-Change = 0.0307, Max-Change = 0.0195, Max-Change = 0.0546, Max-Change = 0.0117, Max-Change = 0.0779, Max-Change = 0.0536, Max-Change = 0.0410, Max-Change = 0.0445, Max-Change = 0.0359, Max-Change = 0.0329, Max-Change = 0.0169, Max-Change = 0.0282, Max-Change = 0.0233, Max-Change = 0.0502, Max-Change = 0.0365, Max-Change = 0.0371, Max-Change = 0.0291, Max-Change = 0.0135, Max-Change = 0.0377, Max-Change = 0.0695, Max-Change = 0.0456, Max-Change = 0.0557, Max-Change = 0.0327, Max-Change = 0.0933, Max-Change = 0.1188, Max-Change = 0.0280, Max-Change = 0.0324, Max-Change = 0.0245, Max-Change = 0.0206, Max-Change = 0.0582, Max-Change = 0.1457, Max-Change = 0.1511, Max-Change = 0.0209, Max-Change = 0.0267, Max-Change = 0.0446, Max-Change = 0.0215, Max-Change = 0.0342, Max-Change = 0.0302, Max-Change = 0.0250, Max-Change = 0.0243, Max-Change = 0.0328, Max-Change = 0.0501, Max-Change = 0.0469, Max-Change = 0.0334, Max-Change = 0.0397, Max-Change = 0.0432, Max-Change = 0.0359, Max-Change = 0.0453, Max-Change = 0.0531, Max-Change = 0.0292, Max-Change = 0.0746, Max-Change = 0.0277, Max-Change = 0.0428, Max-Change = 0.0360, Max-Change = 0.0192, Max-Change = 0.0417, Max-Change = 0.0985, Max-Change = 0.0430, Max-Change = 0.0719, Max-Change = 0.0375, Max-Change = 0.0897, Max-Change = 0.0965, Max-Change = 0.0335, Max-Change = 0.0142, Max-Change = 0.0691, Max-Change = 0.0262, Max-Change = 0.0221, Max-Change = 0.0268, Max-Change = 0.0380, Max-Change = 0.0164, Max-Change = 0.0363, Max-Change = 0.0327, Max-Change = 0.0249, Max-Change = 0.0424, Max-Change = 0.0251, Max-Change = 0.0268, Max-Change = 0.0135, Max-Change = 0.0284, Max-Change = 0.0227, Max-Change = 0.0602, Max-Change = 0.0376, Max-Change = 0.0923, Max-Change = 0.0242, Max-Change = 0.0351, Max-Change = 0.0323, Max-Change = 0.0183, Max-Change = 0.0798, Max-Change = 0.0240, Max-Change = 0.0152, Max-Change = 0.0306, Max-Change = 0.0358, Max-Change = 0.0224, Max-Change = 0.0456, Max-Change = 0.0368, Max-Change = 0.0433, Max-Change = 0.0282, Max-Change = 0.0515, Max-Change = 0.0197, Max-Change = 0.0383, Max-Change = 0.0347, Max-Change = 0.0552, Max-Change = 0.0335, Max-Change = 0.0451, Max-Change = 0.0781, Max-Change = 0.0216, Max-Change = 0.0632, Max-Change = 0.0692, Max-Change = 0.0258, Max-Change = 0.0163, Max-Change = 0.0691, Max-Change = 0.0801, Max-Change = 0.0167, Max-Change = 0.0222, Max-Change = 0.0589, Max-Change = 0.0476, Max-Change = 0.0379, Max-Change = 0.0200, Max-Change = 0.0338, Max-Change = 0.0330, Max-Change = 0.0485, Max-Change = 0.0172, Max-Change = 0.0572, Max-Change = 0.0768, Max-Change = 0.0778, Max-Change = 0.0265, Max-Change = 0.0154, Max-Change = 0.0443, Max-Change = 0.0493, Max-Change = 0.0453, Max-Change = 0.0535, Max-Change = 0.0715, Max-Change = 0.0221, Max-Change = 0.0111, Max-Change = 0.0247, Max-Change = 0.0247, Max-Change = 0.0241, Max-Change = 0.0272, Max-Change = 0.0306, Max-Change = 0.0162, Max-Change = 0.0221, Max-Change = 0.0294, Max-Change = 0.0372, Max-Change = 0.0296, Max-Change = 0.0488, Max-Change = 0.0391, Max-Change = 0.0507, Max-Change = 0.0285, Max-Change = 0.0618, Max-Change = 0.0331, Max-Change = 0.0732, Max-Change = 0.0846, Max-Change = 0.0608, Max-Change = 0.0069, Max-Change = 0.0398, Max-Change = 0.0189, Max-Change = 0.0586, Max-Change = 0.0618, Max-Change = 0.0484, Max-Change = 0.0347, Max-Change = 0.0301, Max-Change = 0.0289, Max-Change = 0.0393, Max-Change = 0.0335, Max-Change = 0.0359, Max-Change = 0.0273, Max-Change = 0.0726, Max-Change = 0.0130, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0356, gam = 0.1057, Max-Change = 0.0097, gam = 0.0780, Max-Change = 0.0097, gam = 0.0629, Max-Change = 0.0189, gam = 0.0532, Max-Change = 0.0062, gam = 0.0464, Max-Change = 0.0075, gam = 0.0413, Max-Change = 0.0093, gam = 0.0374, Max-Change = 0.0104, gam = 0.0342, Max-Change = 0.0023, gam = 0.0316, Max-Change = 0.0036, gam = 0.0294, Max-Change = 0.0027, gam = 0.0276, Max-Change = 0.0059, gam = 0.0260, Max-Change = 0.0041, gam = 0.0246, Max-Change = 0.0063, gam = 0.0233, Max-Change = 0.0052, gam = 0.0222, Max-Change = 0.0033, gam = 0.0212, Max-Change = 0.0020, gam = 0.0203, Max-Change = 0.0038, gam = 0.0195, Max-Change = 0.0046, gam = 0.0188, Max-Change = 0.0025, gam = 0.0181, Max-Change = 0.0020, gam = 0.0175, Max-Change = 0.0008, gam = 0.0169, Max-Change = 0.0059, gam = 0.0164, Max-Change = 0.0058, gam = 0.0159, Max-Change = 0.0049, gam = 0.0154, Max-Change = 0.0028, gam = 0.0150, Max-Change = 0.0015, gam = 0.0146, Max-Change = 0.0032, gam = 0.0142, Max-Change = 0.0028, gam = 0.0139, Max-Change = 0.0042, gam = 0.0135, Max-Change = 0.0025, gam = 0.0132, Max-Change = 0.0016, gam = 0.0129, Max-Change = 0.0025, gam = 0.0126, Max-Change = 0.0016, gam = 0.0124, Max-Change = 0.0036, gam = 0.0121, Max-Change = 0.0046, gam = 0.0119, Max-Change = 0.0026, gam = 0.0116, Max-Change = 0.0014, gam = 0.0114, Max-Change = 0.0016, gam = 0.0112, Max-Change = 0.0031, gam = 0.0110, Max-Change = 0.0015, gam = 0.0108, Max-Change = 0.0022, gam = 0.0106, Max-Change = 0.0009, gam = 0.0104, Max-Change = 0.0015, gam = 0.0102, Max-Change = 0.0025, gam = 0.0101, Max-Change = 0.0024, gam = 0.0099, Max-Change = 0.0014, gam = 0.0098, Max-Change = 0.0035, gam = 0.0096, Max-Change = 0.0030, gam = 0.0095, Max-Change = 0.0020, gam = 0.0093, Max-Change = 0.0007, gam = 0.0092, Max-Change = 0.0024, gam = 0.0091, Max-Change = 0.0014, gam = 0.0089, Max-Change = 0.0028, gam = 0.0088, Max-Change = 0.0025, gam = 0.0087, Max-Change = 0.0007, gam = 0.0086, Max-Change = 0.0009, gam = 0.0085, Max-Change = 0.0007 #>  #> Calculating log-likelihood... coef(mod2) #> $Item.1 #>        a1     d g u #> par 0.965 1.842 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.093 0.809 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.747 1.822 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.779 0.487 0 1 #>  #> $Item.5 #>         a      b #> par 0.752 -2.474 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   # same definition as above, but using symbolic derivative computations # (can be more accurate/stable) xs <- createItem(name, par=par, est=est, P=P.old2PL, derivType = 'symbolic') mod <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=xs)) #>  coef(mod, simplify=TRUE) #> $items #>           a1     d  g  u     a      b #> Item.1 0.989 1.856  0  1    NA     NA #> Item.2 1.081 0.808  0  1    NA     NA #> Item.3 1.703 1.803  0  1    NA     NA #> Item.4 0.766 0.486  0  1    NA     NA #> Item.5    NA    NA NA NA 0.737 -2.518 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # several secondary functions supported M2(mod, calcNull=FALSE) #>             M2 df          p      RMSEA     RMSEA_5   RMSEA_95      SRMSR #> stats 11.93609  5 0.03567406 0.03726401 0.008942493 0.06496201 0.03195094 itemfit(mod) #>     item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1 Item.1  4.750       2      0.037  0.093 #> 2 Item.2 14.441       2      0.079  0.001 #> 3 Item.3  1.266       2      0.000  0.531 #> 4 Item.4  5.241       2      0.040  0.073 #> 5 Item.5  0.941       2      0.000  0.625 fscores(mod, full.scores=FALSE) #>  #> Method:  EAP #>  #> Empirical Reliability: #>  #>     F1  #> 0.4521  #>       Item.1 Item.2 Item.3 Item.4 Item.5     F1 SE_F1 #>  [1,]      0      0      0      0      0 -1.870 0.693 #>  [2,]      0      0      0      0      1 -1.527 0.674 #>  [3,]      0      0      0      1      0 -1.514 0.673 #>  [4,]      0      0      0      1      1 -1.185 0.665 #>  [5,]      0      0      1      0      0 -1.096 0.665 #>  [6,]      0      0      1      0      1 -0.767 0.672 #>  [7,]      0      0      1      1      0 -0.754 0.673 #>  [8,]      0      0      1      1      1 -0.412 0.692 #>  [9,]      0      1      0      0      0 -1.372 0.668 #> [10,]      0      1      0      0      1 -1.045 0.666 #> [11,]      0      1      0      1      0 -1.032 0.666 #> [12,]      0      1      0      1      1 -0.702 0.675 #> [13,]      0      1      1      0      0 -0.610 0.680 #> [14,]      0      1      1      0      1 -0.258 0.704 #> [15,]      0      1      1      1      0 -0.244 0.705 #> [16,]      0      1      1      1      1  0.141 0.741 #> [17,]      1      0      0      0      0 -1.413 0.670 #> [18,]      1      0      0      0      1 -1.086 0.665 #> [19,]      1      0      0      1      0 -1.073 0.665 #> [20,]      1      0      0      1      1 -0.744 0.673 #> [21,]      1      0      1      0      0 -0.653 0.678 #> [22,]      1      0      1      0      1 -0.304 0.701 #> [23,]      1      0      1      1      0 -0.290 0.702 #> [24,]      1      0      1      1      1  0.090 0.736 #> [25,]      1      1      0      0      0 -0.933 0.667 #> [26,]      1      1      0      0      1 -0.600 0.680 #> [27,]      1      1      0      1      0 -0.587 0.681 #> [28,]      1      1      0      1      1 -0.233 0.706 #> [29,]      1      1      1      0      0 -0.132 0.715 #> [30,]      1      1      1      0      1  0.265 0.754 #> [31,]      1      1      1      1      0  0.282 0.755 #> [32,]      1      1      1      1      1  0.727 0.801 plot(mod)   # fit the same model, but specify gradient function explicitly (use of a browser() may be helpful) gr <- function(x, Theta){      # browser()      a <- x@par[1]      b <- x@par[2]      P <- probtrace(x, Theta)      PQ <- apply(P, 1, prod)      r_P <- x@dat / P      grad <- numeric(2)      grad[2] <- sum(-a * PQ * (r_P[,2] - r_P[,1]))      grad[1] <- sum((Theta - b) * PQ * (r_P[,2] - r_P[,1]))       ## check with internal numerical form to be safe      # numerical_deriv(x@par[x@est], mirt:::EML, obj=x, Theta=Theta)      grad }  x <- createItem(name, par=par, est=est, P=P.old2PL, gr=gr) mod <- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x)) #>  coef(mod, simplify=TRUE) #> $items #>           a1     d  g  u     a      b #> Item.1 0.989 1.856  0  1    NA     NA #> Item.2 1.081 0.808  0  1    NA     NA #> Item.3 1.703 1.803  0  1    NA     NA #> Item.4 0.766 0.486  0  1    NA     NA #> Item.5    NA    NA NA NA 0.737 -2.518 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   ### non-linear name <- 'nonlin' par <- c(a1 = .5, a2 = .1, d = 0) est <- c(TRUE, TRUE, TRUE) P.nonlin <- function(par,Theta, ncat=2){      a1 <- par[1]      a2 <- par[2]      d <- par[3]      P1 <- 1 / (1 + exp(-1*(a1*Theta + a2*Theta^2 + d)))      cbind(1-P1, P1) }  x2 <- createItem(name, par=par, est=est, P=P.nonlin)  mod <- mirt(dat, 1, c(rep('2PL',4), 'nonlin'), customItems=list(nonlin=x2)) #>  coef(mod) #> $Item.1 #>        a1     d g u #> par 0.984 1.854 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.087 0.809 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.704 1.803 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.762 0.486 0 1 #>  #> $Item.5 #>        a1    a2     d #> par 0.806 0.065 1.818 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   ### nominal response model (Bock 1972 version) Tnom.dev <- function(ncat) {    T <- matrix(1/ncat, ncat, ncat - 1)    diag(T[-1, ]) <-  diag(T[-1, ]) - 1    return(T) }  name <- 'nom' par <- c(alp=c(3,0,-3),gam=rep(.4,3)) est <- rep(TRUE, length(par)) P.nom <- function(par, Theta, ncat){    alp <- par[1:(ncat-1)]    gam <- par[ncat:length(par)]    a <- Tnom.dev(ncat) %*% alp    c <- Tnom.dev(ncat) %*% gam    z <- matrix(0, nrow(Theta), ncat)    for(i in 1:ncat)        z[,i] <- a[i] * Theta + c[i]    P <- exp(z) / rowSums(exp(z))    P }  nom1 <- createItem(name, par=par, est=est, P=P.nom) nommod <- mirt(Science, 1, 'nom1', customItems=list(nom1=nom1)) #>  coef(nommod) #> $Comfort #>       alp1   alp2   alp3   gam1   gam2   gam3 #> par -1.552 -2.015 -3.024 -3.639 -5.905 -4.533 #>  #> $Work #>      alp1   alp2   alp3   gam1   gam2   gam3 #> par -0.58 -1.262 -2.523 -1.464 -2.327 -0.326 #>  #> $Future #>       alp1 alp2   alp3   gam1   gam2  gam3 #> par -1.559 -3.8 -6.118 -3.676 -5.875 -3.96 #>  #> $Benefit #>       alp1   alp2   alp3   gam1   gam2   gam3 #> par -0.808 -1.358 -2.338 -2.145 -2.912 -1.622 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  Tnom.dev(4) %*% coef(nommod)[[1]][1:3] #a #>             [,1] #> [1,] -1.64770841 #> [2,] -0.09534806 #> [3,]  0.36680247 #> [4,]  1.37625400 Tnom.dev(4) %*% coef(nommod)[[1]][4:6] #d #>            [,1] #> [1,] -3.5191097 #> [2,]  0.1195514 #> [3,]  2.3861166 #> [4,]  1.0134416  # }"},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":null,"dir":"Reference","previous_headings":"","what":"Description of deAyala data — deAyala","title":"Description of deAyala data — deAyala","text":"Mathematics data de Ayala (2009; pg. 14); 5 item dataset table format.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Description of deAyala data — deAyala","text":"de Ayala, R. J. (2009). theory practice item response theory. Guilford Press.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Description of deAyala data — deAyala","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/deAyala.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Description of deAyala data — deAyala","text":"","code":"# \\donttest{ dat <- expand.table(deAyala) head(dat) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 itemstats(dat) #> $overall #>      N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  19601            2.912          1.434 0.233 0.074 0.608     0.898 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 19601 2 0.887 0.316   0.447         0.246       0.605 #> Item.2 19601 2 0.644 0.479   0.688         0.439       0.510 #> Item.3 19601 2 0.566 0.496   0.680         0.416       0.523 #> Item.4 19601 2 0.427 0.495   0.673         0.405       0.529 #> Item.5 19601 2 0.387 0.487   0.602         0.312       0.581 #>  #> $proportions #>            0     1 #> Item.1 0.113 0.887 #> Item.2 0.356 0.644 #> Item.3 0.434 0.566 #> Item.4 0.573 0.427 #> Item.5 0.613 0.387 #>   # }"},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw plausible parameter instantiations from a given model — draw_parameters","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"Draws plausible parameters model using parametric sampling (information matrix computed) via bootstrap sampling. Primarily use DRF function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"","code":"draw_parameters(   mod,   draws,   method = c(\"parametric\", \"boostrap\"),   redraws = 20,   verbose = FALSE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"mod estimated single multiple-group model draws number draws obtain method type plausible values obtain. Can 'parametric', parametric sampling scheme uses estimated information matrix, 'boostrap' obtain values boot function. Default 'parametric' redraws number redraws perform given parameteric sample satisfy upper lower parameter bounds. valid set found within number draws error thrown verbose logical; include additional information console? ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"returns draws x p matrix plausible parameters, row correspeonds single   set","code":""},{"path":"https://philchalmers.github.io/mirt/reference/draw_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw plausible parameter instantiations from a given model — draw_parameters","text":"","code":"# \\donttest{ set.seed(1234) n <- 40 N <- 500  # only first 5 items as anchors model <- 'F = 1-40           CONSTRAINB = (1-5, a1), (1-5, d)'  a <- matrix(1, n) d <- matrix(rnorm(n), n) group <- c(rep('Group_1', N), rep('Group_2', N))  ## ------------- # groups completely equal dat1 <- simdata(a, d, N, itemtype = 'dich') dat2 <- simdata(a, d, N, itemtype = 'dich') dat <- rbind(dat1, dat2) mod <- multipleGroup(dat, model, group=group, SE=TRUE,                      invariance=c('free_means', 'free_var')) #>  #>  #> Calculating information matrix...  param_set <- draw_parameters(mod, 100) head(param_set) #>           [,1]      [,2] [,3] [,4]      [,5]      [,6] [,7] [,8]     [,9] #> [1,] 1.1391483 -1.262734    0    1 1.0429570 0.4288435    0    1 1.426608 #> [2,] 1.0484967 -1.270230    0    1 1.2642261 0.4139742    0    1 1.055071 #> [3,] 0.9015559 -1.120842    0    1 1.1142861 0.2913104    0    1 1.179315 #> [4,] 1.2083665 -1.252647    0    1 1.2302625 0.3839666    0    1 1.282218 #> [5,] 1.0422827 -1.129914    0    1 1.0267393 0.4106227    0    1 1.109890 #> [6,] 0.9569286 -1.073822    0    1 0.8923384 0.5172578    0    1 1.122109 #>          [,10] [,11] [,12]     [,13]     [,14] [,15] [,16]     [,17]     [,18] #> [1,] 1.3571747     0     1 1.3228956 -2.259732     0     1 0.7230044 0.4307506 #> [2,] 0.9838252     0     1 1.1902988 -2.265339     0     1 0.7787847 0.6617051 #> [3,] 1.1912044     0     1 1.1822386 -2.236731     0     1 0.9837777 0.5259832 #> [4,] 0.9824300     0     1 1.0777324 -2.368948     0     1 0.8211154 0.3825540 #> [5,] 1.0501543     0     1 1.1938541 -2.170218     0     1 0.7517767 0.3950822 #> [6,] 1.3031493     0     1 0.9314969 -2.084266     0     1 0.8255591 0.5518456 #>      [,19] [,20]    [,21]     [,22] [,23] [,24]    [,25]      [,26] [,27] [,28] #> [1,]     0     1 1.163287 0.4935805     0     1 1.138408 -0.4730967     0     1 #> [2,]     0     1 1.295991 0.2962779     0     1 1.277705 -0.3843515     0     1 #> [3,]     0     1 1.393149 0.4957497     0     1 1.207929 -0.5509638     0     1 #> [4,]     0     1 1.221361 0.2570856     0     1 1.050326 -0.5914620     0     1 #> [5,]     0     1 1.051667 0.1174200     0     1 1.302897 -0.4298341     0     1 #> [6,]     0     1 1.066978 0.3894473     0     1 1.192809 -0.4857318     0     1 #>          [,29]      [,30] [,31] [,32]     [,33]      [,34] [,35] [,36] #> [1,] 1.3527927 -0.5621654     0     1 0.8924490 -0.5117369     0     1 #> [2,] 1.1797525 -0.5450951     0     1 0.9312760 -0.4114297     0     1 #> [3,] 1.4737991 -0.6303803     0     1 0.8593670 -0.4383557     0     1 #> [4,] 1.0532493 -0.6968834     0     1 1.0448990 -0.4547611     0     1 #> [5,] 0.9259638 -0.5687452     0     1 0.8781231 -0.6390878     0     1 #> [6,] 1.4960325 -0.4478350     0     1 0.8747685 -0.4139600     0     1 #>          [,37]      [,38] [,39] [,40]     [,41]      [,42] [,43] [,44] #> [1,] 1.0394553 -0.9996527     0     1 1.3385259 -0.4398979     0     1 #> [2,] 0.8843201 -0.9601152     0     1 1.0098380 -0.4068918     0     1 #> [3,] 1.0472870 -0.8472980     0     1 1.0328674 -0.4165800     0     1 #> [4,] 1.0481757 -1.1208763     0     1 1.5198539 -0.3905815     0     1 #> [5,] 0.8323413 -0.7925520     0     1 0.9477638 -0.4690871     0     1 #> [6,] 0.8903164 -0.8060033     0     1 1.1486378 -0.5070993     0     1 #>          [,45]      [,46] [,47] [,48]     [,49]      [,50] [,51] [,52] #> [1,] 1.0213159 -1.0562492     0     1 1.2856206 -0.9979787     0     1 #> [2,] 1.0863032 -0.9086148     0     1 1.1838084 -0.6952002     0     1 #> [3,] 1.3031167 -1.0691703     0     1 1.0733004 -0.7782127     0     1 #> [4,] 1.2671267 -1.2655045     0     1 1.0755923 -0.8150892     0     1 #> [5,] 0.9003792 -0.8236895     0     1 1.0510657 -0.7829129     0     1 #> [6,] 0.7936887 -0.8023501     0     1 0.8012048 -0.7711545     0     1 #>          [,53]      [,54] [,55] [,56]    [,57]     [,58] [,59] [,60]     [,61] #> [1,] 0.8176167 0.14318947     0     1 1.300685 1.0884976     0     1 0.8592561 #> [2,] 0.9589934 0.23632198     0     1 1.465501 1.0258817     0     1 1.1314657 #> [3,] 0.8126472 0.21273220     0     1 1.384537 1.0716981     0     1 0.8341391 #> [4,] 0.9141176 0.12657353     0     1 1.376907 0.9620398     0     1 0.9868454 #> [5,] 0.9342273 0.07780975     0     1 1.084790 1.0487968     0     1 0.9410801 #> [6,] 1.0545787 0.01144851     0     1 1.368823 1.3333772     0     1 1.0745862 #>            [,62] [,63] [,64]     [,65]      [,66] [,67] [,68]    [,69] #> [1,] -0.11398977     0     1 0.8092362 -0.5233638     0     1 1.313814 #> [2,] -0.02999061     0     1 1.0429873 -0.5469506     0     1 1.241366 #> [3,] -0.11669005     0     1 1.2888696 -0.5121943     0     1 1.274844 #> [4,] -0.21986790     0     1 1.1642875 -0.7154811     0     1 1.077224 #> [5,]  0.06666290     0     1 0.9142215 -0.4847582     0     1 1.226571 #> [6,]  0.11548131     0     1 0.8656718 -0.3201650     0     1 1.139974 #>           [,70] [,71] [,72]     [,73]      [,74] [,75] [,76]    [,77]    [,78] #> [1,] -0.9808331     0     1 1.0888395 -0.7741633     0     1 1.178652 2.567549 #> [2,] -0.9901081     0     1 1.0017605 -0.5739486     0     1 1.713045 3.165311 #> [3,] -1.1133870     0     1 0.8404789 -0.5877353     0     1 1.559142 2.637752 #> [4,] -0.9457014     0     1 0.9973526 -0.5775381     0     1 1.482782 2.682691 #> [5,] -1.0808264     0     1 1.0079996 -0.6276290     0     1 1.150029 2.552863 #> [6,] -0.7694778     0     1 1.3709521 -0.6365566     0     1 1.572618 2.960950 #>      [,79] [,80]     [,81]         [,82] [,83] [,84]     [,85]      [,86] [,87] #> [1,]     0     1 0.9749305  0.1262429236     0     1 1.2569358 -0.6753280     0 #> [2,]     0     1 0.6378724 -0.0416338706     0     1 1.3503421 -0.6989674     0 #> [3,]     0     1 1.0769431  0.0747536323     0     1 1.1304521 -0.4273371     0 #> [4,]     0     1 0.9466751  0.0001031707     0     1 1.2338620 -0.7305857     0 #> [5,]     0     1 0.9646448  0.0222661239     0     1 0.8675040 -0.5533663     0 #> [6,]     0     1 0.8953228  0.0550655416     0     1 0.9862147 -0.5061780     0 #>      [,88]     [,89]      [,90] [,91] [,92]     [,93]     [,94] [,95] [,96] #> [1,]     1 0.8943719 -0.3695982     0     1 1.1414398 0.4496614     0     1 #> [2,]     1 0.8856734 -0.3901241     0     1 1.1720906 0.4237425     0     1 #> [3,]     1 0.7230547 -0.4177326     0     1 1.1242046 0.3721096     0     1 #> [4,]     1 0.7502933 -0.4709276     0     1 1.1538624 0.5534905     0     1 #> [5,]     1 0.8277912 -0.5723144     0     1 0.9200630 0.4596039     0     1 #> [6,]     1 0.8063404 -0.2832000     0     1 0.9777813 0.4521504     0     1 #>          [,97]      [,98] [,99] [,100]   [,101]    [,102] [,103] [,104] #> [1,] 0.9558493 -0.6142083     0      1 1.345436 -1.290430      0      1 #> [2,] 1.1158185 -0.5876543     0      1 1.575489 -1.563281      0      1 #> [3,] 1.2789162 -0.6620510     0      1 1.565974 -1.553429      0      1 #> [4,] 1.0295191 -0.6704559     0      1 1.205470 -1.614799      0      1 #> [5,] 0.9924574 -0.5624854     0      1 1.092117 -1.555365      0      1 #> [6,] 1.0533410 -0.3613626     0      1 1.402935 -1.392786      0      1 #>        [,105]    [,106] [,107] [,108]    [,109]     [,110] [,111] [,112] #> [1,] 1.371332 0.8212177      0      1 1.0591471 -0.7177690      0      1 #> [2,] 1.387874 0.6305876      0      1 1.2003535 -0.9511692      0      1 #> [3,] 1.236606 0.5940211      0      1 0.9270756 -0.9554089      0      1 #> [4,] 1.229710 0.5414306      0      1 0.8022847 -0.8891033      0      1 #> [5,] 1.279885 0.9269728      0      1 1.0720169 -1.0762113      0      1 #> [6,] 1.553092 1.0841679      0      1 1.3316026 -0.9780309      0      1 #>         [,113]      [,114] [,115] [,116]    [,117]     [,118] [,119] [,120] #> [1,] 1.3841756 -0.11060699      0      1 0.9359201 -0.9057253      0      1 #> [2,] 1.2721103 -0.12842834      0      1 1.1714803 -0.9517779      0      1 #> [3,] 0.9154547 -0.25247189      0      1 1.2103058 -0.9697586      0      1 #> [4,] 1.2261748 -0.23379251      0      1 1.0271747 -0.7794432      0      1 #> [5,] 1.3606454 -0.11402304      0      1 0.9669171 -0.8006616      0      1 #> [6,] 1.1510466 -0.05004385      0      1 0.8964734 -0.7972526      0      1 #>         [,121]   [,122] [,123] [,124]    [,125]      [,126] [,127] [,128] #> [1,] 1.0723199 1.231363      0      1 0.9407801 -0.32888706      0      1 #> [2,] 1.0880423 1.285115      0      1 1.0321004 -0.34028929      0      1 #> [3,] 1.3211033 1.525651      0      1 0.9438052 -0.27036514      0      1 #> [4,] 0.7331608 1.299447      0      1 1.0681655 -0.30187607      0      1 #> [5,] 1.1344802 1.469861      0      1 0.7784913 -0.10341687      0      1 #> [6,] 0.9448852 1.203271      0      1 0.8675714 -0.06169187      0      1 #>         [,129]     [,130] [,131] [,132]    [,133]     [,134] [,135] [,136] #> [1,] 0.8582874 -0.5372013      0      1 1.0455382 -0.5890014      0      1 #> [2,] 1.0358113 -0.5796357      0      1 0.7891645 -0.4892293      0      1 #> [3,] 1.0376528 -0.5784212      0      1 1.0742268 -0.7452434      0      1 #> [4,] 0.9488976 -0.7974830      0      1 0.8301226 -0.6310398      0      1 #> [5,] 0.7512012 -0.7169425      0      1 0.8355660 -0.4990204      0      1 #> [6,] 1.2407201 -0.6411234      0      1 1.0449233 -0.4900304      0      1 #>         [,137]    [,138] [,139] [,140]    [,141]     [,142] [,143] [,144] #> [1,] 1.2294920 -1.652615      0      1 0.8113578 -1.0591070      0      1 #> [2,] 0.9020178 -1.372767      0      1 0.9551101 -1.1610801      0      1 #> [3,] 1.0222270 -1.510696      0      1 0.8123737 -0.9439134      0      1 #> [4,] 0.7451938 -1.646804      0      1 0.9577529 -1.1057927      0      1 #> [5,] 0.9055046 -1.493831      0      1 0.8405730 -0.9015825      0      1 #> [6,] 1.0238206 -1.606561      0      1 0.5875165 -0.6929282      0      1 #>         [,145]    [,146] [,147] [,148]   [,149]    [,150] [,151] [,152] #> [1,] 0.9904563 -2.317328      0      1 1.117666 -1.358481      0      1 #> [2,] 1.1253025 -2.307848      0      1 1.051013 -1.437488      0      1 #> [3,] 1.1460402 -2.378569      0      1 1.337640 -1.418852      0      1 #> [4,] 1.2316904 -2.440186      0      1 1.103262 -1.415161      0      1 #> [5,] 1.2664414 -2.624070      0      1 1.225435 -1.484993      0      1 #> [6,] 1.1905030 -2.587987      0      1 1.003452 -1.142934      0      1 #>         [,153]     [,154] [,155] [,156]    [,157]     [,158] [,159] [,160] #> [1,] 1.0051995 -0.1446553      0      1 1.2271219 -0.2833820      0      1 #> [2,] 0.7331594 -0.1336442      0      1 0.8868186 -0.3848605      0      1 #> [3,] 0.7006688 -0.1968375      0      1 1.1800772 -0.3825698      0      1 #> [4,] 0.7622295 -0.2943384      0      1 1.0171924 -0.2595975      0      1 #> [5,] 0.7589873 -0.3463519      0      1 0.9470745 -0.4106848      0      1 #> [6,] 0.8812607 -0.1017558      0      1 1.1799064 -0.2237318      0      1 #>      [,161] [,162]    [,163]    [,164] [,165] [,166]    [,167]    [,168] [,169] #> [1,]      0      1 1.1391483 -1.262734      0      1 1.0429570 0.4288435      0 #> [2,]      0      1 1.0484967 -1.270230      0      1 1.2642261 0.4139742      0 #> [3,]      0      1 0.9015559 -1.120842      0      1 1.1142861 0.2913104      0 #> [4,]      0      1 1.2083665 -1.252647      0      1 1.2302625 0.3839666      0 #> [5,]      0      1 1.0422827 -1.129914      0      1 1.0267393 0.4106227      0 #> [6,]      0      1 0.9569286 -1.073822      0      1 0.8923384 0.5172578      0 #>      [,170]   [,171]    [,172] [,173] [,174]    [,175]    [,176] [,177] [,178] #> [1,]      1 1.426608 1.3571747      0      1 1.3228956 -2.259732      0      1 #> [2,]      1 1.055071 0.9838252      0      1 1.1902988 -2.265339      0      1 #> [3,]      1 1.179315 1.1912044      0      1 1.1822386 -2.236731      0      1 #> [4,]      1 1.282218 0.9824300      0      1 1.0777324 -2.368948      0      1 #> [5,]      1 1.109890 1.0501543      0      1 1.1938541 -2.170218      0      1 #> [6,]      1 1.122109 1.3031493      0      1 0.9314969 -2.084266      0      1 #>         [,179]    [,180] [,181] [,182]    [,183]    [,184] [,185] [,186] #> [1,] 0.7230044 0.4307506      0      1 0.5769400 0.3785568      0      1 #> [2,] 0.7787847 0.6617051      0      1 0.9951140 0.5035113      0      1 #> [3,] 0.9837777 0.5259832      0      1 0.6653239 0.2314147      0      1 #> [4,] 0.8211154 0.3825540      0      1 0.9269246 0.3332767      0      1 #> [5,] 0.7517767 0.3950822      0      1 0.6941908 0.4616564      0      1 #> [6,] 0.8255591 0.5518456      0      1 0.8832430 0.6587134      0      1 #>         [,187]     [,188] [,189] [,190]    [,191]     [,192] [,193] [,194] #> [1,] 1.1773545 -0.5980234      0      1 0.8270737 -0.3566087      0      1 #> [2,] 1.2006478 -0.4580348      0      1 1.2312037 -0.4468948      0      1 #> [3,] 0.9915550 -0.4397290      0      1 0.7832430 -0.3698797      0      1 #> [4,] 0.8631297 -0.6454328      0      1 0.9260373 -0.5538133      0      1 #> [5,] 1.1585987 -0.5414463      0      1 0.9432157 -0.4511684      0      1 #> [6,] 1.1344615 -0.1556385      0      1 0.8387850 -0.2676433      0      1 #>         [,195]     [,196] [,197] [,198]    [,199]     [,200] [,201] [,202] #> [1,] 0.7955699 -0.6940803      0      1 1.1881239 -0.8672510      0      1 #> [2,] 1.0363203 -0.6676152      0      1 0.9175631 -0.8380532      0      1 #> [3,] 0.8495424 -0.4471806      0      1 1.0530127 -0.7772087      0      1 #> [4,] 0.6804526 -0.7378925      0      1 0.9491316 -0.8842658      0      1 #> [5,] 0.8446033 -0.3752518      0      1 0.7418598 -0.4362928      0      1 #> [6,] 0.7291273 -0.3666299      0      1 0.8138697 -0.5491436      0      1 #>         [,203]     [,204] [,205] [,206]    [,207]     [,208] [,209] [,210] #> [1,] 1.1721489 -0.5048728      0      1 1.4271251 -0.8890863      0      1 #> [2,] 0.9024861 -0.3658105      0      1 1.3371533 -0.7301275      0      1 #> [3,] 0.8207097 -0.6218768      0      1 1.2301967 -0.8838977      0      1 #> [4,] 1.1753180 -0.8479833      0      1 1.0316888 -1.2796689      0      1 #> [5,] 0.9550732 -0.3683144      0      1 1.5088175 -0.9401377      0      1 #> [6,] 0.7787624 -0.1532742      0      1 0.6774223 -0.6721852      0      1 #>         [,211]     [,212] [,213] [,214]    [,215]     [,216] [,217] [,218] #> [1,] 1.0828472 -0.5861585      0      1 0.9437358 0.09630408      0      1 #> [2,] 0.9179892 -0.6699237      0      1 1.1634037 0.40872859      0      1 #> [3,] 0.8099097 -0.6891387      0      1 0.9437236 0.36898206      0      1 #> [4,] 0.9380615 -0.7708514      0      1 0.9953149 0.24996260      0      1 #> [5,] 0.9065562 -0.5227436      0      1 0.8901240 0.22865150      0      1 #> [6,] 0.8478866 -0.5027821      0      1 0.8493834 0.64925158      0      1 #>        [,219]    [,220] [,221] [,222]    [,223]      [,224] [,225] [,226] #> [1,] 1.251224 1.2660189      0      1 0.8093795 -0.03781640      0      1 #> [2,] 1.275120 1.1705077      0      1 0.8337834 -0.08649986      0      1 #> [3,] 1.075980 1.0332136      0      1 0.8603016 -0.24082097      0      1 #> [4,] 1.178972 0.8965858      0      1 1.0906790 -0.21602316      0      1 #> [5,] 1.465808 1.4528392      0      1 0.9667611  0.16206703      0      1 #> [6,] 1.003672 1.2810119      0      1 0.9793605  0.08787089      0      1 #>         [,227]     [,228] [,229] [,230]    [,231]     [,232] [,233] [,234] #> [1,] 1.1241183 -0.2655857      0      1 0.8256868 -0.6485636      0      1 #> [2,] 1.1013506 -0.3204781      0      1 1.0770762 -0.8222196      0      1 #> [3,] 1.2208786 -0.2838600      0      1 0.7337529 -0.7363470      0      1 #> [4,] 1.1255067 -0.5292478      0      1 0.7869537 -1.0085999      0      1 #> [5,] 1.3929457 -0.1996818      0      1 0.7863723 -0.7639843      0      1 #> [6,] 0.9912025 -0.1305252      0      1 0.7348674 -0.7732220      0      1 #>         [,235]     [,236] [,237] [,238]    [,239]   [,240] [,241] [,242] #> [1,] 1.0720096 -0.4475839      0      1 1.0192282 2.661379      0      1 #> [2,] 0.9165160 -0.5343116      0      1 1.3177852 2.757122      0      1 #> [3,] 0.9368496 -0.6705828      0      1 0.9742986 2.529694      0      1 #> [4,] 0.8131281 -0.5930921      0      1 0.9871176 2.429140      0      1 #> [5,] 1.0643592 -0.4905213      0      1 1.2126925 2.697152      0      1 #> [6,] 0.8418799 -0.4321622      0      1 0.7567293 2.617328      0      1 #>         [,243]      [,244] [,245] [,246]    [,247]      [,248] [,249] [,250] #> [1,] 0.8355139  0.06780849      0      1 1.4137807 -0.21321010      0      1 #> [2,] 1.1336181  0.25348032      0      1 1.2815150 -0.17706914      0      1 #> [3,] 0.5790901  0.13768769      0      1 1.2638156 -0.27375929      0      1 #> [4,] 0.9006494 -0.10519192      0      1 1.0604866 -0.50714435      0      1 #> [5,] 0.9075233  0.18475994      0      1 1.5191410 -0.14976089      0      1 #> [6,] 0.9369082  0.43920923      0      1 0.9969382  0.06122104      0      1 #>         [,251]     [,252] [,253] [,254]    [,255]    [,256] [,257] [,258] #> [1,] 1.1006399 -0.2310053      0      1 1.4072880 0.8882977      0      1 #> [2,] 1.0802270 -0.6114761      0      1 1.2684383 0.9621852      0      1 #> [3,] 0.7880503 -0.3299453      0      1 1.1213552 0.9072474      0      1 #> [4,] 0.9676510 -0.5462906      0      1 1.3448628 0.6590025      0      1 #> [5,] 1.2516757 -0.2830300      0      1 1.4669848 1.2250279      0      1 #> [6,] 0.8800138 -0.2295392      0      1 0.9690171 1.0716043      0      1 #>         [,259]     [,260] [,261] [,262]    [,263]    [,264] [,265] [,266] #> [1,] 1.0834722 -0.2874127      0      1 1.2372506 -1.584907      0      1 #> [2,] 1.0168680 -0.4050232      0      1 0.7296544 -1.262677      0      1 #> [3,] 1.2575131 -0.5186062      0      1 0.8585354 -1.362950      0      1 #> [4,] 0.9251556 -0.7952507      0      1 1.1705181 -1.415852      0      1 #> [5,] 1.0538602 -0.5370181      0      1 0.9277027 -1.212450      0      1 #> [6,] 0.6340691 -0.3535315      0      1 0.8223446 -1.063424      0      1 #>        [,267]    [,268] [,269] [,270]    [,271]     [,272] [,273] [,274] #> [1,] 1.306097 0.6539537      0      1 0.9254586 -1.0119491      0      1 #> [2,] 1.165129 0.6360237      0      1 0.6041956 -0.8960488      0      1 #> [3,] 1.042479 0.5804395      0      1 0.9719401 -0.9049817      0      1 #> [4,] 1.020745 0.4597267      0      1 0.8854014 -0.8461745      0      1 #> [5,] 1.343508 0.7992399      0      1 1.0889584 -0.7382598      0      1 #> [6,] 0.879896 0.8475393      0      1 0.8833642 -0.9095443      0      1 #>         [,275]     [,276] [,277] [,278]    [,279]     [,280] [,281] [,282] #> [1,] 1.1094789 0.26995895      0      1 1.2318738 -0.9162557      0      1 #> [2,] 1.1581189 0.22195525      0      1 0.9474658 -0.8550226      0      1 #> [3,] 0.8855246 0.02187095      0      1 1.0470295 -1.0408474      0      1 #> [4,] 1.0652445 0.08395807      0      1 1.0388042 -0.9947872      0      1 #> [5,] 1.2904380 0.37359394      0      1 0.9947444 -0.7320669      0      1 #> [6,] 1.0330133 0.53339806      0      1 1.0023877 -0.6590216      0      1 #>         [,283]   [,284] [,285] [,286]    [,287]     [,288] [,289] [,290] #> [1,] 1.0127844 1.086732      0      1 1.3016443 -0.5645592      0      1 #> [2,] 0.9325888 1.185042      0      1 1.2797563 -0.3321682      0      1 #> [3,] 0.8565901 1.200676      0      1 1.0858069 -0.5370129      0      1 #> [4,] 0.7655193 1.001382      0      1 0.9557799 -0.6196782      0      1 #> [5,] 0.9698498 1.206204      0      1 1.0974389 -0.3217740      0      1 #> [6,] 0.8846890 1.368720      0      1 0.6796244 -0.4113879      0      1 #>         [,291]     [,292] [,293] [,294]    [,295]      [,296] [,297] [,298] #> [1,] 0.9665674 -0.4499613      0      1 1.2751161 -0.27242604      0      1 #> [2,] 1.0356792 -0.5721748      0      1 1.1089584 -0.16897865      0      1 #> [3,] 0.9499328 -0.4461424      0      1 1.1750413 -0.44589779      0      1 #> [4,] 0.6212662 -0.6609387      0      1 0.9129298 -0.70055663      0      1 #> [5,] 0.9964689 -0.5005593      0      1 1.1185746 -0.19530607      0      1 #> [6,] 0.7778953 -0.4090593      0      1 1.0454056 -0.08128737      0      1 #>         [,299]    [,300] [,301] [,302]    [,303]    [,304] [,305] [,306] #> [1,] 0.9457179 -1.694390      0      1 0.8919277 -1.298184      0      1 #> [2,] 1.1671609 -1.568946      0      1 1.1484235 -1.217317      0      1 #> [3,] 0.9104849 -1.588931      0      1 0.7172764 -1.194908      0      1 #> [4,] 0.7951303 -1.910015      0      1 0.9743124 -1.257373      0      1 #> [5,] 0.8852897 -1.377146      0      1 0.9976067 -1.021570      0      1 #> [6,] 0.8919738 -1.526346      0      1 0.7979590 -1.070965      0      1 #>         [,307]    [,308] [,309] [,310]    [,311]     [,312] [,313] [,314] #> [1,] 0.9776854 -1.917578      0      1 0.7331039 -0.9768044      0      1 #> [2,] 0.9623468 -1.886203      0      1 1.0542581 -1.0651804      0      1 #> [3,] 0.9433850 -2.146880      0      1 1.0355126 -1.1161856      0      1 #> [4,] 1.0764607 -2.357394      0      1 1.0398717 -1.2172835      0      1 #> [5,] 1.0682621 -2.334701      0      1 1.1997906 -1.0727553      0      1 #> [6,] 0.8298646 -1.838798      0      1 1.0184908 -1.0133290      0      1 #>         [,315]        [,316] [,317] [,318]    [,319]      [,320] [,321] [,322] #> [1,] 1.0091757 -0.2196782520      0      1 1.0090705 -0.25004128      0      1 #> [2,] 1.0190809 -0.0007938555      0      1 0.9135201 -0.29224069      0      1 #> [3,] 1.0794888 -0.1673724693      0      1 0.7342355 -0.35306806      0      1 #> [4,] 0.9524044 -0.4012855790      0      1 0.9772383 -0.27937015      0      1 #> [5,] 1.1289982  0.1365135265      0      1 0.7633150 -0.12458776      0      1 #> [6,] 0.8079603 -0.0062007574      0      1 0.7488032 -0.06740662      0      1 #>           [,323]    [,324] #> [1,] -0.17452981 0.7971819 #> [2,] -0.23051322 0.8413638 #> [3,] -0.17643483 1.0450858 #> [4,]  0.06443079 1.0789363 #> [5,] -0.27483253 0.8621822 #> [6,] -0.47547745 1.1212340 # }"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical effect sizes based on latent trait estimates — empirical_ES","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"Computes effect size measures differential item functioning differential test/bundle functioning based expected scores Meade (2010). Item parameters reference focal group used conjunction focal group empirical theta estimates (assumed normally distributed theta) compute expected scores.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"","code":"empirical_ES(   mod,   Theta.focal = NULL,   focal_items = 1L:extract.mirt(mod, \"nitems\"),   DIF = TRUE,   npts = 61,   theta_lim = c(-6, 6),   plot = FALSE,   type = \"b\",   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"mod multipleGroup object estimated 2 groups. first group object assumed reference group default (.e., ref.group = 1), conforms  invariance arguments multipleGroup Theta.focal optional matrix Theta values focal group evaluated. supplied default values fscores used conjunction ... arguments passed focal_items numeric vector indicating items include tests. default uses items. Selecting fewer items result tests 'differential bundle functioning' DIF = FALSE DIF logical; return data.frame item-level imputation properties? FALSE, DBF DTF statistics reported npts number points use integration. Default 61 theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts plot logical; plot expected scores items/test expected scores computed using focal group thetas focal reference group item parameters type type objects draw lattice; default plots points lines par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice ... additional arguments passed fscores xyplot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"dif","dir":"Reference","previous_headings":"","what":"DIF","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"default DIF = TRUE produces several effect sizes indices item level. Signed indices allow DIF favoring focal group one point theta distribution cancel DIF favoring reference group another point theta distribution. Unsigned indices take absolute value summing averaging, thus allowing cancellation DIF across theta. SIDS Signed Item Difference Sample. average difference expected scores across focal sample using focal reference group item parameters. UIDS Unsigned Item Difference Sample. SIDS except absolute value expected scores taken prior averaging across sample. D-Max maximum difference expected scores sample. ESSD Expected Score Standardized Difference. Cohen's D difference expected scores. SIDN Signed Item Difference Normal distribution. Identical SIDS averaged across normal distribution rather sample. UIDN Unsigned Item Difference Normal distribution. Identical UIDS averaged across normal distribution rather sample.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"dbf-dtf","dir":"Reference","previous_headings":"","what":"DBF/DTF","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"DIF = FALSE produces series test/bundle-level indices based item-level indices. STDS Signed Test Differences Sample. sum SIDS across items. UTDS Unsigned Test Differences Sample. sum UIDS across items. Stark's DTFR Stark's version STDS using normal distribution rather sample estimated thetas. UDTFR Unsigned Expected Test Scores Differences Sample. difference observed summed scale scores expected, average, across hypothetical focal group normally distributed theta, DF uniform nature items UETSDS Unsigned Expected Test Score Differences Sample. hypothetical difference expected scale scores present scale-level DF uniform across respondents (.e., always favoring focal group). UETSDN Identical UETSDS computed using normal distribution. Test D-Max Maximum expected test score differences sample. ETSSD Expected Test Score Standardized Difference. Cohen's D expected test scores.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Meade, . W. (2010). taxonomy effect size measures differential functioning items scales. Journal Applied Psychology, 95, 728-743.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"Adam Meade, contributions Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_ES.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empirical effect sizes based on latent trait estimates — empirical_ES","text":"","code":"# \\donttest{  # no DIF set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2)  # ensure 'Ref' is the first group (and therefore reference group during estimation) group <- factor(c(rep('Ref', N), rep('Focal', N)), levels = c('Ref', 'Focal'))  mod <- multipleGroup(dat, 1, group = group,    invariance = c(colnames(dat)[1:5], 'free_means', 'free_var')) #>  coef(mod, simplify=TRUE) #> $Ref #> $items #>            a1      d g u #> Item_1  1.085  0.518 0 1 #> Item_2  1.182 -0.652 0 1 #> Item_3  1.040 -0.284 0 1 #> Item_4  0.869  0.885 0 1 #> Item_5  1.063  0.144 0 1 #> Item_6  0.567  0.683 0 1 #> Item_7  1.273  1.001 0 1 #> Item_8  0.924 -0.330 0 1 #> Item_9  0.890 -1.059 0 1 #> Item_10 0.721 -1.082 0 1 #> Item_11 0.832  1.188 0 1 #> Item_12 1.478 -0.252 0 1 #> Item_13 1.288  0.445 0 1 #> Item_14 1.034  0.452 0 1 #> Item_15 0.864 -0.062 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $Focal #> $items #>            a1      d g u #> Item_1  1.085  0.518 0 1 #> Item_2  1.182 -0.652 0 1 #> Item_3  1.040 -0.284 0 1 #> Item_4  0.869  0.885 0 1 #> Item_5  1.063  0.144 0 1 #> Item_6  0.363  0.585 0 1 #> Item_7  1.083  0.915 0 1 #> Item_8  0.997 -0.471 0 1 #> Item_9  0.840 -1.041 0 1 #> Item_10 0.647 -1.181 0 1 #> Item_11 1.009  1.199 0 1 #> Item_12 1.278 -0.240 0 1 #> Item_13 1.201  0.366 0 1 #> Item_14 1.219  0.403 0 1 #> Item_15 0.696 -0.103 0 1 #>  #> $means #>    F1  #> 0.106  #>  #> $cov #>       F1 #> F1 1.697 #>  #>   empirical_ES(mod) #>           SIDS  UIDS   SIDN  UIDN   ESSD theta.of.max.D  max.D mean.ES.foc #> Item_1   0.000 0.000  0.000 0.000  0.000         -1.786  0.000       0.618 #> Item_2   0.000 0.000  0.000 0.000  0.000         -1.786  0.000       0.408 #> Item_3   0.000 0.000  0.000 0.000  0.000         -1.786  0.000       0.468 #> Item_4   0.000 0.000  0.000 0.000  0.000         -1.786  0.000       0.691 #> Item_5   0.000 0.000  0.000 0.000  0.000         -1.786  0.000       0.550 #> Item_6  -0.018 0.042 -0.020 0.037 -0.148         -2.560  0.098       0.645 #> Item_7  -0.004 0.023 -0.007 0.021 -0.018         -1.935  0.047       0.686 #> Item_8  -0.024 0.024 -0.026 0.026 -0.106         -0.533 -0.037       0.431 #> Item_9  -0.001 0.007  0.000 0.006 -0.005          2.571 -0.020       0.313 #> Item_10 -0.024 0.025 -0.023 0.023 -0.163          2.571 -0.065       0.271 #> Item_11 -0.009 0.024 -0.006 0.021 -0.048         -2.357 -0.081       0.736 #> Item_12 -0.003 0.023 -0.003 0.022 -0.012          1.229 -0.036       0.484 #> Item_13 -0.012 0.015 -0.014 0.015 -0.045          0.618 -0.024       0.589 #> Item_14 -0.012 0.027 -0.012 0.025 -0.048         -1.426 -0.056       0.595 #> Item_15 -0.013 0.031 -0.013 0.028 -0.064          1.901 -0.057       0.494 #>         mean.ES.ref #> Item_1        0.618 #> Item_2        0.408 #> Item_3        0.468 #> Item_4        0.691 #> Item_5        0.550 #> Item_6        0.663 #> Item_7        0.690 #> Item_8        0.455 #> Item_9        0.314 #> Item_10       0.295 #> Item_11       0.744 #> Item_12       0.487 #> Item_13       0.601 #> Item_14       0.607 #> Item_15       0.507 empirical_ES(mod, DIF=FALSE) #>           Effect Size       Value #> 1                STDS -0.12007524 #> 2                UTDS  0.24122923 #> 3              UETSDS  0.13068433 #> 4               ETSSD -0.03693475 #> 5         Starks.DTFR -0.12338715 #> 6               UDTFR  0.22580510 #> 7              UETSDN  0.12941066 #> 8 theta.of.max.test.D  1.73546824 #> 9           Test.Dmax -0.23002060 empirical_ES(mod, DIF=FALSE, focal_items = 10:15) #>           Effect Size       Value #> 1                STDS -0.07301229 #> 2                UTDS  0.14449888 #> 3              UETSDS  0.07301229 #> 4               ETSSD -0.05523295 #> 5         Starks.DTFR -0.06993679 #> 6               UDTFR  0.13444167 #> 7              UETSDN  0.06993679 #> 8 theta.of.max.test.D  1.90144409 #> 9           Test.Dmax -0.12250160  empirical_ES(mod, plot=TRUE)  empirical_ES(mod, plot=TRUE, DIF=FALSE)   ###--------------------------------------------- # DIF set.seed(12345) a1 <- a2 <- matrix(abs(rnorm(15,1,.3)), ncol=1) d1 <- d2 <- matrix(rnorm(15,0,.7),ncol=1) a2[10:15,] <- a2[10:15,] + rnorm(6, 0, .3) d2[10:15,] <- d2[10:15,] + rnorm(6, 0, .3) itemtype <- rep('dich', nrow(a1)) N <- 1000 dataset1 <- simdata(a1, d1, N, itemtype) dataset2 <- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- factor(c(rep('Ref', N), rep('Focal', N)), levels = c('Ref', 'Focal'))  mod <- multipleGroup(dat, 1, group = group,    invariance = c(colnames(dat)[1:5], 'free_means', 'free_var')) #>  coef(mod, simplify=TRUE) #> $Ref #> $items #>            a1      d g u #> Item_1  1.202  0.566 0 1 #> Item_2  1.163 -0.626 0 1 #> Item_3  0.965 -0.316 0 1 #> Item_4  0.819  0.872 0 1 #> Item_5  1.165  0.161 0 1 #> Item_6  0.533  0.631 0 1 #> Item_7  1.147  1.022 0 1 #> Item_8  1.064 -0.319 0 1 #> Item_9  0.889 -1.003 0 1 #> Item_10 0.756 -1.098 0 1 #> Item_11 1.024  1.394 0 1 #> Item_12 1.485 -0.268 0 1 #> Item_13 1.280  0.402 0 1 #> Item_14 1.009  0.490 0 1 #> Item_15 0.745 -0.136 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $Focal #> $items #>            a1      d g u #> Item_1  1.202  0.566 0 1 #> Item_2  1.163 -0.626 0 1 #> Item_3  0.965 -0.316 0 1 #> Item_4  0.819  0.872 0 1 #> Item_5  1.165  0.161 0 1 #> Item_6  0.326  0.556 0 1 #> Item_7  1.085  0.947 0 1 #> Item_8  0.987 -0.529 0 1 #> Item_9  0.786 -1.009 0 1 #> Item_10 0.908 -1.274 0 1 #> Item_11 1.437  0.628 0 1 #> Item_12 1.947  0.153 0 1 #> Item_13 1.477  0.315 0 1 #> Item_14 1.313  0.623 0 1 #> Item_15 0.919 -0.878 0 1 #>  #> $means #>    F1  #> 0.123  #>  #> $cov #>       F1 #> F1 1.788 #>  #>   empirical_ES(mod) #>           SIDS  UIDS   SIDN  UIDN   ESSD theta.of.max.D  max.D mean.ES.foc #> Item_1   0.000 0.000  0.000 0.000  0.000          1.153  0.000       0.624 #> Item_2   0.000 0.000  0.000 0.000  0.000          1.153  0.000       0.417 #> Item_3   0.000 0.000  0.000 0.000  0.000          1.153  0.000       0.464 #> Item_4   0.000 0.000  0.000 0.000  0.000          1.153  0.000       0.691 #> Item_5   0.000 0.000  0.000 0.000  0.000          1.153  0.000       0.556 #> Item_6  -0.014 0.045 -0.017 0.037 -0.120         -2.463  0.103       0.640 #> Item_7  -0.009 0.010 -0.010 0.011 -0.037          0.312 -0.016       0.691 #> Item_8  -0.043 0.043 -0.046 0.046 -0.174          0.940 -0.066       0.424 #> Item_9  -0.010 0.018 -0.008 0.015 -0.054          2.421 -0.050       0.319 #> Item_10 -0.016 0.025 -0.020 0.025 -0.089          2.622  0.043       0.284 #> Item_11 -0.136 0.136 -0.138 0.138 -0.545         -1.274 -0.291       0.627 #> Item_12  0.064 0.070  0.075 0.079  0.195          0.536  0.139       0.555 #> Item_13 -0.016 0.026 -0.017 0.025 -0.055         -1.037 -0.055       0.579 #> Item_14  0.014 0.042  0.019 0.039  0.055         -1.774 -0.061       0.630 #> Item_15 -0.137 0.137 -0.147 0.147 -0.663         -0.086 -0.173       0.355 #>         mean.ES.ref #> Item_1        0.624 #> Item_2        0.417 #> Item_3        0.464 #> Item_4        0.691 #> Item_5        0.556 #> Item_6        0.654 #> Item_7        0.699 #> Item_8        0.467 #> Item_9        0.329 #> Item_10       0.300 #> Item_11       0.763 #> Item_12       0.490 #> Item_13       0.595 #> Item_14       0.616 #> Item_15       0.492 empirical_ES(mod, DIF = FALSE) #>           Effect Size       Value #> 1                STDS -0.30204052 #> 2                UTDS  0.55171554 #> 3              UETSDS  0.30204052 #> 4               ETSSD -0.08665251 #> 5         Starks.DTFR -0.30918657 #> 6               UDTFR  0.56373600 #> 7              UETSDN  0.30918906 #> 8 theta.of.max.test.D -1.05111220 #> 9           Test.Dmax -0.54821795 empirical_ES(mod, plot=TRUE)  empirical_ES(mod, plot=TRUE, DIF=FALSE)   # }"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to generate empirical unidimensional item and test plots — empirical_plot","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"Given dataset containing item responses function construct empirical graphics using observed responses item conditioned total score. individual item plots requested total score formed without item interest (.e., total score without item).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"","code":"empirical_plot(   data,   which.items = NULL,   type = \"prop\",   smooth = FALSE,   formula = resp ~ s(TS, k = 5),   main = NULL,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"data data.frame matrix item responses (see mirt typical input) .items numeric vector indicating items plot faceted image plot. NULL empirical test plots constructed instead type character vector specifying type plot draw. .item NULL can 'prop' (default) 'hist', otherwise can 'prop' (default) 'boxplot' smooth logical; include GAM smoother instead raw proportions? Default FALSE formula formula used GAM smoother main main title plot. NULL internal default used par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed lattice coef()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"Note types plots used unidimensional tests monotonically increasing item response functions. monotonicity true items, however, plots may serve visual diagnostic tool long majority items indeed monotonic.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/empirical_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to generate empirical unidimensional item and test plots — empirical_plot","text":"","code":"# \\donttest{  SAT12[SAT12 == 8] <- NA data <- key2binary(SAT12,    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  # test plot empirical_plot(data)  empirical_plot(data, type = 'hist')  empirical_plot(data, type = 'hist', breaks=20)   # items 1, 2 and 5 empirical_plot(data, c(1, 2, 5))  empirical_plot(data, c(1, 2, 5), smooth = TRUE)  empirical_plot(data, c(1, 2, 5), type = 'boxplot')   # replace weird looking items with unscored versions for diagnostics empirical_plot(data, 32)  data[,32] <- SAT12[,32] empirical_plot(data, 32)  empirical_plot(data, 32, smooth = TRUE)   # }"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the empirical (marginal) reliability — empirical_rxx","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Given secondary latent trait estimates associated standard errors returned fscores, compute empirical reliability.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"","code":"empirical_rxx(Theta_SE, T_as_X = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Theta_SE matrix latent trait estimates returned fscores options full.scores = TRUE full.scores.SE = TRUE T_as_X logical; observed variance equal var(X) = var(T) + E(E^2) var(X) = var(T) computing empirical reliability estimates? Default (FALSE) uses former","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/empirical_rxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate the empirical (marginal) reliability — empirical_rxx","text":"","code":"# \\donttest{  dat <- expand.table(deAyala) itemstats(dat) #> $overall #>      N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  19601            2.912          1.434 0.233 0.074 0.608     0.898 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 19601 2 0.887 0.316   0.447         0.246       0.605 #> Item.2 19601 2 0.644 0.479   0.688         0.439       0.510 #> Item.3 19601 2 0.566 0.496   0.680         0.416       0.523 #> Item.4 19601 2 0.427 0.495   0.673         0.405       0.529 #> Item.5 19601 2 0.387 0.487   0.602         0.312       0.581 #>  #> $proportions #>            0     1 #> Item.1 0.113 0.887 #> Item.2 0.356 0.644 #> Item.3 0.434 0.566 #> Item.4 0.573 0.427 #> Item.5 0.613 0.387 #>  mod <- mirt(dat) #>   theta_se <- fscores(mod, full.scores.SE = TRUE) empirical_rxx(theta_se) #>        F1  #> 0.6200703   theta_se <- fscores(mod, full.scores.SE = TRUE, method = 'ML') empirical_rxx(theta_se) #>        F1  #> 0.5636644  empirical_rxx(theta_se, T_as_X = TRUE) #>        F1  #> 0.2258948   # }"},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Empirical Estimating Functions — estfun.AllModelClass","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"function extracting empirical estimating functions fitted mirt, multipleGroup, bfactor, mdirt model. derivative log-likelihood respect parameter vector, evaluated observed (case-wise) data. words, function returns case-wise scores, evaluated fitted model parameters. Currently, models fitted via EM BL method supported. computations, internal Theta grid model used already used estimation model along matching normalized density.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"","code":"estfun.AllModelClass(   x,   weights = extract.mirt(x, \"survey.weights\"),   centering = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"x fitted model object class SingleGroupClass, MultipleGroupClass, DiscreteClass weights default, survey.weights (optionally) specified fitting model included calculate scores. specified user, numeric vector length equal total sample size. Note cases weighted equally fitting model, weights must corrected taking square root scores used compute outer product gradients (OPG) estimate variance-covariance matrix (see examples ). centering boolean variable allows centering case-wise scores (.e., setting expected values 0). case-wise scores obtained maximum likelihood estimates, setting affect result.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"n x k matrix corresponding n observations k parameters","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"Lennart Schneider lennart.sch@web.de Phil Chalmers; centering argument contributed Rudolf Debelak (rudolf.debelak@psychologie.uzh.ch)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/estfun.AllModelClass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Empirical Estimating Functions — estfun.AllModelClass","text":"","code":"# \\donttest{ # fit a 2PL on the LSAT7 data and get the scores mod1 <- mirt(expand.table(LSAT7), 1, SE = TRUE, SE.type = \"crossprod\") #>  #>  #> Calculating information matrix... sc1 <- estfun.AllModelClass(mod1) # get the gradient colSums(sc1) #>          a1.1           d.2          a1.5           d.6          a1.9  #> -2.477600e-03 -1.749068e-03  8.292831e-05 -1.521604e-03  1.198404e-02  #>          d.10         a1.13          d.14         a1.17          d.18  #>  6.498262e-03 -2.188204e-03  4.417930e-03 -8.004882e-04 -5.566577e-04  # calculate the OPG estimate of the variance-covariance matrix \"by hand\" vc1 <- vcov(mod1) all.equal(crossprod(sc1), chol2inv(chol(vc1)), check.attributes = FALSE) #> [1] TRUE  # Discrete group modd <- mdirt(expand.table(LSAT7), 2, SE = TRUE, SE.type = \"crossprod\") #>  #>  #> Calculating information matrix... sc1 <- estfun.AllModelClass(modd) # get the gradient colSums(sc1) #>        a1.1        a2.2        a1.3        a2.4        a1.5        a2.6  #> 0.010556101 0.012533394 0.015994245 0.016832573 0.021043233 0.020842514  #>        a1.7        a2.8        a1.9       a2.10       c1.11  #> 0.013694253 0.011470847 0.007827056 0.009231532 0.059032788  # calculate the OPG estimate of the variance-covariance matrix \"by hand\" vc1 <- vcov(modd) all.equal(crossprod(sc1), chol2inv(chol(vc1)), check.attributes = FALSE) #> [1] TRUE  # fit a multiple group 2PL and do the same as above group <- rep(c(\"G1\", \"G2\"), 500) mod2 <- multipleGroup(expand.table(LSAT7), 1, group, SE = TRUE,   SE.type = \"crossprod\") #>  #>  #> Calculating information matrix... sc2 <- estfun.AllModelClass(mod2) colSums(sc2) #>          a1.1           d.2          a1.5           d.6          a1.9  #> -3.118728e-04 -2.982410e-03 -2.735485e-04 -6.118069e-04  7.440279e-03  #>          d.10         a1.13          d.14         a1.17          d.18  #>  7.274125e-03 -9.423217e-04 -3.379603e-04  6.496281e-04 -1.868471e-03  #>         a1.23          d.24         a1.27          d.28         a1.31  #> -1.197098e-04 -4.435649e-04 -2.378475e-05  1.458023e-04  6.403262e-04  #>          d.32         a1.35          d.36         a1.39          d.40  #>  1.212925e-03 -1.443583e-04  4.381246e-05  4.279434e-04 -9.488836e-04  vc2 <- vcov(mod2) all.equal(crossprod(sc2), chol2inv(chol(vc2)), check.attributes = FALSE) #> [1] TRUE  # fit a bifactor model with 2 specific factors and do the same as above mod3 <- bfactor(expand.table(LSAT7), c(2, 2, 1, 1, 2), SE = TRUE,   SE.type = \"crossprod\") #>  #>  #> Calculating information matrix... sc3 <- estfun.AllModelClass(mod3) colSums(sc3) #>          a1.1          a3.3           d.4          a1.7          a3.9  #>  0.0018172801  0.0007522911  0.0008693077  0.0026167974 -0.0065562618  #>          d.10         a1.13         a2.14          d.16         a1.19  #>  0.0010184719  0.0002582749 -0.0123565804  0.0003107030 -0.0001820340  #>         a2.20          d.22         a1.25         a3.27          d.28  #> -0.0048417996  0.0020931538 -0.0005721500 -0.0060778033 -0.0028105998  vc3 <- vcov(mod3) all.equal(crossprod(sc3), chol2inv(chol(vc3)), check.attributes = FALSE) #> [1] TRUE  # fit a 2PL not weighting all cases equally survey.weights <- c(rep(2, sum(LSAT7$freq) / 2), rep(1, sum(LSAT7$freq) / 2)) survey.weights <- survey.weights / sum(survey.weights) * sum(LSAT7$freq) mod4 <- mirt(expand.table(LSAT7), 1, SE = TRUE, SE.type = \"crossprod\",   survey.weights = survey.weights) #>  #>  #> Calculating information matrix... sc4 <- estfun.AllModelClass(mod4,   weights = extract.mirt(mod4, \"survey.weights\")) # get the gradient colSums(sc4) #>          a1.1           d.2          a1.5           d.6          a1.9  #> -0.0067330450 -0.0001045753  0.0019680853  0.0007675188  0.0088929479  #>          d.10         a1.13          d.14         a1.17          d.18  #>  0.0012985459  0.0016433039 -0.0008952128 -0.0071939497 -0.0031136208  # to calculate the OPG estimate of the variance-covariance matrix \"by hand\", # the weights must be adjusted by taking their square root sc4_crp <- estfun.AllModelClass(mod4,   weights = sqrt(extract.mirt(mod4, \"survey.weights\"))) vc4 <- vcov(mod4) all.equal(crossprod(sc4_crp), chol2inv(chol(vc4)), check.attributes = FALSE) #> [1] TRUE  # }"},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand summary table of patterns and frequencies — expand.table","title":"Expand summary table of patterns and frequencies — expand.table","text":"expand.table function expands summary table unique response patterns full sized data-set. default response frequencies assumed rightmost column input data, though can modified.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand summary table of patterns and frequencies — expand.table","text":"","code":"expand.table(tabdata, freq = colnames(tabdata)[ncol(tabdata)], sample = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand summary table of patterns and frequencies — expand.table","text":"tabdata object class data.frame matrix unique response patterns number frequencies rightmost column (though see freq details omit column) freq either character vector specifying column tabdata used frequency count indicator response pattern (defaults right-column) integer vector length nrow(tabdata) specifying frequency counts. using latter approach tabdata input include information regarding counts, instead include unique response patterns sample logical; randomly switch rows expanded table? change expanded data, row locations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand summary table of patterns and frequencies — expand.table","text":"Returns numeric matrix response patterns.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Expand summary table of patterns and frequencies — expand.table","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Expand summary table of patterns and frequencies — expand.table","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expand.table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand summary table of patterns and frequencies — expand.table","text":"","code":"data(LSAT7) head(LSAT7) # frequency in right-most column #>   Item.1 Item.2 Item.3 Item.4 Item.5 freq #> 1      0      0      0      0      0   12 #> 2      0      0      0      0      1   19 #> 3      0      0      0      1      0    1 #> 4      0      0      0      1      1    7 #> 5      0      0      1      0      0    3 #> 6      0      0      1      0      1   19 LSAT7full <- expand.table(LSAT7) head(LSAT7full) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 dim(LSAT7full) #> [1] 1000    5  # randomly switch rows in the expanded response table LSAT7samp <- expand.table(LSAT7, sample = TRUE) head(LSAT7samp) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      1      1      1      1      1 #> 2      1      0      1      1      1 #> 3      1      1      0      1      1 #> 4      1      0      1      1      1 #> 5      1      1      1      1      1 #> 6      1      1      1      1      1 colMeans(LSAT7full) #> Item.1 Item.2 Item.3 Item.4 Item.5  #>  0.828  0.658  0.772  0.606  0.843  colMeans(LSAT7samp) #equal #> Item.1 Item.2 Item.3 Item.4 Item.5  #>  0.828  0.658  0.772  0.606  0.843   #--------  # \\donttest{ # Generate data from separate response pattern matrix and freq vector # The following uses Table 2.1 from de Ayala (2009) f <- c(691,2280,242,235,158,184,1685,1053,134,462,92,65,571,79,87,41,1682,702,        370,63,626,412,166,52,28,15,2095,1219,500,187,40,3385)  pat <- matrix(c(    0, 0, 0, 0, 0,    1, 0, 0, 0, 0,    0, 1, 0, 0, 0,    0, 0, 1, 0, 0,    0, 0, 0, 1, 0,    0, 0, 0, 0, 1,    1, 1, 0, 0, 0,    1, 0, 1, 0, 0,    0, 1, 1, 0, 0,    1, 0, 0, 1, 0,    0, 1, 0, 1, 0,    0, 0, 1, 1, 0,    1, 0, 0, 0, 1,    0, 1, 0, 0, 1,    0, 0, 1, 0, 1,    0, 0, 0, 1, 1,    1, 1, 1, 0, 0,    1, 1, 0, 1, 0,    1, 0, 1, 1, 0,    0, 1, 1, 1, 0,    1, 1, 0, 0, 1,    1, 0, 1, 0, 1,    1, 0, 0, 1, 1,    0, 1, 1, 0, 1,    0, 1, 0, 1, 1,    0, 0, 1, 1, 1,    1, 1, 1, 1, 0,    1, 1, 1, 0, 1,    1, 1, 0, 1, 1,    1, 0, 1, 1, 1,    0, 1, 1, 1, 1,    1, 1, 1, 1, 1), ncol=5, byrow=TRUE)  colnames(pat) <- paste0('Item.', 1:5) head(pat) #>      Item.1 Item.2 Item.3 Item.4 Item.5 #> [1,]      0      0      0      0      0 #> [2,]      1      0      0      0      0 #> [3,]      0      1      0      0      0 #> [4,]      0      0      1      0      0 #> [5,]      0      0      0      1      0 #> [6,]      0      0      0      0      1  table2.1 <- expand.table(pat, freq = f) dim(table2.1) #> [1] 19601     5  # }"},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate expected value of item — expected.item","title":"Function to calculate expected value of item — expected.item","text":"Given internal mirt object extracted estimated model compute expected value item given ability parameter(s).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate expected value of item — expected.item","text":"","code":"expected.item(x, Theta, min = 0, include.var = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate expected value of item — expected.item","text":"x extracted internal mirt object containing item information (see extract.item) Theta vector (unidimensional) matrix (multidimensional) latent trait values min constant value added expected values indicating lowest theoretical category. Default 0 include.var logical; include model-implied variance expected scores well? TRUE return list containing expected values (E) variances (VAR)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate expected value of item — expected.item","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate expected value of item — expected.item","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.item.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate expected value of item — expected.item","text":"","code":"mod <- mirt(Science, 1) #>  extr.2 <- extract.item(mod, 2) Theta <- matrix(seq(-6,6, length.out=200)) expected <- expected.item(extr.2, Theta, min(Science[,1])) #min() of first item head(data.frame(expected, Theta=Theta)) #>   expected     Theta #> 1 1.013391 -6.000000 #> 2 1.014407 -5.939698 #> 3 1.015498 -5.879397 #> 4 1.016672 -5.819095 #> 5 1.017933 -5.758794 #> 6 1.019289 -5.698492  expected.item(extr.2, Theta, min(Science[,1]), include.var=TRUE) #> $E #>   [1] 1.013391 1.014407 1.015498 1.016672 1.017933 1.019289 1.020744 1.022308 #>   [9] 1.023988 1.025791 1.027727 1.029805 1.032035 1.034427 1.036992 1.039742 #>  [17] 1.042690 1.045848 1.049231 1.052853 1.056729 1.060875 1.065309 1.070047 #>  [25] 1.075108 1.080511 1.086276 1.092422 1.098971 1.105943 1.113361 1.121247 #>  [33] 1.129622 1.138510 1.147932 1.157911 1.168469 1.179625 1.191402 1.203817 #>  [41] 1.216889 1.230634 1.245068 1.260201 1.276046 1.292610 1.309898 1.327913 #>  [49] 1.346654 1.366117 1.386296 1.407180 1.428756 1.451008 1.473916 1.497459 #>  [57] 1.521611 1.546346 1.571635 1.597448 1.623754 1.650519 1.677712 1.705300 #>  [65] 1.733251 1.761532 1.790113 1.818965 1.848058 1.877365 1.906859 1.936516 #>  [73] 1.966312 1.996222 2.026225 2.056299 2.086421 2.116571 2.146726 2.176865 #>  [81] 2.206964 2.237001 2.266952 2.296794 2.326501 2.356050 2.385416 2.414575 #>  [89] 2.443504 2.472180 2.500583 2.528693 2.556494 2.583970 2.611109 2.637904 #>  [97] 2.664348 2.690439 2.716178 2.741571 2.766624 2.791350 2.815763 2.839881 #> [105] 2.863722 2.887310 2.910668 2.933821 2.956795 2.979616 3.002311 3.024906 #> [113] 3.047424 3.069889 3.092321 3.114739 3.137157 3.159587 3.182039 3.204516 #> [121] 3.227018 3.249541 3.272079 3.294617 3.317140 3.339628 3.362056 3.384398 #> [129] 3.406624 3.428701 3.450594 3.472269 3.493688 3.514816 3.535615 3.556050 #> [137] 3.576087 3.595693 3.614838 3.633495 3.651638 3.669246 3.686301 3.702787 #> [145] 3.718692 3.734007 3.748728 3.762852 3.776380 3.789316 3.801665 3.813436 #> [153] 3.824638 3.835286 3.845391 3.854970 3.864039 3.872615 3.880715 3.888358 #> [161] 3.895562 3.902347 3.908731 3.914733 3.920370 3.925662 3.930626 3.935280 #> [169] 3.939639 3.943720 3.947540 3.951112 3.954452 3.957572 3.960487 3.963208 #> [177] 3.965749 3.968118 3.970329 3.972390 3.974312 3.976102 3.977771 3.979325 #> [185] 3.980773 3.982120 3.983375 3.984543 3.985630 3.986642 3.987583 3.988458 #> [193] 3.989273 3.990030 3.990735 3.991390 3.991999 3.992565 3.993092 3.993581 #>  #> $VAR #>   [1] 1.016618 1.017866 1.019207 1.020645 1.022188 1.023843 1.025618 1.027521 #>   [9] 1.029559 1.031743 1.034082 1.036585 1.039263 1.042127 1.045188 1.048457 #>  [17] 1.051948 1.055673 1.059644 1.063876 1.068380 1.073172 1.078265 1.083673 #>  [25] 1.089410 1.095488 1.101921 1.108722 1.115902 1.123471 1.131439 1.139814 #>  [33] 1.148602 1.157807 1.167431 1.177473 1.187930 1.198794 1.210054 1.221698 #>  [41] 1.233706 1.246057 1.258724 1.271677 1.284881 1.298297 1.311884 1.325594 #>  [49] 1.339380 1.353188 1.366966 1.380659 1.394211 1.407567 1.420673 1.433478 #>  [57] 1.445931 1.457987 1.469604 1.480744 1.491375 1.501468 1.511003 1.519961 #>  [65] 1.528331 1.536103 1.543274 1.549843 1.555812 1.561184 1.565964 1.570157 #>  [73] 1.573769 1.576804 1.579266 1.581159 1.582485 1.583244 1.583437 1.583064 #>  [81] 1.582126 1.580625 1.578563 1.575947 1.572785 1.569088 1.564875 1.560165 #>  [89] 1.554985 1.549365 1.543342 1.536957 1.530255 1.523285 1.516100 1.508754 #>  [97] 1.501305 1.493809 1.486322 1.478902 1.471600 1.464468 1.457551 1.450890 #> [105] 1.444522 1.438478 1.432779 1.427443 1.422479 1.417891 1.413671 1.409809 #> [113] 1.406285 1.403072 1.400140 1.397448 1.394955 1.392612 1.390368 1.388168 #> [121] 1.385957 1.383677 1.381273 1.378688 1.375872 1.372773 1.369347 1.365556 #> [129] 1.361365 1.356749 1.351687 1.346169 1.340189 1.333753 1.326870 1.319558 #> [137] 1.311842 1.303752 1.295323 1.286593 1.277605 1.268404 1.259035 1.249544 #> [145] 1.239978 1.230381 1.220797 1.211267 1.201828 1.192517 1.183365 1.174401 #> [153] 1.165650 1.157134 1.148870 1.140874 1.133157 1.125728 1.118592 1.111753 #> [161] 1.105213 1.098969 1.093021 1.087362 1.081989 1.076893 1.072068 1.067505 #> [169] 1.063195 1.059129 1.055297 1.051689 1.048296 1.045106 1.042112 1.039302 #> [177] 1.036667 1.034199 1.031887 1.029723 1.027699 1.025807 1.024039 1.022387 #> [185] 1.020845 1.019406 1.018063 1.016810 1.015642 1.014553 1.013539 1.012593 #> [193] 1.011713 1.010892 1.010129 1.009418 1.008756 1.008140 1.007567 1.007034 #>"},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate expected test score — expected.test","title":"Function to calculate expected test score — expected.test","text":"Given estimated model compute expected test score. Returns expected values form data used estimate model.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate expected test score — expected.test","text":"","code":"expected.test(   x,   Theta,   group = NULL,   mins = TRUE,   individual = FALSE,   which.items = NULL,   probs.only = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate expected test score — expected.test","text":"x estimated mirt object Theta matrix latent trait values (vector supplied, coerced matrix one column) group number character signifying group item extracted (applies 'MultipleGroupClass' objects ) mins logical; include minimum value constants dataset. FALSE, expected values item determined scoring 0:(ncat-1) individual logical; return tracelines individual items? .items integer vector indicating items include expected test score. Default uses possible items probs.logical; return probability category instead traceline score functions? useful individual=TRUE","code":""},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate expected test score — expected.test","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/expected.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate expected test score — expected.test","text":"","code":"# \\donttest{ dat <- expand.table(deAyala) model <- 'F = 1-5           CONSTRAIN = (1-5, a1)' mod <- mirt(dat, model) #>   Theta <- matrix(seq(-6,6,.01)) tscore <- expected.test(mod, Theta) tail(cbind(Theta, tscore)) #>                tscore #> [1196,] 5.95 4.999138 #> [1197,] 5.96 4.999150 #> [1198,] 5.97 4.999162 #> [1199,] 5.98 4.999174 #> [1200,] 5.99 4.999186 #> [1201,] 6.00 4.999198  # use only first two items (i.e., a bundle) bscore <- expected.test(mod, Theta, which.items = 1:2) tail(cbind(Theta, bscore)) #>                bscore #> [1196,] 5.95 1.999905 #> [1197,] 5.96 1.999906 #> [1198,] 5.97 1.999908 #> [1199,] 5.98 1.999909 #> [1200,] 5.99 1.999910 #> [1201,] 6.00 1.999912  # more low-level output (score and probabilty elements) expected.test(mod, Theta, individual=TRUE) #>                [,1]         [,2]         [,3]         [,4]         [,5] #>    [1,] 0.002708164 0.0004016443 0.0002558693 0.0001175518 9.361023e-05 #>    [2,] 0.002747363 0.0004074715 0.0002595820 0.0001192578 9.496877e-05 #>    [3,] 0.002787127 0.0004133831 0.0002633486 0.0001209885 9.634703e-05 #>    [4,] 0.002827465 0.0004193805 0.0002671699 0.0001227443 9.774529e-05 #>    [5,] 0.002868386 0.0004254649 0.0002710466 0.0001245257 9.916384e-05 #>    [6,] 0.002909897 0.0004316375 0.0002749795 0.0001263328 1.006030e-04 #>    [7,] 0.002952007 0.0004378996 0.0002789695 0.0001281662 1.020630e-04 #>    [8,] 0.002994724 0.0004442525 0.0002830174 0.0001300262 1.035442e-04 #>    [9,] 0.003038058 0.0004506975 0.0002871239 0.0001319131 1.050469e-04 #>   [10,] 0.003082017 0.0004572360 0.0002912901 0.0001338275 1.065714e-04 #>   [11,] 0.003126610 0.0004638693 0.0002955166 0.0001357696 1.081180e-04 #>   [12,] 0.003171846 0.0004705988 0.0002998045 0.0001377399 1.096871e-04 #>   [13,] 0.003217735 0.0004774259 0.0003041546 0.0001397388 1.112789e-04 #>   [14,] 0.003264285 0.0004843520 0.0003085678 0.0001417667 1.128939e-04 #>   [15,] 0.003311506 0.0004913785 0.0003130450 0.0001438241 1.145322e-04 #>   [16,] 0.003359409 0.0004985069 0.0003175871 0.0001459112 1.161944e-04 #>   [17,] 0.003408001 0.0005057386 0.0003221951 0.0001480287 1.178806e-04 #>   [18,] 0.003457295 0.0005130752 0.0003268700 0.0001501769 1.195914e-04 #>   [19,] 0.003507298 0.0005205182 0.0003316127 0.0001523562 1.213269e-04 #>   [20,] 0.003558023 0.0005280691 0.0003364241 0.0001545672 1.230877e-04 #>   [21,] 0.003609478 0.0005357294 0.0003413054 0.0001568103 1.248740e-04 #>   [22,] 0.003661674 0.0005435009 0.0003462574 0.0001590859 1.266862e-04 #>   [23,] 0.003714623 0.0005513850 0.0003512813 0.0001613945 1.285247e-04 #>   [24,] 0.003768335 0.0005593834 0.0003563780 0.0001637366 1.303898e-04 #>   [25,] 0.003822820 0.0005674977 0.0003615487 0.0001661127 1.322821e-04 #>   [26,] 0.003878089 0.0005757297 0.0003667943 0.0001685233 1.342018e-04 #>   [27,] 0.003934155 0.0005840811 0.0003721160 0.0001709689 1.361494e-04 #>   [28,] 0.003991028 0.0005925535 0.0003775149 0.0001734499 1.381252e-04 #>   [29,] 0.004048720 0.0006011487 0.0003829921 0.0001759669 1.401297e-04 #>   [30,] 0.004107242 0.0006098686 0.0003885488 0.0001785205 1.421632e-04 #>   [31,] 0.004166607 0.0006187148 0.0003941860 0.0001811111 1.442263e-04 #>   [32,] 0.004226826 0.0006276893 0.0003999050 0.0001837393 1.463193e-04 #>   [33,] 0.004287912 0.0006367939 0.0004057069 0.0001864056 1.484427e-04 #>   [34,] 0.004349876 0.0006460304 0.0004115930 0.0001891106 1.505969e-04 #>   [35,] 0.004412733 0.0006554008 0.0004175644 0.0001918548 1.527824e-04 #>   [36,] 0.004476493 0.0006649071 0.0004236224 0.0001946389 1.549995e-04 #>   [37,] 0.004541170 0.0006745511 0.0004297683 0.0001974634 1.572489e-04 #>   [38,] 0.004606778 0.0006843350 0.0004360033 0.0002003288 1.595308e-04 #>   [39,] 0.004673329 0.0006942606 0.0004423287 0.0002032358 1.618459e-04 #>   [40,] 0.004740837 0.0007043301 0.0004487459 0.0002061850 1.641946e-04 #>   [41,] 0.004809315 0.0007145456 0.0004552561 0.0002091770 1.665773e-04 #>   [42,] 0.004878777 0.0007249090 0.0004618607 0.0002122124 1.689946e-04 #>   [43,] 0.004949238 0.0007354227 0.0004685610 0.0002152918 1.714470e-04 #>   [44,] 0.005020712 0.0007460888 0.0004753586 0.0002184159 1.739350e-04 #>   [45,] 0.005093212 0.0007569095 0.0004822547 0.0002215853 1.764591e-04 #>   [46,] 0.005166753 0.0007678869 0.0004892507 0.0002248007 1.790198e-04 #>   [47,] 0.005241351 0.0007790235 0.0004963483 0.0002280627 1.816176e-04 #>   [48,] 0.005317021 0.0007903214 0.0005035487 0.0002313721 1.842532e-04 #>   [49,] 0.005393776 0.0008017830 0.0005108536 0.0002347295 1.869269e-04 #>   [50,] 0.005471634 0.0008134107 0.0005182643 0.0002381356 1.896395e-04 #>   [51,] 0.005550609 0.0008252070 0.0005257825 0.0002415911 1.923914e-04 #>   [52,] 0.005630718 0.0008371741 0.0005334097 0.0002450967 1.951833e-04 #>   [53,] 0.005711976 0.0008493147 0.0005411475 0.0002486532 1.980156e-04 #>   [54,] 0.005794400 0.0008616311 0.0005489975 0.0002522613 2.008891e-04 #>   [55,] 0.005878007 0.0008741260 0.0005569613 0.0002559217 2.038042e-04 #>   [56,] 0.005962812 0.0008868020 0.0005650406 0.0002596352 2.067617e-04 #>   [57,] 0.006048834 0.0008996615 0.0005732369 0.0002634026 2.097620e-04 #>   [58,] 0.006136089 0.0009127074 0.0005815521 0.0002672246 2.128059e-04 #>   [59,] 0.006224595 0.0009259423 0.0005899879 0.0002711021 2.158939e-04 #>   [60,] 0.006314369 0.0009393690 0.0005985459 0.0002750358 2.190267e-04 #>   [61,] 0.006405429 0.0009529901 0.0006072280 0.0002790266 2.222050e-04 #>   [62,] 0.006497795 0.0009668086 0.0006160360 0.0002830753 2.254294e-04 #>   [63,] 0.006591483 0.0009808272 0.0006249717 0.0002871827 2.287006e-04 #>   [64,] 0.006686513 0.0009950489 0.0006340368 0.0002913497 2.320192e-04 #>   [65,] 0.006782904 0.0010094766 0.0006432334 0.0002955772 2.353859e-04 #>   [66,] 0.006880674 0.0010241133 0.0006525633 0.0002998659 2.388016e-04 #>   [67,] 0.006979844 0.0010389620 0.0006620284 0.0003042169 2.422667e-04 #>   [68,] 0.007080433 0.0010540257 0.0006716308 0.0003086310 2.457821e-04 #>   [69,] 0.007182462 0.0010693077 0.0006813723 0.0003131091 2.493486e-04 #>   [70,] 0.007285950 0.0010848109 0.0006912550 0.0003176522 2.529667e-04 #>   [71,] 0.007390917 0.0011005387 0.0007012809 0.0003222611 2.566374e-04 #>   [72,] 0.007497386 0.0011164942 0.0007114521 0.0003269370 2.603613e-04 #>   [73,] 0.007605376 0.0011326808 0.0007217708 0.0003316806 2.641392e-04 #>   [74,] 0.007714910 0.0011491018 0.0007322390 0.0003364930 2.679719e-04 #>   [75,] 0.007826009 0.0011657606 0.0007428590 0.0003413753 2.718603e-04 #>   [76,] 0.007938695 0.0011826606 0.0007536328 0.0003463283 2.758050e-04 #>   [77,] 0.008052991 0.0011998053 0.0007645628 0.0003513532 2.798070e-04 #>   [78,] 0.008168918 0.0012171983 0.0007756511 0.0003564510 2.838670e-04 #>   [79,] 0.008286501 0.0012348431 0.0007869002 0.0003616227 2.879859e-04 #>   [80,] 0.008405761 0.0012527433 0.0007983122 0.0003668694 2.921645e-04 #>   [81,] 0.008526723 0.0012709027 0.0008098897 0.0003721922 2.964038e-04 #>   [82,] 0.008649411 0.0012893250 0.0008216349 0.0003775923 3.007045e-04 #>   [83,] 0.008773848 0.0013080139 0.0008335503 0.0003830706 3.050677e-04 #>   [84,] 0.008900060 0.0013269735 0.0008456383 0.0003886284 3.094941e-04 #>   [85,] 0.009028070 0.0013462074 0.0008579015 0.0003942667 3.139847e-04 #>   [86,] 0.009157905 0.0013657198 0.0008703424 0.0003999869 3.185405e-04 #>   [87,] 0.009289589 0.0013855146 0.0008829635 0.0004057900 3.231623e-04 #>   [88,] 0.009423149 0.0014055959 0.0008957675 0.0004116773 3.278512e-04 #>   [89,] 0.009558611 0.0014259678 0.0009087569 0.0004176499 3.326081e-04 #>   [90,] 0.009696001 0.0014466346 0.0009219346 0.0004237092 3.374340e-04 #>   [91,] 0.009835346 0.0014676004 0.0009353032 0.0004298563 3.423299e-04 #>   [92,] 0.009976673 0.0014888696 0.0009488654 0.0004360926 3.472968e-04 #>   [93,] 0.010120011 0.0015104467 0.0009626241 0.0004424193 3.523357e-04 #>   [94,] 0.010265386 0.0015323359 0.0009765822 0.0004488378 3.574478e-04 #>   [95,] 0.010412828 0.0015545419 0.0009907424 0.0004553493 3.626339e-04 #>   [96,] 0.010562365 0.0015770692 0.0010051077 0.0004619552 3.678953e-04 #>   [97,] 0.010714026 0.0015999223 0.0010196811 0.0004686570 3.732330e-04 #>   [98,] 0.010867841 0.0016231062 0.0010344656 0.0004754559 3.786481e-04 #>   [99,] 0.011023840 0.0016466254 0.0010494642 0.0004823534 3.841418e-04 #>  [100,] 0.011182052 0.0016704848 0.0010646801 0.0004893509 3.897151e-04 #>  [101,] 0.011342509 0.0016946894 0.0010801163 0.0004964499 3.953692e-04 #>  [102,] 0.011505242 0.0017192440 0.0010957761 0.0005036518 4.011054e-04 #>  [103,] 0.011670282 0.0017441539 0.0011116627 0.0005109582 4.069247e-04 #>  [104,] 0.011837661 0.0017694240 0.0011277793 0.0005183705 4.128284e-04 #>  [105,] 0.012007411 0.0017950595 0.0011441293 0.0005258902 4.188178e-04 #>  [106,] 0.012179566 0.0018210659 0.0011607161 0.0005335190 4.248940e-04 #>  [107,] 0.012354158 0.0018474482 0.0011775431 0.0005412584 4.310583e-04 #>  [108,] 0.012531221 0.0018742121 0.0011946137 0.0005491099 4.373120e-04 #>  [109,] 0.012710789 0.0019013630 0.0012119315 0.0005570754 4.436564e-04 #>  [110,] 0.012892897 0.0019289064 0.0012295000 0.0005651563 4.500928e-04 #>  [111,] 0.013077579 0.0019568480 0.0012473229 0.0005733543 4.566225e-04 #>  [112,] 0.013264871 0.0019851936 0.0012654038 0.0005816712 4.632469e-04 #>  [113,] 0.013454809 0.0020139490 0.0012837464 0.0005901087 4.699674e-04 #>  [114,] 0.013647429 0.0020431200 0.0013023547 0.0005986685 4.767853e-04 #>  [115,] 0.013842768 0.0020727127 0.0013212322 0.0006073524 4.837021e-04 #>  [116,] 0.014040862 0.0021027331 0.0013403831 0.0006161622 4.907192e-04 #>  [117,] 0.014241751 0.0021331873 0.0013598112 0.0006250996 4.978380e-04 #>  [118,] 0.014445472 0.0021640817 0.0013795204 0.0006341667 5.050600e-04 #>  [119,] 0.014652064 0.0021954226 0.0013995150 0.0006433651 5.123868e-04 #>  [120,] 0.014861565 0.0022272163 0.0014197989 0.0006526969 5.198198e-04 #>  [121,] 0.015074017 0.0022594694 0.0014403764 0.0006621640 5.273605e-04 #>  [122,] 0.015289458 0.0022921885 0.0014612516 0.0006717683 5.350106e-04 #>  [123,] 0.015507930 0.0023253802 0.0014824290 0.0006815118 5.427716e-04 #>  [124,] 0.015729474 0.0023590515 0.0015039129 0.0006913965 5.506452e-04 #>  [125,] 0.015954132 0.0023932092 0.0015257076 0.0007014245 5.586328e-04 #>  [126,] 0.016181945 0.0024278603 0.0015478176 0.0007115978 5.667363e-04 #>  [127,] 0.016412957 0.0024630118 0.0015702476 0.0007219186 5.749573e-04 #>  [128,] 0.016647212 0.0024986710 0.0015930021 0.0007323890 5.832974e-04 #>  [129,] 0.016884752 0.0025348451 0.0016160858 0.0007430111 5.917585e-04 #>  [130,] 0.017125623 0.0025715416 0.0016395034 0.0007537871 6.003422e-04 #>  [131,] 0.017369869 0.0026087680 0.0016632598 0.0007647193 6.090503e-04 #>  [132,] 0.017617536 0.0026465318 0.0016873599 0.0007758099 6.178847e-04 #>  [133,] 0.017868670 0.0026848408 0.0017118086 0.0007870613 6.268472e-04 #>  [134,] 0.018123319 0.0027237028 0.0017366108 0.0007984757 6.359395e-04 #>  [135,] 0.018381528 0.0027631258 0.0017617719 0.0008100555 6.451637e-04 #>  [136,] 0.018643346 0.0028031178 0.0017872968 0.0008218031 6.545216e-04 #>  [137,] 0.018908822 0.0028436869 0.0018131908 0.0008337209 6.640151e-04 #>  [138,] 0.019178004 0.0028848416 0.0018394593 0.0008458114 6.736462e-04 #>  [139,] 0.019450942 0.0029265900 0.0018661077 0.0008580771 6.834169e-04 #>  [140,] 0.019727686 0.0029689409 0.0018931413 0.0008705205 6.933292e-04 #>  [141,] 0.020008288 0.0030119027 0.0019205659 0.0008831442 7.033852e-04 #>  [142,] 0.020292798 0.0030554843 0.0019483870 0.0008959508 7.135870e-04 #>  [143,] 0.020581269 0.0030996946 0.0019766102 0.0009089430 7.239366e-04 #>  [144,] 0.020873753 0.0031445425 0.0020052415 0.0009221233 7.344362e-04 #>  [145,] 0.021170304 0.0031900373 0.0020342867 0.0009354946 7.450880e-04 #>  [146,] 0.021470975 0.0032361881 0.0020637517 0.0009490597 7.558941e-04 #>  [147,] 0.021775822 0.0032830044 0.0020936425 0.0009628212 7.668568e-04 #>  [148,] 0.022084899 0.0033304957 0.0021239654 0.0009767821 7.779785e-04 #>  [149,] 0.022398263 0.0033786717 0.0021547265 0.0009909452 7.892612e-04 #>  [150,] 0.022715970 0.0034275421 0.0021859322 0.0010053134 8.007075e-04 #>  [151,] 0.023038077 0.0034771170 0.0022175888 0.0010198898 8.123197e-04 #>  [152,] 0.023364642 0.0035274063 0.0022497028 0.0010346773 8.241001e-04 #>  [153,] 0.023695724 0.0035784204 0.0022822807 0.0010496790 8.360512e-04 #>  [154,] 0.024031382 0.0036301696 0.0023153294 0.0010648980 8.481755e-04 #>  [155,] 0.024371677 0.0036826644 0.0023488555 0.0010803374 8.604754e-04 #>  [156,] 0.024716668 0.0037359154 0.0023828659 0.0010960004 8.729536e-04 #>  [157,] 0.025066417 0.0037899335 0.0024173675 0.0011118902 8.856125e-04 #>  [158,] 0.025420985 0.0038447296 0.0024523675 0.0011280101 8.984549e-04 #>  [159,] 0.025780437 0.0039003150 0.0024878730 0.0011443635 9.114833e-04 #>  [160,] 0.026144835 0.0039567007 0.0025238912 0.0011609536 9.247005e-04 #>  [161,] 0.026514244 0.0040138983 0.0025604295 0.0011777841 9.381091e-04 #>  [162,] 0.026888728 0.0040719194 0.0025974954 0.0011948582 9.517120e-04 #>  [163,] 0.027268353 0.0041307757 0.0026350965 0.0012121795 9.655119e-04 #>  [164,] 0.027653185 0.0041904791 0.0026732404 0.0012297516 9.795118e-04 #>  [165,] 0.028043292 0.0042510418 0.0027119350 0.0012475781 9.937144e-04 #>  [166,] 0.028438741 0.0043124759 0.0027511881 0.0012656627 1.008123e-03 #>  [167,] 0.028839601 0.0043747940 0.0027910078 0.0012840091 1.022740e-03 #>  [168,] 0.029245941 0.0044380086 0.0028314022 0.0013026212 1.037569e-03 #>  [169,] 0.029657832 0.0045021325 0.0028723795 0.0013215026 1.052612e-03 #>  [170,] 0.030075344 0.0045671786 0.0029139482 0.0013406574 1.067874e-03 #>  [171,] 0.030498548 0.0046331602 0.0029561166 0.0013600894 1.083356e-03 #>  [172,] 0.030927518 0.0047000905 0.0029988935 0.0013798027 1.099063e-03 #>  [173,] 0.031362327 0.0047679830 0.0030422874 0.0013998013 1.114997e-03 #>  [174,] 0.031803047 0.0048368515 0.0030863073 0.0014200894 1.131162e-03 #>  [175,] 0.032249755 0.0049067098 0.0031309622 0.0014406711 1.147561e-03 #>  [176,] 0.032702525 0.0049775720 0.0031762611 0.0014615506 1.164197e-03 #>  [177,] 0.033161434 0.0050494524 0.0032222132 0.0014827323 1.181075e-03 #>  [178,] 0.033626560 0.0051223655 0.0032688280 0.0015042205 1.198197e-03 #>  [179,] 0.034097978 0.0051963259 0.0033161149 0.0015260197 1.215566e-03 #>  [180,] 0.034575770 0.0052713485 0.0033640836 0.0015481343 1.233187e-03 #>  [181,] 0.035060013 0.0053474485 0.0034127438 0.0015705688 1.251064e-03 #>  [182,] 0.035550788 0.0054246411 0.0034621053 0.0015933280 1.269199e-03 #>  [183,] 0.036048177 0.0055029419 0.0035121783 0.0016164164 1.287596e-03 #>  [184,] 0.036552261 0.0055823665 0.0035629730 0.0016398388 1.306260e-03 #>  [185,] 0.037063123 0.0056629309 0.0036144996 0.0016636001 1.325194e-03 #>  [186,] 0.037580846 0.0057446514 0.0036667686 0.0016877050 1.344403e-03 #>  [187,] 0.038105515 0.0058275442 0.0037197906 0.0017121587 1.363889e-03 #>  [188,] 0.038637215 0.0059116260 0.0037735764 0.0017369661 1.383657e-03 #>  [189,] 0.039176032 0.0059969136 0.0038281370 0.0017621322 1.403712e-03 #>  [190,] 0.039722052 0.0060834242 0.0038834834 0.0017876623 1.424056e-03 #>  [191,] 0.040275364 0.0061711750 0.0039396267 0.0018135617 1.444695e-03 #>  [192,] 0.040836055 0.0062601836 0.0039965785 0.0018398355 1.465633e-03 #>  [193,] 0.041404215 0.0063504678 0.0040543503 0.0018664893 1.486874e-03 #>  [194,] 0.041979934 0.0064420456 0.0041129536 0.0018935285 1.508422e-03 #>  [195,] 0.042563303 0.0065349354 0.0041724006 0.0019209587 1.530282e-03 #>  [196,] 0.043154413 0.0066291556 0.0042327031 0.0019487854 1.552458e-03 #>  [197,] 0.043753358 0.0067247251 0.0042938733 0.0019770144 1.574955e-03 #>  [198,] 0.044360230 0.0068216629 0.0043559238 0.0020056516 1.597778e-03 #>  [199,] 0.044975123 0.0069199883 0.0044188669 0.0020347026 1.620931e-03 #>  [200,] 0.045598133 0.0070197210 0.0044827155 0.0020641736 1.644418e-03 #>  [201,] 0.046229356 0.0071208807 0.0045474824 0.0020940706 1.668246e-03 #>  [202,] 0.046868887 0.0072234876 0.0046131807 0.0021243997 1.692418e-03 #>  [203,] 0.047516825 0.0073275621 0.0046798237 0.0021551671 1.716940e-03 #>  [204,] 0.048173268 0.0074331249 0.0047474249 0.0021863791 1.741816e-03 #>  [205,] 0.048838314 0.0075401968 0.0048159979 0.0022180421 1.767053e-03 #>  [206,] 0.049512064 0.0076487993 0.0048855564 0.0022501627 1.792654e-03 #>  [207,] 0.050194618 0.0077589537 0.0049561147 0.0022827473 1.818626e-03 #>  [208,] 0.050886078 0.0078706819 0.0050276868 0.0023158027 1.844973e-03 #>  [209,] 0.051586545 0.0079840060 0.0051002872 0.0023493356 1.871701e-03 #>  [210,] 0.052296124 0.0080989485 0.0051739305 0.0023833530 1.898815e-03 #>  [211,] 0.053014917 0.0082155321 0.0052486315 0.0024178616 1.926322e-03 #>  [212,] 0.053743030 0.0083337798 0.0053244053 0.0024528688 1.954226e-03 #>  [213,] 0.054480567 0.0084537149 0.0054012670 0.0024883815 1.982534e-03 #>  [214,] 0.055227636 0.0085753612 0.0054792323 0.0025244070 2.011251e-03 #>  [215,] 0.055984341 0.0086987425 0.0055583166 0.0025609528 2.040383e-03 #>  [216,] 0.056750793 0.0088238832 0.0056385359 0.0025980263 2.069936e-03 #>  [217,] 0.057527097 0.0089508080 0.0057199063 0.0026356350 2.099916e-03 #>  [218,] 0.058313365 0.0090795418 0.0058024442 0.0026737867 2.130330e-03 #>  [219,] 0.059109705 0.0092101098 0.0058861659 0.0027124892 2.161183e-03 #>  [220,] 0.059916228 0.0093425378 0.0059710885 0.0027517503 2.192482e-03 #>  [221,] 0.060733045 0.0094768517 0.0060572288 0.0027915781 2.224233e-03 #>  [222,] 0.061560268 0.0096130778 0.0061446040 0.0028319807 2.256443e-03 #>  [223,] 0.062398011 0.0097512429 0.0062332318 0.0028729664 2.289118e-03 #>  [224,] 0.063246385 0.0098913739 0.0063231298 0.0029145435 2.322266e-03 #>  [225,] 0.064105506 0.0100334982 0.0064143159 0.0029567205 2.355892e-03 #>  [226,] 0.064975487 0.0101776437 0.0065068085 0.0029995061 2.390004e-03 #>  [227,] 0.065856443 0.0103238385 0.0066006258 0.0030429089 2.424609e-03 #>  [228,] 0.066748492 0.0104721110 0.0066957868 0.0030869378 2.459713e-03 #>  [229,] 0.067651748 0.0106224902 0.0067923103 0.0031316017 2.495325e-03 #>  [230,] 0.068566329 0.0107750053 0.0068902156 0.0031769098 2.531451e-03 #>  [231,] 0.069492353 0.0109296860 0.0069895222 0.0032228713 2.568098e-03 #>  [232,] 0.070429938 0.0110865623 0.0070902498 0.0032694956 2.605275e-03 #>  [233,] 0.071379203 0.0112456647 0.0071924186 0.0033167922 2.642988e-03 #>  [234,] 0.072340266 0.0114070240 0.0072960487 0.0033647706 2.681246e-03 #>  [235,] 0.073313247 0.0115706715 0.0074011609 0.0034134406 2.720056e-03 #>  [236,] 0.074298267 0.0117366389 0.0075077759 0.0034628122 2.759427e-03 #>  [237,] 0.075295445 0.0119049581 0.0076159149 0.0035128954 2.799365e-03 #>  [238,] 0.076304905 0.0120756619 0.0077255995 0.0035637004 2.839880e-03 #>  [239,] 0.077326766 0.0122487829 0.0078368512 0.0036152375 2.880980e-03 #>  [240,] 0.078361150 0.0124243547 0.0079496921 0.0036675171 2.922673e-03 #>  [241,] 0.079408181 0.0126024110 0.0080641446 0.0037205499 2.964967e-03 #>  [242,] 0.080467980 0.0127829861 0.0081802313 0.0037743467 3.007872e-03 #>  [243,] 0.081540670 0.0129661145 0.0082979752 0.0038289184 3.051395e-03 #>  [244,] 0.082626376 0.0131518315 0.0084173994 0.0038842760 3.095546e-03 #>  [245,] 0.083725219 0.0133401726 0.0085385276 0.0039404308 3.140334e-03 #>  [246,] 0.084837325 0.0135311738 0.0086613836 0.0039973941 3.185768e-03 #>  [247,] 0.085962816 0.0137248718 0.0087859917 0.0040551776 3.231858e-03 #>  [248,] 0.087101818 0.0139213033 0.0089123763 0.0041137929 3.278612e-03 #>  [249,] 0.088254454 0.0141205060 0.0090405624 0.0041732519 3.326040e-03 #>  [250,] 0.089420850 0.0143225177 0.0091705751 0.0042335667 3.374151e-03 #>  [251,] 0.090601128 0.0145273768 0.0093024399 0.0042947494 3.422957e-03 #>  [252,] 0.091795416 0.0147351223 0.0094361828 0.0043568124 3.472465e-03 #>  [253,] 0.093003835 0.0149457936 0.0095718300 0.0044197683 3.522688e-03 #>  [254,] 0.094226513 0.0151594305 0.0097094080 0.0044836298 3.573634e-03 #>  [255,] 0.095463572 0.0153760736 0.0098489438 0.0045484099 3.625314e-03 #>  [256,] 0.096715139 0.0155957636 0.0099904647 0.0046141216 3.677739e-03 #>  [257,] 0.097981336 0.0158185421 0.0101339983 0.0046807781 3.730919e-03 #>  [258,] 0.099262289 0.0160444510 0.0102795726 0.0047483930 3.784865e-03 #>  [259,] 0.100558121 0.0162735328 0.0104272160 0.0048169799 3.839588e-03 #>  [260,] 0.101868957 0.0165058306 0.0105769574 0.0048865526 3.895099e-03 #>  [261,] 0.103194920 0.0167413879 0.0107288259 0.0049571251 3.951410e-03 #>  [262,] 0.104536133 0.0169802488 0.0108828509 0.0050287118 4.008531e-03 #>  [263,] 0.105892719 0.0172224581 0.0110390625 0.0051013269 4.066475e-03 #>  [264,] 0.107264802 0.0174680608 0.0111974909 0.0051749851 4.125253e-03 #>  [265,] 0.108652502 0.0177171029 0.0113581670 0.0052497013 4.184877e-03 #>  [266,] 0.110055942 0.0179696306 0.0115211217 0.0053254904 4.245359e-03 #>  [267,] 0.111475243 0.0182256909 0.0116863868 0.0054023678 4.306712e-03 #>  [268,] 0.112910525 0.0184853312 0.0118539940 0.0054803488 4.368947e-03 #>  [269,] 0.114361908 0.0187485998 0.0120239759 0.0055594491 4.432077e-03 #>  [270,] 0.115829512 0.0190155451 0.0121963651 0.0056396847 4.496116e-03 #>  [271,] 0.117313455 0.0192862166 0.0123711949 0.0057210716 4.561075e-03 #>  [272,] 0.118813854 0.0195606640 0.0125484991 0.0058036262 4.626969e-03 #>  [273,] 0.120330828 0.0198389379 0.0127283116 0.0058873649 4.693810e-03 #>  [274,] 0.121864490 0.0201210894 0.0129106670 0.0059723046 4.761613e-03 #>  [275,] 0.123414958 0.0204071700 0.0130956003 0.0060584624 4.830390e-03 #>  [276,] 0.124982344 0.0206972323 0.0132831470 0.0061458553 4.900155e-03 #>  [277,] 0.126566762 0.0209913290 0.0134733429 0.0062345010 4.970923e-03 #>  [278,] 0.128168324 0.0212895139 0.0136662245 0.0063244172 5.042708e-03 #>  [279,] 0.129787141 0.0215918411 0.0138618285 0.0064156218 5.115524e-03 #>  [280,] 0.131423321 0.0218983655 0.0140601923 0.0065081330 5.189386e-03 #>  [281,] 0.133076974 0.0222091427 0.0142613536 0.0066019694 5.264309e-03 #>  [282,] 0.134748207 0.0225242288 0.0144653507 0.0066971496 5.340308e-03 #>  [283,] 0.136437124 0.0228436806 0.0146722224 0.0067936926 5.417398e-03 #>  [284,] 0.138143830 0.0231675557 0.0148820080 0.0068916177 5.495595e-03 #>  [285,] 0.139868428 0.0234959123 0.0150947471 0.0069909443 5.574914e-03 #>  [286,] 0.141611018 0.0238288092 0.0153104801 0.0070916923 5.655372e-03 #>  [287,] 0.143371700 0.0241663059 0.0155292477 0.0071938817 5.736984e-03 #>  [288,] 0.145150571 0.0245084627 0.0157510913 0.0072975328 5.819766e-03 #>  [289,] 0.146947727 0.0248553405 0.0159760525 0.0074026661 5.903737e-03 #>  [290,] 0.148763262 0.0252070010 0.0162041739 0.0075093027 5.988911e-03 #>  [291,] 0.150597268 0.0255635064 0.0164354981 0.0076174635 6.075307e-03 #>  [292,] 0.152449835 0.0259249198 0.0166700687 0.0077271702 6.162941e-03 #>  [293,] 0.154321051 0.0262913050 0.0169079296 0.0078384443 6.251832e-03 #>  [294,] 0.156211002 0.0266627264 0.0171491252 0.0079513080 6.341997e-03 #>  [295,] 0.158119771 0.0270392492 0.0173937007 0.0080657836 6.433453e-03 #>  [296,] 0.160047439 0.0274209394 0.0176417017 0.0081818937 6.526220e-03 #>  [297,] 0.161994086 0.0278078636 0.0178931742 0.0082996613 6.620315e-03 #>  [298,] 0.163959789 0.0282000891 0.0181481652 0.0084191096 6.715758e-03 #>  [299,] 0.165944620 0.0285976842 0.0184067218 0.0085402622 6.812567e-03 #>  [300,] 0.167948653 0.0290007178 0.0186688921 0.0086631429 6.910763e-03 #>  [301,] 0.169971955 0.0294092594 0.0189347245 0.0087877761 7.010363e-03 #>  [302,] 0.172014593 0.0298233795 0.0192042681 0.0089141861 7.111389e-03 #>  [303,] 0.174076630 0.0302431493 0.0194775725 0.0090423980 7.213860e-03 #>  [304,] 0.176158126 0.0306686406 0.0197546882 0.0091724368 7.317797e-03 #>  [305,] 0.178259141 0.0310999262 0.0200356659 0.0093043282 7.423220e-03 #>  [306,] 0.180379727 0.0315370795 0.0203205572 0.0094380980 7.530151e-03 #>  [307,] 0.182519936 0.0319801748 0.0206094142 0.0095737725 7.638609e-03 #>  [308,] 0.184679818 0.0324292871 0.0209022898 0.0097113781 7.748618e-03 #>  [309,] 0.186859416 0.0328844923 0.0211992372 0.0098509420 7.860199e-03 #>  [310,] 0.189058774 0.0333458669 0.0215003106 0.0099924912 7.973373e-03 #>  [311,] 0.191277928 0.0338134883 0.0218055646 0.0101360536 8.088164e-03 #>  [312,] 0.193516915 0.0342874347 0.0221150545 0.0102816572 8.204594e-03 #>  [313,] 0.195775766 0.0347677852 0.0224288363 0.0104293303 8.322685e-03 #>  [314,] 0.198054508 0.0352546195 0.0227469667 0.0105791017 8.442462e-03 #>  [315,] 0.200353166 0.0357480182 0.0230695030 0.0107310006 8.563948e-03 #>  [316,] 0.202671760 0.0362480627 0.0233965032 0.0108850565 8.687166e-03 #>  [317,] 0.205010308 0.0367548352 0.0237280258 0.0110412994 8.812142e-03 #>  [318,] 0.207368821 0.0372684188 0.0240641303 0.0111997596 8.938899e-03 #>  [319,] 0.209747308 0.0377888972 0.0244048767 0.0113604678 9.067463e-03 #>  [320,] 0.212145775 0.0383163552 0.0247503256 0.0115234552 9.197859e-03 #>  [321,] 0.214564221 0.0388508782 0.0251005385 0.0116887533 9.330113e-03 #>  [322,] 0.217002644 0.0393925525 0.0254555775 0.0118563941 9.464250e-03 #>  [323,] 0.219461036 0.0399414652 0.0258155055 0.0120264099 9.600297e-03 #>  [324,] 0.221939384 0.0404977042 0.0261803859 0.0121988336 9.738280e-03 #>  [325,] 0.224437672 0.0410613582 0.0265502831 0.0123736984 9.878226e-03 #>  [326,] 0.226955879 0.0416325169 0.0269252619 0.0125510380 1.002016e-02 #>  [327,] 0.229493980 0.0422112707 0.0273053882 0.0127308864 1.016412e-02 #>  [328,] 0.232051945 0.0427977107 0.0276907283 0.0129132782 1.031012e-02 #>  [329,] 0.234629739 0.0433919289 0.0280813494 0.0130982484 1.045820e-02 #>  [330,] 0.237227323 0.0439940183 0.0284773195 0.0132858325 1.060838e-02 #>  [331,] 0.239844653 0.0446040726 0.0288787071 0.0134760664 1.076070e-02 #>  [332,] 0.242481680 0.0452221861 0.0292855818 0.0136689864 1.091517e-02 #>  [333,] 0.245138351 0.0458484543 0.0296980136 0.0138646294 1.107184e-02 #>  [334,] 0.247814606 0.0464829732 0.0301160736 0.0140630326 1.123074e-02 #>  [335,] 0.250510383 0.0471258398 0.0305398334 0.0142642340 1.139188e-02 #>  [336,] 0.253225613 0.0477771519 0.0309693655 0.0144682717 1.155532e-02 #>  [337,] 0.255960221 0.0484370079 0.0314047431 0.0146751846 1.172107e-02 #>  [338,] 0.258714131 0.0491055074 0.0318460402 0.0148850119 1.188917e-02 #>  [339,] 0.261487256 0.0497827504 0.0322933316 0.0150977933 1.205965e-02 #>  [340,] 0.264279510 0.0504688380 0.0327466930 0.0153135692 1.223254e-02 #>  [341,] 0.267090796 0.0511638718 0.0332062006 0.0155323802 1.240788e-02 #>  [342,] 0.269921016 0.0518679544 0.0336719317 0.0157542678 1.258571e-02 #>  [343,] 0.272770065 0.0525811893 0.0341439641 0.0159792737 1.276604e-02 #>  [344,] 0.275637832 0.0533036804 0.0346223767 0.0162074402 1.294893e-02 #>  [345,] 0.278524202 0.0540355327 0.0351072490 0.0164388103 1.313441e-02 #>  [346,] 0.281429054 0.0547768518 0.0355986613 0.0166734274 1.332250e-02 #>  [347,] 0.284352262 0.0555277442 0.0360966948 0.0169113354 1.351325e-02 #>  [348,] 0.287293693 0.0562883170 0.0366014314 0.0171525788 1.370670e-02 #>  [349,] 0.290253211 0.0570586781 0.0371129540 0.0173972026 1.390287e-02 #>  [350,] 0.293230672 0.0578389362 0.0376313462 0.0176452526 1.410182e-02 #>  [351,] 0.296225929 0.0586292007 0.0381566923 0.0178967749 1.430357e-02 #>  [352,] 0.299238828 0.0594295815 0.0386890775 0.0181518162 1.450816e-02 #>  [353,] 0.302269209 0.0602401897 0.0392285880 0.0184104239 1.471563e-02 #>  [354,] 0.305316908 0.0610611366 0.0397753105 0.0186726459 1.492603e-02 #>  [355,] 0.308381754 0.0618925344 0.0403293328 0.0189385307 1.513939e-02 #>  [356,] 0.311463572 0.0627344961 0.0408907433 0.0192081274 1.535575e-02 #>  [357,] 0.314562181 0.0635871352 0.0414596314 0.0194814857 1.557515e-02 #>  [358,] 0.317677394 0.0644505657 0.0420360872 0.0197586559 1.579764e-02 #>  [359,] 0.320809018 0.0653249027 0.0426202017 0.0200396889 1.602326e-02 #>  [360,] 0.323956856 0.0662102614 0.0432120666 0.0203246362 1.625204e-02 #>  [361,] 0.327120705 0.0671067581 0.0438117746 0.0206135500 1.648404e-02 #>  [362,] 0.330300357 0.0680145093 0.0444194191 0.0209064830 1.671929e-02 #>  [363,] 0.333495597 0.0689336323 0.0450350944 0.0212034888 1.695784e-02 #>  [364,] 0.336706206 0.0698642449 0.0456588955 0.0215046212 1.719974e-02 #>  [365,] 0.339931960 0.0708064654 0.0462909183 0.0218099350 1.744502e-02 #>  [366,] 0.343172629 0.0717604128 0.0469312595 0.0221194856 1.769374e-02 #>  [367,] 0.346427978 0.0727262064 0.0475800166 0.0224333288 1.794594e-02 #>  [368,] 0.349697766 0.0737039662 0.0482372879 0.0227515215 1.820167e-02 #>  [369,] 0.352981748 0.0746938125 0.0489031726 0.0230741208 1.846097e-02 #>  [370,] 0.356279674 0.0756958660 0.0495777706 0.0234011849 1.872390e-02 #>  [371,] 0.359591288 0.0767102482 0.0502611826 0.0237327722 1.899050e-02 #>  [372,] 0.362916330 0.0777370806 0.0509535102 0.0240689423 1.926082e-02 #>  [373,] 0.366254533 0.0787764853 0.0516548556 0.0244097551 1.953492e-02 #>  [374,] 0.369605628 0.0798285846 0.0523653219 0.0247552713 1.981283e-02 #>  [375,] 0.372969340 0.0808935014 0.0530850131 0.0251055524 2.009462e-02 #>  [376,] 0.376345389 0.0819713588 0.0538140338 0.0254606605 2.038033e-02 #>  [377,] 0.379733490 0.0830622800 0.0545524894 0.0258206585 2.067002e-02 #>  [378,] 0.383133354 0.0841663888 0.0553004861 0.0261856098 2.096374e-02 #>  [379,] 0.386544689 0.0852838089 0.0560581309 0.0265555787 2.126154e-02 #>  [380,] 0.389967196 0.0864146644 0.0568255314 0.0269306303 2.156348e-02 #>  [381,] 0.393400573 0.0875590796 0.0576027960 0.0273108302 2.186961e-02 #>  [382,] 0.396844513 0.0887171789 0.0583900340 0.0276962449 2.217999e-02 #>  [383,] 0.400298708 0.0898890868 0.0591873552 0.0280869416 2.249467e-02 #>  [384,] 0.403762842 0.0910749278 0.0599948701 0.0284829882 2.281371e-02 #>  [385,] 0.407236596 0.0922748267 0.0608126902 0.0288844534 2.313717e-02 #>  [386,] 0.410719650 0.0934889080 0.0616409273 0.0292914066 2.346511e-02 #>  [387,] 0.414211677 0.0947172965 0.0624796942 0.0297039179 2.379758e-02 #>  [388,] 0.417712349 0.0959601167 0.0633291041 0.0301220584 2.413465e-02 #>  [389,] 0.421221332 0.0972174931 0.0641892712 0.0305458998 2.447637e-02 #>  [390,] 0.424738290 0.0984895502 0.0650603099 0.0309755144 2.482280e-02 #>  [391,] 0.428262885 0.0997764122 0.0659423356 0.0314109757 2.517401e-02 #>  [392,] 0.431794775 0.1010782031 0.0668354641 0.0318523575 2.553006e-02 #>  [393,] 0.435333613 0.1023950466 0.0677398120 0.0322997347 2.589102e-02 #>  [394,] 0.438879053 0.1037270663 0.0686554963 0.0327531829 2.625694e-02 #>  [395,] 0.442430743 0.1050743854 0.0695826347 0.0332127785 2.662789e-02 #>  [396,] 0.445988331 0.1064371266 0.0705213452 0.0336785986 2.700393e-02 #>  [397,] 0.449551461 0.1078154124 0.0714717468 0.0341507212 2.738514e-02 #>  [398,] 0.453119775 0.1092093647 0.0724339585 0.0346292251 2.777157e-02 #>  [399,] 0.456692913 0.1106191050 0.0734081003 0.0351141897 2.816330e-02 #>  [400,] 0.460270513 0.1120447540 0.0743942922 0.0356056956 2.856039e-02 #>  [401,] 0.463852212 0.1134864323 0.0753926549 0.0361038238 2.896291e-02 #>  [402,] 0.467437645 0.1149442593 0.0764033097 0.0366086564 2.937094e-02 #>  [403,] 0.471026443 0.1164183540 0.0774263780 0.0371202761 2.978454e-02 #>  [404,] 0.474618239 0.1179088347 0.0784619818 0.0376387665 3.020378e-02 #>  [405,] 0.478212664 0.1194158187 0.0795102433 0.0381642121 3.062873e-02 #>  [406,] 0.481809346 0.1209394226 0.0805712853 0.0386966981 3.105947e-02 #>  [407,] 0.485407914 0.1224797621 0.0816452307 0.0392363105 3.149608e-02 #>  [408,] 0.489007996 0.1240369519 0.0827322028 0.0397831361 3.193861e-02 #>  [409,] 0.492609219 0.1256111056 0.0838323251 0.0403372628 3.238716e-02 #>  [410,] 0.496211208 0.1272023359 0.0849457214 0.0408987790 3.284180e-02 #>  [411,] 0.499813591 0.1288107543 0.0860725158 0.0414677741 3.330259e-02 #>  [412,] 0.503415994 0.1304364709 0.0872128324 0.0420443381 3.376963e-02 #>  [413,] 0.507018041 0.1320795950 0.0883667956 0.0426285621 3.424298e-02 #>  [414,] 0.510619361 0.1337402343 0.0895345298 0.0432205379 3.472273e-02 #>  [415,] 0.514219578 0.1354184950 0.0907161596 0.0438203581 3.520896e-02 #>  [416,] 0.517818320 0.1371144823 0.0919118097 0.0444281162 3.570174e-02 #>  [417,] 0.521415215 0.1388282995 0.0931216048 0.0450439063 3.620116e-02 #>  [418,] 0.525009890 0.1405600486 0.0943456694 0.0456678236 3.670730e-02 #>  [419,] 0.528601976 0.1423098298 0.0955841282 0.0462999640 3.722025e-02 #>  [420,] 0.532191102 0.1440777418 0.0968371058 0.0469404242 3.774008e-02 #>  [421,] 0.535776899 0.1458638814 0.0981047265 0.0475893016 3.826689e-02 #>  [422,] 0.539359002 0.1476683437 0.0993871147 0.0482466948 3.880075e-02 #>  [423,] 0.542937043 0.1494912218 0.1006843944 0.0489127026 3.934175e-02 #>  [424,] 0.546510660 0.1513326069 0.1019966896 0.0495874252 3.988998e-02 #>  [425,] 0.550079490 0.1531925882 0.1033241237 0.0502709633 4.044554e-02 #>  [426,] 0.553643173 0.1550712529 0.1046668201 0.0509634183 4.100850e-02 #>  [427,] 0.557201351 0.1569686858 0.1060249018 0.0516648927 4.157895e-02 #>  [428,] 0.560753668 0.1588849696 0.1073984911 0.0523754895 4.215699e-02 #>  [429,] 0.564299771 0.1608201848 0.1087877103 0.0530953126 4.274271e-02 #>  [430,] 0.567839309 0.1627744094 0.1101926809 0.0538244667 4.333620e-02 #>  [431,] 0.571371933 0.1647477190 0.1116135239 0.0545630572 4.393755e-02 #>  [432,] 0.574897299 0.1667401866 0.1130503599 0.0553111903 4.454686e-02 #>  [433,] 0.578415063 0.1687518827 0.1145033088 0.0560689730 4.516422e-02 #>  [434,] 0.581924887 0.1707828752 0.1159724895 0.0568365130 4.578972e-02 #>  [435,] 0.585426434 0.1728332291 0.1174580207 0.0576139187 4.642347e-02 #>  [436,] 0.588919372 0.1749030066 0.1189600200 0.0584012992 4.706555e-02 #>  [437,] 0.592403369 0.1769922672 0.1204786041 0.0591987646 4.771607e-02 #>  [438,] 0.595878101 0.1791010673 0.1220138891 0.0600064253 4.837513e-02 #>  [439,] 0.599343245 0.1812294602 0.1235659899 0.0608243927 4.904282e-02 #>  [440,] 0.602798483 0.1833774962 0.1251350204 0.0616527787 4.971924e-02 #>  [441,] 0.606243500 0.1855452225 0.1267210938 0.0624916961 5.040450e-02 #>  [442,] 0.609677984 0.1877326827 0.1283243217 0.0633412582 5.109870e-02 #>  [443,] 0.613101630 0.1899399176 0.1299448148 0.0642015790 5.180193e-02 #>  [444,] 0.616514135 0.1921669640 0.1315826826 0.0650727731 5.251431e-02 #>  [445,] 0.619915200 0.1944138557 0.1332380333 0.0659549558 5.323593e-02 #>  [446,] 0.623304532 0.1966806227 0.1349109736 0.0668482431 5.396691e-02 #>  [447,] 0.626681841 0.1989672914 0.1366016089 0.0677527513 5.470734e-02 #>  [448,] 0.630046843 0.2012738846 0.1383100431 0.0686685977 5.545733e-02 #>  [449,] 0.633399256 0.2036004211 0.1400363787 0.0695958997 5.621700e-02 #>  [450,] 0.636738807 0.2059469161 0.1417807164 0.0705347757 5.698644e-02 #>  [451,] 0.640065223 0.2083133807 0.1435431553 0.0714853443 5.776578e-02 #>  [452,] 0.643378238 0.2106998222 0.1453237928 0.0724477248 5.855510e-02 #>  [453,] 0.646677593 0.2131062436 0.1471227246 0.0734220370 5.935454e-02 #>  [454,] 0.649963030 0.2155326441 0.1489400443 0.0744084011 6.016419e-02 #>  [455,] 0.653234298 0.2179790182 0.1507758438 0.0754069378 6.098416e-02 #>  [456,] 0.656491153 0.2204453567 0.1526302128 0.0764177682 6.181458e-02 #>  [457,] 0.659733352 0.2229316457 0.1545032391 0.0774410139 6.265555e-02 #>  [458,] 0.662960660 0.2254378669 0.1563950083 0.0784767968 6.350719e-02 #>  [459,] 0.666172847 0.2279639977 0.1583056038 0.0795252392 6.436961e-02 #>  [460,] 0.669369688 0.2305100110 0.1602351067 0.0805864637 6.524293e-02 #>  [461,] 0.672550963 0.2330758749 0.1621835957 0.0816605935 6.612725e-02 #>  [462,] 0.675716457 0.2356615529 0.1641511471 0.0827477517 6.702271e-02 #>  [463,] 0.678865962 0.2382670040 0.1661378349 0.0838480618 6.792940e-02 #>  [464,] 0.681999273 0.2408921823 0.1681437302 0.0849616478 6.884746e-02 #>  [465,] 0.685116193 0.2435370368 0.1701689017 0.0860886336 6.977700e-02 #>  [466,] 0.688216529 0.2462015121 0.1722134153 0.0872291433 7.071813e-02 #>  [467,] 0.691300094 0.2488855477 0.1742773341 0.0883833014 7.167098e-02 #>  [468,] 0.694366705 0.2515890778 0.1763607183 0.0895512323 7.263567e-02 #>  [469,] 0.697416186 0.2543120320 0.1784636254 0.0907330606 7.361231e-02 #>  [470,] 0.700448367 0.2570543347 0.1805861095 0.0919289110 7.460102e-02 #>  [471,] 0.703463083 0.2598159050 0.1827282220 0.0931389080 7.560193e-02 #>  [472,] 0.706460173 0.2625966570 0.1848900108 0.0943631764 7.661516e-02 #>  [473,] 0.709439483 0.2653964995 0.1870715208 0.0956018408 7.764082e-02 #>  [474,] 0.712400864 0.2682153362 0.1892727935 0.0968550256 7.867905e-02 #>  [475,] 0.715344174 0.2710530654 0.1914938670 0.0981228555 7.972996e-02 #>  [476,] 0.718269273 0.2739095800 0.1937347760 0.0994054545 8.079368e-02 #>  [477,] 0.721176031 0.2767847678 0.1959955516 0.1007029469 8.187032e-02 #>  [478,] 0.724064319 0.2796785109 0.1982762214 0.1020154564 8.296002e-02 #>  [479,] 0.726934017 0.2825906863 0.2005768091 0.1033431067 8.406290e-02 #>  [480,] 0.729785008 0.2855211655 0.2028973349 0.1046860210 8.517907e-02 #>  [481,] 0.732617182 0.2884698143 0.2052378150 0.1060443222 8.630867e-02 #>  [482,] 0.735430432 0.2914364935 0.2075982619 0.1074181330 8.745181e-02 #>  [483,] 0.738224660 0.2944210580 0.2099786838 0.1088075752 8.860863e-02 #>  [484,] 0.740999769 0.2974233574 0.2123790852 0.1102127707 8.977925e-02 #>  [485,] 0.743755671 0.3004432357 0.2147994663 0.1116338403 9.096378e-02 #>  [486,] 0.746492281 0.3034805317 0.2172398232 0.1130709045 9.216237e-02 #>  [487,] 0.749209520 0.3065350783 0.2197001477 0.1145240833 9.337512e-02 #>  [488,] 0.751907313 0.3096067031 0.2221804273 0.1159934957 9.460217e-02 #>  [489,] 0.754585592 0.3126952282 0.2246806451 0.1174792602 9.584364e-02 #>  [490,] 0.757244292 0.3158004702 0.2272007798 0.1189814944 9.709966e-02 #>  [491,] 0.759883355 0.3189222402 0.2297408057 0.1205003152 9.837034e-02 #>  [492,] 0.762502726 0.3220603437 0.2323006922 0.1220358385 9.965581e-02 #>  [493,] 0.765102355 0.3252145810 0.2348804043 0.1235881791 1.009562e-01 #>  [494,] 0.767682199 0.3283847468 0.2374799024 0.1251574512 1.022716e-01 #>  [495,] 0.770242218 0.3315706306 0.2400991420 0.1267437677 1.036022e-01 #>  [496,] 0.772782376 0.3347720162 0.2427380737 0.1283472403 1.049481e-01 #>  [497,] 0.775302643 0.3379886823 0.2453966434 0.1299679797 1.063094e-01 #>  [498,] 0.777802994 0.3412204022 0.2480747921 0.1316060954 1.076863e-01 #>  [499,] 0.780283406 0.3444669441 0.2507724557 0.1332616953 1.090787e-01 #>  [500,] 0.782743864 0.3477280708 0.2534895652 0.1349348865 1.104870e-01 #>  [501,] 0.785184353 0.3510035398 0.2562260464 0.1366257741 1.119112e-01 #>  [502,] 0.787604868 0.3542931038 0.2589818202 0.1383344622 1.133514e-01 #>  [503,] 0.790005402 0.3575965103 0.2617568021 0.1400610530 1.148077e-01 #>  [504,] 0.792385957 0.3609135016 0.2645509026 0.1418056473 1.162802e-01 #>  [505,] 0.794746537 0.3642438153 0.2673640268 0.1435683443 1.177692e-01 #>  [506,] 0.797087150 0.3675871840 0.2701960746 0.1453492413 1.192746e-01 #>  [507,] 0.799407808 0.3709433355 0.2730469408 0.1471484338 1.207967e-01 #>  [508,] 0.801708529 0.3743119927 0.2759165145 0.1489660157 1.223355e-01 #>  [509,] 0.803989331 0.3776928742 0.2788046796 0.1508020785 1.238911e-01 #>  [510,] 0.806250239 0.3810856935 0.2817113146 0.1526567122 1.254636e-01 #>  [511,] 0.808491280 0.3844901600 0.2846362927 0.1545300044 1.270533e-01 #>  [512,] 0.810712486 0.3879059786 0.2875794815 0.1564220407 1.286601e-01 #>  [513,] 0.812913890 0.3913328496 0.2905407431 0.1583329045 1.302842e-01 #>  [514,] 0.815095531 0.3947704693 0.2935199343 0.1602626767 1.319257e-01 #>  [515,] 0.817257451 0.3982185300 0.2965169063 0.1622114362 1.335847e-01 #>  [516,] 0.819399695 0.4016767195 0.2995315049 0.1641792592 1.352613e-01 #>  [517,] 0.821522309 0.4051447220 0.3025635703 0.1661662196 1.369556e-01 #>  [518,] 0.823625347 0.4086222178 0.3056129371 0.1681723885 1.386678e-01 #>  [519,] 0.825708861 0.4121088834 0.3086794348 0.1701978345 1.403978e-01 #>  [520,] 0.827772909 0.4156043917 0.3117628869 0.1722426236 1.421459e-01 #>  [521,] 0.829817551 0.4191084122 0.3148631117 0.1743068187 1.439122e-01 #>  [522,] 0.831842851 0.4226206109 0.3179799220 0.1763904801 1.456966e-01 #>  [523,] 0.833848875 0.4261406505 0.3211131250 0.1784936652 1.474993e-01 #>  [524,] 0.835835690 0.4296681908 0.3242625225 0.1806164280 1.493205e-01 #>  [525,] 0.837803369 0.4332028883 0.3274279110 0.1827588199 1.511602e-01 #>  [526,] 0.839751984 0.4367443968 0.3306090814 0.1849208888 1.530184e-01 #>  [527,] 0.841681613 0.4402923673 0.3338058194 0.1871026795 1.548953e-01 #>  [528,] 0.843592335 0.4438464480 0.3370179051 0.1893042335 1.567910e-01 #>  [529,] 0.845484229 0.4474062850 0.3402451135 0.1915255888 1.587055e-01 #>  [530,] 0.847357380 0.4509715218 0.3434872142 0.1937667800 1.606390e-01 #>  [531,] 0.849211873 0.4545417996 0.3467439718 0.1960278383 1.625914e-01 #>  [532,] 0.851047795 0.4581167579 0.3500151453 0.1983087911 1.645629e-01 #>  [533,] 0.852865238 0.4616960338 0.3533004888 0.2006096622 1.665536e-01 #>  [534,] 0.854664292 0.4652792630 0.3565997514 0.2029304716 1.685635e-01 #>  [535,] 0.856445051 0.4688660795 0.3599126770 0.2052712355 1.705927e-01 #>  [536,] 0.858207610 0.4724561157 0.3632390046 0.2076319663 1.726413e-01 #>  [537,] 0.859952068 0.4760490028 0.3665784683 0.2100126723 1.747092e-01 #>  [538,] 0.861678523 0.4796443707 0.3699307972 0.2124133578 1.767967e-01 #>  [539,] 0.863387076 0.4832418484 0.3732957159 0.2148340229 1.789036e-01 #>  [540,] 0.865077830 0.4868410640 0.3766729441 0.2172746638 1.810302e-01 #>  [541,] 0.866750888 0.4904416447 0.3800621970 0.2197352721 1.831764e-01 #>  [542,] 0.868406355 0.4940432174 0.3834631851 0.2222158353 1.853423e-01 #>  [543,] 0.870044339 0.4976454084 0.3868756146 0.2247163364 1.875279e-01 #>  [544,] 0.871664947 0.5012478439 0.3902991872 0.2272367541 1.897333e-01 #>  [545,] 0.873268290 0.5048501498 0.3937336006 0.2297770626 1.919585e-01 #>  [546,] 0.874854477 0.5084519522 0.3971785481 0.2323372312 1.942035e-01 #>  [547,] 0.876423621 0.5120528775 0.4006337188 0.2349172250 1.964685e-01 #>  [548,] 0.877975834 0.5156525521 0.4040987981 0.2375170041 1.987533e-01 #>  [549,] 0.879511230 0.5192506033 0.4075734675 0.2401365239 2.010580e-01 #>  [550,] 0.881029925 0.5228466590 0.4110574045 0.2427757353 2.033827e-01 #>  [551,] 0.882532035 0.5264403477 0.4145502831 0.2454345838 2.057273e-01 #>  [552,] 0.884017675 0.5300312990 0.4180517739 0.2481130104 2.080919e-01 #>  [553,] 0.885486964 0.5336191439 0.4215615439 0.2508109510 2.104765e-01 #>  [554,] 0.886940021 0.5372035142 0.4250792567 0.2535283364 2.128811e-01 #>  [555,] 0.888376964 0.5407840436 0.4286045731 0.2562650925 2.153056e-01 #>  [556,] 0.889797913 0.5443603670 0.4321371504 0.2590211400 2.177501e-01 #>  [557,] 0.891202989 0.5479321212 0.4356766434 0.2617963943 2.202146e-01 #>  [558,] 0.892592312 0.5514989450 0.4392227037 0.2645907660 2.226990e-01 #>  [559,] 0.893966005 0.5550604790 0.4427749806 0.2674041599 2.252034e-01 #>  [560,] 0.895324190 0.5586163660 0.4463331207 0.2702364761 2.277277e-01 #>  [561,] 0.896666988 0.5621662512 0.4498967681 0.2730876090 2.302718e-01 #>  [562,] 0.897994523 0.5657097822 0.4534655650 0.2759574479 2.328358e-01 #>  [563,] 0.899306919 0.5692466092 0.4570391511 0.2788458765 2.354197e-01 #>  [564,] 0.900604298 0.5727763851 0.4606171644 0.2817527732 2.380233e-01 #>  [565,] 0.901886785 0.5762987655 0.4641992409 0.2846780111 2.406466e-01 #>  [566,] 0.903154504 0.5798134091 0.4677850152 0.2876214578 2.432896e-01 #>  [567,] 0.904407578 0.5833199779 0.4713741201 0.2905829754 2.459523e-01 #>  [568,] 0.905646134 0.5868181367 0.4749661871 0.2935624205 2.486345e-01 #>  [569,] 0.906870294 0.5903075540 0.4785608466 0.2965596442 2.513362e-01 #>  [570,] 0.908080183 0.5937879015 0.4821577277 0.2995744922 2.540574e-01 #>  [571,] 0.909275927 0.5972588548 0.4857564588 0.3026068048 2.567979e-01 #>  [572,] 0.910457650 0.6007200929 0.4893566675 0.3056564164 2.595576e-01 #>  [573,] 0.911625476 0.6041712987 0.4929579806 0.3087231564 2.623366e-01 #>  [574,] 0.912779531 0.6076121591 0.4965600247 0.3118068482 2.651347e-01 #>  [575,] 0.913919938 0.6110423650 0.5001624259 0.3149073102 2.679517e-01 #>  [576,] 0.915046822 0.6144616112 0.5037648102 0.3180243549 2.707877e-01 #>  [577,] 0.916160307 0.6178695969 0.5073668037 0.3211577895 2.736425e-01 #>  [578,] 0.917260517 0.6212660257 0.5109680325 0.3243074159 2.765159e-01 #>  [579,] 0.918347576 0.6246506054 0.5145681232 0.3274730302 2.794080e-01 #>  [580,] 0.919421608 0.6280230484 0.5181667028 0.3306544235 2.823184e-01 #>  [581,] 0.920482735 0.6313830717 0.5217633988 0.3338513812 2.852472e-01 #>  [582,] 0.921531082 0.6347303967 0.5253578397 0.3370636835 2.881942e-01 #>  [583,] 0.922566769 0.6380647499 0.5289496548 0.3402911053 2.911592e-01 #>  [584,] 0.923589921 0.6413858624 0.5325384744 0.3435334161 2.941421e-01 #>  [585,] 0.924600658 0.6446934701 0.5361239303 0.3467903803 2.971427e-01 #>  [586,] 0.925599102 0.6479873139 0.5397056554 0.3500617570 3.001610e-01 #>  [587,] 0.926585374 0.6512671399 0.5432832844 0.3533473002 3.031966e-01 #>  [588,] 0.927559596 0.6545326989 0.5468564534 0.3566467589 3.062496e-01 #>  [589,] 0.928521887 0.6577837470 0.5504248007 0.3599598769 3.093196e-01 #>  [590,] 0.929472366 0.6610200456 0.5539879661 0.3632863931 3.124066e-01 #>  [591,] 0.930411154 0.6642413610 0.5575455921 0.3666260416 3.155103e-01 #>  [592,] 0.931338369 0.6674474649 0.5610973228 0.3699785515 3.186305e-01 #>  [593,] 0.932254130 0.6706381345 0.5646428053 0.3733436472 3.217671e-01 #>  [594,] 0.933158553 0.6738131519 0.5681816889 0.3767210483 3.249198e-01 #>  [595,] 0.934051755 0.6769723049 0.5717136256 0.3801104701 3.280885e-01 #>  [596,] 0.934933855 0.6801153867 0.5752382703 0.3835116229 3.312730e-01 #>  [597,] 0.935804966 0.6832421956 0.5787552808 0.3869242129 3.344729e-01 #>  [598,] 0.936665205 0.6863525357 0.5822643179 0.3903479419 3.376882e-01 #>  [599,] 0.937514686 0.6894462164 0.5857650457 0.3937825072 3.409185e-01 #>  [600,] 0.938353524 0.6925230526 0.5892571315 0.3972276022 3.441637e-01 #>  [601,] 0.939181831 0.6955828647 0.5927402461 0.4006829160 3.474234e-01 #>  [602,] 0.939999720 0.6986254785 0.5962140639 0.4041481339 3.506976e-01 #>  [603,] 0.940807303 0.7016507254 0.5996782627 0.4076229373 3.539858e-01 #>  [604,] 0.941604691 0.7046584424 0.6031325244 0.4111070037 3.572880e-01 #>  [605,] 0.942391996 0.7076484717 0.6065765346 0.4146000071 3.606037e-01 #>  [606,] 0.943169327 0.7106206614 0.6100099830 0.4181016180 3.639328e-01 #>  [607,] 0.943936793 0.7135748647 0.6134325632 0.4216115032 3.672750e-01 #>  [608,] 0.944694502 0.7165109405 0.6168439731 0.4251293266 3.706299e-01 #>  [609,] 0.945442563 0.7194287532 0.6202439149 0.4286547486 3.739974e-01 #>  [610,] 0.946181081 0.7223281725 0.6236320953 0.4321874267 3.773772e-01 #>  [611,] 0.946910165 0.7252090737 0.6270082251 0.4357270154 3.807689e-01 #>  [612,] 0.947629917 0.7280713374 0.6303720199 0.4392731666 3.841723e-01 #>  [613,] 0.948340445 0.7309148496 0.6337232000 0.4428255294 3.875871e-01 #>  [614,] 0.949041851 0.7337395016 0.6370614901 0.4463837502 3.910129e-01 #>  [615,] 0.949734238 0.7365451901 0.6403866200 0.4499474734 3.944495e-01 #>  [616,] 0.950417709 0.7393318171 0.6436983242 0.4535163409 3.978966e-01 #>  [617,] 0.951092365 0.7420992899 0.6469963421 0.4570899925 4.013539e-01 #>  [618,] 0.951758308 0.7448475208 0.6502804181 0.4606680661 4.048210e-01 #>  [619,] 0.952415636 0.7475764277 0.6535503016 0.4642501978 4.082976e-01 #>  [620,] 0.953064449 0.7502859331 0.6568057473 0.4678360220 4.117835e-01 #>  [621,] 0.953704846 0.7529759651 0.6600465147 0.4714251716 4.152782e-01 #>  [622,] 0.954336924 0.7556464564 0.6632723688 0.4750172780 4.187814e-01 #>  [623,] 0.954960780 0.7582973451 0.6664830797 0.4786119717 4.222928e-01 #>  [624,] 0.955576509 0.7609285740 0.6696784227 0.4822088817 4.258122e-01 #>  [625,] 0.956184206 0.7635400909 0.6728581787 0.4858076365 4.293390e-01 #>  [626,] 0.956783967 0.7661318483 0.6760221337 0.4894078635 4.328731e-01 #>  [627,] 0.957375884 0.7687038037 0.6791700792 0.4930091896 4.364140e-01 #>  [628,] 0.957960050 0.7712559191 0.6823018121 0.4966112414 4.399613e-01 #>  [629,] 0.958536556 0.7737881614 0.6854171345 0.5002136449 4.435149e-01 #>  [630,] 0.959105494 0.7763005020 0.6885158545 0.5038160263 4.470742e-01 #>  [631,] 0.959666954 0.7787929168 0.6915977851 0.5074180115 4.506389e-01 #>  [632,] 0.960221025 0.7812653862 0.6946627451 0.5110192268 4.542088e-01 #>  [633,] 0.960767796 0.7837178951 0.6977105587 0.5146192987 4.577833e-01 #>  [634,] 0.961307354 0.7861504327 0.7007410557 0.5182178541 4.613622e-01 #>  [635,] 0.961839787 0.7885629925 0.7037540713 0.5218145206 4.649451e-01 #>  [636,] 0.962365179 0.7909555722 0.7067494462 0.5254089268 4.685316e-01 #>  [637,] 0.962883618 0.7933281736 0.7097270266 0.5290007018 4.721213e-01 #>  [638,] 0.963395186 0.7956808028 0.7126866643 0.5325894762 4.757139e-01 #>  [639,] 0.963899967 0.7980134696 0.7156282165 0.5361748816 4.793091e-01 #>  [640,] 0.964398045 0.8003261880 0.7185515458 0.5397565511 4.829064e-01 #>  [641,] 0.964889501 0.8026189757 0.7214565205 0.5433341192 4.865055e-01 #>  [642,] 0.965374417 0.8048918544 0.7243430140 0.5469072222 4.901059e-01 #>  [643,] 0.965852872 0.8071448492 0.7272109054 0.5504754983 4.937074e-01 #>  [644,] 0.966324947 0.8093779892 0.7300600791 0.5540385875 4.973096e-01 #>  [645,] 0.966790720 0.8115913068 0.7328904248 0.5575961321 5.009120e-01 #>  [646,] 0.967250268 0.8137848382 0.7357018375 0.5611477765 5.045143e-01 #>  [647,] 0.967703670 0.8159586227 0.7384942178 0.5646931676 5.081162e-01 #>  [648,] 0.968151002 0.8181127032 0.7412674712 0.5682319549 5.117172e-01 #>  [649,] 0.968592339 0.8202471258 0.7440215086 0.5717637903 5.153170e-01 #>  [650,] 0.969027755 0.8223619397 0.7467562462 0.5752883289 5.189153e-01 #>  [651,] 0.969457326 0.8244571974 0.7494716051 0.5788052284 5.225115e-01 #>  [652,] 0.969881124 0.8265329545 0.7521675117 0.5823141497 5.261054e-01 #>  [653,] 0.970299222 0.8285892693 0.7548438974 0.5858147569 5.296967e-01 #>  [654,] 0.970711691 0.8306262032 0.7575006987 0.5893067175 5.332848e-01 #>  [655,] 0.971118602 0.8326438206 0.7601378568 0.5927897022 5.368695e-01 #>  [656,] 0.971520026 0.8346421883 0.7627553181 0.5962633854 5.404504e-01 #>  [657,] 0.971916032 0.8366213760 0.7653530337 0.5997274452 5.440272e-01 #>  [658,] 0.972306689 0.8385814560 0.7679309597 0.6031815633 5.475993e-01 #>  [659,] 0.972692064 0.8405225032 0.7704890566 0.6066254255 5.511666e-01 #>  [660,] 0.973072225 0.8424445948 0.7730272899 0.6100587215 5.547287e-01 #>  [661,] 0.973447237 0.8443478104 0.7755456296 0.6134811450 5.582851e-01 #>  [662,] 0.973817168 0.8462322322 0.7780440503 0.6168923939 5.618356e-01 #>  [663,] 0.974182082 0.8480979444 0.7805225311 0.6202921706 5.653797e-01 #>  [664,] 0.974542043 0.8499450333 0.7829810554 0.6236801816 5.689172e-01 #>  [665,] 0.974897114 0.8517735876 0.7854196113 0.6270561380 5.724476e-01 #>  [666,] 0.975247359 0.8535836978 0.7878381908 0.6304197554 5.759707e-01 #>  [667,] 0.975592839 0.8553754566 0.7902367905 0.6337707541 5.794861e-01 #>  [668,] 0.975933617 0.8571489583 0.7926154109 0.6371088591 5.829934e-01 #>  [669,] 0.976269752 0.8589042994 0.7949740569 0.6404337999 5.864924e-01 #>  [670,] 0.976601305 0.8606415778 0.7973127371 0.6437453113 5.899826e-01 #>  [671,] 0.976928335 0.8623608933 0.7996314642 0.6470431328 5.934638e-01 #>  [672,] 0.977250901 0.8640623474 0.8019302550 0.6503270087 5.969357e-01 #>  [673,] 0.977569060 0.8657460431 0.8042091297 0.6535966887 6.003978e-01 #>  [674,] 0.977882871 0.8674120849 0.8064681127 0.6568519273 6.038500e-01 #>  [675,] 0.978192389 0.8690605786 0.8087072317 0.6600924844 6.072918e-01 #>  [676,] 0.978497671 0.8706916317 0.8109265182 0.6633181247 6.107230e-01 #>  [677,] 0.978798772 0.8723053529 0.8131260071 0.6665286187 6.141433e-01 #>  [678,] 0.979095747 0.8739018519 0.8153057370 0.6697237417 6.175524e-01 #>  [679,] 0.979388649 0.8754812400 0.8174657496 0.6729032745 6.209499e-01 #>  [680,] 0.979677533 0.8770436295 0.8196060901 0.6760670033 6.243356e-01 #>  [681,] 0.979962451 0.8785891337 0.8217268067 0.6792147197 6.277092e-01 #>  [682,] 0.980243454 0.8801178669 0.8238279510 0.6823462206 6.310704e-01 #>  [683,] 0.980520595 0.8816299446 0.8259095776 0.6854613084 6.344189e-01 #>  [684,] 0.980793925 0.8831254831 0.8279717440 0.6885597909 6.377545e-01 #>  [685,] 0.981063493 0.8846045994 0.8300145108 0.6916414815 6.410768e-01 #>  [686,] 0.981329350 0.8860674117 0.8320379414 0.6947061989 6.443857e-01 #>  [687,] 0.981591545 0.8875140385 0.8340421018 0.6977537676 6.476808e-01 #>  [688,] 0.981850125 0.8889445993 0.8360270609 0.7007840171 6.509620e-01 #>  [689,] 0.982105140 0.8903592143 0.8379928904 0.7037967830 6.542289e-01 #>  [690,] 0.982356636 0.8917580042 0.8399396641 0.7067919059 6.574813e-01 #>  [691,] 0.982604660 0.8931410901 0.8418674587 0.7097692323 6.607190e-01 #>  [692,] 0.982849258 0.8945085940 0.8437763532 0.7127286138 6.639417e-01 #>  [693,] 0.983090476 0.8958606381 0.8456664288 0.7156699079 6.671492e-01 #>  [694,] 0.983328359 0.8971973451 0.8475377691 0.7185929772 6.703413e-01 #>  [695,] 0.983562951 0.8985188380 0.8493904600 0.7214976899 6.735178e-01 #>  [696,] 0.983794297 0.8998252402 0.8512245894 0.7243839198 6.766785e-01 #>  [697,] 0.984022439 0.9011166755 0.8530402472 0.7272515459 6.798231e-01 #>  [698,] 0.984247421 0.9023932678 0.8548375254 0.7301004526 6.829514e-01 #>  [699,] 0.984469286 0.9036551413 0.8566165179 0.7329305298 6.860633e-01 #>  [700,] 0.984688074 0.9049024203 0.8583773205 0.7357416727 6.891585e-01 #>  [701,] 0.984903827 0.9061352293 0.8601200307 0.7385337817 6.922369e-01 #>  [702,] 0.985116586 0.9073536929 0.8618447479 0.7413067625 6.952983e-01 #>  [703,] 0.985326391 0.9085579357 0.8635515729 0.7440605261 6.983426e-01 #>  [704,] 0.985533282 0.9097480823 0.8652406083 0.7467949887 7.013694e-01 #>  [705,] 0.985737298 0.9109242576 0.8669119581 0.7495100715 7.043788e-01 #>  [706,] 0.985938478 0.9120865859 0.8685657278 0.7522057010 7.073705e-01 #>  [707,] 0.986136860 0.9132351920 0.8702020244 0.7548818087 7.103443e-01 #>  [708,] 0.986332482 0.9143702002 0.8718209562 0.7575383311 7.133002e-01 #>  [709,] 0.986525382 0.9154917347 0.8734226326 0.7601752095 7.162380e-01 #>  [710,] 0.986715596 0.9165999199 0.8750071645 0.7627923904 7.191575e-01 #>  [711,] 0.986903160 0.9176948795 0.8765746638 0.7653898250 7.220587e-01 #>  [712,] 0.987088110 0.9187767372 0.8781252435 0.7679674693 7.249413e-01 #>  [713,] 0.987270483 0.9198456166 0.8796590177 0.7705252840 7.278053e-01 #>  [714,] 0.987450312 0.9209016407 0.8811761015 0.7730632347 7.306506e-01 #>  [715,] 0.987627633 0.9219449325 0.8826766110 0.7755812914 7.334770e-01 #>  [716,] 0.987802479 0.9229756144 0.8841606629 0.7780794287 7.362844e-01 #>  [717,] 0.987974884 0.9239938086 0.8856283751 0.7805576258 7.390728e-01 #>  [718,] 0.988144882 0.9249996369 0.8870798661 0.7830158663 7.418421e-01 #>  [719,] 0.988312505 0.9259932206 0.8885152550 0.7854541382 7.445921e-01 #>  [720,] 0.988477786 0.9269746808 0.8899346618 0.7878724337 7.473228e-01 #>  [721,] 0.988640756 0.9279441380 0.8913382070 0.7902707493 7.500342e-01 #>  [722,] 0.988801447 0.9289017121 0.8927260118 0.7926490857 7.527260e-01 #>  [723,] 0.988959890 0.9298475227 0.8940981977 0.7950074477 7.553983e-01 #>  [724,] 0.989116116 0.9307816889 0.8954548869 0.7973458441 7.580510e-01 #>  [725,] 0.989270156 0.9317043293 0.8967962020 0.7996642877 7.606841e-01 #>  [726,] 0.989422039 0.9326155616 0.8981222660 0.8019627951 7.632975e-01 #>  [727,] 0.989571794 0.9335155035 0.8994332020 0.8042413869 7.658911e-01 #>  [728,] 0.989719451 0.9344042717 0.9007291338 0.8065000872 7.684649e-01 #>  [729,] 0.989865039 0.9352819825 0.9020101853 0.8087389240 7.710188e-01 #>  [730,] 0.990008586 0.9361487516 0.9032764804 0.8109579288 7.735529e-01 #>  [731,] 0.990150121 0.9370046938 0.9045281437 0.8131571365 7.760671e-01 #>  [732,] 0.990289670 0.9378499238 0.9057652994 0.8153365858 7.785614e-01 #>  [733,] 0.990427261 0.9386845550 0.9069880721 0.8174963184 7.810357e-01 #>  [734,] 0.990562920 0.9395087007 0.9081965865 0.8196363795 7.834901e-01 #>  [735,] 0.990696676 0.9403224733 0.9093909672 0.8217568175 7.859245e-01 #>  [736,] 0.990828553 0.9411259844 0.9105713389 0.8238576839 7.883389e-01 #>  [737,] 0.990958578 0.9419193452 0.9117378262 0.8259390334 7.907334e-01 #>  [738,] 0.991086776 0.9427026658 0.9128905537 0.8280009235 7.931078e-01 #>  [739,] 0.991213173 0.9434760559 0.9140296458 0.8300434150 7.954623e-01 #>  [740,] 0.991337793 0.9442396244 0.9151552269 0.8320665710 7.977968e-01 #>  [741,] 0.991460660 0.9449934794 0.9162674212 0.8340704579 8.001114e-01 #>  [742,] 0.991581800 0.9457377283 0.9173663526 0.8360551446 8.024061e-01 #>  [743,] 0.991701235 0.9464724777 0.9184521450 0.8380207026 8.046808e-01 #>  [744,] 0.991818990 0.9471978336 0.9195249217 0.8399672060 8.069357e-01 #>  [745,] 0.991935088 0.9479139011 0.9205848062 0.8418947313 8.091706e-01 #>  [746,] 0.992049551 0.9486207845 0.9216319213 0.8438033576 8.113858e-01 #>  [747,] 0.992162403 0.9493185874 0.9226663897 0.8456931663 8.135812e-01 #>  [748,] 0.992273665 0.9500074126 0.9236883336 0.8475642409 8.157568e-01 #>  [749,] 0.992383360 0.9506873621 0.9246978750 0.8494166672 8.179127e-01 #>  [750,] 0.992491509 0.9513585371 0.9256951353 0.8512505333 8.200490e-01 #>  [751,] 0.992598134 0.9520210380 0.9266802356 0.8530659291 8.221656e-01 #>  [752,] 0.992703256 0.9526749645 0.9276532966 0.8548629467 8.242627e-01 #>  [753,] 0.992806896 0.9533204153 0.9286144385 0.8566416799 8.263403e-01 #>  [754,] 0.992909075 0.9539574885 0.9295637809 0.8584022246 8.283984e-01 #>  [755,] 0.993009812 0.9545862812 0.9305014431 0.8601446783 8.304371e-01 #>  [756,] 0.993109128 0.9552068899 0.9314275437 0.8618691404 8.324565e-01 #>  [757,] 0.993207042 0.9558194100 0.9323422009 0.8635757117 8.344567e-01 #>  [758,] 0.993303575 0.9564239364 0.9332455323 0.8652644949 8.364377e-01 #>  [759,] 0.993398745 0.9570205630 0.9341376549 0.8669355940 8.383995e-01 #>  [760,] 0.993492571 0.9576093828 0.9350186851 0.8685891146 8.403424e-01 #>  [761,] 0.993585073 0.9581904882 0.9358887387 0.8702251635 8.422662e-01 #>  [762,] 0.993676267 0.9587639706 0.9367479310 0.8718438492 8.441712e-01 #>  [763,] 0.993766174 0.9593299208 0.9375963766 0.8734452811 8.460573e-01 #>  [764,] 0.993854810 0.9598884284 0.9384341893 0.8750295700 8.479248e-01 #>  [765,] 0.993942194 0.9604395825 0.9392614825 0.8765968279 8.497736e-01 #>  [766,] 0.994028342 0.9609834712 0.9400783687 0.8781471679 8.516039e-01 #>  [767,] 0.994113273 0.9615201821 0.9408849598 0.8796807040 8.534157e-01 #>  [768,] 0.994197002 0.9620498015 0.9416813672 0.8811975514 8.552092e-01 #>  [769,] 0.994279548 0.9625724151 0.9424677014 0.8826978260 8.569844e-01 #>  [770,] 0.994360926 0.9630881080 0.9432440720 0.8841816448 8.587414e-01 #>  [771,] 0.994441153 0.9635969642 0.9440105884 0.8856491255 8.604804e-01 #>  [772,] 0.994520245 0.9640990669 0.9447673587 0.8871003867 8.622014e-01 #>  [773,] 0.994598218 0.9645944987 0.9455144907 0.8885355476 8.639045e-01 #>  [774,] 0.994675087 0.9650833411 0.9462520911 0.8899547280 8.655898e-01 #>  [775,] 0.994750868 0.9655656750 0.9469802662 0.8913580486 8.672575e-01 #>  [776,] 0.994825576 0.9660415805 0.9476991213 0.8927456304 8.689076e-01 #>  [777,] 0.994899226 0.9665111368 0.9484087609 0.8941175952 8.705403e-01 #>  [778,] 0.994971833 0.9669744223 0.9491092889 0.8954740650 8.721556e-01 #>  [779,] 0.995043412 0.9674315147 0.9498008083 0.8968151624 8.737537e-01 #>  [780,] 0.995113977 0.9678824907 0.9504834214 0.8981410103 8.753347e-01 #>  [781,] 0.995183542 0.9683274266 0.9511572295 0.8994517322 8.768987e-01 #>  [782,] 0.995252122 0.9687663975 0.9518223334 0.9007474516 8.784458e-01 #>  [783,] 0.995319729 0.9691994779 0.9524788329 0.9020282923 8.799761e-01 #>  [784,] 0.995386379 0.9696267416 0.9531268271 0.9032943786 8.814897e-01 #>  [785,] 0.995452083 0.9700482615 0.9537664142 0.9045458347 8.829868e-01 #>  [786,] 0.995516856 0.9704641097 0.9543976917 0.9057827850 8.844674e-01 #>  [787,] 0.995580711 0.9708743576 0.9550207561 0.9070053542 8.859317e-01 #>  [788,] 0.995643660 0.9712790759 0.9556357033 0.9082136667 8.873799e-01 #>  [789,] 0.995705716 0.9716783345 0.9562426283 0.9094078474 8.888119e-01 #>  [790,] 0.995766893 0.9720722025 0.9568416252 0.9105880208 8.902280e-01 #>  [791,] 0.995827201 0.9724607481 0.9574327875 0.9117543116 8.916283e-01 #>  [792,] 0.995886653 0.9728440392 0.9580162076 0.9129068444 8.930128e-01 #>  [793,] 0.995945262 0.9732221425 0.9585919772 0.9140457435 8.943818e-01 #>  [794,] 0.996003040 0.9735951242 0.9591601873 0.9151711334 8.957352e-01 #>  [795,] 0.996059997 0.9739630497 0.9597209280 0.9162831383 8.970734e-01 #>  [796,] 0.996116146 0.9743259838 0.9602742884 0.9173818820 8.983963e-01 #>  [797,] 0.996171497 0.9746839903 0.9608203570 0.9184674884 8.997041e-01 #>  [798,] 0.996226063 0.9750371326 0.9613592213 0.9195400810 9.009969e-01 #>  [799,] 0.996279854 0.9753854732 0.9618909683 0.9205997831 9.022749e-01 #>  [800,] 0.996332881 0.9757290739 0.9624156839 0.9216467175 9.035381e-01 #>  [801,] 0.996385155 0.9760679959 0.9629334531 0.9226810070 9.047868e-01 #>  [802,] 0.996436686 0.9764022996 0.9634443604 0.9237027737 9.060209e-01 #>  [803,] 0.996487486 0.9767320447 0.9639484892 0.9247121396 9.072407e-01 #>  [804,] 0.996537564 0.9770572904 0.9644459223 0.9257092262 9.084463e-01 #>  [805,] 0.996586930 0.9773780951 0.9649367415 0.9266941545 9.096377e-01 #>  [806,] 0.996635595 0.9776945163 0.9654210280 0.9276670452 9.108152e-01 #>  [807,] 0.996683568 0.9780066113 0.9658988620 0.9286280184 9.119788e-01 #>  [808,] 0.996730859 0.9783144363 0.9663703230 0.9295771940 9.131287e-01 #>  [809,] 0.996777479 0.9786180471 0.9668354897 0.9305146909 9.142650e-01 #>  [810,] 0.996823435 0.9789174988 0.9672944399 0.9314406280 9.153877e-01 #>  [811,] 0.996868738 0.9792128458 0.9677472508 0.9323551234 9.164972e-01 #>  [812,] 0.996913397 0.9795041419 0.9681939986 0.9332582946 9.175934e-01 #>  [813,] 0.996957422 0.9797914402 0.9686347589 0.9341502587 9.186764e-01 #>  [814,] 0.997000820 0.9800747933 0.9690696063 0.9350311320 9.197465e-01 #>  [815,] 0.997043601 0.9803542530 0.9694986149 0.9359010304 9.208037e-01 #>  [816,] 0.997085773 0.9806298706 0.9699218577 0.9367600691 9.218482e-01 #>  [817,] 0.997127346 0.9809016968 0.9703394073 0.9376083627 9.228801e-01 #>  [818,] 0.997168327 0.9811697816 0.9707513351 0.9384460251 9.238994e-01 #>  [819,] 0.997208725 0.9814341746 0.9711577121 0.9392731695 9.249064e-01 #>  [820,] 0.997248549 0.9816949245 0.9715586084 0.9400899085 9.259011e-01 #>  [821,] 0.997287806 0.9819520796 0.9719540933 0.9408963541 9.268837e-01 #>  [822,] 0.997326504 0.9822056875 0.9723442354 0.9416926175 9.278543e-01 #>  [823,] 0.997364651 0.9824557955 0.9727291026 0.9424788092 9.288129e-01 #>  [824,] 0.997402256 0.9827024500 0.9731087620 0.9432550390 9.297598e-01 #>  [825,] 0.997439325 0.9829456970 0.9734832799 0.9440214160 9.306951e-01 #>  [826,] 0.997475867 0.9831855818 0.9738527220 0.9447780486 9.316188e-01 #>  [827,] 0.997511889 0.9834221494 0.9742171532 0.9455250443 9.325311e-01 #>  [828,] 0.997547398 0.9836554439 0.9745766377 0.9462625100 9.334321e-01 #>  [829,] 0.997582401 0.9838855091 0.9749312390 0.9469905519 9.343219e-01 #>  [830,] 0.997616906 0.9841123883 0.9752810198 0.9477092752 9.352006e-01 #>  [831,] 0.997650920 0.9843361240 0.9756260422 0.9484187845 9.360684e-01 #>  [832,] 0.997684449 0.9845567585 0.9759663675 0.9491191837 9.369254e-01 #>  [833,] 0.997717501 0.9847743332 0.9763020563 0.9498105758 9.377716e-01 #>  [834,] 0.997750082 0.9849888894 0.9766331687 0.9504930629 9.386072e-01 #>  [835,] 0.997782199 0.9852004675 0.9769597639 0.9511667466 9.394323e-01 #>  [836,] 0.997813859 0.9854091076 0.9772819006 0.9518317275 9.402470e-01 #>  [837,] 0.997845067 0.9856148494 0.9775996365 0.9524881054 9.410515e-01 #>  [838,] 0.997875831 0.9858177318 0.9779130290 0.9531359793 9.418458e-01 #>  [839,] 0.997906157 0.9860177934 0.9782221347 0.9537754476 9.426301e-01 #>  [840,] 0.997936051 0.9862150723 0.9785270094 0.9544066076 9.434044e-01 #>  [841,] 0.997965519 0.9864096061 0.9788277085 0.9550295560 9.441689e-01 #>  [842,] 0.997994567 0.9866014319 0.9791242866 0.9556443885 9.449236e-01 #>  [843,] 0.998023201 0.9867905864 0.9794167975 0.9562512001 9.456687e-01 #>  [844,] 0.998051426 0.9869771058 0.9797052948 0.9568500850 9.464044e-01 #>  [845,] 0.998079250 0.9871610258 0.9799898311 0.9574411365 9.471306e-01 #>  [846,] 0.998106677 0.9873423815 0.9802704584 0.9580244472 9.478475e-01 #>  [847,] 0.998133714 0.9875212080 0.9805472283 0.9586001087 9.485553e-01 #>  [848,] 0.998160365 0.9876975395 0.9808201916 0.9591682120 9.492539e-01 #>  [849,] 0.998186636 0.9878714099 0.9810893985 0.9597288471 9.499436e-01 #>  [850,] 0.998212532 0.9880428528 0.9813548986 0.9602821032 9.506243e-01 #>  [851,] 0.998238059 0.9882119011 0.9816167410 0.9608280687 9.512963e-01 #>  [852,] 0.998263223 0.9883785876 0.9818749742 0.9613668313 9.519596e-01 #>  [853,] 0.998288028 0.9885429445 0.9821296459 0.9618984777 9.526144e-01 #>  [854,] 0.998312479 0.9887050034 0.9823808036 0.9624230939 9.532606e-01 #>  [855,] 0.998336581 0.9888647959 0.9826284937 0.9629407650 9.538984e-01 #>  [856,] 0.998360340 0.9890223529 0.9828727626 0.9634515753 9.545280e-01 #>  [857,] 0.998383759 0.9891777049 0.9831136557 0.9639556083 9.551494e-01 #>  [858,] 0.998406845 0.9893308821 0.9833512180 0.9644529468 9.557626e-01 #>  [859,] 0.998429602 0.9894819144 0.9835854941 0.9649436726 9.563679e-01 #>  [860,] 0.998452034 0.9896308310 0.9838165277 0.9654278668 9.569653e-01 #>  [861,] 0.998474146 0.9897776611 0.9840443623 0.9659056096 9.575548e-01 #>  [862,] 0.998495943 0.9899224331 0.9842690407 0.9663769806 9.581366e-01 #>  [863,] 0.998517429 0.9900651755 0.9844906052 0.9668420583 9.587108e-01 #>  [864,] 0.998538608 0.9902059159 0.9847090975 0.9673009207 9.592775e-01 #>  [865,] 0.998559486 0.9903446821 0.9849245589 0.9677536449 9.598367e-01 #>  [866,] 0.998580065 0.9904815010 0.9851370300 0.9682003070 9.603885e-01 #>  [867,] 0.998600351 0.9906163996 0.9853465512 0.9686409827 9.609331e-01 #>  [868,] 0.998620347 0.9907494042 0.9855531621 0.9690757466 9.614704e-01 #>  [869,] 0.998640059 0.9908805409 0.9857569019 0.9695046727 9.620007e-01 #>  [870,] 0.998659488 0.9910098355 0.9859578094 0.9699278341 9.625240e-01 #>  [871,] 0.998678641 0.9911373134 0.9861559228 0.9703453032 9.630403e-01 #>  [872,] 0.998697521 0.9912629996 0.9863512797 0.9707571516 9.635498e-01 #>  [873,] 0.998716131 0.9913869188 0.9865439176 0.9711634502 9.640525e-01 #>  [874,] 0.998734475 0.9915090956 0.9867338732 0.9715642691 9.645486e-01 #>  [875,] 0.998752558 0.9916295539 0.9869211827 0.9719596775 9.650380e-01 #>  [876,] 0.998770382 0.9917483175 0.9871058821 0.9723497442 9.655210e-01 #>  [877,] 0.998787952 0.9918654099 0.9872880068 0.9727345369 9.659975e-01 #>  [878,] 0.998805272 0.9919808541 0.9874675917 0.9731141227 9.664676e-01 #>  [879,] 0.998822344 0.9920946730 0.9876446713 0.9734885680 9.669315e-01 #>  [880,] 0.998839173 0.9922068892 0.9878192797 0.9738579384 9.673892e-01 #>  [881,] 0.998855761 0.9923175248 0.9879914505 0.9742222988 9.678407e-01 #>  [882,] 0.998872113 0.9924266017 0.9881612169 0.9745817135 9.682862e-01 #>  [883,] 0.998888231 0.9925341416 0.9883286116 0.9749362458 9.687257e-01 #>  [884,] 0.998904119 0.9926401658 0.9884936670 0.9752859585 9.691594e-01 #>  [885,] 0.998919780 0.9927446953 0.9886564150 0.9756309136 9.695872e-01 #>  [886,] 0.998935218 0.9928477509 0.9888168871 0.9759711726 9.700092e-01 #>  [887,] 0.998950435 0.9929493531 0.9889751144 0.9763067960 9.704256e-01 #>  [888,] 0.998965435 0.9930495220 0.9891311276 0.9766378437 9.708363e-01 #>  [889,] 0.998980221 0.9931482777 0.9892849569 0.9769643751 9.712416e-01 #>  [890,] 0.998994796 0.9932456398 0.9894366323 0.9772864488 9.716413e-01 #>  [891,] 0.999009163 0.9933416276 0.9895861834 0.9776041226 9.720357e-01 #>  [892,] 0.999023324 0.9934362603 0.9897336391 0.9779174537 9.724247e-01 #>  [893,] 0.999037284 0.9935295569 0.9898790282 0.9782264989 9.728085e-01 #>  [894,] 0.999051044 0.9936215358 0.9900223791 0.9785313138 9.731871e-01 #>  [895,] 0.999064607 0.9937122155 0.9901637199 0.9788319540 9.735606e-01 #>  [896,] 0.999077977 0.9938016141 0.9903030780 0.9791284738 9.739290e-01 #>  [897,] 0.999091156 0.9938897494 0.9904404808 0.9794209274 9.742924e-01 #>  [898,] 0.999104147 0.9939766392 0.9905759552 0.9797093679 9.746508e-01 #>  [899,] 0.999116952 0.9940623007 0.9907095277 0.9799938483 9.750044e-01 #>  [900,] 0.999129574 0.9941467512 0.9908412244 0.9802744204 9.753532e-01 #>  [901,] 0.999142016 0.9942300075 0.9909710714 0.9805511358 9.756972e-01 #>  [902,] 0.999154281 0.9943120863 0.9910990940 0.9808240453 9.760366e-01 #>  [903,] 0.999166370 0.9943930042 0.9912253174 0.9810931992 9.763713e-01 #>  [904,] 0.999178286 0.9944727773 0.9913497665 0.9813586470 9.767015e-01 #>  [905,] 0.999190033 0.9945514216 0.9914724657 0.9816204377 9.770272e-01 #>  [906,] 0.999201611 0.9946289530 0.9915934392 0.9818786199 9.773484e-01 #>  [907,] 0.999213024 0.9947053871 0.9917127110 0.9821332414 9.776652e-01 #>  [908,] 0.999224275 0.9947807391 0.9918303044 0.9823843494 9.779777e-01 #>  [909,] 0.999235364 0.9948550242 0.9919462428 0.9826319906 9.782859e-01 #>  [910,] 0.999246295 0.9949282575 0.9920605491 0.9828762111 9.785899e-01 #>  [911,] 0.999257070 0.9950004536 0.9921732458 0.9831170565 9.788898e-01 #>  [912,] 0.999267691 0.9950716271 0.9922843553 0.9833545719 9.791855e-01 #>  [913,] 0.999278160 0.9951417923 0.9923938996 0.9835888015 9.794772e-01 #>  [914,] 0.999288480 0.9952109634 0.9925019003 0.9838197894 9.797648e-01 #>  [915,] 0.999298652 0.9952791543 0.9926083789 0.9840475788 9.800485e-01 #>  [916,] 0.999308679 0.9953463788 0.9927133566 0.9842722126 9.803284e-01 #>  [917,] 0.999318562 0.9954126504 0.9928168541 0.9844937331 9.806043e-01 #>  [918,] 0.999328305 0.9954779825 0.9929188921 0.9847121820 9.808765e-01 #>  [919,] 0.999337908 0.9955423883 0.9930194908 0.9849276006 9.811449e-01 #>  [920,] 0.999347374 0.9956058809 0.9931186702 0.9851400295 9.814097e-01 #>  [921,] 0.999356705 0.9956684731 0.9932164501 0.9853495090 9.816708e-01 #>  [922,] 0.999365902 0.9957301775 0.9933128500 0.9855560788 9.819283e-01 #>  [923,] 0.999374968 0.9957910066 0.9934078890 0.9857597781 9.821822e-01 #>  [924,] 0.999383905 0.9958509727 0.9935015861 0.9859606456 9.824326e-01 #>  [925,] 0.999392714 0.9959100880 0.9935939601 0.9861587195 9.826796e-01 #>  [926,] 0.999401397 0.9959683644 0.9936850293 0.9863540376 9.829232e-01 #>  [927,] 0.999409956 0.9960258137 0.9937748120 0.9865466371 9.831634e-01 #>  [928,] 0.999418392 0.9960824477 0.9938633261 0.9867365548 9.834002e-01 #>  [929,] 0.999426708 0.9961382777 0.9939505893 0.9869238270 9.836338e-01 #>  [930,] 0.999434905 0.9961933151 0.9940366191 0.9871084895 9.838642e-01 #>  [931,] 0.999442985 0.9962475711 0.9941214327 0.9872905778 9.840914e-01 #>  [932,] 0.999450950 0.9963010566 0.9942050470 0.9874701269 9.843154e-01 #>  [933,] 0.999458801 0.9963537826 0.9942874789 0.9876471711 9.845363e-01 #>  [934,] 0.999466539 0.9964057597 0.9943687448 0.9878217446 9.847542e-01 #>  [935,] 0.999474167 0.9964569985 0.9944488612 0.9879938810 9.849690e-01 #>  [936,] 0.999481686 0.9965075094 0.9945278439 0.9881636134 9.851809e-01 #>  [937,] 0.999489097 0.9965573027 0.9946057090 0.9883309747 9.853898e-01 #>  [938,] 0.999496403 0.9966063885 0.9946824721 0.9884959970 9.855958e-01 #>  [939,] 0.999503604 0.9966547768 0.9947581485 0.9886587124 9.857989e-01 #>  [940,] 0.999510702 0.9967024774 0.9948327535 0.9888191524 9.859993e-01 #>  [941,] 0.999517699 0.9967495000 0.9949063021 0.9889773480 9.861968e-01 #>  [942,] 0.999524596 0.9967958543 0.9949788092 0.9891333299 9.863916e-01 #>  [943,] 0.999531394 0.9968415496 0.9950502893 0.9892871284 9.865837e-01 #>  [944,] 0.999538095 0.9968865953 0.9951207568 0.9894387735 9.867731e-01 #>  [945,] 0.999544700 0.9969310005 0.9951902259 0.9895882945 9.869598e-01 #>  [946,] 0.999551211 0.9969747743 0.9952587107 0.9897357206 9.871440e-01 #>  [947,] 0.999557629 0.9970179256 0.9953262249 0.9898810806 9.873256e-01 #>  [948,] 0.999563955 0.9970604633 0.9953927822 0.9900244027 9.875046e-01 #>  [949,] 0.999570190 0.9971023959 0.9954583960 0.9901657151 9.876812e-01 #>  [950,] 0.999576337 0.9971437320 0.9955230796 0.9903050452 9.878553e-01 #>  [951,] 0.999582396 0.9971844802 0.9955868460 0.9904424204 9.880270e-01 #>  [952,] 0.999588368 0.9972246486 0.9956497081 0.9905778676 9.881962e-01 #>  [953,] 0.999594254 0.9972642455 0.9957116786 0.9907114132 9.883631e-01 #>  [954,] 0.999600057 0.9973032791 0.9957727701 0.9908430835 9.885277e-01 #>  [955,] 0.999605776 0.9973417571 0.9958329950 0.9909729043 9.886900e-01 #>  [956,] 0.999611414 0.9973796876 0.9958923653 0.9911009011 9.888500e-01 #>  [957,] 0.999616971 0.9974170783 0.9959508933 0.9912270992 9.890078e-01 #>  [958,] 0.999622449 0.9974539368 0.9960085906 0.9913515232 9.891633e-01 #>  [959,] 0.999627848 0.9974902706 0.9960654690 0.9914741977 9.893167e-01 #>  [960,] 0.999633171 0.9975260872 0.9961215400 0.9915951469 9.894679e-01 #>  [961,] 0.999638417 0.9975613939 0.9961768151 0.9917143946 9.896170e-01 #>  [962,] 0.999643588 0.9975961980 0.9962313053 0.9918319644 9.897641e-01 #>  [963,] 0.999648685 0.9976305065 0.9962850218 0.9919478794 9.899090e-01 #>  [964,] 0.999653709 0.9976643265 0.9963379755 0.9920621626 9.900520e-01 #>  [965,] 0.999658662 0.9976976648 0.9963901772 0.9921748366 9.901929e-01 #>  [966,] 0.999663544 0.9977305284 0.9964416373 0.9922859237 9.903318e-01 #>  [967,] 0.999668356 0.9977629240 0.9964923665 0.9923954459 9.904688e-01 #>  [968,] 0.999673099 0.9977948581 0.9965423749 0.9925034248 9.906039e-01 #>  [969,] 0.999677774 0.9978263374 0.9965916728 0.9926098820 9.907371e-01 #>  [970,] 0.999682382 0.9978573683 0.9966402702 0.9927148384 9.908684e-01 #>  [971,] 0.999686925 0.9978879571 0.9966881770 0.9928183151 9.909979e-01 #>  [972,] 0.999691403 0.9979181101 0.9967354029 0.9929203324 9.911255e-01 #>  [973,] 0.999695816 0.9979478335 0.9967819575 0.9930209108 9.912514e-01 #>  [974,] 0.999700167 0.9979771335 0.9968278504 0.9931200702 9.913754e-01 #>  [975,] 0.999704455 0.9980060159 0.9968730909 0.9932178303 9.914978e-01 #>  [976,] 0.999708682 0.9980344868 0.9969176881 0.9933142107 9.916184e-01 #>  [977,] 0.999712849 0.9980625519 0.9969616512 0.9934092305 9.917373e-01 #>  [978,] 0.999716956 0.9980902170 0.9970049891 0.9935029087 9.918546e-01 #>  [979,] 0.999721004 0.9981174879 0.9970477107 0.9935952640 9.919702e-01 #>  [980,] 0.999724994 0.9981443701 0.9970898247 0.9936863148 9.920841e-01 #>  [981,] 0.999728927 0.9981708691 0.9971313397 0.9937760794 9.921965e-01 #>  [982,] 0.999732804 0.9981969904 0.9971722642 0.9938645756 9.923073e-01 #>  [983,] 0.999736626 0.9982227393 0.9972126064 0.9939518211 9.924165e-01 #>  [984,] 0.999740393 0.9982481211 0.9972523747 0.9940378335 9.925242e-01 #>  [985,] 0.999744106 0.9982731411 0.9972915771 0.9941226299 9.926303e-01 #>  [986,] 0.999747766 0.9982978043 0.9973302217 0.9942062273 9.927350e-01 #>  [987,] 0.999751374 0.9983221159 0.9973683163 0.9942886425 9.928382e-01 #>  [988,] 0.999754930 0.9983460809 0.9974058688 0.9943698919 9.929399e-01 #>  [989,] 0.999758435 0.9983697041 0.9974428869 0.9944499920 9.930402e-01 #>  [990,] 0.999761890 0.9983929904 0.9974793780 0.9945289588 9.931391e-01 #>  [991,] 0.999765296 0.9984159447 0.9975153497 0.9946068081 9.932366e-01 #>  [992,] 0.999768653 0.9984385716 0.9975508092 0.9946835556 9.933327e-01 #>  [993,] 0.999771962 0.9984608758 0.9975857640 0.9947592167 9.934275e-01 #>  [994,] 0.999775224 0.9984828618 0.9976202211 0.9948338066 9.935209e-01 #>  [995,] 0.999778439 0.9985045343 0.9976541875 0.9949073403 9.936130e-01 #>  [996,] 0.999781608 0.9985258977 0.9976876703 0.9949798327 9.937038e-01 #>  [997,] 0.999784732 0.9985469563 0.9977206762 0.9950512983 9.937933e-01 #>  [998,] 0.999787811 0.9985677144 0.9977532121 0.9951217515 9.938816e-01 #>  [999,] 0.999790846 0.9985881765 0.9977852845 0.9951912065 9.939686e-01 #> [1000,] 0.999793837 0.9986083466 0.9978169002 0.9952596774 9.940544e-01 #> [1001,] 0.999796786 0.9986282290 0.9978480655 0.9953271779 9.941389e-01 #> [1002,] 0.999799693 0.9986478277 0.9978787868 0.9953937217 9.942223e-01 #> [1003,] 0.999802558 0.9986671468 0.9979090705 0.9954593222 9.943045e-01 #> [1004,] 0.999805382 0.9986861902 0.9979389227 0.9955239926 9.943855e-01 #> [1005,] 0.999808166 0.9987049619 0.9979683496 0.9955877460 9.944654e-01 #> [1006,] 0.999810910 0.9987234657 0.9979973572 0.9956505954 9.945441e-01 #> [1007,] 0.999813615 0.9987417054 0.9980259515 0.9957125533 9.946218e-01 #> [1008,] 0.999816281 0.9987596849 0.9980541382 0.9957736324 9.946983e-01 #> [1009,] 0.999818909 0.9987774078 0.9980819233 0.9958338451 9.947738e-01 #> [1010,] 0.999821499 0.9987948777 0.9981093124 0.9958932034 9.948481e-01 #> [1011,] 0.999824052 0.9988120983 0.9981363111 0.9959517194 9.949215e-01 #> [1012,] 0.999826569 0.9988290731 0.9981629250 0.9960094050 9.949938e-01 #> [1013,] 0.999829050 0.9988458056 0.9981891595 0.9960662718 9.950650e-01 #> [1014,] 0.999831495 0.9988622993 0.9982150200 0.9961223315 9.951353e-01 #> [1015,] 0.999833905 0.9988785576 0.9982405119 0.9961775953 9.952046e-01 #> [1016,] 0.999836281 0.9988945838 0.9982656403 0.9962320745 9.952728e-01 #> [1017,] 0.999838623 0.9989103812 0.9982904105 0.9962857800 9.953402e-01 #> [1018,] 0.999840931 0.9989259531 0.9983148276 0.9963387230 9.954065e-01 #> [1019,] 0.999843207 0.9989413026 0.9983388964 0.9963909140 9.954719e-01 #> [1020,] 0.999845450 0.9989564331 0.9983626221 0.9964423637 9.955364e-01 #> [1021,] 0.999847660 0.9989713475 0.9983860094 0.9964930825 9.956000e-01 #> [1022,] 0.999849839 0.9989860490 0.9984090632 0.9965430808 9.956627e-01 #> [1023,] 0.999851987 0.9990005406 0.9984317883 0.9965923686 9.957245e-01 #> [1024,] 0.999854105 0.9990148253 0.9984541892 0.9966409561 9.957854e-01 #> [1025,] 0.999856192 0.9990289060 0.9984762707 0.9966888532 9.958454e-01 #> [1026,] 0.999858249 0.9990427856 0.9984980371 0.9967360695 9.959046e-01 #> [1027,] 0.999860276 0.9990564671 0.9985194932 0.9967826146 9.959630e-01 #> [1028,] 0.999862275 0.9990699532 0.9985406431 0.9968284982 9.960205e-01 #> [1029,] 0.999864245 0.9990832467 0.9985614914 0.9968737294 9.960772e-01 #> [1030,] 0.999866187 0.9990963504 0.9985820422 0.9969183176 9.961331e-01 #> [1031,] 0.999868101 0.9991092669 0.9986022999 0.9969622717 9.961882e-01 #> [1032,] 0.999869988 0.9991219990 0.9986222685 0.9970056008 9.962425e-01 #> [1033,] 0.999871848 0.9991345493 0.9986419522 0.9970483138 9.962961e-01 #> [1034,] 0.999873681 0.9991469203 0.9986613551 0.9970904192 9.963489e-01 #> [1035,] 0.999875488 0.9991591146 0.9986804812 0.9971319257 9.964009e-01 #> [1036,] 0.999877269 0.9991711347 0.9986993343 0.9971728418 9.964523e-01 #> [1037,] 0.999879025 0.9991829832 0.9987179184 0.9972131758 9.965028e-01 #> [1038,] 0.999880755 0.9991946624 0.9987362374 0.9972529360 9.965527e-01 #> [1039,] 0.999882461 0.9992061749 0.9987542949 0.9972921304 9.966018e-01 #> [1040,] 0.999884142 0.9992175228 0.9987720946 0.9973307671 9.966503e-01 #> [1041,] 0.999885800 0.9992287087 0.9987896404 0.9973688540 9.966981e-01 #> [1042,] 0.999887433 0.9992397348 0.9988069358 0.9974063989 9.967451e-01 #> [1043,] 0.999889044 0.9992506034 0.9988239843 0.9974434094 9.967916e-01 #> [1044,] 0.999890631 0.9992613167 0.9988407894 0.9974798931 9.968373e-01 #> [1045,] 0.999892195 0.9992718770 0.9988573547 0.9975158574 9.968824e-01 #> [1046,] 0.999893737 0.9992822864 0.9988736836 0.9975513097 9.969269e-01 #> [1047,] 0.999895258 0.9992925471 0.9988897793 0.9975862574 9.969707e-01 #> [1048,] 0.999896756 0.9993026612 0.9989056453 0.9976207074 9.970139e-01 #> [1049,] 0.999898233 0.9993126308 0.9989212848 0.9976546669 9.970565e-01 #> [1050,] 0.999899689 0.9993224580 0.9989367010 0.9976881428 9.970985e-01 #> [1051,] 0.999901124 0.9993321448 0.9989518972 0.9977211421 9.971399e-01 #> [1052,] 0.999902538 0.9993416932 0.9989668763 0.9977536713 9.971807e-01 #> [1053,] 0.999903932 0.9993511051 0.9989816417 0.9977857372 9.972209e-01 #> [1054,] 0.999905306 0.9993603826 0.9989961962 0.9978173464 9.972606e-01 #> [1055,] 0.999906661 0.9993695275 0.9990105429 0.9978485054 9.972997e-01 #> [1056,] 0.999907996 0.9993785418 0.9990246848 0.9978792204 9.973382e-01 #> [1057,] 0.999909312 0.9993874272 0.9990386247 0.9979094979 9.973762e-01 #> [1058,] 0.999910610 0.9993961857 0.9990523656 0.9979393441 9.974136e-01 #> [1059,] 0.999911888 0.9994048190 0.9990659102 0.9979687650 9.974505e-01 #> [1060,] 0.999913149 0.9994133290 0.9990792615 0.9979977666 9.974869e-01 #> [1061,] 0.999914391 0.9994217173 0.9990924221 0.9980263551 9.975228e-01 #> [1062,] 0.999915616 0.9994299858 0.9991053947 0.9980545361 9.975581e-01 #> [1063,] 0.999916823 0.9994381361 0.9991181821 0.9980823155 9.975930e-01 #> [1064,] 0.999918013 0.9994461700 0.9991307869 0.9981096990 9.976273e-01 #> [1065,] 0.999919186 0.9994540890 0.9991432116 0.9981366921 9.976612e-01 #> [1066,] 0.999920342 0.9994618949 0.9991554589 0.9981633006 9.976946e-01 #> [1067,] 0.999921481 0.9994695892 0.9991675312 0.9981895298 9.977275e-01 #> [1068,] 0.999922605 0.9994771736 0.9991794312 0.9982153850 9.977599e-01 #> [1069,] 0.999923712 0.9994846495 0.9991911612 0.9982408717 9.977919e-01 #> [1070,] 0.999924803 0.9994920186 0.9992027236 0.9982659950 9.978234e-01 #> [1071,] 0.999925879 0.9994992824 0.9992141209 0.9982907602 9.978545e-01 #> [1072,] 0.999926939 0.9995064424 0.9992253553 0.9983151722 9.978851e-01 #> [1073,] 0.999927984 0.9995135001 0.9992364293 0.9983392361 9.979153e-01 #> [1074,] 0.999929015 0.9995204568 0.9992473451 0.9983629570 9.979451e-01 #> [1075,] 0.999930030 0.9995273142 0.9992581050 0.9983863395 9.979744e-01 #> [1076,] 0.999931031 0.9995340735 0.9992687111 0.9984093886 9.980033e-01 #> [1077,] 0.999932018 0.9995407362 0.9992791658 0.9984321090 9.980318e-01 #> [1078,] 0.999932990 0.9995473037 0.9992894711 0.9984545054 9.980600e-01 #> [1079,] 0.999933949 0.9995537773 0.9992996291 0.9984765823 9.980877e-01 #> [1080,] 0.999934894 0.9995601584 0.9993096421 0.9984983444 9.981150e-01 #> [1081,] 0.999935825 0.9995664482 0.9993195119 0.9985197960 9.981419e-01 #> [1082,] 0.999936743 0.9995726482 0.9993292408 0.9985409416 9.981684e-01 #> [1083,] 0.999937648 0.9995787595 0.9993388307 0.9985617856 9.981946e-01 #> [1084,] 0.999938540 0.9995847835 0.9993482835 0.9985823323 9.982204e-01 #> [1085,] 0.999939419 0.9995907214 0.9993576013 0.9986025858 9.982458e-01 #> [1086,] 0.999940286 0.9995965743 0.9993667860 0.9986225503 9.982708e-01 #> [1087,] 0.999941140 0.9996023437 0.9993758394 0.9986422301 9.982955e-01 #> [1088,] 0.999941982 0.9996080305 0.9993847635 0.9986616290 9.983199e-01 #> [1089,] 0.999942812 0.9996136360 0.9993935600 0.9986807511 9.983439e-01 #> [1090,] 0.999943630 0.9996191615 0.9994022308 0.9986996004 9.983675e-01 #> [1091,] 0.999944437 0.9996246079 0.9994107778 0.9987181807 9.983908e-01 #> [1092,] 0.999945232 0.9996299764 0.9994192026 0.9987364959 9.984138e-01 #> [1093,] 0.999946015 0.9996352682 0.9994275070 0.9987545497 9.984365e-01 #> [1094,] 0.999946787 0.9996404844 0.9994356928 0.9987723459 9.984588e-01 #> [1095,] 0.999947549 0.9996456260 0.9994437615 0.9987898881 9.984808e-01 #> [1096,] 0.999948299 0.9996506941 0.9994517150 0.9988071799 9.985025e-01 #> [1097,] 0.999949039 0.9996556897 0.9994595548 0.9988242249 9.985239e-01 #> [1098,] 0.999949768 0.9996606139 0.9994672826 0.9988410266 9.985450e-01 #> [1099,] 0.999950486 0.9996654677 0.9994748999 0.9988575885 9.985658e-01 #> [1100,] 0.999951195 0.9996702521 0.9994824083 0.9988739140 9.985863e-01 #> [1101,] 0.999951893 0.9996749681 0.9994898095 0.9988900065 9.986065e-01 #> [1102,] 0.999952581 0.9996796167 0.9994971048 0.9989058692 9.986264e-01 #> [1103,] 0.999953259 0.9996841988 0.9995042959 0.9989215055 9.986460e-01 #> [1104,] 0.999953928 0.9996887154 0.9995113843 0.9989369186 9.986654e-01 #> [1105,] 0.999954587 0.9996931674 0.9995183713 0.9989521116 9.986844e-01 #> [1106,] 0.999955237 0.9996975558 0.9995252584 0.9989670878 9.987032e-01 #> [1107,] 0.999955877 0.9997018814 0.9995320471 0.9989818501 9.987218e-01 #> [1108,] 0.999956508 0.9997061452 0.9995387388 0.9989964016 9.987400e-01 #> [1109,] 0.999957131 0.9997103480 0.9995453349 0.9990107454 9.987580e-01 #> [1110,] 0.999957744 0.9997144907 0.9995518366 0.9990248844 9.987758e-01 #> [1111,] 0.999958348 0.9997185742 0.9995582454 0.9990388214 9.987933e-01 #> [1112,] 0.999958944 0.9997225993 0.9995645626 0.9990525595 9.988105e-01 #> [1113,] 0.999959532 0.9997265669 0.9995707895 0.9990661014 9.988275e-01 #> [1114,] 0.999960111 0.9997304777 0.9995769274 0.9990794499 9.988443e-01 #> [1115,] 0.999960681 0.9997343326 0.9995829776 0.9990926078 9.988608e-01 #> [1116,] 0.999961244 0.9997381324 0.9995889413 0.9991055778 9.988771e-01 #> [1117,] 0.999961798 0.9997418778 0.9995948197 0.9991183626 9.988931e-01 #> [1118,] 0.999962345 0.9997455697 0.9996006141 0.9991309648 9.989089e-01 #> [1119,] 0.999962883 0.9997492088 0.9996063257 0.9991433870 9.989245e-01 #> [1120,] 0.999963414 0.9997527958 0.9996119556 0.9991556317 9.989399e-01 #> [1121,] 0.999963938 0.9997563316 0.9996175050 0.9991677016 9.989550e-01 #> [1122,] 0.999964454 0.9997598168 0.9996229751 0.9991795991 9.989700e-01 #> [1123,] 0.999964962 0.9997632522 0.9996283670 0.9991913267 9.989847e-01 #> [1124,] 0.999965463 0.9997666384 0.9996336818 0.9992028868 9.989992e-01 #> [1125,] 0.999965958 0.9997699762 0.9996389207 0.9992142817 9.990135e-01 #> [1126,] 0.999966445 0.9997732663 0.9996440846 0.9992255139 9.990276e-01 #> [1127,] 0.999966925 0.9997765094 0.9996491747 0.9992365856 9.990415e-01 #> [1128,] 0.999967398 0.9997797060 0.9996541921 0.9992474992 9.990552e-01 #> [1129,] 0.999967864 0.9997828570 0.9996591377 0.9992582568 9.990687e-01 #> [1130,] 0.999968324 0.9997859629 0.9996640126 0.9992688608 9.990820e-01 #> [1131,] 0.999968777 0.9997890243 0.9996688178 0.9992793133 9.990951e-01 #> [1132,] 0.999969224 0.9997920420 0.9996735543 0.9992896165 9.991081e-01 #> [1133,] 0.999969664 0.9997950166 0.9996782231 0.9992997725 9.991208e-01 #> [1134,] 0.999970098 0.9997979486 0.9996828251 0.9993097834 9.991334e-01 #> [1135,] 0.999970526 0.9998008387 0.9996873614 0.9993196512 9.991458e-01 #> [1136,] 0.999970947 0.9998036874 0.9996918328 0.9993293781 9.991580e-01 #> [1137,] 0.999971363 0.9998064954 0.9996962402 0.9993389660 9.991700e-01 #> [1138,] 0.999971773 0.9998092632 0.9997005847 0.9993484170 9.991819e-01 #> [1139,] 0.999972177 0.9998119915 0.9997048670 0.9993577328 9.991936e-01 #> [1140,] 0.999972575 0.9998146808 0.9997090881 0.9993669156 9.992051e-01 #> [1141,] 0.999972967 0.9998173315 0.9997132488 0.9993759672 9.992165e-01 #> [1142,] 0.999973354 0.9998199444 0.9997173501 0.9993848894 9.992277e-01 #> [1143,] 0.999973735 0.9998225199 0.9997213927 0.9993936842 9.992387e-01 #> [1144,] 0.999974111 0.9998250586 0.9997253775 0.9994023532 9.992496e-01 #> [1145,] 0.999974481 0.9998275610 0.9997293053 0.9994108984 9.992603e-01 #> [1146,] 0.999974846 0.9998300275 0.9997331769 0.9994193215 9.992709e-01 #> [1147,] 0.999975206 0.9998324588 0.9997369932 0.9994276242 9.992813e-01 #> [1148,] 0.999975561 0.9998348554 0.9997407550 0.9994358083 9.992916e-01 #> [1149,] 0.999975910 0.9998372176 0.9997444629 0.9994438754 9.993017e-01 #> [1150,] 0.999976255 0.9998395461 0.9997481178 0.9994518273 9.993117e-01 #> [1151,] 0.999976595 0.9998418413 0.9997517205 0.9994596654 9.993215e-01 #> [1152,] 0.999976929 0.9998441036 0.9997552716 0.9994673916 9.993312e-01 #> [1153,] 0.999977260 0.9998463336 0.9997587720 0.9994750074 9.993408e-01 #> [1154,] 0.999977585 0.9998485317 0.9997622223 0.9994825143 9.993502e-01 #> [1155,] 0.999977906 0.9998506984 0.9997656233 0.9994899139 9.993595e-01 #> [1156,] 0.999978222 0.9998528340 0.9997689756 0.9994972078 9.993687e-01 #> [1157,] 0.999978533 0.9998549392 0.9997722800 0.9995043974 9.993777e-01 #> [1158,] 0.999978840 0.9998570142 0.9997755371 0.9995114843 9.993866e-01 #> [1159,] 0.999979143 0.9998590595 0.9997787477 0.9995184699 9.993954e-01 #> [1160,] 0.999979441 0.9998610756 0.9997819124 0.9995253556 9.994040e-01 #> [1161,] 0.999979736 0.9998630628 0.9997850318 0.9995321430 9.994125e-01 #> [1162,] 0.999980025 0.9998650217 0.9997881066 0.9995388333 9.994209e-01 #> [1163,] 0.999980311 0.9998669525 0.9997911374 0.9995454279 9.994292e-01 #> [1164,] 0.999980593 0.9998688557 0.9997941249 0.9995519284 9.994374e-01 #> [1165,] 0.999980871 0.9998707316 0.9997970696 0.9995583359 9.994454e-01 #> [1166,] 0.999981144 0.9998725808 0.9997999723 0.9995646518 9.994534e-01 #> [1167,] 0.999981414 0.9998744035 0.9998028334 0.9995708774 9.994612e-01 #> [1168,] 0.999981680 0.9998762001 0.9998056536 0.9995770141 9.994689e-01 #> [1169,] 0.999981942 0.9998779710 0.9998084335 0.9995830630 9.994765e-01 #> [1170,] 0.999982200 0.9998797166 0.9998111736 0.9995890254 9.994840e-01 #> [1171,] 0.999982455 0.9998814373 0.9998138746 0.9995949027 9.994913e-01 #> [1172,] 0.999982706 0.9998831333 0.9998165369 0.9996006959 9.994986e-01 #> [1173,] 0.999982953 0.9998848050 0.9998191611 0.9996064063 9.995058e-01 #> [1174,] 0.999983197 0.9998864529 0.9998217478 0.9996120350 9.995128e-01 #> [1175,] 0.999983438 0.9998880772 0.9998242975 0.9996175833 9.995198e-01 #> [1176,] 0.999983675 0.9998896782 0.9998268108 0.9996230523 9.995267e-01 #> [1177,] 0.999983908 0.9998912564 0.9998292881 0.9996284431 9.995334e-01 #> [1178,] 0.999984138 0.9998928119 0.9998317300 0.9996337568 9.995401e-01 #> [1179,] 0.999984365 0.9998943453 0.9998341369 0.9996389946 9.995467e-01 #> [1180,] 0.999984589 0.9998958566 0.9998365095 0.9996441575 9.995532e-01 #> [1181,] 0.999984809 0.9998973464 0.9998388481 0.9996492466 9.995596e-01 #> [1182,] 0.999985027 0.9998988149 0.9998411532 0.9996542629 9.995659e-01 #> [1183,] 0.999985241 0.9999002623 0.9998434254 0.9996592075 9.995721e-01 #> [1184,] 0.999985452 0.9999016891 0.9998456651 0.9996640814 9.995782e-01 #> [1185,] 0.999985660 0.9999030955 0.9998478727 0.9996688856 9.995842e-01 #> [1186,] 0.999985865 0.9999044817 0.9998500488 0.9996736212 9.995902e-01 #> [1187,] 0.999986068 0.9999058481 0.9998521938 0.9996782890 9.995960e-01 #> [1188,] 0.999986267 0.9999071949 0.9998543081 0.9996828901 9.996018e-01 #> [1189,] 0.999986463 0.9999085225 0.9998563921 0.9996874254 9.996075e-01 #> [1190,] 0.999986657 0.9999098311 0.9998584463 0.9996918959 9.996131e-01 #> [1191,] 0.999986848 0.9999111210 0.9998604712 0.9996963024 9.996186e-01 #> [1192,] 0.999987036 0.9999123925 0.9998624671 0.9997006460 9.996241e-01 #> [1193,] 0.999987222 0.9999136457 0.9998644344 0.9997049274 9.996295e-01 #> [1194,] 0.999987404 0.9999148810 0.9998663736 0.9997091477 9.996348e-01 #> [1195,] 0.999987585 0.9999160987 0.9998682851 0.9997133075 9.996400e-01 #> [1196,] 0.999987762 0.9999172989 0.9998701693 0.9997174079 9.996451e-01 #> [1197,] 0.999987937 0.9999184820 0.9998720264 0.9997214497 9.996502e-01 #> [1198,] 0.999988110 0.9999196481 0.9998738571 0.9997254337 9.996552e-01 #> [1199,] 0.999988280 0.9999207976 0.9998756615 0.9997293607 9.996602e-01 #> [1200,] 0.999988448 0.9999219306 0.9998774401 0.9997332316 9.996650e-01 #> [1201,] 0.999988613 0.9999230474 0.9998791933 0.9997370471 9.996698e-01 expected.test(mod, Theta, individual=TRUE, probs.only=TRUE) #>                 [,1]        [,2]         [,3]         [,4]         [,5] #>    [1,] 9.972918e-01 0.002708164 9.995984e-01 0.0004016443 0.9997441307 #>    [2,] 9.972526e-01 0.002747363 9.995925e-01 0.0004074715 0.9997404180 #>    [3,] 9.972129e-01 0.002787127 9.995866e-01 0.0004133831 0.9997366514 #>    [4,] 9.971725e-01 0.002827465 9.995806e-01 0.0004193805 0.9997328301 #>    [5,] 9.971316e-01 0.002868386 9.995745e-01 0.0004254649 0.9997289534 #>    [6,] 9.970901e-01 0.002909897 9.995684e-01 0.0004316375 0.9997250205 #>    [7,] 9.970480e-01 0.002952007 9.995621e-01 0.0004378996 0.9997210305 #>    [8,] 9.970053e-01 0.002994724 9.995557e-01 0.0004442525 0.9997169826 #>    [9,] 9.969619e-01 0.003038058 9.995493e-01 0.0004506975 0.9997128761 #>   [10,] 9.969180e-01 0.003082017 9.995428e-01 0.0004572360 0.9997087099 #>   [11,] 9.968734e-01 0.003126610 9.995361e-01 0.0004638693 0.9997044834 #>   [12,] 9.968282e-01 0.003171846 9.995294e-01 0.0004705988 0.9997001955 #>   [13,] 9.967823e-01 0.003217735 9.995226e-01 0.0004774259 0.9996958454 #>   [14,] 9.967357e-01 0.003264285 9.995156e-01 0.0004843520 0.9996914322 #>   [15,] 9.966885e-01 0.003311506 9.995086e-01 0.0004913785 0.9996869550 #>   [16,] 9.966406e-01 0.003359409 9.995015e-01 0.0004985069 0.9996824129 #>   [17,] 9.965920e-01 0.003408001 9.994943e-01 0.0005057386 0.9996778049 #>   [18,] 9.965427e-01 0.003457295 9.994869e-01 0.0005130752 0.9996731300 #>   [19,] 9.964927e-01 0.003507298 9.994795e-01 0.0005205182 0.9996683873 #>   [20,] 9.964420e-01 0.003558023 9.994719e-01 0.0005280691 0.9996635759 #>   [21,] 9.963905e-01 0.003609478 9.994643e-01 0.0005357294 0.9996586946 #>   [22,] 9.963383e-01 0.003661674 9.994565e-01 0.0005435009 0.9996537426 #>   [23,] 9.962854e-01 0.003714623 9.994486e-01 0.0005513850 0.9996487187 #>   [24,] 9.962317e-01 0.003768335 9.994406e-01 0.0005593834 0.9996436220 #>   [25,] 9.961772e-01 0.003822820 9.994325e-01 0.0005674977 0.9996384513 #>   [26,] 9.961219e-01 0.003878089 9.994243e-01 0.0005757297 0.9996332057 #>   [27,] 9.960658e-01 0.003934155 9.994159e-01 0.0005840811 0.9996278840 #>   [28,] 9.960090e-01 0.003991028 9.994074e-01 0.0005925535 0.9996224851 #>   [29,] 9.959513e-01 0.004048720 9.993989e-01 0.0006011487 0.9996170079 #>   [30,] 9.958928e-01 0.004107242 9.993901e-01 0.0006098686 0.9996114512 #>   [31,] 9.958334e-01 0.004166607 9.993813e-01 0.0006187148 0.9996058140 #>   [32,] 9.957732e-01 0.004226826 9.993723e-01 0.0006276893 0.9996000950 #>   [33,] 9.957121e-01 0.004287912 9.993632e-01 0.0006367939 0.9995942931 #>   [34,] 9.956501e-01 0.004349876 9.993540e-01 0.0006460304 0.9995884070 #>   [35,] 9.955873e-01 0.004412733 9.993446e-01 0.0006554008 0.9995824356 #>   [36,] 9.955235e-01 0.004476493 9.993351e-01 0.0006649071 0.9995763776 #>   [37,] 9.954588e-01 0.004541170 9.993254e-01 0.0006745511 0.9995702317 #>   [38,] 9.953932e-01 0.004606778 9.993157e-01 0.0006843350 0.9995639967 #>   [39,] 9.953267e-01 0.004673329 9.993057e-01 0.0006942606 0.9995576713 #>   [40,] 9.952592e-01 0.004740837 9.992957e-01 0.0007043301 0.9995512541 #>   [41,] 9.951907e-01 0.004809315 9.992855e-01 0.0007145456 0.9995447439 #>   [42,] 9.951212e-01 0.004878777 9.992751e-01 0.0007249090 0.9995381393 #>   [43,] 9.950508e-01 0.004949238 9.992646e-01 0.0007354227 0.9995314390 #>   [44,] 9.949793e-01 0.005020712 9.992539e-01 0.0007460888 0.9995246414 #>   [45,] 9.949068e-01 0.005093212 9.992431e-01 0.0007569095 0.9995177453 #>   [46,] 9.948332e-01 0.005166753 9.992321e-01 0.0007678869 0.9995107493 #>   [47,] 9.947586e-01 0.005241351 9.992210e-01 0.0007790235 0.9995036517 #>   [48,] 9.946830e-01 0.005317021 9.992097e-01 0.0007903214 0.9994964513 #>   [49,] 9.946062e-01 0.005393776 9.991982e-01 0.0008017830 0.9994891464 #>   [50,] 9.945284e-01 0.005471634 9.991866e-01 0.0008134107 0.9994817357 #>   [51,] 9.944494e-01 0.005550609 9.991748e-01 0.0008252070 0.9994742175 #>   [52,] 9.943693e-01 0.005630718 9.991628e-01 0.0008371741 0.9994665903 #>   [53,] 9.942880e-01 0.005711976 9.991507e-01 0.0008493147 0.9994588525 #>   [54,] 9.942056e-01 0.005794400 9.991384e-01 0.0008616311 0.9994510025 #>   [55,] 9.941220e-01 0.005878007 9.991259e-01 0.0008741260 0.9994430387 #>   [56,] 9.940372e-01 0.005962812 9.991132e-01 0.0008868020 0.9994349594 #>   [57,] 9.939512e-01 0.006048834 9.991003e-01 0.0008996615 0.9994267631 #>   [58,] 9.938639e-01 0.006136089 9.990873e-01 0.0009127074 0.9994184479 #>   [59,] 9.937754e-01 0.006224595 9.990741e-01 0.0009259423 0.9994100121 #>   [60,] 9.936856e-01 0.006314369 9.990606e-01 0.0009393690 0.9994014541 #>   [61,] 9.935946e-01 0.006405429 9.990470e-01 0.0009529901 0.9993927720 #>   [62,] 9.935022e-01 0.006497795 9.990332e-01 0.0009668086 0.9993839640 #>   [63,] 9.934085e-01 0.006591483 9.990192e-01 0.0009808272 0.9993750283 #>   [64,] 9.933135e-01 0.006686513 9.990050e-01 0.0009950489 0.9993659632 #>   [65,] 9.932171e-01 0.006782904 9.989905e-01 0.0010094766 0.9993567666 #>   [66,] 9.931193e-01 0.006880674 9.989759e-01 0.0010241133 0.9993474367 #>   [67,] 9.930202e-01 0.006979844 9.989610e-01 0.0010389620 0.9993379716 #>   [68,] 9.929196e-01 0.007080433 9.989460e-01 0.0010540257 0.9993283692 #>   [69,] 9.928175e-01 0.007182462 9.989307e-01 0.0010693077 0.9993186277 #>   [70,] 9.927141e-01 0.007285950 9.989152e-01 0.0010848109 0.9993087450 #>   [71,] 9.926091e-01 0.007390917 9.988995e-01 0.0011005387 0.9992987191 #>   [72,] 9.925026e-01 0.007497386 9.988835e-01 0.0011164942 0.9992885479 #>   [73,] 9.923946e-01 0.007605376 9.988673e-01 0.0011326808 0.9992782292 #>   [74,] 9.922851e-01 0.007714910 9.988509e-01 0.0011491018 0.9992677610 #>   [75,] 9.921740e-01 0.007826009 9.988342e-01 0.0011657606 0.9992571410 #>   [76,] 9.920613e-01 0.007938695 9.988173e-01 0.0011826606 0.9992463672 #>   [77,] 9.919470e-01 0.008052991 9.988002e-01 0.0011998053 0.9992354372 #>   [78,] 9.918311e-01 0.008168918 9.987828e-01 0.0012171983 0.9992243489 #>   [79,] 9.917135e-01 0.008286501 9.987652e-01 0.0012348431 0.9992130998 #>   [80,] 9.915942e-01 0.008405761 9.987473e-01 0.0012527433 0.9992016878 #>   [81,] 9.914733e-01 0.008526723 9.987291e-01 0.0012709027 0.9991901103 #>   [82,] 9.913506e-01 0.008649411 9.987107e-01 0.0012893250 0.9991783651 #>   [83,] 9.912262e-01 0.008773848 9.986920e-01 0.0013080139 0.9991664497 #>   [84,] 9.910999e-01 0.008900060 9.986730e-01 0.0013269735 0.9991543617 #>   [85,] 9.909719e-01 0.009028070 9.986538e-01 0.0013462074 0.9991420985 #>   [86,] 9.908421e-01 0.009157905 9.986343e-01 0.0013657198 0.9991296576 #>   [87,] 9.907104e-01 0.009289589 9.986145e-01 0.0013855146 0.9991170365 #>   [88,] 9.905769e-01 0.009423149 9.985944e-01 0.0014055959 0.9991042325 #>   [89,] 9.904414e-01 0.009558611 9.985740e-01 0.0014259678 0.9990912431 #>   [90,] 9.903040e-01 0.009696001 9.985534e-01 0.0014466346 0.9990780654 #>   [91,] 9.901647e-01 0.009835346 9.985324e-01 0.0014676004 0.9990646968 #>   [92,] 9.900233e-01 0.009976673 9.985111e-01 0.0014888696 0.9990511346 #>   [93,] 9.898800e-01 0.010120011 9.984896e-01 0.0015104467 0.9990373759 #>   [94,] 9.897346e-01 0.010265386 9.984677e-01 0.0015323359 0.9990234178 #>   [95,] 9.895872e-01 0.010412828 9.984455e-01 0.0015545419 0.9990092576 #>   [96,] 9.894376e-01 0.010562365 9.984229e-01 0.0015770692 0.9989948923 #>   [97,] 9.892860e-01 0.010714026 9.984001e-01 0.0015999223 0.9989803189 #>   [98,] 9.891322e-01 0.010867841 9.983769e-01 0.0016231062 0.9989655344 #>   [99,] 9.889762e-01 0.011023840 9.983534e-01 0.0016466254 0.9989505358 #>  [100,] 9.888179e-01 0.011182052 9.983295e-01 0.0016704848 0.9989353199 #>  [101,] 9.886575e-01 0.011342509 9.983053e-01 0.0016946894 0.9989198837 #>  [102,] 9.884948e-01 0.011505242 9.982808e-01 0.0017192440 0.9989042239 #>  [103,] 9.883297e-01 0.011670282 9.982558e-01 0.0017441539 0.9988883373 #>  [104,] 9.881623e-01 0.011837661 9.982306e-01 0.0017694240 0.9988722207 #>  [105,] 9.879926e-01 0.012007411 9.982049e-01 0.0017950595 0.9988558707 #>  [106,] 9.878204e-01 0.012179566 9.981789e-01 0.0018210659 0.9988392839 #>  [107,] 9.876458e-01 0.012354158 9.981526e-01 0.0018474482 0.9988224569 #>  [108,] 9.874688e-01 0.012531221 9.981258e-01 0.0018742121 0.9988053863 #>  [109,] 9.872892e-01 0.012710789 9.980986e-01 0.0019013630 0.9987880685 #>  [110,] 9.871071e-01 0.012892897 9.980711e-01 0.0019289064 0.9987705000 #>  [111,] 9.869224e-01 0.013077579 9.980432e-01 0.0019568480 0.9987526771 #>  [112,] 9.867351e-01 0.013264871 9.980148e-01 0.0019851936 0.9987345962 #>  [113,] 9.865452e-01 0.013454809 9.979861e-01 0.0020139490 0.9987162536 #>  [114,] 9.863526e-01 0.013647429 9.979569e-01 0.0020431200 0.9986976453 #>  [115,] 9.861572e-01 0.013842768 9.979273e-01 0.0020727127 0.9986787678 #>  [116,] 9.859591e-01 0.014040862 9.978973e-01 0.0021027331 0.9986596169 #>  [117,] 9.857582e-01 0.014241751 9.978668e-01 0.0021331873 0.9986401888 #>  [118,] 9.855545e-01 0.014445472 9.978359e-01 0.0021640817 0.9986204796 #>  [119,] 9.853479e-01 0.014652064 9.978046e-01 0.0021954226 0.9986004850 #>  [120,] 9.851384e-01 0.014861565 9.977728e-01 0.0022272163 0.9985802011 #>  [121,] 9.849260e-01 0.015074017 9.977405e-01 0.0022594694 0.9985596236 #>  [122,] 9.847105e-01 0.015289458 9.977078e-01 0.0022921885 0.9985387484 #>  [123,] 9.844921e-01 0.015507930 9.976746e-01 0.0023253802 0.9985175710 #>  [124,] 9.842705e-01 0.015729474 9.976409e-01 0.0023590515 0.9984960871 #>  [125,] 9.840459e-01 0.015954132 9.976068e-01 0.0023932092 0.9984742924 #>  [126,] 9.838181e-01 0.016181945 9.975721e-01 0.0024278603 0.9984521824 #>  [127,] 9.835870e-01 0.016412957 9.975370e-01 0.0024630118 0.9984297524 #>  [128,] 9.833528e-01 0.016647212 9.975013e-01 0.0024986710 0.9984069979 #>  [129,] 9.831152e-01 0.016884752 9.974652e-01 0.0025348451 0.9983839142 #>  [130,] 9.828744e-01 0.017125623 9.974285e-01 0.0025715416 0.9983604966 #>  [131,] 9.826301e-01 0.017369869 9.973912e-01 0.0026087680 0.9983367402 #>  [132,] 9.823825e-01 0.017617536 9.973535e-01 0.0026465318 0.9983126401 #>  [133,] 9.821313e-01 0.017868670 9.973152e-01 0.0026848408 0.9982881914 #>  [134,] 9.818767e-01 0.018123319 9.972763e-01 0.0027237028 0.9982633892 #>  [135,] 9.816185e-01 0.018381528 9.972369e-01 0.0027631258 0.9982382281 #>  [136,] 9.813567e-01 0.018643346 9.971969e-01 0.0028031178 0.9982127032 #>  [137,] 9.810912e-01 0.018908822 9.971563e-01 0.0028436869 0.9981868092 #>  [138,] 9.808220e-01 0.019178004 9.971152e-01 0.0028848416 0.9981605407 #>  [139,] 9.805491e-01 0.019450942 9.970734e-01 0.0029265900 0.9981338923 #>  [140,] 9.802723e-01 0.019727686 9.970311e-01 0.0029689409 0.9981068587 #>  [141,] 9.799917e-01 0.020008288 9.969881e-01 0.0030119027 0.9980794341 #>  [142,] 9.797072e-01 0.020292798 9.969445e-01 0.0030554843 0.9980516130 #>  [143,] 9.794187e-01 0.020581269 9.969003e-01 0.0030996946 0.9980233898 #>  [144,] 9.791262e-01 0.020873753 9.968555e-01 0.0031445425 0.9979947585 #>  [145,] 9.788297e-01 0.021170304 9.968100e-01 0.0031900373 0.9979657133 #>  [146,] 9.785290e-01 0.021470975 9.967638e-01 0.0032361881 0.9979362483 #>  [147,] 9.782242e-01 0.021775822 9.967170e-01 0.0032830044 0.9979063575 #>  [148,] 9.779151e-01 0.022084899 9.966695e-01 0.0033304957 0.9978760346 #>  [149,] 9.776017e-01 0.022398263 9.966213e-01 0.0033786717 0.9978452735 #>  [150,] 9.772840e-01 0.022715970 9.965725e-01 0.0034275421 0.9978140678 #>  [151,] 9.769619e-01 0.023038077 9.965229e-01 0.0034771170 0.9977824112 #>  [152,] 9.766354e-01 0.023364642 9.964726e-01 0.0035274063 0.9977502972 #>  [153,] 9.763043e-01 0.023695724 9.964216e-01 0.0035784204 0.9977177193 #>  [154,] 9.759686e-01 0.024031382 9.963698e-01 0.0036301696 0.9976846706 #>  [155,] 9.756283e-01 0.024371677 9.963173e-01 0.0036826644 0.9976511445 #>  [156,] 9.752833e-01 0.024716668 9.962641e-01 0.0037359154 0.9976171341 #>  [157,] 9.749336e-01 0.025066417 9.962101e-01 0.0037899335 0.9975826325 #>  [158,] 9.745790e-01 0.025420985 9.961553e-01 0.0038447296 0.9975476325 #>  [159,] 9.742196e-01 0.025780437 9.960997e-01 0.0039003150 0.9975121270 #>  [160,] 9.738552e-01 0.026144835 9.960433e-01 0.0039567007 0.9974761088 #>  [161,] 9.734858e-01 0.026514244 9.959861e-01 0.0040138983 0.9974395705 #>  [162,] 9.731113e-01 0.026888728 9.959281e-01 0.0040719194 0.9974025046 #>  [163,] 9.727316e-01 0.027268353 9.958692e-01 0.0041307757 0.9973649035 #>  [164,] 9.723468e-01 0.027653185 9.958095e-01 0.0041904791 0.9973267596 #>  [165,] 9.719567e-01 0.028043292 9.957490e-01 0.0042510418 0.9972880650 #>  [166,] 9.715613e-01 0.028438741 9.956875e-01 0.0043124759 0.9972488119 #>  [167,] 9.711604e-01 0.028839601 9.956252e-01 0.0043747940 0.9972089922 #>  [168,] 9.707541e-01 0.029245941 9.955620e-01 0.0044380086 0.9971685978 #>  [169,] 9.703422e-01 0.029657832 9.954979e-01 0.0045021325 0.9971276205 #>  [170,] 9.699247e-01 0.030075344 9.954328e-01 0.0045671786 0.9970860518 #>  [171,] 9.695015e-01 0.030498548 9.953668e-01 0.0046331602 0.9970438834 #>  [172,] 9.690725e-01 0.030927518 9.952999e-01 0.0047000905 0.9970011065 #>  [173,] 9.686377e-01 0.031362327 9.952320e-01 0.0047679830 0.9969577126 #>  [174,] 9.681970e-01 0.031803047 9.951631e-01 0.0048368515 0.9969136927 #>  [175,] 9.677502e-01 0.032249755 9.950933e-01 0.0049067098 0.9968690378 #>  [176,] 9.672975e-01 0.032702525 9.950224e-01 0.0049775720 0.9968237389 #>  [177,] 9.668386e-01 0.033161434 9.949505e-01 0.0050494524 0.9967777868 #>  [178,] 9.663734e-01 0.033626560 9.948776e-01 0.0051223655 0.9967311720 #>  [179,] 9.659020e-01 0.034097978 9.948037e-01 0.0051963259 0.9966838851 #>  [180,] 9.654242e-01 0.034575770 9.947287e-01 0.0052713485 0.9966359164 #>  [181,] 9.649400e-01 0.035060013 9.946526e-01 0.0053474485 0.9965872562 #>  [182,] 9.644492e-01 0.035550788 9.945754e-01 0.0054246411 0.9965378947 #>  [183,] 9.639518e-01 0.036048177 9.944971e-01 0.0055029419 0.9964878217 #>  [184,] 9.634477e-01 0.036552261 9.944176e-01 0.0055823665 0.9964370270 #>  [185,] 9.629369e-01 0.037063123 9.943371e-01 0.0056629309 0.9963855004 #>  [186,] 9.624192e-01 0.037580846 9.942553e-01 0.0057446514 0.9963332314 #>  [187,] 9.618945e-01 0.038105515 9.941725e-01 0.0058275442 0.9962802094 #>  [188,] 9.613628e-01 0.038637215 9.940884e-01 0.0059116260 0.9962264236 #>  [189,] 9.608240e-01 0.039176032 9.940031e-01 0.0059969136 0.9961718630 #>  [190,] 9.602779e-01 0.039722052 9.939166e-01 0.0060834242 0.9961165166 #>  [191,] 9.597246e-01 0.040275364 9.938288e-01 0.0061711750 0.9960603733 #>  [192,] 9.591639e-01 0.040836055 9.937398e-01 0.0062601836 0.9960034215 #>  [193,] 9.585958e-01 0.041404215 9.936495e-01 0.0063504678 0.9959456497 #>  [194,] 9.580201e-01 0.041979934 9.935580e-01 0.0064420456 0.9958870464 #>  [195,] 9.574367e-01 0.042563303 9.934651e-01 0.0065349354 0.9958275994 #>  [196,] 9.568456e-01 0.043154413 9.933708e-01 0.0066291556 0.9957672969 #>  [197,] 9.562466e-01 0.043753358 9.932753e-01 0.0067247251 0.9957061267 #>  [198,] 9.556398e-01 0.044360230 9.931783e-01 0.0068216629 0.9956440762 #>  [199,] 9.550249e-01 0.044975123 9.930800e-01 0.0069199883 0.9955811331 #>  [200,] 9.544019e-01 0.045598133 9.929803e-01 0.0070197210 0.9955172845 #>  [201,] 9.537706e-01 0.046229356 9.928791e-01 0.0071208807 0.9954525176 #>  [202,] 9.531311e-01 0.046868887 9.927765e-01 0.0072234876 0.9953868193 #>  [203,] 9.524832e-01 0.047516825 9.926724e-01 0.0073275621 0.9953201763 #>  [204,] 9.518267e-01 0.048173268 9.925669e-01 0.0074331249 0.9952525751 #>  [205,] 9.511617e-01 0.048838314 9.924598e-01 0.0075401968 0.9951840021 #>  [206,] 9.504879e-01 0.049512064 9.923512e-01 0.0076487993 0.9951144436 #>  [207,] 9.498054e-01 0.050194618 9.922410e-01 0.0077589537 0.9950438853 #>  [208,] 9.491139e-01 0.050886078 9.921293e-01 0.0078706819 0.9949723132 #>  [209,] 9.484135e-01 0.051586545 9.920160e-01 0.0079840060 0.9948997128 #>  [210,] 9.477039e-01 0.052296124 9.919011e-01 0.0080989485 0.9948260695 #>  [211,] 9.469851e-01 0.053014917 9.917845e-01 0.0082155321 0.9947513685 #>  [212,] 9.462570e-01 0.053743030 9.916662e-01 0.0083337798 0.9946755947 #>  [213,] 9.455194e-01 0.054480567 9.915463e-01 0.0084537149 0.9945987330 #>  [214,] 9.447724e-01 0.055227636 9.914246e-01 0.0085753612 0.9945207677 #>  [215,] 9.440157e-01 0.055984341 9.913013e-01 0.0086987425 0.9944416834 #>  [216,] 9.432492e-01 0.056750793 9.911761e-01 0.0088238832 0.9943614641 #>  [217,] 9.424729e-01 0.057527097 9.910492e-01 0.0089508080 0.9942800937 #>  [218,] 9.416866e-01 0.058313365 9.909205e-01 0.0090795418 0.9941975558 #>  [219,] 9.408903e-01 0.059109705 9.907899e-01 0.0092101098 0.9941138341 #>  [220,] 9.400838e-01 0.059916228 9.906575e-01 0.0093425378 0.9940289115 #>  [221,] 9.392670e-01 0.060733045 9.905231e-01 0.0094768517 0.9939427712 #>  [222,] 9.384397e-01 0.061560268 9.903869e-01 0.0096130778 0.9938553960 #>  [223,] 9.376020e-01 0.062398011 9.902488e-01 0.0097512429 0.9937667682 #>  [224,] 9.367536e-01 0.063246385 9.901086e-01 0.0098913739 0.9936768702 #>  [225,] 9.358945e-01 0.064105506 9.899665e-01 0.0100334982 0.9935856841 #>  [226,] 9.350245e-01 0.064975487 9.898224e-01 0.0101776437 0.9934931915 #>  [227,] 9.341436e-01 0.065856443 9.896762e-01 0.0103238385 0.9933993742 #>  [228,] 9.332515e-01 0.066748492 9.895279e-01 0.0104721110 0.9933042132 #>  [229,] 9.323483e-01 0.067651748 9.893775e-01 0.0106224902 0.9932076897 #>  [230,] 9.314337e-01 0.068566329 9.892250e-01 0.0107750053 0.9931097844 #>  [231,] 9.305076e-01 0.069492353 9.890703e-01 0.0109296860 0.9930104778 #>  [232,] 9.295701e-01 0.070429938 9.889134e-01 0.0110865623 0.9929097502 #>  [233,] 9.286208e-01 0.071379203 9.887543e-01 0.0112456647 0.9928075814 #>  [234,] 9.276597e-01 0.072340266 9.885930e-01 0.0114070240 0.9927039513 #>  [235,] 9.266868e-01 0.073313247 9.884293e-01 0.0115706715 0.9925988391 #>  [236,] 9.257017e-01 0.074298267 9.882634e-01 0.0117366389 0.9924922241 #>  [237,] 9.247046e-01 0.075295445 9.880950e-01 0.0119049581 0.9923840851 #>  [238,] 9.236951e-01 0.076304905 9.879243e-01 0.0120756619 0.9922744005 #>  [239,] 9.226732e-01 0.077326766 9.877512e-01 0.0122487829 0.9921631488 #>  [240,] 9.216388e-01 0.078361150 9.875756e-01 0.0124243547 0.9920503079 #>  [241,] 9.205918e-01 0.079408181 9.873976e-01 0.0126024110 0.9919358554 #>  [242,] 9.195320e-01 0.080467980 9.872170e-01 0.0127829861 0.9918197687 #>  [243,] 9.184593e-01 0.081540670 9.870339e-01 0.0129661145 0.9917020248 #>  [244,] 9.173736e-01 0.082626376 9.868482e-01 0.0131518315 0.9915826006 #>  [245,] 9.162748e-01 0.083725219 9.866598e-01 0.0133401726 0.9914614724 #>  [246,] 9.151627e-01 0.084837325 9.864688e-01 0.0135311738 0.9913386164 #>  [247,] 9.140372e-01 0.085962816 9.862751e-01 0.0137248718 0.9912140083 #>  [248,] 9.128982e-01 0.087101818 9.860787e-01 0.0139213033 0.9910876237 #>  [249,] 9.117455e-01 0.088254454 9.858795e-01 0.0141205060 0.9909594376 #>  [250,] 9.105792e-01 0.089420850 9.856775e-01 0.0143225177 0.9908294249 #>  [251,] 9.093989e-01 0.090601128 9.854726e-01 0.0145273768 0.9906975601 #>  [252,] 9.082046e-01 0.091795416 9.852649e-01 0.0147351223 0.9905638172 #>  [253,] 9.069962e-01 0.093003835 9.850542e-01 0.0149457936 0.9904281700 #>  [254,] 9.057735e-01 0.094226513 9.848406e-01 0.0151594305 0.9902905920 #>  [255,] 9.045364e-01 0.095463572 9.846239e-01 0.0153760736 0.9901510562 #>  [256,] 9.032849e-01 0.096715139 9.844042e-01 0.0155957636 0.9900095353 #>  [257,] 9.020187e-01 0.097981336 9.841815e-01 0.0158185421 0.9898660017 #>  [258,] 9.007377e-01 0.099262289 9.839555e-01 0.0160444510 0.9897204274 #>  [259,] 8.994419e-01 0.100558121 9.837265e-01 0.0162735328 0.9895727840 #>  [260,] 8.981310e-01 0.101868957 9.834942e-01 0.0165058306 0.9894230426 #>  [261,] 8.968051e-01 0.103194920 9.832586e-01 0.0167413879 0.9892711741 #>  [262,] 8.954639e-01 0.104536133 9.830198e-01 0.0169802488 0.9891171491 #>  [263,] 8.941073e-01 0.105892719 9.827775e-01 0.0172224581 0.9889609375 #>  [264,] 8.927352e-01 0.107264802 9.825319e-01 0.0174680608 0.9888025091 #>  [265,] 8.913475e-01 0.108652502 9.822829e-01 0.0177171029 0.9886418330 #>  [266,] 8.899441e-01 0.110055942 9.820304e-01 0.0179696306 0.9884788783 #>  [267,] 8.885248e-01 0.111475243 9.817743e-01 0.0182256909 0.9883136132 #>  [268,] 8.870895e-01 0.112910525 9.815147e-01 0.0184853312 0.9881460060 #>  [269,] 8.856381e-01 0.114361908 9.812514e-01 0.0187485998 0.9879760241 #>  [270,] 8.841705e-01 0.115829512 9.809845e-01 0.0190155451 0.9878036349 #>  [271,] 8.826865e-01 0.117313455 9.807138e-01 0.0192862166 0.9876288051 #>  [272,] 8.811861e-01 0.118813854 9.804393e-01 0.0195606640 0.9874515009 #>  [273,] 8.796692e-01 0.120330828 9.801611e-01 0.0198389379 0.9872716884 #>  [274,] 8.781355e-01 0.121864490 9.798789e-01 0.0201210894 0.9870893330 #>  [275,] 8.765850e-01 0.123414958 9.795928e-01 0.0204071700 0.9869043997 #>  [276,] 8.750177e-01 0.124982344 9.793028e-01 0.0206972323 0.9867168530 #>  [277,] 8.734332e-01 0.126566762 9.790087e-01 0.0209913290 0.9865266571 #>  [278,] 8.718317e-01 0.128168324 9.787105e-01 0.0212895139 0.9863337755 #>  [279,] 8.702129e-01 0.129787141 9.784082e-01 0.0215918411 0.9861381715 #>  [280,] 8.685767e-01 0.131423321 9.781016e-01 0.0218983655 0.9859398077 #>  [281,] 8.669230e-01 0.133076974 9.777909e-01 0.0222091427 0.9857386464 #>  [282,] 8.652518e-01 0.134748207 9.774758e-01 0.0225242288 0.9855346493 #>  [283,] 8.635629e-01 0.136437124 9.771563e-01 0.0228436806 0.9853277776 #>  [284,] 8.618562e-01 0.138143830 9.768324e-01 0.0231675557 0.9851179920 #>  [285,] 8.601316e-01 0.139868428 9.765041e-01 0.0234959123 0.9849052529 #>  [286,] 8.583890e-01 0.141611018 9.761712e-01 0.0238288092 0.9846895199 #>  [287,] 8.566283e-01 0.143371700 9.758337e-01 0.0241663059 0.9844707523 #>  [288,] 8.548494e-01 0.145150571 9.754915e-01 0.0245084627 0.9842489087 #>  [289,] 8.530523e-01 0.146947727 9.751447e-01 0.0248553405 0.9840239475 #>  [290,] 8.512367e-01 0.148763262 9.747930e-01 0.0252070010 0.9837958261 #>  [291,] 8.494027e-01 0.150597268 9.744365e-01 0.0255635064 0.9835645019 #>  [292,] 8.475502e-01 0.152449835 9.740751e-01 0.0259249198 0.9833299313 #>  [293,] 8.456789e-01 0.154321051 9.737087e-01 0.0262913050 0.9830920704 #>  [294,] 8.437890e-01 0.156211002 9.733373e-01 0.0266627264 0.9828508748 #>  [295,] 8.418802e-01 0.158119771 9.729608e-01 0.0270392492 0.9826062993 #>  [296,] 8.399526e-01 0.160047439 9.725791e-01 0.0274209394 0.9823582983 #>  [297,] 8.380059e-01 0.161994086 9.721921e-01 0.0278078636 0.9821068258 #>  [298,] 8.360402e-01 0.163959789 9.717999e-01 0.0282000891 0.9818518348 #>  [299,] 8.340554e-01 0.165944620 9.714023e-01 0.0285976842 0.9815932782 #>  [300,] 8.320513e-01 0.167948653 9.709993e-01 0.0290007178 0.9813311079 #>  [301,] 8.300280e-01 0.169971955 9.705907e-01 0.0294092594 0.9810652755 #>  [302,] 8.279854e-01 0.172014593 9.701766e-01 0.0298233795 0.9807957319 #>  [303,] 8.259234e-01 0.174076630 9.697569e-01 0.0302431493 0.9805224275 #>  [304,] 8.238419e-01 0.176158126 9.693314e-01 0.0306686406 0.9802453118 #>  [305,] 8.217409e-01 0.178259141 9.689001e-01 0.0310999262 0.9799643341 #>  [306,] 8.196203e-01 0.180379727 9.684629e-01 0.0315370795 0.9796794428 #>  [307,] 8.174801e-01 0.182519936 9.680198e-01 0.0319801748 0.9793905858 #>  [308,] 8.153202e-01 0.184679818 9.675707e-01 0.0324292871 0.9790977102 #>  [309,] 8.131406e-01 0.186859416 9.671155e-01 0.0328844923 0.9788007628 #>  [310,] 8.109412e-01 0.189058774 9.666541e-01 0.0333458669 0.9784996894 #>  [311,] 8.087221e-01 0.191277928 9.661865e-01 0.0338134883 0.9781944354 #>  [312,] 8.064831e-01 0.193516915 9.657126e-01 0.0342874347 0.9778849455 #>  [313,] 8.042242e-01 0.195775766 9.652322e-01 0.0347677852 0.9775711637 #>  [314,] 8.019455e-01 0.198054508 9.647454e-01 0.0352546195 0.9772530333 #>  [315,] 7.996468e-01 0.200353166 9.642520e-01 0.0357480182 0.9769304970 #>  [316,] 7.973282e-01 0.202671760 9.637519e-01 0.0362480627 0.9766034968 #>  [317,] 7.949897e-01 0.205010308 9.632452e-01 0.0367548352 0.9762719742 #>  [318,] 7.926312e-01 0.207368821 9.627316e-01 0.0372684188 0.9759358697 #>  [319,] 7.902527e-01 0.209747308 9.622111e-01 0.0377888972 0.9755951233 #>  [320,] 7.878542e-01 0.212145775 9.616836e-01 0.0383163552 0.9752496744 #>  [321,] 7.854358e-01 0.214564221 9.611491e-01 0.0388508782 0.9748994615 #>  [322,] 7.829974e-01 0.217002644 9.606074e-01 0.0393925525 0.9745444225 #>  [323,] 7.805390e-01 0.219461036 9.600585e-01 0.0399414652 0.9741844945 #>  [324,] 7.780606e-01 0.221939384 9.595023e-01 0.0404977042 0.9738196141 #>  [325,] 7.755623e-01 0.224437672 9.589386e-01 0.0410613582 0.9734497169 #>  [326,] 7.730441e-01 0.226955879 9.583675e-01 0.0416325169 0.9730747381 #>  [327,] 7.705060e-01 0.229493980 9.577887e-01 0.0422112707 0.9726946118 #>  [328,] 7.679481e-01 0.232051945 9.572023e-01 0.0427977107 0.9723092717 #>  [329,] 7.653703e-01 0.234629739 9.566081e-01 0.0433919289 0.9719186506 #>  [330,] 7.627727e-01 0.237227323 9.560060e-01 0.0439940183 0.9715226805 #>  [331,] 7.601553e-01 0.239844653 9.553959e-01 0.0446040726 0.9711212929 #>  [332,] 7.575183e-01 0.242481680 9.547778e-01 0.0452221861 0.9707144182 #>  [333,] 7.548616e-01 0.245138351 9.541515e-01 0.0458484543 0.9703019864 #>  [334,] 7.521854e-01 0.247814606 9.535170e-01 0.0464829732 0.9698839264 #>  [335,] 7.494896e-01 0.250510383 9.528742e-01 0.0471258398 0.9694601666 #>  [336,] 7.467744e-01 0.253225613 9.522228e-01 0.0477771519 0.9690306345 #>  [337,] 7.440398e-01 0.255960221 9.515630e-01 0.0484370079 0.9685952569 #>  [338,] 7.412859e-01 0.258714131 9.508945e-01 0.0491055074 0.9681539598 #>  [339,] 7.385127e-01 0.261487256 9.502172e-01 0.0497827504 0.9677066684 #>  [340,] 7.357205e-01 0.264279510 9.495312e-01 0.0504688380 0.9672533070 #>  [341,] 7.329092e-01 0.267090796 9.488361e-01 0.0511638718 0.9667937994 #>  [342,] 7.300790e-01 0.269921016 9.481320e-01 0.0518679544 0.9663280683 #>  [343,] 7.272299e-01 0.272770065 9.474188e-01 0.0525811893 0.9658560359 #>  [344,] 7.243622e-01 0.275637832 9.466963e-01 0.0533036804 0.9653776233 #>  [345,] 7.214758e-01 0.278524202 9.459645e-01 0.0540355327 0.9648927510 #>  [346,] 7.185709e-01 0.281429054 9.452231e-01 0.0547768518 0.9644013387 #>  [347,] 7.156477e-01 0.284352262 9.444723e-01 0.0555277442 0.9639033052 #>  [348,] 7.127063e-01 0.287293693 9.437117e-01 0.0562883170 0.9633985686 #>  [349,] 7.097468e-01 0.290253211 9.429413e-01 0.0570586781 0.9628870460 #>  [350,] 7.067693e-01 0.293230672 9.421611e-01 0.0578389362 0.9623686538 #>  [351,] 7.037741e-01 0.296225929 9.413708e-01 0.0586292007 0.9618433077 #>  [352,] 7.007612e-01 0.299238828 9.405704e-01 0.0594295815 0.9613109225 #>  [353,] 6.977308e-01 0.302269209 9.397598e-01 0.0602401897 0.9607714120 #>  [354,] 6.946831e-01 0.305316908 9.389389e-01 0.0610611366 0.9602246895 #>  [355,] 6.916182e-01 0.308381754 9.381075e-01 0.0618925344 0.9596706672 #>  [356,] 6.885364e-01 0.311463572 9.372655e-01 0.0627344961 0.9591092567 #>  [357,] 6.854378e-01 0.314562181 9.364129e-01 0.0635871352 0.9585403686 #>  [358,] 6.823226e-01 0.317677394 9.355494e-01 0.0644505657 0.9579639128 #>  [359,] 6.791910e-01 0.320809018 9.346751e-01 0.0653249027 0.9573797983 #>  [360,] 6.760431e-01 0.323956856 9.337897e-01 0.0662102614 0.9567879334 #>  [361,] 6.728793e-01 0.327120705 9.328932e-01 0.0671067581 0.9561882254 #>  [362,] 6.696996e-01 0.330300357 9.319855e-01 0.0680145093 0.9555805809 #>  [363,] 6.665044e-01 0.333495597 9.310664e-01 0.0689336323 0.9549649056 #>  [364,] 6.632938e-01 0.336706206 9.301358e-01 0.0698642449 0.9543411045 #>  [365,] 6.600680e-01 0.339931960 9.291935e-01 0.0708064654 0.9537090817 #>  [366,] 6.568274e-01 0.343172629 9.282396e-01 0.0717604128 0.9530687405 #>  [367,] 6.535720e-01 0.346427978 9.272738e-01 0.0727262064 0.9524199834 #>  [368,] 6.503022e-01 0.349697766 9.262960e-01 0.0737039662 0.9517627121 #>  [369,] 6.470183e-01 0.352981748 9.253062e-01 0.0746938125 0.9510968274 #>  [370,] 6.437203e-01 0.356279674 9.243041e-01 0.0756958660 0.9504222294 #>  [371,] 6.404087e-01 0.359591288 9.232898e-01 0.0767102482 0.9497388174 #>  [372,] 6.370837e-01 0.362916330 9.222629e-01 0.0777370806 0.9490464898 #>  [373,] 6.337455e-01 0.366254533 9.212235e-01 0.0787764853 0.9483451444 #>  [374,] 6.303944e-01 0.369605628 9.201714e-01 0.0798285846 0.9476346781 #>  [375,] 6.270307e-01 0.372969340 9.191065e-01 0.0808935014 0.9469149869 #>  [376,] 6.236546e-01 0.376345389 9.180286e-01 0.0819713588 0.9461859662 #>  [377,] 6.202665e-01 0.379733490 9.169377e-01 0.0830622800 0.9454475106 #>  [378,] 6.168666e-01 0.383133354 9.158336e-01 0.0841663888 0.9446995139 #>  [379,] 6.134553e-01 0.386544689 9.147162e-01 0.0852838089 0.9439418691 #>  [380,] 6.100328e-01 0.389967196 9.135853e-01 0.0864146644 0.9431744686 #>  [381,] 6.065994e-01 0.393400573 9.124409e-01 0.0875590796 0.9423972040 #>  [382,] 6.031555e-01 0.396844513 9.112828e-01 0.0887171789 0.9416099660 #>  [383,] 5.997013e-01 0.400298708 9.101109e-01 0.0898890868 0.9408126448 #>  [384,] 5.962372e-01 0.403762842 9.089251e-01 0.0910749278 0.9400051299 #>  [385,] 5.927634e-01 0.407236596 9.077252e-01 0.0922748267 0.9391873098 #>  [386,] 5.892803e-01 0.410719650 9.065111e-01 0.0934889080 0.9383590727 #>  [387,] 5.857883e-01 0.414211677 9.052827e-01 0.0947172965 0.9375203058 #>  [388,] 5.822877e-01 0.417712349 9.040399e-01 0.0959601167 0.9366708959 #>  [389,] 5.787787e-01 0.421221332 9.027825e-01 0.0972174931 0.9358107288 #>  [390,] 5.752617e-01 0.424738290 9.015104e-01 0.0984895502 0.9349396901 #>  [391,] 5.717371e-01 0.428262885 9.002236e-01 0.0997764122 0.9340576644 #>  [392,] 5.682052e-01 0.431794775 8.989218e-01 0.1010782031 0.9331645359 #>  [393,] 5.646664e-01 0.435333613 8.976050e-01 0.1023950466 0.9322601880 #>  [394,] 5.611209e-01 0.438879053 8.962729e-01 0.1037270663 0.9313445037 #>  [395,] 5.575693e-01 0.442430743 8.949256e-01 0.1050743854 0.9304173653 #>  [396,] 5.540117e-01 0.445988331 8.935629e-01 0.1064371266 0.9294786548 #>  [397,] 5.504485e-01 0.449551461 8.921846e-01 0.1078154124 0.9285282532 #>  [398,] 5.468802e-01 0.453119775 8.907906e-01 0.1092093647 0.9275660415 #>  [399,] 5.433071e-01 0.456692913 8.893809e-01 0.1106191050 0.9265918997 #>  [400,] 5.397295e-01 0.460270513 8.879552e-01 0.1120447540 0.9256057078 #>  [401,] 5.361478e-01 0.463852212 8.865136e-01 0.1134864323 0.9246073451 #>  [402,] 5.325624e-01 0.467437645 8.850557e-01 0.1149442593 0.9235966903 #>  [403,] 5.289736e-01 0.471026443 8.835816e-01 0.1164183540 0.9225736220 #>  [404,] 5.253818e-01 0.474618239 8.820912e-01 0.1179088347 0.9215380182 #>  [405,] 5.217873e-01 0.478212664 8.805842e-01 0.1194158187 0.9204897567 #>  [406,] 5.181907e-01 0.481809346 8.790606e-01 0.1209394226 0.9194287147 #>  [407,] 5.145921e-01 0.485407914 8.775202e-01 0.1224797621 0.9183547693 #>  [408,] 5.109920e-01 0.489007996 8.759630e-01 0.1240369519 0.9172677972 #>  [409,] 5.073908e-01 0.492609219 8.743889e-01 0.1256111056 0.9161676749 #>  [410,] 5.037888e-01 0.496211208 8.727977e-01 0.1272023359 0.9150542786 #>  [411,] 5.001864e-01 0.499813591 8.711892e-01 0.1288107543 0.9139274842 #>  [412,] 4.965840e-01 0.503415994 8.695635e-01 0.1304364709 0.9127871676 #>  [413,] 4.929820e-01 0.507018041 8.679204e-01 0.1320795950 0.9116332044 #>  [414,] 4.893806e-01 0.510619361 8.662598e-01 0.1337402343 0.9104654702 #>  [415,] 4.857804e-01 0.514219578 8.645815e-01 0.1354184950 0.9092838404 #>  [416,] 4.821817e-01 0.517818320 8.628855e-01 0.1371144823 0.9080881903 #>  [417,] 4.785848e-01 0.521415215 8.611717e-01 0.1388282995 0.9068783952 #>  [418,] 4.749901e-01 0.525009890 8.594400e-01 0.1405600486 0.9056543306 #>  [419,] 4.713980e-01 0.528601976 8.576902e-01 0.1423098298 0.9044158718 #>  [420,] 4.678089e-01 0.532191102 8.559223e-01 0.1440777418 0.9031628942 #>  [421,] 4.642231e-01 0.535776899 8.541361e-01 0.1458638814 0.9018952735 #>  [422,] 4.606410e-01 0.539359002 8.523317e-01 0.1476683437 0.9006128853 #>  [423,] 4.570630e-01 0.542937043 8.505088e-01 0.1494912218 0.8993156056 #>  [424,] 4.534893e-01 0.546510660 8.486674e-01 0.1513326069 0.8980033104 #>  [425,] 4.499205e-01 0.550079490 8.468074e-01 0.1531925882 0.8966758763 #>  [426,] 4.463568e-01 0.553643173 8.449287e-01 0.1550712529 0.8953331799 #>  [427,] 4.427986e-01 0.557201351 8.430313e-01 0.1569686858 0.8939750982 #>  [428,] 4.392463e-01 0.560753668 8.411150e-01 0.1588849696 0.8926015089 #>  [429,] 4.357002e-01 0.564299771 8.391798e-01 0.1608201848 0.8912122897 #>  [430,] 4.321607e-01 0.567839309 8.372256e-01 0.1627744094 0.8898073191 #>  [431,] 4.286281e-01 0.571371933 8.352523e-01 0.1647477190 0.8883864761 #>  [432,] 4.251027e-01 0.574897299 8.332598e-01 0.1667401866 0.8869496401 #>  [433,] 4.215849e-01 0.578415063 8.312481e-01 0.1687518827 0.8854966912 #>  [434,] 4.180751e-01 0.581924887 8.292171e-01 0.1707828752 0.8840275105 #>  [435,] 4.145736e-01 0.585426434 8.271668e-01 0.1728332291 0.8825419793 #>  [436,] 4.110806e-01 0.588919372 8.250970e-01 0.1749030066 0.8810399800 #>  [437,] 4.075966e-01 0.592403369 8.230077e-01 0.1769922672 0.8795213959 #>  [438,] 4.041219e-01 0.595878101 8.208989e-01 0.1791010673 0.8779861109 #>  [439,] 4.006568e-01 0.599343245 8.187705e-01 0.1812294602 0.8764340101 #>  [440,] 3.972015e-01 0.602798483 8.166225e-01 0.1833774962 0.8748649796 #>  [441,] 3.937565e-01 0.606243500 8.144548e-01 0.1855452225 0.8732789062 #>  [442,] 3.903220e-01 0.609677984 8.122673e-01 0.1877326827 0.8716756783 #>  [443,] 3.868984e-01 0.613101630 8.100601e-01 0.1899399176 0.8700551852 #>  [444,] 3.834859e-01 0.616514135 8.078330e-01 0.1921669640 0.8684173174 #>  [445,] 3.800848e-01 0.619915200 8.055861e-01 0.1944138557 0.8667619667 #>  [446,] 3.766955e-01 0.623304532 8.033194e-01 0.1966806227 0.8650890264 #>  [447,] 3.733182e-01 0.626681841 8.010327e-01 0.1989672914 0.8633983911 #>  [448,] 3.699532e-01 0.630046843 7.987261e-01 0.2012738846 0.8616899569 #>  [449,] 3.666007e-01 0.633399256 7.963996e-01 0.2036004211 0.8599636213 #>  [450,] 3.632612e-01 0.636738807 7.940531e-01 0.2059469161 0.8582192836 #>  [451,] 3.599348e-01 0.640065223 7.916866e-01 0.2083133807 0.8564568447 #>  [452,] 3.566218e-01 0.643378238 7.893002e-01 0.2106998222 0.8546762072 #>  [453,] 3.533224e-01 0.646677593 7.868938e-01 0.2131062436 0.8528772754 #>  [454,] 3.500370e-01 0.649963030 7.844674e-01 0.2155326441 0.8510599557 #>  [455,] 3.467657e-01 0.653234298 7.820210e-01 0.2179790182 0.8492241562 #>  [456,] 3.435088e-01 0.656491153 7.795546e-01 0.2204453567 0.8473697872 #>  [457,] 3.402666e-01 0.659733352 7.770684e-01 0.2229316457 0.8454967609 #>  [458,] 3.370393e-01 0.662960660 7.745621e-01 0.2254378669 0.8436049917 #>  [459,] 3.338272e-01 0.666172847 7.720360e-01 0.2279639977 0.8416943962 #>  [460,] 3.306303e-01 0.669369688 7.694900e-01 0.2305100110 0.8397648933 #>  [461,] 3.274490e-01 0.672550963 7.669241e-01 0.2330758749 0.8378164043 #>  [462,] 3.242835e-01 0.675716457 7.643384e-01 0.2356615529 0.8358488529 #>  [463,] 3.211340e-01 0.678865962 7.617330e-01 0.2382670040 0.8338621651 #>  [464,] 3.180007e-01 0.681999273 7.591078e-01 0.2408921823 0.8318562698 #>  [465,] 3.148838e-01 0.685116193 7.564630e-01 0.2435370368 0.8298310983 #>  [466,] 3.117835e-01 0.688216529 7.537985e-01 0.2462015121 0.8277865847 #>  [467,] 3.086999e-01 0.691300094 7.511145e-01 0.2488855477 0.8257226659 #>  [468,] 3.056333e-01 0.694366705 7.484109e-01 0.2515890778 0.8236392817 #>  [469,] 3.025838e-01 0.697416186 7.456880e-01 0.2543120320 0.8215363746 #>  [470,] 2.995516e-01 0.700448367 7.429457e-01 0.2570543347 0.8194138905 #>  [471,] 2.965369e-01 0.703463083 7.401841e-01 0.2598159050 0.8172717780 #>  [472,] 2.935398e-01 0.706460173 7.374033e-01 0.2625966570 0.8151099892 #>  [473,] 2.905605e-01 0.709439483 7.346035e-01 0.2653964995 0.8129284792 #>  [474,] 2.875991e-01 0.712400864 7.317847e-01 0.2682153362 0.8107272065 #>  [475,] 2.846558e-01 0.715344174 7.289469e-01 0.2710530654 0.8085061330 #>  [476,] 2.817307e-01 0.718269273 7.260904e-01 0.2739095800 0.8062652240 #>  [477,] 2.788240e-01 0.721176031 7.232152e-01 0.2767847678 0.8040044484 #>  [478,] 2.759357e-01 0.724064319 7.203215e-01 0.2796785109 0.8017237786 #>  [479,] 2.730660e-01 0.726934017 7.174093e-01 0.2825906863 0.7994231909 #>  [480,] 2.702150e-01 0.729785008 7.144788e-01 0.2855211655 0.7971026651 #>  [481,] 2.673828e-01 0.732617182 7.115302e-01 0.2884698143 0.7947621850 #>  [482,] 2.645696e-01 0.735430432 7.085635e-01 0.2914364935 0.7924017381 #>  [483,] 2.617753e-01 0.738224660 7.055789e-01 0.2944210580 0.7900213162 #>  [484,] 2.590002e-01 0.740999769 7.025766e-01 0.2974233574 0.7876209148 #>  [485,] 2.562443e-01 0.743755671 6.995568e-01 0.3004432357 0.7852005337 #>  [486,] 2.535077e-01 0.746492281 6.965195e-01 0.3034805317 0.7827601768 #>  [487,] 2.507905e-01 0.749209520 6.934649e-01 0.3065350783 0.7802998523 #>  [488,] 2.480927e-01 0.751907313 6.903933e-01 0.3096067031 0.7778195727 #>  [489,] 2.454144e-01 0.754585592 6.873048e-01 0.3126952282 0.7753193549 #>  [490,] 2.427557e-01 0.757244292 6.841995e-01 0.3158004702 0.7727992202 #>  [491,] 2.401166e-01 0.759883355 6.810778e-01 0.3189222402 0.7702591943 #>  [492,] 2.374973e-01 0.762502726 6.779397e-01 0.3220603437 0.7676993078 #>  [493,] 2.348976e-01 0.765102355 6.747854e-01 0.3252145810 0.7651195957 #>  [494,] 2.323178e-01 0.767682199 6.716153e-01 0.3283847468 0.7625200976 #>  [495,] 2.297578e-01 0.770242218 6.684294e-01 0.3315706306 0.7599008580 #>  [496,] 2.272176e-01 0.772782376 6.652280e-01 0.3347720162 0.7572619263 #>  [497,] 2.246974e-01 0.775302643 6.620113e-01 0.3379886823 0.7546033566 #>  [498,] 2.221970e-01 0.777802994 6.587796e-01 0.3412204022 0.7519252079 #>  [499,] 2.197166e-01 0.780283406 6.555331e-01 0.3444669441 0.7492275443 #>  [500,] 2.172561e-01 0.782743864 6.522719e-01 0.3477280708 0.7465104348 #>  [501,] 2.148156e-01 0.785184353 6.489965e-01 0.3510035398 0.7437739536 #>  [502,] 2.123951e-01 0.787604868 6.457069e-01 0.3542931038 0.7410181798 #>  [503,] 2.099946e-01 0.790005402 6.424035e-01 0.3575965103 0.7382431979 #>  [504,] 2.076140e-01 0.792385957 6.390865e-01 0.3609135016 0.7354490974 #>  [505,] 2.052535e-01 0.794746537 6.357562e-01 0.3642438153 0.7326359732 #>  [506,] 2.029129e-01 0.797087150 6.324128e-01 0.3675871840 0.7298039254 #>  [507,] 2.005922e-01 0.799407808 6.290567e-01 0.3709433355 0.7269530592 #>  [508,] 1.982915e-01 0.801708529 6.256880e-01 0.3743119927 0.7240834855 #>  [509,] 1.960107e-01 0.803989331 6.223071e-01 0.3776928742 0.7211953204 #>  [510,] 1.937498e-01 0.806250239 6.189143e-01 0.3810856935 0.7182886854 #>  [511,] 1.915087e-01 0.808491280 6.155098e-01 0.3844901600 0.7153637073 #>  [512,] 1.892875e-01 0.810712486 6.120940e-01 0.3879059786 0.7124205185 #>  [513,] 1.870861e-01 0.812913890 6.086672e-01 0.3913328496 0.7094592569 #>  [514,] 1.849045e-01 0.815095531 6.052295e-01 0.3947704693 0.7064800657 #>  [515,] 1.827425e-01 0.817257451 6.017815e-01 0.3982185300 0.7034830937 #>  [516,] 1.806003e-01 0.819399695 5.983233e-01 0.4016767195 0.7004684951 #>  [517,] 1.784777e-01 0.821522309 5.948553e-01 0.4051447220 0.6974364297 #>  [518,] 1.763747e-01 0.823625347 5.913778e-01 0.4086222178 0.6943870629 #>  [519,] 1.742911e-01 0.825708861 5.878911e-01 0.4121088834 0.6913205652 #>  [520,] 1.722271e-01 0.827772909 5.843956e-01 0.4156043917 0.6882371131 #>  [521,] 1.701824e-01 0.829817551 5.808916e-01 0.4191084122 0.6851368883 #>  [522,] 1.681571e-01 0.831842851 5.773794e-01 0.4226206109 0.6820200780 #>  [523,] 1.661511e-01 0.833848875 5.738593e-01 0.4261406505 0.6788868750 #>  [524,] 1.641643e-01 0.835835690 5.703318e-01 0.4296681908 0.6757374775 #>  [525,] 1.621966e-01 0.837803369 5.667971e-01 0.4332028883 0.6725720890 #>  [526,] 1.602480e-01 0.839751984 5.632556e-01 0.4367443968 0.6693909186 #>  [527,] 1.583184e-01 0.841681613 5.597076e-01 0.4402923673 0.6661941806 #>  [528,] 1.564077e-01 0.843592335 5.561536e-01 0.4438464480 0.6629820949 #>  [529,] 1.545158e-01 0.845484229 5.525937e-01 0.4474062850 0.6597548865 #>  [530,] 1.526426e-01 0.847357380 5.490285e-01 0.4509715218 0.6565127858 #>  [531,] 1.507881e-01 0.849211873 5.454582e-01 0.4545417996 0.6532560282 #>  [532,] 1.489522e-01 0.851047795 5.418832e-01 0.4581167579 0.6499848547 #>  [533,] 1.471348e-01 0.852865238 5.383040e-01 0.4616960338 0.6466995112 #>  [534,] 1.453357e-01 0.854664292 5.347207e-01 0.4652792630 0.6434002486 #>  [535,] 1.435549e-01 0.856445051 5.311339e-01 0.4688660795 0.6400873230 #>  [536,] 1.417924e-01 0.858207610 5.275439e-01 0.4724561157 0.6367609954 #>  [537,] 1.400479e-01 0.859952068 5.239510e-01 0.4760490028 0.6334215317 #>  [538,] 1.383215e-01 0.861678523 5.203556e-01 0.4796443707 0.6300692028 #>  [539,] 1.366129e-01 0.863387076 5.167582e-01 0.4832418484 0.6267042841 #>  [540,] 1.349222e-01 0.865077830 5.131589e-01 0.4868410640 0.6233270559 #>  [541,] 1.332491e-01 0.866750888 5.095584e-01 0.4904416447 0.6199378030 #>  [542,] 1.315936e-01 0.868406355 5.059568e-01 0.4940432174 0.6165368149 #>  [543,] 1.299557e-01 0.870044339 5.023546e-01 0.4976454084 0.6131243854 #>  [544,] 1.283351e-01 0.871664947 4.987522e-01 0.5012478439 0.6097008128 #>  [545,] 1.267317e-01 0.873268290 4.951499e-01 0.5048501498 0.6062663994 #>  [546,] 1.251455e-01 0.874854477 4.915480e-01 0.5084519522 0.6028214519 #>  [547,] 1.235764e-01 0.876423621 4.879471e-01 0.5120528775 0.5993662812 #>  [548,] 1.220242e-01 0.877975834 4.843474e-01 0.5156525521 0.5959012019 #>  [549,] 1.204888e-01 0.879511230 4.807494e-01 0.5192506033 0.5924265325 #>  [550,] 1.189701e-01 0.881029925 4.771533e-01 0.5228466590 0.5889425955 #>  [551,] 1.174680e-01 0.882532035 4.735597e-01 0.5264403477 0.5854497169 #>  [552,] 1.159823e-01 0.884017675 4.699687e-01 0.5300312990 0.5819482261 #>  [553,] 1.145130e-01 0.885486964 4.663809e-01 0.5336191439 0.5784384561 #>  [554,] 1.130600e-01 0.886940021 4.627965e-01 0.5372035142 0.5749207433 #>  [555,] 1.116230e-01 0.888376964 4.592160e-01 0.5407840436 0.5713954269 #>  [556,] 1.102021e-01 0.889797913 4.556396e-01 0.5443603670 0.5678628496 #>  [557,] 1.087970e-01 0.891202989 4.520679e-01 0.5479321212 0.5643233566 #>  [558,] 1.074077e-01 0.892592312 4.485011e-01 0.5514989450 0.5607772963 #>  [559,] 1.060340e-01 0.893966005 4.449395e-01 0.5550604790 0.5572250194 #>  [560,] 1.046758e-01 0.895324190 4.413836e-01 0.5586163660 0.5536668793 #>  [561,] 1.033330e-01 0.896666988 4.378337e-01 0.5621662512 0.5501032319 #>  [562,] 1.020055e-01 0.897994523 4.342902e-01 0.5657097822 0.5465344350 #>  [563,] 1.006931e-01 0.899306919 4.307534e-01 0.5692466092 0.5429608489 #>  [564,] 9.939570e-02 0.900604298 4.272236e-01 0.5727763851 0.5393828356 #>  [565,] 9.811321e-02 0.901886785 4.237012e-01 0.5762987655 0.5358007591 #>  [566,] 9.684550e-02 0.903154504 4.201866e-01 0.5798134091 0.5322149848 #>  [567,] 9.559242e-02 0.904407578 4.166800e-01 0.5833199779 0.5286258799 #>  [568,] 9.435387e-02 0.905646134 4.131819e-01 0.5868181367 0.5250338129 #>  [569,] 9.312971e-02 0.906870294 4.096924e-01 0.5903075540 0.5214391534 #>  [570,] 9.191982e-02 0.908080183 4.062121e-01 0.5937879015 0.5178422723 #>  [571,] 9.072407e-02 0.909275927 4.027411e-01 0.5972588548 0.5142435412 #>  [572,] 8.954235e-02 0.910457650 3.992799e-01 0.6007200929 0.5106433325 #>  [573,] 8.837452e-02 0.911625476 3.958287e-01 0.6041712987 0.5070420194 #>  [574,] 8.722047e-02 0.912779531 3.923878e-01 0.6076121591 0.5034399753 #>  [575,] 8.608006e-02 0.913919938 3.889576e-01 0.6110423650 0.4998375741 #>  [576,] 8.495318e-02 0.915046822 3.855384e-01 0.6144616112 0.4962351898 #>  [577,] 8.383969e-02 0.916160307 3.821304e-01 0.6178695969 0.4926331963 #>  [578,] 8.273948e-02 0.917260517 3.787340e-01 0.6212660257 0.4890319675 #>  [579,] 8.165242e-02 0.918347576 3.753494e-01 0.6246506054 0.4854318768 #>  [580,] 8.057839e-02 0.919421608 3.719770e-01 0.6280230484 0.4818332972 #>  [581,] 7.951726e-02 0.920482735 3.686169e-01 0.6313830717 0.4782366012 #>  [582,] 7.846892e-02 0.921531082 3.652696e-01 0.6347303967 0.4746421603 #>  [583,] 7.743323e-02 0.922566769 3.619353e-01 0.6380647499 0.4710503452 #>  [584,] 7.641008e-02 0.923589921 3.586141e-01 0.6413858624 0.4674615256 #>  [585,] 7.539934e-02 0.924600658 3.553065e-01 0.6446934701 0.4638760697 #>  [586,] 7.440090e-02 0.925599102 3.520127e-01 0.6479873139 0.4602943446 #>  [587,] 7.341463e-02 0.926585374 3.487329e-01 0.6512671399 0.4567167156 #>  [588,] 7.244040e-02 0.927559596 3.454673e-01 0.6545326989 0.4531435466 #>  [589,] 7.147811e-02 0.928521887 3.422163e-01 0.6577837470 0.4495751993 #>  [590,] 7.052763e-02 0.929472366 3.389800e-01 0.6610200456 0.4460120339 #>  [591,] 6.958885e-02 0.930411154 3.357586e-01 0.6642413610 0.4424544079 #>  [592,] 6.866163e-02 0.931338369 3.325525e-01 0.6674474649 0.4389026772 #>  [593,] 6.774587e-02 0.932254130 3.293619e-01 0.6706381345 0.4353571947 #>  [594,] 6.684145e-02 0.933158553 3.261868e-01 0.6738131519 0.4318183111 #>  [595,] 6.594824e-02 0.934051755 3.230277e-01 0.6769723049 0.4282863744 #>  [596,] 6.506615e-02 0.934933855 3.198846e-01 0.6801153867 0.4247617297 #>  [597,] 6.419503e-02 0.935804966 3.167578e-01 0.6832421956 0.4212447192 #>  [598,] 6.333479e-02 0.936665205 3.136475e-01 0.6863525357 0.4177356821 #>  [599,] 6.248531e-02 0.937514686 3.105538e-01 0.6894462164 0.4142349543 #>  [600,] 6.164648e-02 0.938353524 3.074769e-01 0.6925230526 0.4107428685 #>  [601,] 6.081817e-02 0.939181831 3.044171e-01 0.6955828647 0.4072597539 #>  [602,] 6.000028e-02 0.939999720 3.013745e-01 0.6986254785 0.4037859361 #>  [603,] 5.919270e-02 0.940807303 2.983493e-01 0.7016507254 0.4003217373 #>  [604,] 5.839531e-02 0.941604691 2.953416e-01 0.7046584424 0.3968674756 #>  [605,] 5.760800e-02 0.942391996 2.923515e-01 0.7076484717 0.3934234654 #>  [606,] 5.683067e-02 0.943169327 2.893793e-01 0.7106206614 0.3899900170 #>  [607,] 5.606321e-02 0.943936793 2.864251e-01 0.7135748647 0.3865674368 #>  [608,] 5.530550e-02 0.944694502 2.834891e-01 0.7165109405 0.3831560269 #>  [609,] 5.455744e-02 0.945442563 2.805712e-01 0.7194287532 0.3797560851 #>  [610,] 5.381892e-02 0.946181081 2.776718e-01 0.7223281725 0.3763679047 #>  [611,] 5.308984e-02 0.946910165 2.747909e-01 0.7252090737 0.3729917749 #>  [612,] 5.237008e-02 0.947629917 2.719287e-01 0.7280713374 0.3696279801 #>  [613,] 5.165956e-02 0.948340445 2.690852e-01 0.7309148496 0.3662768000 #>  [614,] 5.095815e-02 0.949041851 2.662605e-01 0.7337395016 0.3629385099 #>  [615,] 5.026576e-02 0.949734238 2.634548e-01 0.7365451901 0.3596133800 #>  [616,] 4.958229e-02 0.950417709 2.606682e-01 0.7393318171 0.3563016758 #>  [617,] 4.890763e-02 0.951092365 2.579007e-01 0.7420992899 0.3530036579 #>  [618,] 4.824169e-02 0.951758308 2.551525e-01 0.7448475208 0.3497195819 #>  [619,] 4.758436e-02 0.952415636 2.524236e-01 0.7475764277 0.3464496984 #>  [620,] 4.693555e-02 0.953064449 2.497141e-01 0.7502859331 0.3431942527 #>  [621,] 4.629515e-02 0.953704846 2.470240e-01 0.7529759651 0.3399534853 #>  [622,] 4.566308e-02 0.954336924 2.443535e-01 0.7556464564 0.3367276312 #>  [623,] 4.503922e-02 0.954960780 2.417027e-01 0.7582973451 0.3335169203 #>  [624,] 4.442349e-02 0.955576509 2.390714e-01 0.7609285740 0.3303215773 #>  [625,] 4.381579e-02 0.956184206 2.364599e-01 0.7635400909 0.3271418213 #>  [626,] 4.321603e-02 0.956783967 2.338682e-01 0.7661318483 0.3239778663 #>  [627,] 4.262412e-02 0.957375884 2.312962e-01 0.7687038037 0.3208299208 #>  [628,] 4.203995e-02 0.957960050 2.287441e-01 0.7712559191 0.3176981879 #>  [629,] 4.146344e-02 0.958536556 2.262118e-01 0.7737881614 0.3145828655 #>  [630,] 4.089451e-02 0.959105494 2.236995e-01 0.7763005020 0.3114841455 #>  [631,] 4.033305e-02 0.959666954 2.212071e-01 0.7787929168 0.3084022149 #>  [632,] 3.977897e-02 0.960221025 2.187346e-01 0.7812653862 0.3053372549 #>  [633,] 3.923220e-02 0.960767796 2.162821e-01 0.7837178951 0.3022894413 #>  [634,] 3.869265e-02 0.961307354 2.138496e-01 0.7861504327 0.2992589443 #>  [635,] 3.816021e-02 0.961839787 2.114370e-01 0.7885629925 0.2962459287 #>  [636,] 3.763482e-02 0.962365179 2.090444e-01 0.7909555722 0.2932505538 #>  [637,] 3.711638e-02 0.962883618 2.066718e-01 0.7933281736 0.2902729734 #>  [638,] 3.660481e-02 0.963395186 2.043192e-01 0.7956808028 0.2873133357 #>  [639,] 3.610003e-02 0.963899967 2.019865e-01 0.7980134696 0.2843717835 #>  [640,] 3.560195e-02 0.964398045 1.996738e-01 0.8003261880 0.2814484542 #>  [641,] 3.511050e-02 0.964889501 1.973810e-01 0.8026189757 0.2785434795 #>  [642,] 3.462558e-02 0.965374417 1.951081e-01 0.8048918544 0.2756569860 #>  [643,] 3.414713e-02 0.965852872 1.928552e-01 0.8071448492 0.2727890946 #>  [644,] 3.367505e-02 0.966324947 1.906220e-01 0.8093779892 0.2699399209 #>  [645,] 3.320928e-02 0.966790720 1.884087e-01 0.8115913068 0.2671095752 #>  [646,] 3.274973e-02 0.967250268 1.862152e-01 0.8137848382 0.2642981625 #>  [647,] 3.229633e-02 0.967703670 1.840414e-01 0.8159586227 0.2615057822 #>  [648,] 3.184900e-02 0.968151002 1.818873e-01 0.8181127032 0.2587325288 #>  [649,] 3.140766e-02 0.968592339 1.797529e-01 0.8202471258 0.2559784914 #>  [650,] 3.097224e-02 0.969027755 1.776381e-01 0.8223619397 0.2532437538 #>  [651,] 3.054267e-02 0.969457326 1.755428e-01 0.8244571974 0.2505283949 #>  [652,] 3.011888e-02 0.969881124 1.734670e-01 0.8265329545 0.2478324883 #>  [653,] 2.970078e-02 0.970299222 1.714107e-01 0.8285892693 0.2451561026 #>  [654,] 2.928831e-02 0.970711691 1.693738e-01 0.8306262032 0.2424993013 #>  [655,] 2.888140e-02 0.971118602 1.673562e-01 0.8326438206 0.2398621432 #>  [656,] 2.847997e-02 0.971520026 1.653578e-01 0.8346421883 0.2372446819 #>  [657,] 2.808397e-02 0.971916032 1.633786e-01 0.8366213760 0.2346469663 #>  [658,] 2.769331e-02 0.972306689 1.614185e-01 0.8385814560 0.2320690403 #>  [659,] 2.730794e-02 0.972692064 1.594775e-01 0.8405225032 0.2295109434 #>  [660,] 2.692778e-02 0.973072225 1.575554e-01 0.8424445948 0.2269727101 #>  [661,] 2.655276e-02 0.973447237 1.556522e-01 0.8443478104 0.2244543704 #>  [662,] 2.618283e-02 0.973817168 1.537678e-01 0.8462322322 0.2219559497 #>  [663,] 2.581792e-02 0.974182082 1.519021e-01 0.8480979444 0.2194774689 #>  [664,] 2.545796e-02 0.974542043 1.500550e-01 0.8499450333 0.2170189446 #>  [665,] 2.510289e-02 0.974897114 1.482264e-01 0.8517735876 0.2145803887 #>  [666,] 2.475264e-02 0.975247359 1.464163e-01 0.8535836978 0.2121618092 #>  [667,] 2.440716e-02 0.975592839 1.446245e-01 0.8553754566 0.2097632095 #>  [668,] 2.406638e-02 0.975933617 1.428510e-01 0.8571489583 0.2073845891 #>  [669,] 2.373025e-02 0.976269752 1.410957e-01 0.8589042994 0.2050259431 #>  [670,] 2.339870e-02 0.976601305 1.393584e-01 0.8606415778 0.2026872629 #>  [671,] 2.307167e-02 0.976928335 1.376391e-01 0.8623608933 0.2003685358 #>  [672,] 2.274910e-02 0.977250901 1.359377e-01 0.8640623474 0.1980697450 #>  [673,] 2.243094e-02 0.977569060 1.342540e-01 0.8657460431 0.1957908703 #>  [674,] 2.211713e-02 0.977882871 1.325879e-01 0.8674120849 0.1935318873 #>  [675,] 2.180761e-02 0.978192389 1.309394e-01 0.8690605786 0.1912927683 #>  [676,] 2.150233e-02 0.978497671 1.293084e-01 0.8706916317 0.1890734818 #>  [677,] 2.120123e-02 0.978798772 1.276946e-01 0.8723053529 0.1868739929 #>  [678,] 2.090425e-02 0.979095747 1.260981e-01 0.8739018519 0.1846942630 #>  [679,] 2.061135e-02 0.979388649 1.245188e-01 0.8754812400 0.1825342504 #>  [680,] 2.032247e-02 0.979677533 1.229564e-01 0.8770436295 0.1803939099 #>  [681,] 2.003755e-02 0.979962451 1.214109e-01 0.8785891337 0.1782731933 #>  [682,] 1.975655e-02 0.980243454 1.198821e-01 0.8801178669 0.1761720490 #>  [683,] 1.947940e-02 0.980520595 1.183701e-01 0.8816299446 0.1740904224 #>  [684,] 1.920608e-02 0.980793925 1.168745e-01 0.8831254831 0.1720282560 #>  [685,] 1.893651e-02 0.981063493 1.153954e-01 0.8846045994 0.1699854892 #>  [686,] 1.867065e-02 0.981329350 1.139326e-01 0.8860674117 0.1679620586 #>  [687,] 1.840846e-02 0.981591545 1.124860e-01 0.8875140385 0.1659578982 #>  [688,] 1.814987e-02 0.981850125 1.110554e-01 0.8889445993 0.1639729391 #>  [689,] 1.789486e-02 0.982105140 1.096408e-01 0.8903592143 0.1620071096 #>  [690,] 1.764336e-02 0.982356636 1.082420e-01 0.8917580042 0.1600603359 #>  [691,] 1.739534e-02 0.982604660 1.068589e-01 0.8931410901 0.1581325413 #>  [692,] 1.715074e-02 0.982849258 1.054914e-01 0.8945085940 0.1562236468 #>  [693,] 1.690952e-02 0.983090476 1.041394e-01 0.8958606381 0.1543335712 #>  [694,] 1.667164e-02 0.983328359 1.028027e-01 0.8971973451 0.1524622309 #>  [695,] 1.643705e-02 0.983562951 1.014812e-01 0.8985188380 0.1506095400 #>  [696,] 1.620570e-02 0.983794297 1.001748e-01 0.8998252402 0.1487754106 #>  [697,] 1.597756e-02 0.984022439 9.888332e-02 0.9011166755 0.1469597528 #>  [698,] 1.575258e-02 0.984247421 9.760673e-02 0.9023932678 0.1451624746 #>  [699,] 1.553071e-02 0.984469286 9.634486e-02 0.9036551413 0.1433834821 #>  [700,] 1.531193e-02 0.984688074 9.509758e-02 0.9049024203 0.1416226795 #>  [701,] 1.509617e-02 0.984903827 9.386477e-02 0.9061352293 0.1398799693 #>  [702,] 1.488341e-02 0.985116586 9.264631e-02 0.9073536929 0.1381552521 #>  [703,] 1.467361e-02 0.985326391 9.144206e-02 0.9085579357 0.1364484271 #>  [704,] 1.446672e-02 0.985533282 9.025192e-02 0.9097480823 0.1347593917 #>  [705,] 1.426270e-02 0.985737298 8.907574e-02 0.9109242576 0.1330880419 #>  [706,] 1.406152e-02 0.985938478 8.791341e-02 0.9120865859 0.1314342722 #>  [707,] 1.386314e-02 0.986136860 8.676481e-02 0.9132351920 0.1297979756 #>  [708,] 1.366752e-02 0.986332482 8.562980e-02 0.9143702002 0.1281790438 #>  [709,] 1.347462e-02 0.986525382 8.450827e-02 0.9154917347 0.1265773674 #>  [710,] 1.328440e-02 0.986715596 8.340008e-02 0.9165999199 0.1249928355 #>  [711,] 1.309684e-02 0.986903160 8.230512e-02 0.9176948795 0.1234253362 #>  [712,] 1.291189e-02 0.987088110 8.122326e-02 0.9187767372 0.1218747565 #>  [713,] 1.272952e-02 0.987270483 8.015438e-02 0.9198456166 0.1203409823 #>  [714,] 1.254969e-02 0.987450312 7.909836e-02 0.9209016407 0.1188238985 #>  [715,] 1.237237e-02 0.987627633 7.805507e-02 0.9219449325 0.1173233890 #>  [716,] 1.219752e-02 0.987802479 7.702439e-02 0.9229756144 0.1158393371 #>  [717,] 1.202512e-02 0.987974884 7.600619e-02 0.9239938086 0.1143716249 #>  [718,] 1.185512e-02 0.988144882 7.500036e-02 0.9249996369 0.1129201339 #>  [719,] 1.168749e-02 0.988312505 7.400678e-02 0.9259932206 0.1114847450 #>  [720,] 1.152221e-02 0.988477786 7.302532e-02 0.9269746808 0.1100653382 #>  [721,] 1.135924e-02 0.988640756 7.205586e-02 0.9279441380 0.1086617930 #>  [722,] 1.119855e-02 0.988801447 7.109829e-02 0.9289017121 0.1072739882 #>  [723,] 1.104011e-02 0.988959890 7.015248e-02 0.9298475227 0.1059018023 #>  [724,] 1.088388e-02 0.989116116 6.921831e-02 0.9307816889 0.1045451131 #>  [725,] 1.072984e-02 0.989270156 6.829567e-02 0.9317043293 0.1032037980 #>  [726,] 1.057796e-02 0.989422039 6.738444e-02 0.9326155616 0.1018777340 #>  [727,] 1.042821e-02 0.989571794 6.648450e-02 0.9335155035 0.1005667980 #>  [728,] 1.028055e-02 0.989719451 6.559573e-02 0.9344042717 0.0992708662 #>  [729,] 1.013496e-02 0.989865039 6.471802e-02 0.9352819825 0.0979898147 #>  [730,] 9.991414e-03 0.990008586 6.385125e-02 0.9361487516 0.0967235196 #>  [731,] 9.849879e-03 0.990150121 6.299531e-02 0.9370046938 0.0954718563 #>  [732,] 9.710330e-03 0.990289670 6.215008e-02 0.9378499238 0.0942347006 #>  [733,] 9.572739e-03 0.990427261 6.131544e-02 0.9386845550 0.0930119279 #>  [734,] 9.437080e-03 0.990562920 6.049130e-02 0.9395087007 0.0918034135 #>  [735,] 9.303324e-03 0.990696676 5.967753e-02 0.9403224733 0.0906090328 #>  [736,] 9.171447e-03 0.990828553 5.887402e-02 0.9411259844 0.0894286611 #>  [737,] 9.041422e-03 0.990958578 5.808065e-02 0.9419193452 0.0882621738 #>  [738,] 8.913224e-03 0.991086776 5.729733e-02 0.9427026658 0.0871094463 #>  [739,] 8.786827e-03 0.991213173 5.652394e-02 0.9434760559 0.0859703542 #>  [740,] 8.662207e-03 0.991337793 5.576038e-02 0.9442396244 0.0848447731 #>  [741,] 8.539340e-03 0.991460660 5.500652e-02 0.9449934794 0.0837325788 #>  [742,] 8.418200e-03 0.991581800 5.426227e-02 0.9457377283 0.0826336474 #>  [743,] 8.298765e-03 0.991701235 5.352752e-02 0.9464724777 0.0815478550 #>  [744,] 8.181010e-03 0.991818990 5.280217e-02 0.9471978336 0.0804750783 #>  [745,] 8.064912e-03 0.991935088 5.208610e-02 0.9479139011 0.0794151938 #>  [746,] 7.950449e-03 0.992049551 5.137922e-02 0.9486207845 0.0783680787 #>  [747,] 7.837597e-03 0.992162403 5.068141e-02 0.9493185874 0.0773336103 #>  [748,] 7.726335e-03 0.992273665 4.999259e-02 0.9500074126 0.0763116664 #>  [749,] 7.616640e-03 0.992383360 4.931264e-02 0.9506873621 0.0753021250 #>  [750,] 7.508491e-03 0.992491509 4.864146e-02 0.9513585371 0.0743048647 #>  [751,] 7.401866e-03 0.992598134 4.797896e-02 0.9520210380 0.0733197644 #>  [752,] 7.296744e-03 0.992703256 4.732504e-02 0.9526749645 0.0723467034 #>  [753,] 7.193104e-03 0.992806896 4.667958e-02 0.9533204153 0.0713855615 #>  [754,] 7.090925e-03 0.992909075 4.604251e-02 0.9539574885 0.0704362191 #>  [755,] 6.990188e-03 0.993009812 4.541372e-02 0.9545862812 0.0694985569 #>  [756,] 6.890872e-03 0.993109128 4.479311e-02 0.9552068899 0.0685724563 #>  [757,] 6.792958e-03 0.993207042 4.418059e-02 0.9558194100 0.0676577991 #>  [758,] 6.696425e-03 0.993303575 4.357606e-02 0.9564239364 0.0667544677 #>  [759,] 6.601255e-03 0.993398745 4.297944e-02 0.9570205630 0.0658623451 #>  [760,] 6.507429e-03 0.993492571 4.239062e-02 0.9576093828 0.0649813149 #>  [761,] 6.414927e-03 0.993585073 4.180951e-02 0.9581904882 0.0641112613 #>  [762,] 6.323733e-03 0.993676267 4.123603e-02 0.9587639706 0.0632520690 #>  [763,] 6.233826e-03 0.993766174 4.067008e-02 0.9593299208 0.0624036234 #>  [764,] 6.145190e-03 0.993854810 4.011157e-02 0.9598884284 0.0615658107 #>  [765,] 6.057806e-03 0.993942194 3.956042e-02 0.9604395825 0.0607385175 #>  [766,] 5.971658e-03 0.994028342 3.901653e-02 0.9609834712 0.0599216313 #>  [767,] 5.886727e-03 0.994113273 3.847982e-02 0.9615201821 0.0591150402 #>  [768,] 5.802998e-03 0.994197002 3.795020e-02 0.9620498015 0.0583186328 #>  [769,] 5.720452e-03 0.994279548 3.742758e-02 0.9625724151 0.0575322986 #>  [770,] 5.639074e-03 0.994360926 3.691189e-02 0.9630881080 0.0567559280 #>  [771,] 5.558847e-03 0.994441153 3.640304e-02 0.9635969642 0.0559894116 #>  [772,] 5.479755e-03 0.994520245 3.590093e-02 0.9640990669 0.0552326413 #>  [773,] 5.401782e-03 0.994598218 3.540550e-02 0.9645944987 0.0544855093 #>  [774,] 5.324913e-03 0.994675087 3.491666e-02 0.9650833411 0.0537479089 #>  [775,] 5.249132e-03 0.994750868 3.443432e-02 0.9655656750 0.0530197338 #>  [776,] 5.174424e-03 0.994825576 3.395842e-02 0.9660415805 0.0523008787 #>  [777,] 5.100774e-03 0.994899226 3.348886e-02 0.9665111368 0.0515912391 #>  [778,] 5.028167e-03 0.994971833 3.302558e-02 0.9669744223 0.0508907111 #>  [779,] 4.956588e-03 0.995043412 3.256849e-02 0.9674315147 0.0501991917 #>  [780,] 4.886023e-03 0.995113977 3.211751e-02 0.9678824907 0.0495165786 #>  [781,] 4.816458e-03 0.995183542 3.167257e-02 0.9683274266 0.0488427705 #>  [782,] 4.747878e-03 0.995252122 3.123360e-02 0.9687663975 0.0481776666 #>  [783,] 4.680271e-03 0.995319729 3.080052e-02 0.9691994779 0.0475211671 #>  [784,] 4.613621e-03 0.995386379 3.037326e-02 0.9696267416 0.0468731729 #>  [785,] 4.547917e-03 0.995452083 2.995174e-02 0.9700482615 0.0462335858 #>  [786,] 4.483144e-03 0.995516856 2.953589e-02 0.9704641097 0.0456023083 #>  [787,] 4.419289e-03 0.995580711 2.912564e-02 0.9708743576 0.0449792439 #>  [788,] 4.356340e-03 0.995643660 2.872092e-02 0.9712790759 0.0443642967 #>  [789,] 4.294284e-03 0.995705716 2.832167e-02 0.9716783345 0.0437573717 #>  [790,] 4.233107e-03 0.995766893 2.792780e-02 0.9720722025 0.0431583748 #>  [791,] 4.172799e-03 0.995827201 2.753925e-02 0.9724607481 0.0425672125 #>  [792,] 4.113347e-03 0.995886653 2.715596e-02 0.9728440392 0.0419837924 #>  [793,] 4.054738e-03 0.995945262 2.677786e-02 0.9732221425 0.0414080228 #>  [794,] 3.996960e-03 0.996003040 2.640488e-02 0.9735951242 0.0408398127 #>  [795,] 3.940003e-03 0.996059997 2.603695e-02 0.9739630497 0.0402790720 #>  [796,] 3.883854e-03 0.996116146 2.567402e-02 0.9743259838 0.0397257116 #>  [797,] 3.828503e-03 0.996171497 2.531601e-02 0.9746839903 0.0391796430 #>  [798,] 3.773937e-03 0.996226063 2.496287e-02 0.9750371326 0.0386407787 #>  [799,] 3.720146e-03 0.996279854 2.461453e-02 0.9753854732 0.0381090317 #>  [800,] 3.667119e-03 0.996332881 2.427093e-02 0.9757290739 0.0375843161 #>  [801,] 3.614845e-03 0.996385155 2.393200e-02 0.9760679959 0.0370665469 #>  [802,] 3.563314e-03 0.996436686 2.359770e-02 0.9764022996 0.0365556396 #>  [803,] 3.512514e-03 0.996487486 2.326796e-02 0.9767320447 0.0360515108 #>  [804,] 3.462436e-03 0.996537564 2.294271e-02 0.9770572904 0.0355540777 #>  [805,] 3.413070e-03 0.996586930 2.262190e-02 0.9773780951 0.0350632585 #>  [806,] 3.364405e-03 0.996635595 2.230548e-02 0.9776945163 0.0345789720 #>  [807,] 3.316432e-03 0.996683568 2.199339e-02 0.9780066113 0.0341011380 #>  [808,] 3.269141e-03 0.996730859 2.168556e-02 0.9783144363 0.0336296770 #>  [809,] 3.222521e-03 0.996777479 2.138195e-02 0.9786180471 0.0331645103 #>  [810,] 3.176565e-03 0.996823435 2.108250e-02 0.9789174988 0.0327055601 #>  [811,] 3.131262e-03 0.996868738 2.078715e-02 0.9792128458 0.0322527492 #>  [812,] 3.086603e-03 0.996913397 2.049586e-02 0.9795041419 0.0318060014 #>  [813,] 3.042578e-03 0.996957422 2.020856e-02 0.9797914402 0.0313652411 #>  [814,] 2.999180e-03 0.997000820 1.992521e-02 0.9800747933 0.0309303937 #>  [815,] 2.956399e-03 0.997043601 1.964575e-02 0.9803542530 0.0305013851 #>  [816,] 2.914227e-03 0.997085773 1.937013e-02 0.9806298706 0.0300781423 #>  [817,] 2.872654e-03 0.997127346 1.909830e-02 0.9809016968 0.0296605927 #>  [818,] 2.831673e-03 0.997168327 1.883022e-02 0.9811697816 0.0292486649 #>  [819,] 2.791275e-03 0.997208725 1.856583e-02 0.9814341746 0.0288422879 #>  [820,] 2.751451e-03 0.997248549 1.830508e-02 0.9816949245 0.0284413916 #>  [821,] 2.712194e-03 0.997287806 1.804792e-02 0.9819520796 0.0280459067 #>  [822,] 2.673496e-03 0.997326504 1.779431e-02 0.9822056875 0.0276557646 #>  [823,] 2.635349e-03 0.997364651 1.754420e-02 0.9824557955 0.0272708974 #>  [824,] 2.597744e-03 0.997402256 1.729755e-02 0.9827024500 0.0268912380 #>  [825,] 2.560675e-03 0.997439325 1.705430e-02 0.9829456970 0.0265167201 #>  [826,] 2.524133e-03 0.997475867 1.681442e-02 0.9831855818 0.0261472780 #>  [827,] 2.488111e-03 0.997511889 1.657785e-02 0.9834221494 0.0257828468 #>  [828,] 2.452602e-03 0.997547398 1.634456e-02 0.9836554439 0.0254233623 #>  [829,] 2.417599e-03 0.997582401 1.611449e-02 0.9838855091 0.0250687610 #>  [830,] 2.383094e-03 0.997616906 1.588761e-02 0.9841123883 0.0247189802 #>  [831,] 2.349080e-03 0.997650920 1.566388e-02 0.9843361240 0.0243739578 #>  [832,] 2.315551e-03 0.997684449 1.544324e-02 0.9845567585 0.0240336325 #>  [833,] 2.282499e-03 0.997717501 1.522567e-02 0.9847743332 0.0236979437 #>  [834,] 2.249918e-03 0.997750082 1.501111e-02 0.9849888894 0.0233668313 #>  [835,] 2.217801e-03 0.997782199 1.479953e-02 0.9852004675 0.0230402361 #>  [836,] 2.186141e-03 0.997813859 1.459089e-02 0.9854091076 0.0227180994 #>  [837,] 2.154933e-03 0.997845067 1.438515e-02 0.9856148494 0.0224003635 #>  [838,] 2.124169e-03 0.997875831 1.418227e-02 0.9858177318 0.0220869710 #>  [839,] 2.093843e-03 0.997906157 1.398221e-02 0.9860177934 0.0217778653 #>  [840,] 2.063949e-03 0.997936051 1.378493e-02 0.9862150723 0.0214729906 #>  [841,] 2.034481e-03 0.997965519 1.359039e-02 0.9864096061 0.0211722915 #>  [842,] 2.005433e-03 0.997994567 1.339857e-02 0.9866014319 0.0208757134 #>  [843,] 1.976799e-03 0.998023201 1.320941e-02 0.9867905864 0.0205832025 #>  [844,] 1.948574e-03 0.998051426 1.302289e-02 0.9869771058 0.0202947052 #>  [845,] 1.920750e-03 0.998079250 1.283897e-02 0.9871610258 0.0200101689 #>  [846,] 1.893323e-03 0.998106677 1.265762e-02 0.9873423815 0.0197295416 #>  [847,] 1.866286e-03 0.998133714 1.247879e-02 0.9875212080 0.0194527717 #>  [848,] 1.839635e-03 0.998160365 1.230246e-02 0.9876975395 0.0191798084 #>  [849,] 1.813364e-03 0.998186636 1.212859e-02 0.9878714099 0.0189106015 #>  [850,] 1.787468e-03 0.998212532 1.195715e-02 0.9880428528 0.0186451014 #>  [851,] 1.761941e-03 0.998238059 1.178810e-02 0.9882119011 0.0183832590 #>  [852,] 1.736777e-03 0.998263223 1.162141e-02 0.9883785876 0.0181250258 #>  [853,] 1.711972e-03 0.998288028 1.145706e-02 0.9885429445 0.0178703541 #>  [854,] 1.687521e-03 0.998312479 1.129500e-02 0.9887050034 0.0176191964 #>  [855,] 1.663419e-03 0.998336581 1.113520e-02 0.9888647959 0.0173715063 #>  [856,] 1.639660e-03 0.998360340 1.097765e-02 0.9890223529 0.0171272374 #>  [857,] 1.616241e-03 0.998383759 1.082230e-02 0.9891777049 0.0168863443 #>  [858,] 1.593155e-03 0.998406845 1.066912e-02 0.9893308821 0.0166487820 #>  [859,] 1.570398e-03 0.998429602 1.051809e-02 0.9894819144 0.0164145059 #>  [860,] 1.547966e-03 0.998452034 1.036917e-02 0.9896308310 0.0161834723 #>  [861,] 1.525854e-03 0.998474146 1.022234e-02 0.9897776611 0.0159556377 #>  [862,] 1.504057e-03 0.998495943 1.007757e-02 0.9899224331 0.0157309593 #>  [863,] 1.482571e-03 0.998517429 9.934825e-03 0.9900651755 0.0155093948 #>  [864,] 1.461392e-03 0.998538608 9.794084e-03 0.9902059159 0.0152909025 #>  [865,] 1.440514e-03 0.998559486 9.655318e-03 0.9903446821 0.0150754411 #>  [866,] 1.419935e-03 0.998580065 9.518499e-03 0.9904815010 0.0148629700 #>  [867,] 1.399649e-03 0.998600351 9.383600e-03 0.9906163996 0.0146534488 #>  [868,] 1.379653e-03 0.998620347 9.250596e-03 0.9907494042 0.0144468379 #>  [869,] 1.359941e-03 0.998640059 9.119459e-03 0.9908805409 0.0142430981 #>  [870,] 1.340512e-03 0.998659488 8.990165e-03 0.9910098355 0.0140421906 #>  [871,] 1.321359e-03 0.998678641 8.862687e-03 0.9911373134 0.0138440772 #>  [872,] 1.302479e-03 0.998697521 8.737000e-03 0.9912629996 0.0136487203 #>  [873,] 1.283869e-03 0.998716131 8.613081e-03 0.9913869188 0.0134560824 #>  [874,] 1.265525e-03 0.998734475 8.490904e-03 0.9915090956 0.0132661268 #>  [875,] 1.247442e-03 0.998752558 8.370446e-03 0.9916295539 0.0130788173 #>  [876,] 1.229618e-03 0.998770382 8.251683e-03 0.9917483175 0.0128941179 #>  [877,] 1.212048e-03 0.998787952 8.134590e-03 0.9918654099 0.0127119932 #>  [878,] 1.194728e-03 0.998805272 8.019146e-03 0.9919808541 0.0125324083 #>  [879,] 1.177656e-03 0.998822344 7.905327e-03 0.9920946730 0.0123553287 #>  [880,] 1.160827e-03 0.998839173 7.793111e-03 0.9922068892 0.0121807203 #>  [881,] 1.144239e-03 0.998855761 7.682475e-03 0.9923175248 0.0120085495 #>  [882,] 1.127887e-03 0.998872113 7.573398e-03 0.9924266017 0.0118387831 #>  [883,] 1.111769e-03 0.998888231 7.465858e-03 0.9925341416 0.0116713884 #>  [884,] 1.095881e-03 0.998904119 7.359834e-03 0.9926401658 0.0115063330 #>  [885,] 1.080220e-03 0.998919780 7.255305e-03 0.9927446953 0.0113435850 #>  [886,] 1.064782e-03 0.998935218 7.152249e-03 0.9928477509 0.0111831129 #>  [887,] 1.049565e-03 0.998950435 7.050647e-03 0.9929493531 0.0110248856 #>  [888,] 1.034565e-03 0.998965435 6.950478e-03 0.9930495220 0.0108688724 #>  [889,] 1.019779e-03 0.998980221 6.851722e-03 0.9931482777 0.0107150431 #>  [890,] 1.005204e-03 0.998994796 6.754360e-03 0.9932456398 0.0105633677 #>  [891,] 9.908373e-04 0.999009163 6.658372e-03 0.9933416276 0.0104138166 #>  [892,] 9.766758e-04 0.999023324 6.563740e-03 0.9934362603 0.0102663609 #>  [893,] 9.627164e-04 0.999037284 6.470443e-03 0.9935295569 0.0101209718 #>  [894,] 9.489564e-04 0.999051044 6.378464e-03 0.9936215358 0.0099776209 #>  [895,] 9.353928e-04 0.999064607 6.287785e-03 0.9937122155 0.0098362801 #>  [896,] 9.220230e-04 0.999077977 6.198386e-03 0.9938016141 0.0096969220 #>  [897,] 9.088440e-04 0.999091156 6.110251e-03 0.9938897494 0.0095595192 #>  [898,] 8.958533e-04 0.999104147 6.023361e-03 0.9939766392 0.0094240448 #>  [899,] 8.830481e-04 0.999116952 5.937699e-03 0.9940623007 0.0092904723 #>  [900,] 8.704258e-04 0.999129574 5.853249e-03 0.9941467512 0.0091587756 #>  [901,] 8.579837e-04 0.999142016 5.769993e-03 0.9942300075 0.0090289286 #>  [902,] 8.457194e-04 0.999154281 5.687914e-03 0.9943120863 0.0089009060 #>  [903,] 8.336302e-04 0.999166370 5.606996e-03 0.9943930042 0.0087746826 #>  [904,] 8.217136e-04 0.999178286 5.527223e-03 0.9944727773 0.0086502335 #>  [905,] 8.099673e-04 0.999190033 5.448578e-03 0.9945514216 0.0085275343 #>  [906,] 7.983888e-04 0.999201611 5.371047e-03 0.9946289530 0.0084065608 #>  [907,] 7.869756e-04 0.999213024 5.294613e-03 0.9947053871 0.0082872890 #>  [908,] 7.757255e-04 0.999224275 5.219261e-03 0.9947807391 0.0081696956 #>  [909,] 7.646361e-04 0.999235364 5.144976e-03 0.9948550242 0.0080537572 #>  [910,] 7.537050e-04 0.999246295 5.071742e-03 0.9949282575 0.0079394509 #>  [911,] 7.429302e-04 0.999257070 4.999546e-03 0.9950004536 0.0078267542 #>  [912,] 7.323092e-04 0.999267691 4.928373e-03 0.9950716271 0.0077156447 #>  [913,] 7.218400e-04 0.999278160 4.858208e-03 0.9951417923 0.0076061004 #>  [914,] 7.115204e-04 0.999288480 4.789037e-03 0.9952109634 0.0074980997 #>  [915,] 7.013481e-04 0.999298652 4.720846e-03 0.9952791543 0.0073916211 #>  [916,] 6.913212e-04 0.999308679 4.653621e-03 0.9953463788 0.0072866434 #>  [917,] 6.814376e-04 0.999318562 4.587350e-03 0.9954126504 0.0071831459 #>  [918,] 6.716951e-04 0.999328305 4.522018e-03 0.9954779825 0.0070811079 #>  [919,] 6.620919e-04 0.999337908 4.457612e-03 0.9955423883 0.0069805092 #>  [920,] 6.526259e-04 0.999347374 4.394119e-03 0.9956058809 0.0068813298 #>  [921,] 6.432951e-04 0.999356705 4.331527e-03 0.9956684731 0.0067835499 #>  [922,] 6.340976e-04 0.999365902 4.269823e-03 0.9957301775 0.0066871500 #>  [923,] 6.250316e-04 0.999374968 4.208993e-03 0.9957910066 0.0065921110 #>  [924,] 6.160951e-04 0.999383905 4.149027e-03 0.9958509727 0.0064984139 #>  [925,] 6.072863e-04 0.999392714 4.089912e-03 0.9959100880 0.0064060399 #>  [926,] 5.986033e-04 0.999401397 4.031636e-03 0.9959683644 0.0063149707 #>  [927,] 5.900445e-04 0.999409956 3.974186e-03 0.9960258137 0.0062251880 #>  [928,] 5.816079e-04 0.999418392 3.917552e-03 0.9960824477 0.0061366739 #>  [929,] 5.732919e-04 0.999426708 3.861722e-03 0.9961382777 0.0060494107 #>  [930,] 5.650947e-04 0.999434905 3.806685e-03 0.9961933151 0.0059633809 #>  [931,] 5.570147e-04 0.999442985 3.752429e-03 0.9962475711 0.0058785673 #>  [932,] 5.490502e-04 0.999450950 3.698943e-03 0.9963010566 0.0057949530 #>  [933,] 5.411994e-04 0.999458801 3.646217e-03 0.9963537826 0.0057125211 #>  [934,] 5.334609e-04 0.999466539 3.594240e-03 0.9964057597 0.0056312552 #>  [935,] 5.258329e-04 0.999474167 3.543002e-03 0.9964569985 0.0055511388 #>  [936,] 5.183140e-04 0.999481686 3.492491e-03 0.9965075094 0.0054721561 #>  [937,] 5.109025e-04 0.999489097 3.442697e-03 0.9965573027 0.0053942910 #>  [938,] 5.035970e-04 0.999496403 3.393612e-03 0.9966063885 0.0053175279 #>  [939,] 4.963959e-04 0.999503604 3.345223e-03 0.9966547768 0.0052418515 #>  [940,] 4.892977e-04 0.999510702 3.297523e-03 0.9967024774 0.0051672465 #>  [941,] 4.823009e-04 0.999517699 3.250500e-03 0.9967495000 0.0050936979 #>  [942,] 4.754041e-04 0.999524596 3.204146e-03 0.9967958543 0.0050211908 #>  [943,] 4.686060e-04 0.999531394 3.158450e-03 0.9968415496 0.0049497107 #>  [944,] 4.619049e-04 0.999538095 3.113405e-03 0.9968865953 0.0048792432 #>  [945,] 4.552997e-04 0.999544700 3.068999e-03 0.9969310005 0.0048097741 #>  [946,] 4.487889e-04 0.999551211 3.025226e-03 0.9969747743 0.0047412893 #>  [947,] 4.423711e-04 0.999557629 2.982074e-03 0.9970179256 0.0046737751 #>  [948,] 4.360451e-04 0.999563955 2.939537e-03 0.9970604633 0.0046072178 #>  [949,] 4.298095e-04 0.999570190 2.897604e-03 0.9971023959 0.0045416040 #>  [950,] 4.236631e-04 0.999576337 2.856268e-03 0.9971437320 0.0044769204 #>  [951,] 4.176045e-04 0.999582396 2.815520e-03 0.9971844802 0.0044131540 #>  [952,] 4.116325e-04 0.999588368 2.775351e-03 0.9972246486 0.0043502919 #>  [953,] 4.057458e-04 0.999594254 2.735754e-03 0.9972642455 0.0042883214 #>  [954,] 3.999433e-04 0.999600057 2.696721e-03 0.9973032791 0.0042272299 #>  [955,] 3.942238e-04 0.999605776 2.658243e-03 0.9973417571 0.0041670050 #>  [956,] 3.885860e-04 0.999611414 2.620312e-03 0.9973796876 0.0041076347 #>  [957,] 3.830289e-04 0.999616971 2.582922e-03 0.9974170783 0.0040491067 #>  [958,] 3.775511e-04 0.999622449 2.546063e-03 0.9974539368 0.0039914094 #>  [959,] 3.721517e-04 0.999627848 2.509729e-03 0.9974902706 0.0039345310 #>  [960,] 3.668295e-04 0.999633171 2.473913e-03 0.9975260872 0.0038784600 #>  [961,] 3.615833e-04 0.999638417 2.438606e-03 0.9975613939 0.0038231849 #>  [962,] 3.564122e-04 0.999643588 2.403802e-03 0.9975961980 0.0037686947 #>  [963,] 3.513150e-04 0.999648685 2.369494e-03 0.9976305065 0.0037149782 #>  [964,] 3.462906e-04 0.999653709 2.335674e-03 0.9976643265 0.0036620245 #>  [965,] 3.413381e-04 0.999658662 2.302335e-03 0.9976976648 0.0036098228 #>  [966,] 3.364564e-04 0.999663544 2.269472e-03 0.9977305284 0.0035583627 #>  [967,] 3.316445e-04 0.999668356 2.237076e-03 0.9977629240 0.0035076335 #>  [968,] 3.269014e-04 0.999673099 2.205142e-03 0.9977948581 0.0034576251 #>  [969,] 3.222260e-04 0.999677774 2.173663e-03 0.9978263374 0.0034083272 #>  [970,] 3.176176e-04 0.999682382 2.142632e-03 0.9978573683 0.0033597298 #>  [971,] 3.130750e-04 0.999686925 2.112043e-03 0.9978879571 0.0033118230 #>  [972,] 3.085974e-04 0.999691403 2.081890e-03 0.9979181101 0.0032645971 #>  [973,] 3.041838e-04 0.999695816 2.052166e-03 0.9979478335 0.0032180425 #>  [974,] 2.998333e-04 0.999700167 2.022867e-03 0.9979771335 0.0031721496 #>  [975,] 2.955450e-04 0.999704455 1.993984e-03 0.9980060159 0.0031269091 #>  [976,] 2.913180e-04 0.999708682 1.965513e-03 0.9980344868 0.0030823119 #>  [977,] 2.871515e-04 0.999712849 1.937448e-03 0.9980625519 0.0030383488 #>  [978,] 2.830445e-04 0.999716956 1.909783e-03 0.9980902170 0.0029950109 #>  [979,] 2.789963e-04 0.999721004 1.882512e-03 0.9981174879 0.0029522893 #>  [980,] 2.750059e-04 0.999724994 1.855630e-03 0.9981443701 0.0029101753 #>  [981,] 2.710726e-04 0.999728927 1.829131e-03 0.9981708691 0.0028686603 #>  [982,] 2.671955e-04 0.999732804 1.803010e-03 0.9981969904 0.0028277358 #>  [983,] 2.633739e-04 0.999736626 1.777261e-03 0.9982227393 0.0027873936 #>  [984,] 2.596069e-04 0.999740393 1.751879e-03 0.9982481211 0.0027476253 #>  [985,] 2.558938e-04 0.999744106 1.726859e-03 0.9982731411 0.0027084229 #>  [986,] 2.522338e-04 0.999747766 1.702196e-03 0.9982978043 0.0026697783 #>  [987,] 2.486261e-04 0.999751374 1.677884e-03 0.9983221159 0.0026316837 #>  [988,] 2.450700e-04 0.999754930 1.653919e-03 0.9983460809 0.0025941312 #>  [989,] 2.415648e-04 0.999758435 1.630296e-03 0.9983697041 0.0025571131 #>  [990,] 2.381096e-04 0.999761890 1.607010e-03 0.9983929904 0.0025206220 #>  [991,] 2.347039e-04 0.999765296 1.584055e-03 0.9984159447 0.0024846503 #>  [992,] 2.313469e-04 0.999768653 1.561428e-03 0.9984385716 0.0024491908 #>  [993,] 2.280379e-04 0.999771962 1.539124e-03 0.9984608758 0.0024142360 #>  [994,] 2.247762e-04 0.999775224 1.517138e-03 0.9984828618 0.0023797789 #>  [995,] 2.215612e-04 0.999778439 1.495466e-03 0.9985045343 0.0023458125 #>  [996,] 2.183921e-04 0.999781608 1.474102e-03 0.9985258977 0.0023123297 #>  [997,] 2.152683e-04 0.999784732 1.453044e-03 0.9985469563 0.0022793238 #>  [998,] 2.121892e-04 0.999787811 1.432286e-03 0.9985677144 0.0022467879 #>  [999,] 2.091542e-04 0.999790846 1.411823e-03 0.9985881765 0.0022147155 #> [1000,] 2.061625e-04 0.999793837 1.391653e-03 0.9986083466 0.0021830998 #> [1001,] 2.032137e-04 0.999796786 1.371771e-03 0.9986282290 0.0021519345 #> [1002,] 2.003070e-04 0.999799693 1.352172e-03 0.9986478277 0.0021212132 #> [1003,] 1.974419e-04 0.999802558 1.332853e-03 0.9986671468 0.0020909295 #> [1004,] 1.946177e-04 0.999805382 1.313810e-03 0.9986861902 0.0020610773 #> [1005,] 1.918340e-04 0.999808166 1.295038e-03 0.9987049619 0.0020316504 #> [1006,] 1.890900e-04 0.999810910 1.276534e-03 0.9987234657 0.0020026428 #> [1007,] 1.863853e-04 0.999813615 1.258295e-03 0.9987417054 0.0019740485 #> [1008,] 1.837193e-04 0.999816281 1.240315e-03 0.9987596849 0.0019458618 #> [1009,] 1.810914e-04 0.999818909 1.222592e-03 0.9987774078 0.0019180767 #> [1010,] 1.785010e-04 0.999821499 1.205122e-03 0.9987948777 0.0018906876 #> [1011,] 1.759478e-04 0.999824052 1.187902e-03 0.9988120983 0.0018636889 #> [1012,] 1.734310e-04 0.999826569 1.170927e-03 0.9988290731 0.0018370750 #> [1013,] 1.709502e-04 0.999829050 1.154194e-03 0.9988458056 0.0018108405 #> [1014,] 1.685049e-04 0.999831495 1.137701e-03 0.9988622993 0.0017849800 #> [1015,] 1.660946e-04 0.999833905 1.121442e-03 0.9988785576 0.0017594881 #> [1016,] 1.637188e-04 0.999836281 1.105416e-03 0.9988945838 0.0017343597 #> [1017,] 1.613769e-04 0.999838623 1.089619e-03 0.9989103812 0.0017095895 #> [1018,] 1.590686e-04 0.999840931 1.074047e-03 0.9989259531 0.0016851724 #> [1019,] 1.567932e-04 0.999843207 1.058697e-03 0.9989413026 0.0016611036 #> [1020,] 1.545504e-04 0.999845450 1.043567e-03 0.9989564331 0.0016373779 #> [1021,] 1.523396e-04 0.999847660 1.028652e-03 0.9989713475 0.0016139906 #> [1022,] 1.501605e-04 0.999849839 1.013951e-03 0.9989860490 0.0015909368 #> [1023,] 1.480126e-04 0.999851987 9.994594e-04 0.9990005406 0.0015682117 #> [1024,] 1.458953e-04 0.999854105 9.851747e-04 0.9990148253 0.0015458108 #> [1025,] 1.438084e-04 0.999856192 9.710940e-04 0.9990289060 0.0015237293 #> [1026,] 1.417513e-04 0.999858249 9.572144e-04 0.9990427856 0.0015019629 #> [1027,] 1.397236e-04 0.999860276 9.435329e-04 0.9990564671 0.0014805068 #> [1028,] 1.377249e-04 0.999862275 9.300468e-04 0.9990699532 0.0014593569 #> [1029,] 1.357548e-04 0.999864245 9.167533e-04 0.9990832467 0.0014385086 #> [1030,] 1.338129e-04 0.999866187 9.036496e-04 0.9990963504 0.0014179578 #> [1031,] 1.318988e-04 0.999868101 8.907331e-04 0.9991092669 0.0013977001 #> [1032,] 1.300120e-04 0.999869988 8.780010e-04 0.9991219990 0.0013777315 #> [1033,] 1.281522e-04 0.999871848 8.654507e-04 0.9991345493 0.0013580478 #> [1034,] 1.263190e-04 0.999873681 8.530797e-04 0.9991469203 0.0013386449 #> [1035,] 1.245121e-04 0.999875488 8.408854e-04 0.9991591146 0.0013195188 #> [1036,] 1.227310e-04 0.999877269 8.288653e-04 0.9991711347 0.0013006657 #> [1037,] 1.209753e-04 0.999879025 8.170168e-04 0.9991829832 0.0012820816 #> [1038,] 1.192448e-04 0.999880755 8.053376e-04 0.9991946624 0.0012637626 #> [1039,] 1.175390e-04 0.999882461 7.938251e-04 0.9992061749 0.0012457051 #> [1040,] 1.158577e-04 0.999884142 7.824772e-04 0.9992175228 0.0012279054 #> [1041,] 1.142003e-04 0.999885800 7.712913e-04 0.9992287087 0.0012103596 #> [1042,] 1.125667e-04 0.999887433 7.602652e-04 0.9992397348 0.0011930642 #> [1043,] 1.109565e-04 0.999889044 7.493966e-04 0.9992506034 0.0011760157 #> [1044,] 1.093692e-04 0.999890631 7.386833e-04 0.9992613167 0.0011592106 #> [1045,] 1.078047e-04 0.999892195 7.281230e-04 0.9992718770 0.0011426453 #> [1046,] 1.062626e-04 0.999893737 7.177136e-04 0.9992822864 0.0011263164 #> [1047,] 1.047425e-04 0.999895258 7.074529e-04 0.9992925471 0.0011102207 #> [1048,] 1.032441e-04 0.999896756 6.973388e-04 0.9993026612 0.0010943547 #> [1049,] 1.017672e-04 0.999898233 6.873692e-04 0.9993126308 0.0010787152 #> [1050,] 1.003114e-04 0.999899689 6.775420e-04 0.9993224580 0.0010632990 #> [1051,] 9.887647e-05 0.999901124 6.678552e-04 0.9993321448 0.0010481028 #> [1052,] 9.746203e-05 0.999902538 6.583068e-04 0.9993416932 0.0010331237 #> [1053,] 9.606783e-05 0.999903932 6.488949e-04 0.9993511051 0.0010183583 #> [1054,] 9.469356e-05 0.999905306 6.396174e-04 0.9993603826 0.0010038038 #> [1055,] 9.333896e-05 0.999906661 6.304725e-04 0.9993695275 0.0009894571 #> [1056,] 9.200373e-05 0.999907996 6.214582e-04 0.9993785418 0.0009753152 #> [1057,] 9.068760e-05 0.999909312 6.125728e-04 0.9993874272 0.0009613753 #> [1058,] 8.939029e-05 0.999910610 6.038143e-04 0.9993961857 0.0009476344 #> [1059,] 8.811154e-05 0.999911888 5.951810e-04 0.9994048190 0.0009340898 #> [1060,] 8.685108e-05 0.999913149 5.866710e-04 0.9994133290 0.0009207385 #> [1061,] 8.560865e-05 0.999914391 5.782827e-04 0.9994217173 0.0009075779 #> [1062,] 8.438400e-05 0.999915616 5.700142e-04 0.9994299858 0.0008946053 #> [1063,] 8.317686e-05 0.999916823 5.618639e-04 0.9994381361 0.0008818179 #> [1064,] 8.198699e-05 0.999918013 5.538300e-04 0.9994461700 0.0008692131 #> [1065,] 8.081413e-05 0.999919186 5.459110e-04 0.9994540890 0.0008567884 #> [1066,] 7.965806e-05 0.999920342 5.381051e-04 0.9994618949 0.0008445411 #> [1067,] 7.851852e-05 0.999921481 5.304108e-04 0.9994695892 0.0008324688 #> [1068,] 7.739528e-05 0.999922605 5.228264e-04 0.9994771736 0.0008205688 #> [1069,] 7.628811e-05 0.999923712 5.153505e-04 0.9994846495 0.0008088388 #> [1070,] 7.519678e-05 0.999924803 5.079814e-04 0.9994920186 0.0007972764 #> [1071,] 7.412106e-05 0.999925879 5.007176e-04 0.9994992824 0.0007858791 #> [1072,] 7.306072e-05 0.999926939 4.935576e-04 0.9995064424 0.0007746447 #> [1073,] 7.201555e-05 0.999927984 4.864999e-04 0.9995135001 0.0007635707 #> [1074,] 7.098534e-05 0.999929015 4.795432e-04 0.9995204568 0.0007526549 #> [1075,] 6.996985e-05 0.999930030 4.726858e-04 0.9995273142 0.0007418950 #> [1076,] 6.896890e-05 0.999931031 4.659265e-04 0.9995340735 0.0007312889 #> [1077,] 6.798226e-05 0.999932018 4.592638e-04 0.9995407362 0.0007208342 #> [1078,] 6.700974e-05 0.999932990 4.526963e-04 0.9995473037 0.0007105289 #> [1079,] 6.605113e-05 0.999933949 4.462227e-04 0.9995537773 0.0007003709 #> [1080,] 6.510623e-05 0.999934894 4.398416e-04 0.9995601584 0.0006903579 #> [1081,] 6.417485e-05 0.999935825 4.335518e-04 0.9995664482 0.0006804881 #> [1082,] 6.325679e-05 0.999936743 4.273518e-04 0.9995726482 0.0006707592 #> [1083,] 6.235186e-05 0.999937648 4.212405e-04 0.9995787595 0.0006611693 #> [1084,] 6.145988e-05 0.999938540 4.152165e-04 0.9995847835 0.0006517165 #> [1085,] 6.058066e-05 0.999939419 4.092786e-04 0.9995907214 0.0006423987 #> [1086,] 5.971401e-05 0.999940286 4.034257e-04 0.9995965743 0.0006332140 #> [1087,] 5.885977e-05 0.999941140 3.976563e-04 0.9996023437 0.0006241606 #> [1088,] 5.801774e-05 0.999941982 3.919695e-04 0.9996080305 0.0006152365 #> [1089,] 5.718775e-05 0.999942812 3.863640e-04 0.9996136360 0.0006064400 #> [1090,] 5.636964e-05 0.999943630 3.808385e-04 0.9996191615 0.0005977692 #> [1091,] 5.556324e-05 0.999944437 3.753921e-04 0.9996246079 0.0005892222 #> [1092,] 5.476836e-05 0.999945232 3.700236e-04 0.9996299764 0.0005807974 #> [1093,] 5.398486e-05 0.999946015 3.647318e-04 0.9996352682 0.0005724930 #> [1094,] 5.321257e-05 0.999946787 3.595156e-04 0.9996404844 0.0005643072 #> [1095,] 5.245132e-05 0.999947549 3.543740e-04 0.9996456260 0.0005562385 #> [1096,] 5.170097e-05 0.999948299 3.493059e-04 0.9996506941 0.0005482850 #> [1097,] 5.096135e-05 0.999949039 3.443103e-04 0.9996556897 0.0005404452 #> [1098,] 5.023230e-05 0.999949768 3.393861e-04 0.9996606139 0.0005327174 #> [1099,] 4.951369e-05 0.999950486 3.345323e-04 0.9996654677 0.0005251001 #> [1100,] 4.880536e-05 0.999951195 3.297479e-04 0.9996702521 0.0005175917 #> [1101,] 4.810716e-05 0.999951893 3.250319e-04 0.9996749681 0.0005101905 #> [1102,] 4.741895e-05 0.999952581 3.203833e-04 0.9996796167 0.0005028952 #> [1103,] 4.674058e-05 0.999953259 3.158012e-04 0.9996841988 0.0004957041 #> [1104,] 4.607192e-05 0.999953928 3.112846e-04 0.9996887154 0.0004886157 #> [1105,] 4.541282e-05 0.999954587 3.068326e-04 0.9996931674 0.0004816287 #> [1106,] 4.476315e-05 0.999955237 3.024442e-04 0.9996975558 0.0004747416 #> [1107,] 4.412277e-05 0.999955877 2.981186e-04 0.9997018814 0.0004679529 #> [1108,] 4.349156e-05 0.999956508 2.938548e-04 0.9997061452 0.0004612612 #> [1109,] 4.286937e-05 0.999957131 2.896520e-04 0.9997103480 0.0004546651 #> [1110,] 4.225609e-05 0.999957744 2.855093e-04 0.9997144907 0.0004481634 #> [1111,] 4.165158e-05 0.999958348 2.814258e-04 0.9997185742 0.0004417546 #> [1112,] 4.105571e-05 0.999958944 2.774007e-04 0.9997225993 0.0004354374 #> [1113,] 4.046837e-05 0.999959532 2.734331e-04 0.9997265669 0.0004292105 #> [1114,] 3.988944e-05 0.999960111 2.695223e-04 0.9997304777 0.0004230726 #> [1115,] 3.931878e-05 0.999960681 2.656674e-04 0.9997343326 0.0004170224 #> [1116,] 3.875629e-05 0.999961244 2.618676e-04 0.9997381324 0.0004110587 #> [1117,] 3.820184e-05 0.999961798 2.581222e-04 0.9997418778 0.0004051803 #> [1118,] 3.765533e-05 0.999962345 2.544303e-04 0.9997455697 0.0003993859 #> [1119,] 3.711663e-05 0.999962883 2.507912e-04 0.9997492088 0.0003936743 #> [1120,] 3.658564e-05 0.999963414 2.472042e-04 0.9997527958 0.0003880444 #> [1121,] 3.606225e-05 0.999963938 2.436684e-04 0.9997563316 0.0003824950 #> [1122,] 3.554634e-05 0.999964454 2.401832e-04 0.9997598168 0.0003770249 #> [1123,] 3.503782e-05 0.999964962 2.367478e-04 0.9997632522 0.0003716330 #> [1124,] 3.453657e-05 0.999965463 2.333616e-04 0.9997666384 0.0003663182 #> [1125,] 3.404249e-05 0.999965958 2.300238e-04 0.9997699762 0.0003610793 #> [1126,] 3.355547e-05 0.999966445 2.267337e-04 0.9997732663 0.0003559154 #> [1127,] 3.307543e-05 0.999966925 2.234906e-04 0.9997765094 0.0003508253 #> [1128,] 3.260225e-05 0.999967398 2.202940e-04 0.9997797060 0.0003458079 #> [1129,] 3.213584e-05 0.999967864 2.171430e-04 0.9997828570 0.0003408623 #> [1130,] 3.167610e-05 0.999968324 2.140371e-04 0.9997859629 0.0003359874 #> [1131,] 3.122294e-05 0.999968777 2.109757e-04 0.9997890243 0.0003311822 #> [1132,] 3.077627e-05 0.999969224 2.079580e-04 0.9997920420 0.0003264457 #> [1133,] 3.033598e-05 0.999969664 2.049834e-04 0.9997950166 0.0003217769 #> [1134,] 2.990199e-05 0.999970098 2.020514e-04 0.9997979486 0.0003171749 #> [1135,] 2.947421e-05 0.999970526 1.991613e-04 0.9998008387 0.0003126386 #> [1136,] 2.905255e-05 0.999970947 1.963126e-04 0.9998036874 0.0003081672 #> [1137,] 2.863692e-05 0.999971363 1.935046e-04 0.9998064954 0.0003037598 #> [1138,] 2.822724e-05 0.999971773 1.907368e-04 0.9998092632 0.0002994153 #> [1139,] 2.782342e-05 0.999972177 1.880085e-04 0.9998119915 0.0002951330 #> [1140,] 2.742537e-05 0.999972575 1.853192e-04 0.9998146808 0.0002909119 #> [1141,] 2.703302e-05 0.999972967 1.826685e-04 0.9998173315 0.0002867512 #> [1142,] 2.664629e-05 0.999973354 1.800556e-04 0.9998199444 0.0002826499 #> [1143,] 2.626508e-05 0.999973735 1.774801e-04 0.9998225199 0.0002786073 #> [1144,] 2.588933e-05 0.999974111 1.749414e-04 0.9998250586 0.0002746225 #> [1145,] 2.551895e-05 0.999974481 1.724390e-04 0.9998275610 0.0002706947 #> [1146,] 2.515388e-05 0.999974846 1.699725e-04 0.9998300275 0.0002668231 #> [1147,] 2.479402e-05 0.999975206 1.675412e-04 0.9998324588 0.0002630068 #> [1148,] 2.443931e-05 0.999975561 1.651446e-04 0.9998348554 0.0002592450 #> [1149,] 2.408968e-05 0.999975910 1.627824e-04 0.9998372176 0.0002555371 #> [1150,] 2.374505e-05 0.999976255 1.604539e-04 0.9998395461 0.0002518822 #> [1151,] 2.340535e-05 0.999976595 1.581587e-04 0.9998418413 0.0002482795 #> [1152,] 2.307051e-05 0.999976929 1.558964e-04 0.9998441036 0.0002447284 #> [1153,] 2.274046e-05 0.999977260 1.536664e-04 0.9998463336 0.0002412280 #> [1154,] 2.241513e-05 0.999977585 1.514683e-04 0.9998485317 0.0002377777 #> [1155,] 2.209445e-05 0.999977906 1.493016e-04 0.9998506984 0.0002343767 #> [1156,] 2.177837e-05 0.999978222 1.471660e-04 0.9998528340 0.0002310244 #> [1157,] 2.146680e-05 0.999978533 1.450608e-04 0.9998549392 0.0002277200 #> [1158,] 2.115969e-05 0.999978840 1.429858e-04 0.9998570142 0.0002244629 #> [1159,] 2.085698e-05 0.999979143 1.409405e-04 0.9998590595 0.0002212523 #> [1160,] 2.055859e-05 0.999979441 1.389244e-04 0.9998610756 0.0002180876 #> [1161,] 2.026448e-05 0.999979736 1.369372e-04 0.9998630628 0.0002149682 #> [1162,] 1.997457e-05 0.999980025 1.349783e-04 0.9998650217 0.0002118934 #> [1163,] 1.968881e-05 0.999980311 1.330475e-04 0.9998669525 0.0002088626 #> [1164,] 1.940714e-05 0.999980593 1.311443e-04 0.9998688557 0.0002058751 #> [1165,] 1.912949e-05 0.999980871 1.292684e-04 0.9998707316 0.0002029304 #> [1166,] 1.885582e-05 0.999981144 1.274192e-04 0.9998725808 0.0002000277 #> [1167,] 1.858607e-05 0.999981414 1.255965e-04 0.9998744035 0.0001971666 #> [1168,] 1.832017e-05 0.999981680 1.237999e-04 0.9998762001 0.0001943464 #> [1169,] 1.805808e-05 0.999981942 1.220290e-04 0.9998779710 0.0001915665 #> [1170,] 1.779974e-05 0.999982200 1.202834e-04 0.9998797166 0.0001888264 #> [1171,] 1.754509e-05 0.999982455 1.185627e-04 0.9998814373 0.0001861254 #> [1172,] 1.729408e-05 0.999982706 1.168667e-04 0.9998831333 0.0001834631 #> [1173,] 1.704667e-05 0.999982953 1.151950e-04 0.9998848050 0.0001808389 #> [1174,] 1.680280e-05 0.999983197 1.135471e-04 0.9998864529 0.0001782522 #> [1175,] 1.656241e-05 0.999983438 1.119228e-04 0.9998880772 0.0001757025 #> [1176,] 1.632546e-05 0.999983675 1.103218e-04 0.9998896782 0.0001731892 #> [1177,] 1.609191e-05 0.999983908 1.087436e-04 0.9998912564 0.0001707119 #> [1178,] 1.586169e-05 0.999984138 1.071881e-04 0.9998928119 0.0001682700 #> [1179,] 1.563477e-05 0.999984365 1.056547e-04 0.9998943453 0.0001658631 #> [1180,] 1.541110e-05 0.999984589 1.041434e-04 0.9998958566 0.0001634905 #> [1181,] 1.519062e-05 0.999984809 1.026536e-04 0.9998973464 0.0001611519 #> [1182,] 1.497330e-05 0.999985027 1.011851e-04 0.9998988149 0.0001588468 #> [1183,] 1.475909e-05 0.999985241 9.973765e-05 0.9999002623 0.0001565746 #> [1184,] 1.454794e-05 0.999985452 9.831090e-05 0.9999016891 0.0001543349 #> [1185,] 1.433981e-05 0.999985660 9.690455e-05 0.9999030955 0.0001521273 #> [1186,] 1.413466e-05 0.999985865 9.551832e-05 0.9999044817 0.0001499512 #> [1187,] 1.393245e-05 0.999986068 9.415191e-05 0.9999058481 0.0001478062 #> [1188,] 1.373313e-05 0.999986267 9.280505e-05 0.9999071949 0.0001456919 #> [1189,] 1.353666e-05 0.999986463 9.147746e-05 0.9999085225 0.0001436079 #> [1190,] 1.334300e-05 0.999986657 9.016885e-05 0.9999098311 0.0001415537 #> [1191,] 1.315211e-05 0.999986848 8.887897e-05 0.9999111210 0.0001395288 #> [1192,] 1.296395e-05 0.999987036 8.760753e-05 0.9999123925 0.0001375329 #> [1193,] 1.277848e-05 0.999987222 8.635429e-05 0.9999136457 0.0001355656 #> [1194,] 1.259567e-05 0.999987404 8.511896e-05 0.9999148810 0.0001336264 #> [1195,] 1.241547e-05 0.999987585 8.390131e-05 0.9999160987 0.0001317149 #> [1196,] 1.223785e-05 0.999987762 8.270108e-05 0.9999172989 0.0001298307 #> [1197,] 1.206277e-05 0.999987937 8.151801e-05 0.9999184820 0.0001279736 #> [1198,] 1.189020e-05 0.999988110 8.035187e-05 0.9999196481 0.0001261429 #> [1199,] 1.172009e-05 0.999988280 7.920240e-05 0.9999207976 0.0001243385 #> [1200,] 1.155242e-05 0.999988448 7.806938e-05 0.9999219306 0.0001225599 #> [1201,] 1.138715e-05 0.999988613 7.695257e-05 0.9999230474 0.0001208067 #>                 [,6]         [,7]         [,8]         [,9]        [,10] #>    [1,] 0.0002558693 0.9998824482 0.0001175518 0.9999063898 9.361023e-05 #>    [2,] 0.0002595820 0.9998807422 0.0001192578 0.9999050312 9.496877e-05 #>    [3,] 0.0002633486 0.9998790115 0.0001209885 0.9999036530 9.634703e-05 #>    [4,] 0.0002671699 0.9998772557 0.0001227443 0.9999022547 9.774529e-05 #>    [5,] 0.0002710466 0.9998754743 0.0001245257 0.9999008362 9.916384e-05 #>    [6,] 0.0002749795 0.9998736672 0.0001263328 0.9998993970 1.006030e-04 #>    [7,] 0.0002789695 0.9998718338 0.0001281662 0.9998979370 1.020630e-04 #>    [8,] 0.0002830174 0.9998699738 0.0001300262 0.9998964558 1.035442e-04 #>    [9,] 0.0002871239 0.9998680869 0.0001319131 0.9998949531 1.050469e-04 #>   [10,] 0.0002912901 0.9998661725 0.0001338275 0.9998934286 1.065714e-04 #>   [11,] 0.0002955166 0.9998642304 0.0001357696 0.9998918820 1.081180e-04 #>   [12,] 0.0002998045 0.9998622601 0.0001377399 0.9998903129 1.096871e-04 #>   [13,] 0.0003041546 0.9998602612 0.0001397388 0.9998887211 1.112789e-04 #>   [14,] 0.0003085678 0.9998582333 0.0001417667 0.9998871061 1.128939e-04 #>   [15,] 0.0003130450 0.9998561759 0.0001438241 0.9998854678 1.145322e-04 #>   [16,] 0.0003175871 0.9998540888 0.0001459112 0.9998838056 1.161944e-04 #>   [17,] 0.0003221951 0.9998519713 0.0001480287 0.9998821194 1.178806e-04 #>   [18,] 0.0003268700 0.9998498231 0.0001501769 0.9998804086 1.195914e-04 #>   [19,] 0.0003316127 0.9998476438 0.0001523562 0.9998786731 1.213269e-04 #>   [20,] 0.0003364241 0.9998454328 0.0001545672 0.9998769123 1.230877e-04 #>   [21,] 0.0003413054 0.9998431897 0.0001568103 0.9998751260 1.248740e-04 #>   [22,] 0.0003462574 0.9998409141 0.0001590859 0.9998733138 1.266862e-04 #>   [23,] 0.0003512813 0.9998386055 0.0001613945 0.9998714753 1.285247e-04 #>   [24,] 0.0003563780 0.9998362634 0.0001637366 0.9998696102 1.303898e-04 #>   [25,] 0.0003615487 0.9998338873 0.0001661127 0.9998677179 1.322821e-04 #>   [26,] 0.0003667943 0.9998314767 0.0001685233 0.9998657982 1.342018e-04 #>   [27,] 0.0003721160 0.9998290311 0.0001709689 0.9998638506 1.361494e-04 #>   [28,] 0.0003775149 0.9998265501 0.0001734499 0.9998618748 1.381252e-04 #>   [29,] 0.0003829921 0.9998240331 0.0001759669 0.9998598703 1.401297e-04 #>   [30,] 0.0003885488 0.9998214795 0.0001785205 0.9998578368 1.421632e-04 #>   [31,] 0.0003941860 0.9998188889 0.0001811111 0.9998557737 1.442263e-04 #>   [32,] 0.0003999050 0.9998162607 0.0001837393 0.9998536807 1.463193e-04 #>   [33,] 0.0004057069 0.9998135944 0.0001864056 0.9998515573 1.484427e-04 #>   [34,] 0.0004115930 0.9998108894 0.0001891106 0.9998494031 1.505969e-04 #>   [35,] 0.0004175644 0.9998081452 0.0001918548 0.9998472176 1.527824e-04 #>   [36,] 0.0004236224 0.9998053611 0.0001946389 0.9998450005 1.549995e-04 #>   [37,] 0.0004297683 0.9998025366 0.0001974634 0.9998427511 1.572489e-04 #>   [38,] 0.0004360033 0.9997996712 0.0002003288 0.9998404692 1.595308e-04 #>   [39,] 0.0004423287 0.9997967642 0.0002032358 0.9998381541 1.618459e-04 #>   [40,] 0.0004487459 0.9997938150 0.0002061850 0.9998358054 1.641946e-04 #>   [41,] 0.0004552561 0.9997908230 0.0002091770 0.9998334227 1.665773e-04 #>   [42,] 0.0004618607 0.9997877876 0.0002122124 0.9998310054 1.689946e-04 #>   [43,] 0.0004685610 0.9997847082 0.0002152918 0.9998285530 1.714470e-04 #>   [44,] 0.0004753586 0.9997815841 0.0002184159 0.9998260650 1.739350e-04 #>   [45,] 0.0004822547 0.9997784147 0.0002215853 0.9998235409 1.764591e-04 #>   [46,] 0.0004892507 0.9997751993 0.0002248007 0.9998209802 1.790198e-04 #>   [47,] 0.0004963483 0.9997719373 0.0002280627 0.9998183824 1.816176e-04 #>   [48,] 0.0005035487 0.9997686279 0.0002313721 0.9998157468 1.842532e-04 #>   [49,] 0.0005108536 0.9997652705 0.0002347295 0.9998130731 1.869269e-04 #>   [50,] 0.0005182643 0.9997618644 0.0002381356 0.9998103605 1.896395e-04 #>   [51,] 0.0005257825 0.9997584089 0.0002415911 0.9998076086 1.923914e-04 #>   [52,] 0.0005334097 0.9997549033 0.0002450967 0.9998048167 1.951833e-04 #>   [53,] 0.0005411475 0.9997513468 0.0002486532 0.9998019844 1.980156e-04 #>   [54,] 0.0005489975 0.9997477387 0.0002522613 0.9997991109 2.008891e-04 #>   [55,] 0.0005569613 0.9997440783 0.0002559217 0.9997961958 2.038042e-04 #>   [56,] 0.0005650406 0.9997403648 0.0002596352 0.9997932383 2.067617e-04 #>   [57,] 0.0005732369 0.9997365974 0.0002634026 0.9997902380 2.097620e-04 #>   [58,] 0.0005815521 0.9997327754 0.0002672246 0.9997871941 2.128059e-04 #>   [59,] 0.0005899879 0.9997288979 0.0002711021 0.9997841061 2.158939e-04 #>   [60,] 0.0005985459 0.9997249642 0.0002750358 0.9997809733 2.190267e-04 #>   [61,] 0.0006072280 0.9997209734 0.0002790266 0.9997777950 2.222050e-04 #>   [62,] 0.0006160360 0.9997169247 0.0002830753 0.9997745706 2.254294e-04 #>   [63,] 0.0006249717 0.9997128173 0.0002871827 0.9997712994 2.287006e-04 #>   [64,] 0.0006340368 0.9997086503 0.0002913497 0.9997679808 2.320192e-04 #>   [65,] 0.0006432334 0.9997044228 0.0002955772 0.9997646141 2.353859e-04 #>   [66,] 0.0006525633 0.9997001341 0.0002998659 0.9997611984 2.388016e-04 #>   [67,] 0.0006620284 0.9996957831 0.0003042169 0.9997577333 2.422667e-04 #>   [68,] 0.0006716308 0.9996913690 0.0003086310 0.9997542179 2.457821e-04 #>   [69,] 0.0006813723 0.9996868909 0.0003131091 0.9997506514 2.493486e-04 #>   [70,] 0.0006912550 0.9996823478 0.0003176522 0.9997470333 2.529667e-04 #>   [71,] 0.0007012809 0.9996777389 0.0003222611 0.9997433626 2.566374e-04 #>   [72,] 0.0007114521 0.9996730630 0.0003269370 0.9997396387 2.603613e-04 #>   [73,] 0.0007217708 0.9996683194 0.0003316806 0.9997358608 2.641392e-04 #>   [74,] 0.0007322390 0.9996635070 0.0003364930 0.9997320281 2.679719e-04 #>   [75,] 0.0007428590 0.9996586247 0.0003413753 0.9997281397 2.718603e-04 #>   [76,] 0.0007536328 0.9996536717 0.0003463283 0.9997241950 2.758050e-04 #>   [77,] 0.0007645628 0.9996486468 0.0003513532 0.9997201930 2.798070e-04 #>   [78,] 0.0007756511 0.9996435490 0.0003564510 0.9997161330 2.838670e-04 #>   [79,] 0.0007869002 0.9996383773 0.0003616227 0.9997120141 2.879859e-04 #>   [80,] 0.0007983122 0.9996331306 0.0003668694 0.9997078355 2.921645e-04 #>   [81,] 0.0008098897 0.9996278078 0.0003721922 0.9997035962 2.964038e-04 #>   [82,] 0.0008216349 0.9996224077 0.0003775923 0.9996992955 3.007045e-04 #>   [83,] 0.0008335503 0.9996169294 0.0003830706 0.9996949323 3.050677e-04 #>   [84,] 0.0008456383 0.9996113716 0.0003886284 0.9996905059 3.094941e-04 #>   [85,] 0.0008579015 0.9996057333 0.0003942667 0.9996860153 3.139847e-04 #>   [86,] 0.0008703424 0.9996000131 0.0003999869 0.9996814595 3.185405e-04 #>   [87,] 0.0008829635 0.9995942100 0.0004057900 0.9996768377 3.231623e-04 #>   [88,] 0.0008957675 0.9995883227 0.0004116773 0.9996721488 3.278512e-04 #>   [89,] 0.0009087569 0.9995823501 0.0004176499 0.9996673919 3.326081e-04 #>   [90,] 0.0009219346 0.9995762908 0.0004237092 0.9996625660 3.374340e-04 #>   [91,] 0.0009353032 0.9995701437 0.0004298563 0.9996576701 3.423299e-04 #>   [92,] 0.0009488654 0.9995639074 0.0004360926 0.9996527032 3.472968e-04 #>   [93,] 0.0009626241 0.9995575807 0.0004424193 0.9996476643 3.523357e-04 #>   [94,] 0.0009765822 0.9995511622 0.0004488378 0.9996425522 3.574478e-04 #>   [95,] 0.0009907424 0.9995446507 0.0004553493 0.9996373661 3.626339e-04 #>   [96,] 0.0010051077 0.9995380448 0.0004619552 0.9996321047 3.678953e-04 #>   [97,] 0.0010196811 0.9995313430 0.0004686570 0.9996267670 3.732330e-04 #>   [98,] 0.0010344656 0.9995245441 0.0004754559 0.9996213519 3.786481e-04 #>   [99,] 0.0010494642 0.9995176466 0.0004823534 0.9996158582 3.841418e-04 #>  [100,] 0.0010646801 0.9995106491 0.0004893509 0.9996102849 3.897151e-04 #>  [101,] 0.0010801163 0.9995035501 0.0004964499 0.9996046308 3.953692e-04 #>  [102,] 0.0010957761 0.9994963482 0.0005036518 0.9995988946 4.011054e-04 #>  [103,] 0.0011116627 0.9994890418 0.0005109582 0.9995930753 4.069247e-04 #>  [104,] 0.0011277793 0.9994816295 0.0005183705 0.9995871716 4.128284e-04 #>  [105,] 0.0011441293 0.9994741098 0.0005258902 0.9995811822 4.188178e-04 #>  [106,] 0.0011607161 0.9994664810 0.0005335190 0.9995751060 4.248940e-04 #>  [107,] 0.0011775431 0.9994587416 0.0005412584 0.9995689417 4.310583e-04 #>  [108,] 0.0011946137 0.9994508901 0.0005491099 0.9995626880 4.373120e-04 #>  [109,] 0.0012119315 0.9994429246 0.0005570754 0.9995563436 4.436564e-04 #>  [110,] 0.0012295000 0.9994348437 0.0005651563 0.9995499072 4.500928e-04 #>  [111,] 0.0012473229 0.9994266457 0.0005733543 0.9995433775 4.566225e-04 #>  [112,] 0.0012654038 0.9994183288 0.0005816712 0.9995367531 4.632469e-04 #>  [113,] 0.0012837464 0.9994098913 0.0005901087 0.9995300326 4.699674e-04 #>  [114,] 0.0013023547 0.9994013315 0.0005986685 0.9995232147 4.767853e-04 #>  [115,] 0.0013212322 0.9993926476 0.0006073524 0.9995162979 4.837021e-04 #>  [116,] 0.0013403831 0.9993838378 0.0006161622 0.9995092808 4.907192e-04 #>  [117,] 0.0013598112 0.9993749004 0.0006250996 0.9995021620 4.978380e-04 #>  [118,] 0.0013795204 0.9993658333 0.0006341667 0.9994949400 5.050600e-04 #>  [119,] 0.0013995150 0.9993566349 0.0006433651 0.9994876132 5.123868e-04 #>  [120,] 0.0014197989 0.9993473031 0.0006526969 0.9994801802 5.198198e-04 #>  [121,] 0.0014403764 0.9993378360 0.0006621640 0.9994726395 5.273605e-04 #>  [122,] 0.0014612516 0.9993282317 0.0006717683 0.9994649894 5.350106e-04 #>  [123,] 0.0014824290 0.9993184882 0.0006815118 0.9994572284 5.427716e-04 #>  [124,] 0.0015039129 0.9993086035 0.0006913965 0.9994493548 5.506452e-04 #>  [125,] 0.0015257076 0.9992985755 0.0007014245 0.9994413672 5.586328e-04 #>  [126,] 0.0015478176 0.9992884022 0.0007115978 0.9994332637 5.667363e-04 #>  [127,] 0.0015702476 0.9992780814 0.0007219186 0.9994250427 5.749573e-04 #>  [128,] 0.0015930021 0.9992676110 0.0007323890 0.9994167026 5.832974e-04 #>  [129,] 0.0016160858 0.9992569889 0.0007430111 0.9994082415 5.917585e-04 #>  [130,] 0.0016395034 0.9992462129 0.0007537871 0.9993996578 6.003422e-04 #>  [131,] 0.0016632598 0.9992352807 0.0007647193 0.9993909497 6.090503e-04 #>  [132,] 0.0016873599 0.9992241901 0.0007758099 0.9993821153 6.178847e-04 #>  [133,] 0.0017118086 0.9992129387 0.0007870613 0.9993731528 6.268472e-04 #>  [134,] 0.0017366108 0.9992015243 0.0007984757 0.9993640605 6.359395e-04 #>  [135,] 0.0017617719 0.9991899445 0.0008100555 0.9993548363 6.451637e-04 #>  [136,] 0.0017872968 0.9991781969 0.0008218031 0.9993454784 6.545216e-04 #>  [137,] 0.0018131908 0.9991662791 0.0008337209 0.9993359849 6.640151e-04 #>  [138,] 0.0018394593 0.9991541886 0.0008458114 0.9993263538 6.736462e-04 #>  [139,] 0.0018661077 0.9991419229 0.0008580771 0.9993165831 6.834169e-04 #>  [140,] 0.0018931413 0.9991294795 0.0008705205 0.9993066708 6.933292e-04 #>  [141,] 0.0019205659 0.9991168558 0.0008831442 0.9992966148 7.033852e-04 #>  [142,] 0.0019483870 0.9991040492 0.0008959508 0.9992864130 7.135870e-04 #>  [143,] 0.0019766102 0.9990910570 0.0009089430 0.9992760634 7.239366e-04 #>  [144,] 0.0020052415 0.9990778767 0.0009221233 0.9992655638 7.344362e-04 #>  [145,] 0.0020342867 0.9990645054 0.0009354946 0.9992549120 7.450880e-04 #>  [146,] 0.0020637517 0.9990509403 0.0009490597 0.9992441059 7.558941e-04 #>  [147,] 0.0020936425 0.9990371788 0.0009628212 0.9992331432 7.668568e-04 #>  [148,] 0.0021239654 0.9990232179 0.0009767821 0.9992220215 7.779785e-04 #>  [149,] 0.0021547265 0.9990090548 0.0009909452 0.9992107388 7.892612e-04 #>  [150,] 0.0021859322 0.9989946866 0.0010053134 0.9991992925 8.007075e-04 #>  [151,] 0.0022175888 0.9989801102 0.0010198898 0.9991876803 8.123197e-04 #>  [152,] 0.0022497028 0.9989653227 0.0010346773 0.9991758999 8.241001e-04 #>  [153,] 0.0022822807 0.9989503210 0.0010496790 0.9991639488 8.360512e-04 #>  [154,] 0.0023153294 0.9989351020 0.0010648980 0.9991518245 8.481755e-04 #>  [155,] 0.0023488555 0.9989196626 0.0010803374 0.9991395246 8.604754e-04 #>  [156,] 0.0023828659 0.9989039996 0.0010960004 0.9991270464 8.729536e-04 #>  [157,] 0.0024173675 0.9988881098 0.0011118902 0.9991143875 8.856125e-04 #>  [158,] 0.0024523675 0.9988719899 0.0011280101 0.9991015451 8.984549e-04 #>  [159,] 0.0024878730 0.9988556365 0.0011443635 0.9990885167 9.114833e-04 #>  [160,] 0.0025238912 0.9988390464 0.0011609536 0.9990752995 9.247005e-04 #>  [161,] 0.0025604295 0.9988222159 0.0011777841 0.9990618909 9.381091e-04 #>  [162,] 0.0025974954 0.9988051418 0.0011948582 0.9990482880 9.517120e-04 #>  [163,] 0.0026350965 0.9987878205 0.0012121795 0.9990344881 9.655119e-04 #>  [164,] 0.0026732404 0.9987702484 0.0012297516 0.9990204882 9.795118e-04 #>  [165,] 0.0027119350 0.9987524219 0.0012475781 0.9990062856 9.937144e-04 #>  [166,] 0.0027511881 0.9987343373 0.0012656627 0.9989918772 1.008123e-03 #>  [167,] 0.0027910078 0.9987159909 0.0012840091 0.9989772601 1.022740e-03 #>  [168,] 0.0028314022 0.9986973788 0.0013026212 0.9989624313 1.037569e-03 #>  [169,] 0.0028723795 0.9986784974 0.0013215026 0.9989473878 1.052612e-03 #>  [170,] 0.0029139482 0.9986593426 0.0013406574 0.9989321263 1.067874e-03 #>  [171,] 0.0029561166 0.9986399106 0.0013600894 0.9989166438 1.083356e-03 #>  [172,] 0.0029988935 0.9986201973 0.0013798027 0.9989009371 1.099063e-03 #>  [173,] 0.0030422874 0.9986001987 0.0013998013 0.9988850029 1.114997e-03 #>  [174,] 0.0030863073 0.9985799106 0.0014200894 0.9988688380 1.131162e-03 #>  [175,] 0.0031309622 0.9985593289 0.0014406711 0.9988524390 1.147561e-03 #>  [176,] 0.0031762611 0.9985384494 0.0014615506 0.9988358025 1.164197e-03 #>  [177,] 0.0032222132 0.9985172677 0.0014827323 0.9988189252 1.181075e-03 #>  [178,] 0.0032688280 0.9984957795 0.0015042205 0.9988018034 1.198197e-03 #>  [179,] 0.0033161149 0.9984739803 0.0015260197 0.9987844338 1.215566e-03 #>  [180,] 0.0033640836 0.9984518657 0.0015481343 0.9987668126 1.233187e-03 #>  [181,] 0.0034127438 0.9984294312 0.0015705688 0.9987489363 1.251064e-03 #>  [182,] 0.0034621053 0.9984066720 0.0015933280 0.9987308013 1.269199e-03 #>  [183,] 0.0035121783 0.9983835836 0.0016164164 0.9987124037 1.287596e-03 #>  [184,] 0.0035629730 0.9983601612 0.0016398388 0.9986937397 1.306260e-03 #>  [185,] 0.0036144996 0.9983363999 0.0016636001 0.9986748056 1.325194e-03 #>  [186,] 0.0036667686 0.9983122950 0.0016877050 0.9986555974 1.344403e-03 #>  [187,] 0.0037197906 0.9982878413 0.0017121587 0.9986361111 1.363889e-03 #>  [188,] 0.0037735764 0.9982630339 0.0017369661 0.9986163429 1.383657e-03 #>  [189,] 0.0038281370 0.9982378678 0.0017621322 0.9985962884 1.403712e-03 #>  [190,] 0.0038834834 0.9982123377 0.0017876623 0.9985759438 1.424056e-03 #>  [191,] 0.0039396267 0.9981864383 0.0018135617 0.9985553047 1.444695e-03 #>  [192,] 0.0039965785 0.9981601645 0.0018398355 0.9985343669 1.465633e-03 #>  [193,] 0.0040543503 0.9981335107 0.0018664893 0.9985131261 1.486874e-03 #>  [194,] 0.0041129536 0.9981064715 0.0018935285 0.9984915780 1.508422e-03 #>  [195,] 0.0041724006 0.9980790413 0.0019209587 0.9984697180 1.530282e-03 #>  [196,] 0.0042327031 0.9980512146 0.0019487854 0.9984475418 1.552458e-03 #>  [197,] 0.0042938733 0.9980229856 0.0019770144 0.9984250447 1.574955e-03 #>  [198,] 0.0043559238 0.9979943484 0.0020056516 0.9984022221 1.597778e-03 #>  [199,] 0.0044188669 0.9979652974 0.0020347026 0.9983790693 1.620931e-03 #>  [200,] 0.0044827155 0.9979358264 0.0020641736 0.9983555815 1.644418e-03 #>  [201,] 0.0045474824 0.9979059294 0.0020940706 0.9983317540 1.668246e-03 #>  [202,] 0.0046131807 0.9978756003 0.0021243997 0.9983075818 1.692418e-03 #>  [203,] 0.0046798237 0.9978448329 0.0021551671 0.9982830600 1.716940e-03 #>  [204,] 0.0047474249 0.9978136209 0.0021863791 0.9982581835 1.741816e-03 #>  [205,] 0.0048159979 0.9977819579 0.0022180421 0.9982329472 1.767053e-03 #>  [206,] 0.0048855564 0.9977498373 0.0022501627 0.9982073459 1.792654e-03 #>  [207,] 0.0049561147 0.9977172527 0.0022827473 0.9981813744 1.818626e-03 #>  [208,] 0.0050276868 0.9976841973 0.0023158027 0.9981550273 1.844973e-03 #>  [209,] 0.0051002872 0.9976506644 0.0023493356 0.9981282992 1.871701e-03 #>  [210,] 0.0051739305 0.9976166470 0.0023833530 0.9981011847 1.898815e-03 #>  [211,] 0.0052486315 0.9975821384 0.0024178616 0.9980736781 1.926322e-03 #>  [212,] 0.0053244053 0.9975471312 0.0024528688 0.9980457738 1.954226e-03 #>  [213,] 0.0054012670 0.9975116185 0.0024883815 0.9980174661 1.982534e-03 #>  [214,] 0.0054792323 0.9974755930 0.0025244070 0.9979887492 2.011251e-03 #>  [215,] 0.0055583166 0.9974390472 0.0025609528 0.9979596172 2.040383e-03 #>  [216,] 0.0056385359 0.9974019737 0.0025980263 0.9979300641 2.069936e-03 #>  [217,] 0.0057199063 0.9973643650 0.0026356350 0.9979000838 2.099916e-03 #>  [218,] 0.0058024442 0.9973262133 0.0026737867 0.9978696703 2.130330e-03 #>  [219,] 0.0058861659 0.9972875108 0.0027124892 0.9978388172 2.161183e-03 #>  [220,] 0.0059710885 0.9972482497 0.0027517503 0.9978075182 2.192482e-03 #>  [221,] 0.0060572288 0.9972084219 0.0027915781 0.9977757670 2.224233e-03 #>  [222,] 0.0061446040 0.9971680193 0.0028319807 0.9977435570 2.256443e-03 #>  [223,] 0.0062332318 0.9971270336 0.0028729664 0.9977108817 2.289118e-03 #>  [224,] 0.0063231298 0.9970854565 0.0029145435 0.9976777342 2.322266e-03 #>  [225,] 0.0064143159 0.9970432795 0.0029567205 0.9976441079 2.355892e-03 #>  [226,] 0.0065068085 0.9970004939 0.0029995061 0.9976099959 2.390004e-03 #>  [227,] 0.0066006258 0.9969570911 0.0030429089 0.9975753912 2.424609e-03 #>  [228,] 0.0066957868 0.9969130622 0.0030869378 0.9975402866 2.459713e-03 #>  [229,] 0.0067923103 0.9968683983 0.0031316017 0.9975046750 2.495325e-03 #>  [230,] 0.0068902156 0.9968230902 0.0031769098 0.9974685492 2.531451e-03 #>  [231,] 0.0069895222 0.9967771287 0.0032228713 0.9974319017 2.568098e-03 #>  [232,] 0.0070902498 0.9967305044 0.0032694956 0.9973947251 2.605275e-03 #>  [233,] 0.0071924186 0.9966832078 0.0033167922 0.9973570117 2.642988e-03 #>  [234,] 0.0072960487 0.9966352294 0.0033647706 0.9973187538 2.681246e-03 #>  [235,] 0.0074011609 0.9965865594 0.0034134406 0.9972799437 2.720056e-03 #>  [236,] 0.0075077759 0.9965371878 0.0034628122 0.9972405734 2.759427e-03 #>  [237,] 0.0076159149 0.9964871046 0.0035128954 0.9972006348 2.799365e-03 #>  [238,] 0.0077255995 0.9964362996 0.0035637004 0.9971601198 2.839880e-03 #>  [239,] 0.0078368512 0.9963847625 0.0036152375 0.9971190201 2.880980e-03 #>  [240,] 0.0079496921 0.9963324829 0.0036675171 0.9970773273 2.922673e-03 #>  [241,] 0.0080641446 0.9962794501 0.0037205499 0.9970350330 2.964967e-03 #>  [242,] 0.0081802313 0.9962256533 0.0037743467 0.9969921285 3.007872e-03 #>  [243,] 0.0082979752 0.9961710816 0.0038289184 0.9969486050 3.051395e-03 #>  [244,] 0.0084173994 0.9961157240 0.0038842760 0.9969044537 3.095546e-03 #>  [245,] 0.0085385276 0.9960595692 0.0039404308 0.9968596656 3.140334e-03 #>  [246,] 0.0086613836 0.9960026059 0.0039973941 0.9968142316 3.185768e-03 #>  [247,] 0.0087859917 0.9959448224 0.0040551776 0.9967681423 3.231858e-03 #>  [248,] 0.0089123763 0.9958862071 0.0041137929 0.9967213884 3.278612e-03 #>  [249,] 0.0090405624 0.9958267481 0.0041732519 0.9966739605 3.326040e-03 #>  [250,] 0.0091705751 0.9957664333 0.0042335667 0.9966258487 3.374151e-03 #>  [251,] 0.0093024399 0.9957052506 0.0042947494 0.9965770435 3.422957e-03 #>  [252,] 0.0094361828 0.9956431876 0.0043568124 0.9965275347 3.472465e-03 #>  [253,] 0.0095718300 0.9955802317 0.0044197683 0.9964773124 3.522688e-03 #>  [254,] 0.0097094080 0.9955163702 0.0044836298 0.9964263663 3.573634e-03 #>  [255,] 0.0098489438 0.9954515901 0.0045484099 0.9963746861 3.625314e-03 #>  [256,] 0.0099904647 0.9953858784 0.0046141216 0.9963222613 3.677739e-03 #>  [257,] 0.0101339983 0.9953192219 0.0046807781 0.9962690812 3.730919e-03 #>  [258,] 0.0102795726 0.9952516070 0.0047483930 0.9962151351 3.784865e-03 #>  [259,] 0.0104272160 0.9951830201 0.0048169799 0.9961604119 3.839588e-03 #>  [260,] 0.0105769574 0.9951134474 0.0048865526 0.9961049007 3.895099e-03 #>  [261,] 0.0107288259 0.9950428749 0.0049571251 0.9960485900 3.951410e-03 #>  [262,] 0.0108828509 0.9949712882 0.0050287118 0.9959914686 4.008531e-03 #>  [263,] 0.0110390625 0.9948986731 0.0051013269 0.9959335248 4.066475e-03 #>  [264,] 0.0111974909 0.9948250149 0.0051749851 0.9958747468 4.125253e-03 #>  [265,] 0.0113581670 0.9947502987 0.0052497013 0.9958151229 4.184877e-03 #>  [266,] 0.0115211217 0.9946745096 0.0053254904 0.9957546409 4.245359e-03 #>  [267,] 0.0116863868 0.9945976322 0.0054023678 0.9956932885 4.306712e-03 #>  [268,] 0.0118539940 0.9945196512 0.0054803488 0.9956310533 4.368947e-03 #>  [269,] 0.0120239759 0.9944405509 0.0055594491 0.9955679229 4.432077e-03 #>  [270,] 0.0121963651 0.9943603153 0.0056396847 0.9955038843 4.496116e-03 #>  [271,] 0.0123711949 0.9942789284 0.0057210716 0.9954389246 4.561075e-03 #>  [272,] 0.0125484991 0.9941963738 0.0058036262 0.9953730309 4.626969e-03 #>  [273,] 0.0127283116 0.9941126351 0.0058873649 0.9953061896 4.693810e-03 #>  [274,] 0.0129106670 0.9940276954 0.0059723046 0.9952383873 4.761613e-03 #>  [275,] 0.0130956003 0.9939415376 0.0060584624 0.9951696104 4.830390e-03 #>  [276,] 0.0132831470 0.9938541447 0.0061458553 0.9950998450 4.900155e-03 #>  [277,] 0.0134733429 0.9937654990 0.0062345010 0.9950290770 4.970923e-03 #>  [278,] 0.0136662245 0.9936755828 0.0063244172 0.9949572921 5.042708e-03 #>  [279,] 0.0138618285 0.9935843782 0.0064156218 0.9948844759 5.115524e-03 #>  [280,] 0.0140601923 0.9934918670 0.0065081330 0.9948106138 5.189386e-03 #>  [281,] 0.0142613536 0.9933980306 0.0066019694 0.9947356908 5.264309e-03 #>  [282,] 0.0144653507 0.9933028504 0.0066971496 0.9946596919 5.340308e-03 #>  [283,] 0.0146722224 0.9932063074 0.0067936926 0.9945826018 5.417398e-03 #>  [284,] 0.0148820080 0.9931083823 0.0068916177 0.9945044050 5.495595e-03 #>  [285,] 0.0150947471 0.9930090557 0.0069909443 0.9944250858 5.574914e-03 #>  [286,] 0.0153104801 0.9929083077 0.0070916923 0.9943446283 5.655372e-03 #>  [287,] 0.0155292477 0.9928061183 0.0071938817 0.9942630164 5.736984e-03 #>  [288,] 0.0157510913 0.9927024672 0.0072975328 0.9941802336 5.819766e-03 #>  [289,] 0.0159760525 0.9925973339 0.0074026661 0.9940962633 5.903737e-03 #>  [290,] 0.0162041739 0.9924906973 0.0075093027 0.9940110888 5.988911e-03 #>  [291,] 0.0164354981 0.9923825365 0.0076174635 0.9939246930 6.075307e-03 #>  [292,] 0.0166700687 0.9922728298 0.0077271702 0.9938370585 6.162941e-03 #>  [293,] 0.0169079296 0.9921615557 0.0078384443 0.9937481679 6.251832e-03 #>  [294,] 0.0171491252 0.9920486920 0.0079513080 0.9936580034 6.341997e-03 #>  [295,] 0.0173937007 0.9919342164 0.0080657836 0.9935665470 6.433453e-03 #>  [296,] 0.0176417017 0.9918181063 0.0081818937 0.9934737803 6.526220e-03 #>  [297,] 0.0178931742 0.9917003387 0.0082996613 0.9933796849 6.620315e-03 #>  [298,] 0.0181481652 0.9915808904 0.0084191096 0.9932842420 6.715758e-03 #>  [299,] 0.0184067218 0.9914597378 0.0085402622 0.9931874326 6.812567e-03 #>  [300,] 0.0186688921 0.9913368571 0.0086631429 0.9930892373 6.910763e-03 #>  [301,] 0.0189347245 0.9912122239 0.0087877761 0.9929896367 7.010363e-03 #>  [302,] 0.0192042681 0.9910858139 0.0089141861 0.9928886108 7.111389e-03 #>  [303,] 0.0194775725 0.9909576020 0.0090423980 0.9927861397 7.213860e-03 #>  [304,] 0.0197546882 0.9908275632 0.0091724368 0.9926822029 7.317797e-03 #>  [305,] 0.0200356659 0.9906956718 0.0093043282 0.9925767797 7.423220e-03 #>  [306,] 0.0203205572 0.9905619020 0.0094380980 0.9924698494 7.530151e-03 #>  [307,] 0.0206094142 0.9904262275 0.0095737725 0.9923613905 7.638609e-03 #>  [308,] 0.0209022898 0.9902886219 0.0097113781 0.9922513817 7.748618e-03 #>  [309,] 0.0211992372 0.9901490580 0.0098509420 0.9921398012 7.860199e-03 #>  [310,] 0.0215003106 0.9900075088 0.0099924912 0.9920266267 7.973373e-03 #>  [311,] 0.0218055646 0.9898639464 0.0101360536 0.9919118361 8.088164e-03 #>  [312,] 0.0221150545 0.9897183428 0.0102816572 0.9917954064 8.204594e-03 #>  [313,] 0.0224288363 0.9895706697 0.0104293303 0.9916773149 8.322685e-03 #>  [314,] 0.0227469667 0.9894208983 0.0105791017 0.9915575381 8.442462e-03 #>  [315,] 0.0230695030 0.9892689994 0.0107310006 0.9914360523 8.563948e-03 #>  [316,] 0.0233965032 0.9891149435 0.0108850565 0.9913128338 8.687166e-03 #>  [317,] 0.0237280258 0.9889587006 0.0110412994 0.9911878581 8.812142e-03 #>  [318,] 0.0240641303 0.9888002404 0.0111997596 0.9910611007 8.938899e-03 #>  [319,] 0.0244048767 0.9886395322 0.0113604678 0.9909325366 9.067463e-03 #>  [320,] 0.0247503256 0.9884765448 0.0115234552 0.9908021407 9.197859e-03 #>  [321,] 0.0251005385 0.9883112467 0.0116887533 0.9906698872 9.330113e-03 #>  [322,] 0.0254555775 0.9881436059 0.0118563941 0.9905357502 9.464250e-03 #>  [323,] 0.0258155055 0.9879735901 0.0120264099 0.9903997035 9.600297e-03 #>  [324,] 0.0261803859 0.9878011664 0.0121988336 0.9902617203 9.738280e-03 #>  [325,] 0.0265502831 0.9876263016 0.0123736984 0.9901217737 9.878226e-03 #>  [326,] 0.0269252619 0.9874489620 0.0125510380 0.9899798364 1.002016e-02 #>  [327,] 0.0273053882 0.9872691136 0.0127308864 0.9898358805 1.016412e-02 #>  [328,] 0.0276907283 0.9870867218 0.0129132782 0.9896898780 1.031012e-02 #>  [329,] 0.0280813494 0.9869017516 0.0130982484 0.9895418004 1.045820e-02 #>  [330,] 0.0284773195 0.9867141675 0.0132858325 0.9893916188 1.060838e-02 #>  [331,] 0.0288787071 0.9865239336 0.0134760664 0.9892393041 1.076070e-02 #>  [332,] 0.0292855818 0.9863310136 0.0136689864 0.9890848266 1.091517e-02 #>  [333,] 0.0296980136 0.9861353706 0.0138646294 0.9889281562 1.107184e-02 #>  [334,] 0.0301160736 0.9859369674 0.0140630326 0.9887692626 1.123074e-02 #>  [335,] 0.0305398334 0.9857357660 0.0142642340 0.9886081150 1.139188e-02 #>  [336,] 0.0309693655 0.9855317283 0.0144682717 0.9884446822 1.155532e-02 #>  [337,] 0.0314047431 0.9853248154 0.0146751846 0.9882789324 1.172107e-02 #>  [338,] 0.0318460402 0.9851149881 0.0148850119 0.9881108338 1.188917e-02 #>  [339,] 0.0322933316 0.9849022067 0.0150977933 0.9879403537 1.205965e-02 #>  [340,] 0.0327466930 0.9846864308 0.0153135692 0.9877674594 1.223254e-02 #>  [341,] 0.0332062006 0.9844676198 0.0155323802 0.9875921175 1.240788e-02 #>  [342,] 0.0336719317 0.9842457322 0.0157542678 0.9874142943 1.258571e-02 #>  [343,] 0.0341439641 0.9840207263 0.0159792737 0.9872339555 1.276604e-02 #>  [344,] 0.0346223767 0.9837925598 0.0162074402 0.9870510666 1.294893e-02 #>  [345,] 0.0351072490 0.9835611897 0.0164388103 0.9868655924 1.313441e-02 #>  [346,] 0.0355986613 0.9833265726 0.0166734274 0.9866774975 1.332250e-02 #>  [347,] 0.0360966948 0.9830886646 0.0169113354 0.9864867458 1.351325e-02 #>  [348,] 0.0366014314 0.9828474212 0.0171525788 0.9862933008 1.370670e-02 #>  [349,] 0.0371129540 0.9826027974 0.0173972026 0.9860971256 1.390287e-02 #>  [350,] 0.0376313462 0.9823547474 0.0176452526 0.9858981829 1.410182e-02 #>  [351,] 0.0381566923 0.9821032251 0.0178967749 0.9856964347 1.430357e-02 #>  [352,] 0.0386890775 0.9818481838 0.0181518162 0.9854918426 1.450816e-02 #>  [353,] 0.0392285880 0.9815895761 0.0184104239 0.9852843679 1.471563e-02 #>  [354,] 0.0397753105 0.9813273541 0.0186726459 0.9850739710 1.492603e-02 #>  [355,] 0.0403293328 0.9810614693 0.0189385307 0.9848606123 1.513939e-02 #>  [356,] 0.0408907433 0.9807918726 0.0192081274 0.9846442512 1.535575e-02 #>  [357,] 0.0414596314 0.9805185143 0.0194814857 0.9844248470 1.557515e-02 #>  [358,] 0.0420360872 0.9802413441 0.0197586559 0.9842023582 1.579764e-02 #>  [359,] 0.0426202017 0.9799603111 0.0200396889 0.9839767429 1.602326e-02 #>  [360,] 0.0432120666 0.9796753638 0.0203246362 0.9837479587 1.625204e-02 #>  [361,] 0.0438117746 0.9793864500 0.0206135500 0.9835159626 1.648404e-02 #>  [362,] 0.0444194191 0.9790935170 0.0209064830 0.9832807110 1.671929e-02 #>  [363,] 0.0450350944 0.9787965112 0.0212034888 0.9830421599 1.695784e-02 #>  [364,] 0.0456588955 0.9784953788 0.0215046212 0.9828002648 1.719974e-02 #>  [365,] 0.0462909183 0.9781900650 0.0218099350 0.9825549803 1.744502e-02 #>  [366,] 0.0469312595 0.9778805144 0.0221194856 0.9823062608 1.769374e-02 #>  [367,] 0.0475800166 0.9775666712 0.0224333288 0.9820540600 1.794594e-02 #>  [368,] 0.0482372879 0.9772484785 0.0227515215 0.9817983311 1.820167e-02 #>  [369,] 0.0489031726 0.9769258792 0.0230741208 0.9815390265 1.846097e-02 #>  [370,] 0.0495777706 0.9765988151 0.0234011849 0.9812760982 1.872390e-02 #>  [371,] 0.0502611826 0.9762672278 0.0237327722 0.9810094977 1.899050e-02 #>  [372,] 0.0509535102 0.9759310577 0.0240689423 0.9807391757 1.926082e-02 #>  [373,] 0.0516548556 0.9755902449 0.0244097551 0.9804650824 1.953492e-02 #>  [374,] 0.0523653219 0.9752447287 0.0247552713 0.9801871674 1.981283e-02 #>  [375,] 0.0530850131 0.9748944476 0.0251055524 0.9799053796 2.009462e-02 #>  [376,] 0.0538140338 0.9745393395 0.0254606605 0.9796196674 2.038033e-02 #>  [377,] 0.0545524894 0.9741793415 0.0258206585 0.9793299786 2.067002e-02 #>  [378,] 0.0553004861 0.9738143902 0.0261856098 0.9790362602 2.096374e-02 #>  [379,] 0.0560581309 0.9734444213 0.0265555787 0.9787384588 2.126154e-02 #>  [380,] 0.0568255314 0.9730693697 0.0269306303 0.9784365200 2.156348e-02 #>  [381,] 0.0576027960 0.9726891698 0.0273108302 0.9781303892 2.186961e-02 #>  [382,] 0.0583900340 0.9723037551 0.0276962449 0.9778200109 2.217999e-02 #>  [383,] 0.0591873552 0.9719130584 0.0280869416 0.9775053289 2.249467e-02 #>  [384,] 0.0599948701 0.9715170118 0.0284829882 0.9771862865 2.281371e-02 #>  [385,] 0.0608126902 0.9711155466 0.0288844534 0.9768628262 2.313717e-02 #>  [386,] 0.0616409273 0.9707085934 0.0292914066 0.9765348899 2.346511e-02 #>  [387,] 0.0624796942 0.9702960821 0.0297039179 0.9762024188 2.379758e-02 #>  [388,] 0.0633291041 0.9698779416 0.0301220584 0.9758653534 2.413465e-02 #>  [389,] 0.0641892712 0.9694541002 0.0305458998 0.9755236336 2.447637e-02 #>  [390,] 0.0650603099 0.9690244856 0.0309755144 0.9751771985 2.482280e-02 #>  [391,] 0.0659423356 0.9685890243 0.0314109757 0.9748259865 2.517401e-02 #>  [392,] 0.0668354641 0.9681476425 0.0318523575 0.9744699354 2.553006e-02 #>  [393,] 0.0677398120 0.9677002653 0.0322997347 0.9741089822 2.589102e-02 #>  [394,] 0.0686554963 0.9672468171 0.0327531829 0.9737430633 2.625694e-02 #>  [395,] 0.0695826347 0.9667872215 0.0332127785 0.9733721141 2.662789e-02 #>  [396,] 0.0705213452 0.9663214014 0.0336785986 0.9729960697 2.700393e-02 #>  [397,] 0.0714717468 0.9658492788 0.0341507212 0.9726148640 2.738514e-02 #>  [398,] 0.0724339585 0.9653707749 0.0346292251 0.9722284307 2.777157e-02 #>  [399,] 0.0734081003 0.9648858103 0.0351141897 0.9718367022 2.816330e-02 #>  [400,] 0.0743942922 0.9643943044 0.0356056956 0.9714396105 2.856039e-02 #>  [401,] 0.0753926549 0.9638961762 0.0361038238 0.9710370869 2.896291e-02 #>  [402,] 0.0764033097 0.9633913436 0.0366086564 0.9706290618 2.937094e-02 #>  [403,] 0.0774263780 0.9628797239 0.0371202761 0.9702154647 2.978454e-02 #>  [404,] 0.0784619818 0.9623612335 0.0376387665 0.9697962247 3.020378e-02 #>  [405,] 0.0795102433 0.9618357879 0.0381642121 0.9693712698 3.062873e-02 #>  [406,] 0.0805712853 0.9613033019 0.0386966981 0.9689405275 3.105947e-02 #>  [407,] 0.0816452307 0.9607636895 0.0392363105 0.9685039243 3.149608e-02 #>  [408,] 0.0827322028 0.9602168639 0.0397831361 0.9680613861 3.193861e-02 #>  [409,] 0.0838323251 0.9596627372 0.0403372628 0.9676128380 3.238716e-02 #>  [410,] 0.0849457214 0.9591012210 0.0408987790 0.9671582040 3.284180e-02 #>  [411,] 0.0860725158 0.9585322259 0.0414677741 0.9666974078 3.330259e-02 #>  [412,] 0.0872128324 0.9579556619 0.0420443381 0.9662303721 3.376963e-02 #>  [413,] 0.0883667956 0.9573714379 0.0426285621 0.9657570186 3.424298e-02 #>  [414,] 0.0895345298 0.9567794621 0.0432205379 0.9652772685 3.472273e-02 #>  [415,] 0.0907161596 0.9561796419 0.0438203581 0.9647910421 3.520896e-02 #>  [416,] 0.0919118097 0.9555718838 0.0444281162 0.9642982588 3.570174e-02 #>  [417,] 0.0931216048 0.9549560937 0.0450439063 0.9637988373 3.620116e-02 #>  [418,] 0.0943456694 0.9543321764 0.0456678236 0.9632926955 3.670730e-02 #>  [419,] 0.0955841282 0.9537000360 0.0462999640 0.9627797504 3.722025e-02 #>  [420,] 0.0968371058 0.9530595758 0.0469404242 0.9622599183 3.774008e-02 #>  [421,] 0.0981047265 0.9524106984 0.0475893016 0.9617331146 3.826689e-02 #>  [422,] 0.0993871147 0.9517533052 0.0482466948 0.9611992539 3.880075e-02 #>  [423,] 0.1006843944 0.9510872974 0.0489127026 0.9606582499 3.934175e-02 #>  [424,] 0.1019966896 0.9504125748 0.0495874252 0.9601100158 3.988998e-02 #>  [425,] 0.1033241237 0.9497290367 0.0502709633 0.9595544635 4.044554e-02 #>  [426,] 0.1046668201 0.9490365817 0.0509634183 0.9589915045 4.100850e-02 #>  [427,] 0.1060249018 0.9483351073 0.0516648927 0.9584210492 4.157895e-02 #>  [428,] 0.1073984911 0.9476245105 0.0523754895 0.9578430074 4.215699e-02 #>  [429,] 0.1087877103 0.9469046874 0.0530953126 0.9572572878 4.274271e-02 #>  [430,] 0.1101926809 0.9461755333 0.0538244667 0.9566637986 4.333620e-02 #>  [431,] 0.1116135239 0.9454369428 0.0545630572 0.9560624469 4.393755e-02 #>  [432,] 0.1130503599 0.9446888097 0.0553111903 0.9554531392 4.454686e-02 #>  [433,] 0.1145033088 0.9439310270 0.0560689730 0.9548357810 4.516422e-02 #>  [434,] 0.1159724895 0.9431634870 0.0568365130 0.9542102771 4.578972e-02 #>  [435,] 0.1174580207 0.9423860813 0.0576139187 0.9535765315 4.642347e-02 #>  [436,] 0.1189600200 0.9415987008 0.0584012992 0.9529344472 4.706555e-02 #>  [437,] 0.1204786041 0.9408012354 0.0591987646 0.9522839266 4.771607e-02 #>  [438,] 0.1220138891 0.9399935747 0.0600064253 0.9516248712 4.837513e-02 #>  [439,] 0.1235659899 0.9391756073 0.0608243927 0.9509571818 4.904282e-02 #>  [440,] 0.1251350204 0.9383472213 0.0616527787 0.9502807581 4.971924e-02 #>  [441,] 0.1267210938 0.9375083039 0.0624916961 0.9495954994 5.040450e-02 #>  [442,] 0.1283243217 0.9366587418 0.0633412582 0.9489013040 5.109870e-02 #>  [443,] 0.1299448148 0.9357984210 0.0642015790 0.9481980692 5.180193e-02 #>  [444,] 0.1315826826 0.9349272269 0.0650727731 0.9474856920 5.251431e-02 #>  [445,] 0.1332380333 0.9340450442 0.0659549558 0.9467640682 5.323593e-02 #>  [446,] 0.1349109736 0.9331517569 0.0668482431 0.9460330931 5.396691e-02 #>  [447,] 0.1366016089 0.9322472487 0.0677527513 0.9452926610 5.470734e-02 #>  [448,] 0.1383100431 0.9313314023 0.0686685977 0.9445426656 5.545733e-02 #>  [449,] 0.1400363787 0.9304041003 0.0695958997 0.9437829998 5.621700e-02 #>  [450,] 0.1417807164 0.9294652243 0.0705347757 0.9430135558 5.698644e-02 #>  [451,] 0.1435431553 0.9285146557 0.0714853443 0.9422342250 5.776578e-02 #>  [452,] 0.1453237928 0.9275522752 0.0724477248 0.9414448980 5.855510e-02 #>  [453,] 0.1471227246 0.9265779630 0.0734220370 0.9406454649 5.935454e-02 #>  [454,] 0.1489400443 0.9255915989 0.0744084011 0.9398358149 6.016419e-02 #>  [455,] 0.1507758438 0.9245930622 0.0754069378 0.9390158366 6.098416e-02 #>  [456,] 0.1526302128 0.9235822318 0.0764177682 0.9381854178 6.181458e-02 #>  [457,] 0.1545032391 0.9225589861 0.0774410139 0.9373444457 6.265555e-02 #>  [458,] 0.1563950083 0.9215232032 0.0784767968 0.9364928069 6.350719e-02 #>  [459,] 0.1583056038 0.9204747608 0.0795252392 0.9356303872 6.436961e-02 #>  [460,] 0.1602351067 0.9194135363 0.0805864637 0.9347570719 6.524293e-02 #>  [461,] 0.1621835957 0.9183394065 0.0816605935 0.9338727455 6.612725e-02 #>  [462,] 0.1641511471 0.9172522483 0.0827477517 0.9329772921 6.702271e-02 #>  [463,] 0.1661378349 0.9161519382 0.0838480618 0.9320705951 6.792940e-02 #>  [464,] 0.1681437302 0.9150383522 0.0849616478 0.9311525372 6.884746e-02 #>  [465,] 0.1701689017 0.9139113664 0.0860886336 0.9302230007 6.977700e-02 #>  [466,] 0.1722134153 0.9127708567 0.0872291433 0.9292818674 7.071813e-02 #>  [467,] 0.1742773341 0.9116166986 0.0883833014 0.9283290183 7.167098e-02 #>  [468,] 0.1763607183 0.9104487677 0.0895512323 0.9273643341 7.263567e-02 #>  [469,] 0.1784636254 0.9092669394 0.0907330606 0.9263876949 7.361231e-02 #>  [470,] 0.1805861095 0.9080710890 0.0919289110 0.9253989805 7.460102e-02 #>  [471,] 0.1827282220 0.9068610920 0.0931389080 0.9243980701 7.560193e-02 #>  [472,] 0.1848900108 0.9056368236 0.0943631764 0.9233848424 7.661516e-02 #>  [473,] 0.1870715208 0.9043981592 0.0956018408 0.9223591759 7.764082e-02 #>  [474,] 0.1892727935 0.9031449744 0.0968550256 0.9213209484 7.867905e-02 #>  [475,] 0.1914938670 0.9018771445 0.0981228555 0.9202700377 7.972996e-02 #>  [476,] 0.1937347760 0.9005945455 0.0994054545 0.9192063210 8.079368e-02 #>  [477,] 0.1959955516 0.8992970531 0.1007029469 0.9181296752 8.187032e-02 #>  [478,] 0.1982762214 0.8979845436 0.1020154564 0.9170399771 8.296002e-02 #>  [479,] 0.2005768091 0.8966568933 0.1033431067 0.9159371030 8.406290e-02 #>  [480,] 0.2028973349 0.8953139790 0.1046860210 0.9148209291 8.517907e-02 #>  [481,] 0.2052378150 0.8939556778 0.1060443222 0.9136913313 8.630867e-02 #>  [482,] 0.2075982619 0.8925818670 0.1074181330 0.9125481855 8.745181e-02 #>  [483,] 0.2099786838 0.8911924248 0.1088075752 0.9113913672 8.860863e-02 #>  [484,] 0.2123790852 0.8897872293 0.1102127707 0.9102207519 8.977925e-02 #>  [485,] 0.2147994663 0.8883661597 0.1116338403 0.9090362150 9.096378e-02 #>  [486,] 0.2172398232 0.8869290955 0.1130709045 0.9078376320 9.216237e-02 #>  [487,] 0.2197001477 0.8854759167 0.1145240833 0.9066248781 9.337512e-02 #>  [488,] 0.2221804273 0.8840065043 0.1159934957 0.9053978287 9.460217e-02 #>  [489,] 0.2246806451 0.8825207398 0.1174792602 0.9041563591 9.584364e-02 #>  [490,] 0.2272007798 0.8810185056 0.1189814944 0.9029003450 9.709966e-02 #>  [491,] 0.2297408057 0.8794996848 0.1205003152 0.9016296617 9.837034e-02 #>  [492,] 0.2323006922 0.8779641615 0.1220358385 0.9003441852 9.965581e-02 #>  [493,] 0.2348804043 0.8764118209 0.1235881791 0.8990437913 1.009562e-01 #>  [494,] 0.2374799024 0.8748425488 0.1251574512 0.8977283563 1.022716e-01 #>  [495,] 0.2400991420 0.8732562323 0.1267437677 0.8963977566 1.036022e-01 #>  [496,] 0.2427380737 0.8716527597 0.1283472403 0.8950518690 1.049481e-01 #>  [497,] 0.2453966434 0.8700320203 0.1299679797 0.8936905707 1.063094e-01 #>  [498,] 0.2480747921 0.8683939046 0.1316060954 0.8923137392 1.076863e-01 #>  [499,] 0.2507724557 0.8667383047 0.1332616953 0.8909212526 1.090787e-01 #>  [500,] 0.2534895652 0.8650651135 0.1349348865 0.8895129893 1.104870e-01 #>  [501,] 0.2562260464 0.8633742259 0.1366257741 0.8880888284 1.119112e-01 #>  [502,] 0.2589818202 0.8616655378 0.1383344622 0.8866486496 1.133514e-01 #>  [503,] 0.2617568021 0.8599389470 0.1400610530 0.8851923331 1.148077e-01 #>  [504,] 0.2645509026 0.8581943527 0.1418056473 0.8837197599 1.162802e-01 #>  [505,] 0.2673640268 0.8564316557 0.1435683443 0.8822308118 1.177692e-01 #>  [506,] 0.2701960746 0.8546507587 0.1453492413 0.8807253713 1.192746e-01 #>  [507,] 0.2730469408 0.8528515662 0.1471484338 0.8792033216 1.207967e-01 #>  [508,] 0.2759165145 0.8510339843 0.1489660157 0.8776645472 1.223355e-01 #>  [509,] 0.2788046796 0.8491979215 0.1508020785 0.8761089331 1.238911e-01 #>  [510,] 0.2817113146 0.8473432878 0.1526567122 0.8745363656 1.254636e-01 #>  [511,] 0.2846362927 0.8454699956 0.1545300044 0.8729467320 1.270533e-01 #>  [512,] 0.2875794815 0.8435779593 0.1564220407 0.8713399208 1.286601e-01 #>  [513,] 0.2905407431 0.8416670955 0.1583329045 0.8697158213 1.302842e-01 #>  [514,] 0.2935199343 0.8397373233 0.1602626767 0.8680743247 1.319257e-01 #>  [515,] 0.2965169063 0.8377885638 0.1622114362 0.8664153228 1.335847e-01 #>  [516,] 0.2995315049 0.8358207408 0.1641792592 0.8647387093 1.352613e-01 #>  [517,] 0.3025635703 0.8338337804 0.1661662196 0.8630443790 1.369556e-01 #>  [518,] 0.3056129371 0.8318276115 0.1681723885 0.8613322283 1.386678e-01 #>  [519,] 0.3086794348 0.8298021655 0.1701978345 0.8596021552 1.403978e-01 #>  [520,] 0.3117628869 0.8277573764 0.1722426236 0.8578540592 1.421459e-01 #>  [521,] 0.3148631117 0.8256931813 0.1743068187 0.8560878416 1.439122e-01 #>  [522,] 0.3179799220 0.8236095199 0.1763904801 0.8543034053 1.456966e-01 #>  [523,] 0.3211131250 0.8215063348 0.1784936652 0.8525006551 1.474993e-01 #>  [524,] 0.3242625225 0.8193835720 0.1806164280 0.8506794977 1.493205e-01 #>  [525,] 0.3274279110 0.8172411801 0.1827588199 0.8488398417 1.511602e-01 #>  [526,] 0.3306090814 0.8150791112 0.1849208888 0.8469815977 1.530184e-01 #>  [527,] 0.3338058194 0.8128973205 0.1871026795 0.8451046785 1.548953e-01 #>  [528,] 0.3370179051 0.8106957665 0.1893042335 0.8432089988 1.567910e-01 #>  [529,] 0.3402451135 0.8084744112 0.1915255888 0.8412944758 1.587055e-01 #>  [530,] 0.3434872142 0.8062332200 0.1937667800 0.8393610288 1.606390e-01 #>  [531,] 0.3467439718 0.8039721617 0.1960278383 0.8374085796 1.625914e-01 #>  [532,] 0.3500151453 0.8016912089 0.1983087911 0.8354370524 1.645629e-01 #>  [533,] 0.3533004888 0.7993903378 0.2006096622 0.8334463738 1.665536e-01 #>  [534,] 0.3565997514 0.7970695284 0.2029304716 0.8314364732 1.685635e-01 #>  [535,] 0.3599126770 0.7947287645 0.2052712355 0.8294072824 1.705927e-01 #>  [536,] 0.3632390046 0.7923680337 0.2076319663 0.8273587362 1.726413e-01 #>  [537,] 0.3665784683 0.7899873277 0.2100126723 0.8252907720 1.747092e-01 #>  [538,] 0.3699307972 0.7875866422 0.2124133578 0.8232033301 1.767967e-01 #>  [539,] 0.3732957159 0.7851659771 0.2148340229 0.8210963539 1.789036e-01 #>  [540,] 0.3766729441 0.7827253362 0.2172746638 0.8189697898 1.810302e-01 #>  [541,] 0.3800621970 0.7802647279 0.2197352721 0.8168235870 1.831764e-01 #>  [542,] 0.3834631851 0.7777841647 0.2222158353 0.8146576983 1.853423e-01 #>  [543,] 0.3868756146 0.7752836636 0.2247163364 0.8124720795 1.875279e-01 #>  [544,] 0.3902991872 0.7727632459 0.2272367541 0.8102666898 1.897333e-01 #>  [545,] 0.3937336006 0.7702229374 0.2297770626 0.8080414917 1.919585e-01 #>  [546,] 0.3971785481 0.7676627688 0.2323372312 0.8057964514 1.942035e-01 #>  [547,] 0.4006337188 0.7650827750 0.2349172250 0.8035315385 1.964685e-01 #>  [548,] 0.4040987981 0.7624829959 0.2375170041 0.8012467262 1.987533e-01 #>  [549,] 0.4075734675 0.7598634761 0.2401365239 0.7989419914 2.010580e-01 #>  [550,] 0.4110574045 0.7572242647 0.2427757353 0.7966173148 2.033827e-01 #>  [551,] 0.4145502831 0.7545654162 0.2454345838 0.7942726810 2.057273e-01 #>  [552,] 0.4180517739 0.7518869896 0.2481130104 0.7919080784 2.080919e-01 #>  [553,] 0.4215615439 0.7491890490 0.2508109510 0.7895234994 2.104765e-01 #>  [554,] 0.4250792567 0.7464716636 0.2535283364 0.7871189406 2.128811e-01 #>  [555,] 0.4286045731 0.7437349075 0.2562650925 0.7846944026 2.153056e-01 #>  [556,] 0.4321371504 0.7409788600 0.2590211400 0.7822498902 2.177501e-01 #>  [557,] 0.4356766434 0.7382036057 0.2617963943 0.7797854123 2.202146e-01 #>  [558,] 0.4392227037 0.7354092340 0.2645907660 0.7773009826 2.226990e-01 #>  [559,] 0.4427749806 0.7325958401 0.2674041599 0.7747966187 2.252034e-01 #>  [560,] 0.4463331207 0.7297635239 0.2702364761 0.7722723428 2.277277e-01 #>  [561,] 0.4498967681 0.7269123910 0.2730876090 0.7697281818 2.302718e-01 #>  [562,] 0.4534655650 0.7240425521 0.2759574479 0.7671641671 2.328358e-01 #>  [563,] 0.4570391511 0.7211541235 0.2788458765 0.7645803345 2.354197e-01 #>  [564,] 0.4606171644 0.7182472268 0.2817527732 0.7619767249 2.380233e-01 #>  [565,] 0.4641992409 0.7153219889 0.2846780111 0.7593533837 2.406466e-01 #>  [566,] 0.4677850152 0.7123785422 0.2876214578 0.7567103612 2.432896e-01 #>  [567,] 0.4713741201 0.7094170246 0.2905829754 0.7540477125 2.459523e-01 #>  [568,] 0.4749661871 0.7064375795 0.2935624205 0.7513654978 2.486345e-01 #>  [569,] 0.4785608466 0.7034403558 0.2965596442 0.7486637822 2.513362e-01 #>  [570,] 0.4821577277 0.7004255078 0.2995744922 0.7459426356 2.540574e-01 #>  [571,] 0.4857564588 0.6973931952 0.3026068048 0.7432021334 2.567979e-01 #>  [572,] 0.4893566675 0.6943435836 0.3056564164 0.7404423558 2.595576e-01 #>  [573,] 0.4929579806 0.6912768436 0.3087231564 0.7376633883 2.623366e-01 #>  [574,] 0.4965600247 0.6881931518 0.3118068482 0.7348653214 2.651347e-01 #>  [575,] 0.5001624259 0.6850926898 0.3149073102 0.7320482513 2.679517e-01 #>  [576,] 0.5037648102 0.6819756451 0.3180243549 0.7292122789 2.707877e-01 #>  [577,] 0.5073668037 0.6788422105 0.3211577895 0.7263575109 2.736425e-01 #>  [578,] 0.5109680325 0.6756925841 0.3243074159 0.7234840591 2.765159e-01 #>  [579,] 0.5145681232 0.6725269698 0.3274730302 0.7205920407 2.794080e-01 #>  [580,] 0.5181667028 0.6693455765 0.3306544235 0.7176815783 2.823184e-01 #>  [581,] 0.5217633988 0.6661486188 0.3338513812 0.7147527999 2.852472e-01 #>  [582,] 0.5253578397 0.6629363165 0.3370636835 0.7118058391 2.881942e-01 #>  [583,] 0.5289496548 0.6597088947 0.3402911053 0.7088408348 2.911592e-01 #>  [584,] 0.5325384744 0.6564665839 0.3435334161 0.7058579314 2.941421e-01 #>  [585,] 0.5361239303 0.6532096197 0.3467903803 0.7028572789 2.971427e-01 #>  [586,] 0.5397056554 0.6499382430 0.3500617570 0.6998390325 3.001610e-01 #>  [587,] 0.5432832844 0.6466526998 0.3533473002 0.6968033534 3.031966e-01 #>  [588,] 0.5468564534 0.6433532411 0.3566467589 0.6937504078 3.062496e-01 #>  [589,] 0.5504248007 0.6400401231 0.3599598769 0.6906803676 3.093196e-01 #>  [590,] 0.5539879661 0.6367136069 0.3632863931 0.6875934104 3.124066e-01 #>  [591,] 0.5575455921 0.6333739584 0.3666260416 0.6844897190 3.155103e-01 #>  [592,] 0.5610973228 0.6300214485 0.3699785515 0.6813694817 3.186305e-01 #>  [593,] 0.5646428053 0.6266563528 0.3733436472 0.6782328925 3.217671e-01 #>  [594,] 0.5681816889 0.6232789517 0.3767210483 0.6750801507 3.249198e-01 #>  [595,] 0.5717136256 0.6198895299 0.3801104701 0.6719114610 3.280885e-01 #>  [596,] 0.5752382703 0.6164883771 0.3835116229 0.6687270335 3.312730e-01 #>  [597,] 0.5787552808 0.6130757871 0.3869242129 0.6655270838 3.344729e-01 #>  [598,] 0.5822643179 0.6096520581 0.3903479419 0.6623118327 3.376882e-01 #>  [599,] 0.5857650457 0.6062174928 0.3937825072 0.6590815064 3.409185e-01 #>  [600,] 0.5892571315 0.6027723978 0.3972276022 0.6558363364 3.441637e-01 #>  [601,] 0.5927402461 0.5993170840 0.4006829160 0.6525765593 3.474234e-01 #>  [602,] 0.5962140639 0.5958518661 0.4041481339 0.6493024169 3.506976e-01 #>  [603,] 0.5996782627 0.5923770627 0.4076229373 0.6460141563 3.539858e-01 #>  [604,] 0.6031325244 0.5888929963 0.4111070037 0.6427120295 3.572880e-01 #>  [605,] 0.6065765346 0.5853999929 0.4146000071 0.6393962936 3.606037e-01 #>  [606,] 0.6100099830 0.5818983820 0.4181016180 0.6360672107 3.639328e-01 #>  [607,] 0.6134325632 0.5783884968 0.4216115032 0.6327250476 3.672750e-01 #>  [608,] 0.6168439731 0.5748706734 0.4251293266 0.6293700762 3.706299e-01 #>  [609,] 0.6202439149 0.5713452514 0.4286547486 0.6260025729 3.739974e-01 #>  [610,] 0.6236320953 0.5678125733 0.4321874267 0.6226228191 3.773772e-01 #>  [611,] 0.6270082251 0.5642729846 0.4357270154 0.6192311005 3.807689e-01 #>  [612,] 0.6303720199 0.5607268334 0.4392731666 0.6158277073 3.841723e-01 #>  [613,] 0.6337232000 0.5571744706 0.4428255294 0.6124129345 3.875871e-01 #>  [614,] 0.6370614901 0.5536162498 0.4463837502 0.6089870811 3.910129e-01 #>  [615,] 0.6403866200 0.5500525266 0.4499474734 0.6055504504 3.944495e-01 #>  [616,] 0.6436983242 0.5464836591 0.4535163409 0.6021033501 3.978966e-01 #>  [617,] 0.6469963421 0.5429100075 0.4570899925 0.5986460915 4.013539e-01 #>  [618,] 0.6502804181 0.5393319339 0.4606680661 0.5951789904 4.048210e-01 #>  [619,] 0.6535503016 0.5357498022 0.4642501978 0.5917023660 4.082976e-01 #>  [620,] 0.6568057473 0.5321639780 0.4678360220 0.5882165415 4.117835e-01 #>  [621,] 0.6600465147 0.5285748284 0.4714251716 0.5847218436 4.152782e-01 #>  [622,] 0.6632723688 0.5249827220 0.4750172780 0.5812186026 4.187814e-01 #>  [623,] 0.6664830797 0.5213880283 0.4786119717 0.5777071521 4.222928e-01 #>  [624,] 0.6696784227 0.5177911183 0.4822088817 0.5741878291 4.258122e-01 #>  [625,] 0.6728581787 0.5141923635 0.4858076365 0.5706609736 4.293390e-01 #>  [626,] 0.6760221337 0.5105921365 0.4894078635 0.5671269287 4.328731e-01 #>  [627,] 0.6791700792 0.5069908104 0.4930091896 0.5635860405 4.364140e-01 #>  [628,] 0.6823018121 0.5033887586 0.4966112414 0.5600386576 4.399613e-01 #>  [629,] 0.6854171345 0.4997863551 0.5002136449 0.5564851316 4.435149e-01 #>  [630,] 0.6885158545 0.4961839737 0.5038160263 0.5529258162 4.470742e-01 #>  [631,] 0.6915977851 0.4925819885 0.5074180115 0.5493610677 4.506389e-01 #>  [632,] 0.6946627451 0.4889807732 0.5110192268 0.5457912446 4.542088e-01 #>  [633,] 0.6977105587 0.4853807013 0.5146192987 0.5422167074 4.577833e-01 #>  [634,] 0.7007410557 0.4817821459 0.5182178541 0.5386378186 4.613622e-01 #>  [635,] 0.7037540713 0.4781854794 0.5218145206 0.5350549425 4.649451e-01 #>  [636,] 0.7067494462 0.4745910732 0.5254089268 0.5314684449 4.685316e-01 #>  [637,] 0.7097270266 0.4709992982 0.5290007018 0.5278786933 4.721213e-01 #>  [638,] 0.7126866643 0.4674105238 0.5325894762 0.5242860563 4.757139e-01 #>  [639,] 0.7156282165 0.4638251184 0.5361748816 0.5206909040 4.793091e-01 #>  [640,] 0.7185515458 0.4602434489 0.5397565511 0.5170936073 4.829064e-01 #>  [641,] 0.7214565205 0.4566658808 0.5433341192 0.5134945380 4.865055e-01 #>  [642,] 0.7243430140 0.4530927778 0.5469072222 0.5098940688 4.901059e-01 #>  [643,] 0.7272109054 0.4495245017 0.5504754983 0.5062925728 4.937074e-01 #>  [644,] 0.7300600791 0.4459614125 0.5540385875 0.5026904236 4.973096e-01 #>  [645,] 0.7328904248 0.4424038679 0.5575961321 0.4990879951 5.009120e-01 #>  [646,] 0.7357018375 0.4388522235 0.5611477765 0.4954856613 5.045143e-01 #>  [647,] 0.7384942178 0.4353068324 0.5646931676 0.4918837961 5.081162e-01 #>  [648,] 0.7412674712 0.4317680451 0.5682319549 0.4882827734 5.117172e-01 #>  [649,] 0.7440215086 0.4282362097 0.5717637903 0.4846829664 5.153170e-01 #>  [650,] 0.7467562462 0.4247116711 0.5752883289 0.4810847480 5.189153e-01 #>  [651,] 0.7494716051 0.4211947716 0.5788052284 0.4774884907 5.225115e-01 #>  [652,] 0.7521675117 0.4176858503 0.5823141497 0.4738945657 5.261054e-01 #>  [653,] 0.7548438974 0.4141852431 0.5858147569 0.4703033435 5.296967e-01 #>  [654,] 0.7575006987 0.4106932825 0.5893067175 0.4667151934 5.332848e-01 #>  [655,] 0.7601378568 0.4072102978 0.5927897022 0.4631304837 5.368695e-01 #>  [656,] 0.7627553181 0.4037366146 0.5962633854 0.4595495808 5.404504e-01 #>  [657,] 0.7653530337 0.4002725548 0.5997274452 0.4559728499 5.440272e-01 #>  [658,] 0.7679309597 0.3968184367 0.6031815633 0.4524006544 5.475993e-01 #>  [659,] 0.7704890566 0.3933745745 0.6066254255 0.4488333557 5.511666e-01 #>  [660,] 0.7730272899 0.3899412785 0.6100587215 0.4452713135 5.547287e-01 #>  [661,] 0.7755456296 0.3865188550 0.6134811450 0.4417148850 5.582851e-01 #>  [662,] 0.7780440503 0.3831076061 0.6168923939 0.4381644253 5.618356e-01 #>  [663,] 0.7805225311 0.3797078294 0.6202921706 0.4346202871 5.653797e-01 #>  [664,] 0.7829810554 0.3763198184 0.6236801816 0.4310828204 5.689172e-01 #>  [665,] 0.7854196113 0.3729438620 0.6270561380 0.4275523726 5.724476e-01 #>  [666,] 0.7878381908 0.3695802446 0.6304197554 0.4240292883 5.759707e-01 #>  [667,] 0.7902367905 0.3662292459 0.6337707541 0.4205139090 5.794861e-01 #>  [668,] 0.7926154109 0.3628911409 0.6371088591 0.4170065733 5.829934e-01 #>  [669,] 0.7949740569 0.3595662001 0.6404337999 0.4135076164 5.864924e-01 #>  [670,] 0.7973127371 0.3562546887 0.6437453113 0.4100173703 5.899826e-01 #>  [671,] 0.7996314642 0.3529568672 0.6470431328 0.4065361634 5.934638e-01 #>  [672,] 0.8019302550 0.3496729913 0.6503270087 0.4030643207 5.969357e-01 #>  [673,] 0.8042091297 0.3464033113 0.6535966887 0.3996021634 6.003978e-01 #>  [674,] 0.8064681127 0.3431480727 0.6568519273 0.3961500091 6.038500e-01 #>  [675,] 0.8087072317 0.3399075156 0.6600924844 0.3927081711 6.072918e-01 #>  [676,] 0.8109265182 0.3366818753 0.6633181247 0.3892769590 6.107230e-01 #>  [677,] 0.8131260071 0.3334713813 0.6665286187 0.3858566783 6.141433e-01 #>  [678,] 0.8153057370 0.3302762583 0.6697237417 0.3824476302 6.175524e-01 #>  [679,] 0.8174657496 0.3270967255 0.6729032745 0.3790501116 6.209499e-01 #>  [680,] 0.8196060901 0.3239329967 0.6760670033 0.3756644150 6.243356e-01 #>  [681,] 0.8217268067 0.3207852803 0.6792147197 0.3722908285 6.277092e-01 #>  [682,] 0.8238279510 0.3176537794 0.6823462206 0.3689296356 6.310704e-01 #>  [683,] 0.8259095776 0.3145386916 0.6854613084 0.3655811151 6.344189e-01 #>  [684,] 0.8279717440 0.3114402091 0.6885597909 0.3622455412 6.377545e-01 #>  [685,] 0.8300145108 0.3083585185 0.6916414815 0.3589231831 6.410768e-01 #>  [686,] 0.8320379414 0.3052938011 0.6947061989 0.3556143054 6.443857e-01 #>  [687,] 0.8340421018 0.3022462324 0.6977537676 0.3523191676 6.476808e-01 #>  [688,] 0.8360270609 0.2992159829 0.7007840171 0.3490380242 6.509620e-01 #>  [689,] 0.8379928904 0.2962032170 0.7037967830 0.3457711248 6.542289e-01 #>  [690,] 0.8399396641 0.2932080941 0.7067919059 0.3425187136 6.574813e-01 #>  [691,] 0.8418674587 0.2902307677 0.7097692323 0.3392810301 6.607190e-01 #>  [692,] 0.8437763532 0.2872713862 0.7127286138 0.3360583082 6.639417e-01 #>  [693,] 0.8456664288 0.2843300921 0.7156699079 0.3328507766 6.671492e-01 #>  [694,] 0.8475377691 0.2814070228 0.7185929772 0.3296586589 6.703413e-01 #>  [695,] 0.8493904600 0.2785023101 0.7214976899 0.3264821733 6.735178e-01 #>  [696,] 0.8512245894 0.2756160802 0.7243839198 0.3233215324 6.766785e-01 #>  [697,] 0.8530402472 0.2727484541 0.7272515459 0.3201769439 6.798231e-01 #>  [698,] 0.8548375254 0.2698995474 0.7301004526 0.3170486095 6.829514e-01 #>  [699,] 0.8566165179 0.2670694702 0.7329305298 0.3139367259 6.860633e-01 #>  [700,] 0.8583773205 0.2642583273 0.7357416727 0.3108414842 6.891585e-01 #>  [701,] 0.8601200307 0.2614662183 0.7385337817 0.3077630700 6.922369e-01 #>  [702,] 0.8618447479 0.2586932375 0.7413067625 0.3047016634 6.952983e-01 #>  [703,] 0.8635515729 0.2559394739 0.7440605261 0.3016574391 6.983426e-01 #>  [704,] 0.8652406083 0.2532050113 0.7467949887 0.2986305662 7.013694e-01 #>  [705,] 0.8669119581 0.2504899285 0.7495100715 0.2956212082 7.043788e-01 #>  [706,] 0.8685657278 0.2477942990 0.7522057010 0.2926295234 7.073705e-01 #>  [707,] 0.8702020244 0.2451181913 0.7548818087 0.2896556644 7.103443e-01 #>  [708,] 0.8718209562 0.2424616689 0.7575383311 0.2866997783 7.133002e-01 #>  [709,] 0.8734226326 0.2398247905 0.7601752095 0.2837620067 7.162380e-01 #>  [710,] 0.8750071645 0.2372076096 0.7627923904 0.2808424858 7.191575e-01 #>  [711,] 0.8765746638 0.2346101750 0.7653898250 0.2779413463 7.220587e-01 #>  [712,] 0.8781252435 0.2320325307 0.7679674693 0.2750587137 7.249413e-01 #>  [713,] 0.8796590177 0.2294747160 0.7705252840 0.2721947076 7.278053e-01 #>  [714,] 0.8811761015 0.2269367653 0.7730632347 0.2693494427 7.306506e-01 #>  [715,] 0.8826766110 0.2244187086 0.7755812914 0.2665230280 7.334770e-01 #>  [716,] 0.8841606629 0.2219205713 0.7780794287 0.2637155673 7.362844e-01 #>  [717,] 0.8856283751 0.2194423742 0.7805576258 0.2609271593 7.390728e-01 #>  [718,] 0.8870798661 0.2169841337 0.7830158663 0.2581578971 7.418421e-01 #>  [719,] 0.8885152550 0.2145458618 0.7854541382 0.2554078687 7.445921e-01 #>  [720,] 0.8899346618 0.2121275663 0.7878724337 0.2526771571 7.473228e-01 #>  [721,] 0.8913382070 0.2097292507 0.7902707493 0.2499658398 7.500342e-01 #>  [722,] 0.8927260118 0.2073509143 0.7926490857 0.2472739895 7.527260e-01 #>  [723,] 0.8940981977 0.2049925523 0.7950074477 0.2446016737 7.553983e-01 #>  [724,] 0.8954548869 0.2026541559 0.7973458441 0.2419489551 7.580510e-01 #>  [725,] 0.8967962020 0.2003357123 0.7996642877 0.2393158911 7.606841e-01 #>  [726,] 0.8981222660 0.1980372049 0.8019627951 0.2367025345 7.632975e-01 #>  [727,] 0.8994332020 0.1957586131 0.8042413869 0.2341089331 7.658911e-01 #>  [728,] 0.9007291338 0.1934999128 0.8065000872 0.2315351300 7.684649e-01 #>  [729,] 0.9020101853 0.1912610760 0.8087389240 0.2289811635 7.710188e-01 #>  [730,] 0.9032764804 0.1890420712 0.8109579288 0.2264470672 7.735529e-01 #>  [731,] 0.9045281437 0.1868428635 0.8131571365 0.2239328702 7.760671e-01 #>  [732,] 0.9057652994 0.1846634142 0.8153365858 0.2214385970 7.785614e-01 #>  [733,] 0.9069880721 0.1825036816 0.8174963184 0.2189642674 7.810357e-01 #>  [734,] 0.9081965865 0.1803636205 0.8196363795 0.2165098972 7.834901e-01 #>  [735,] 0.9093909672 0.1782431825 0.8217568175 0.2140754974 7.859245e-01 #>  [736,] 0.9105713389 0.1761423161 0.8238576839 0.2116610750 7.883389e-01 #>  [737,] 0.9117378262 0.1740609666 0.8259390334 0.2092666327 7.907334e-01 #>  [738,] 0.9128905537 0.1719990765 0.8280009235 0.2068921689 7.931078e-01 #>  [739,] 0.9140296458 0.1699565850 0.8300434150 0.2045376782 7.954623e-01 #>  [740,] 0.9151552269 0.1679334290 0.8320665710 0.2022031509 7.977968e-01 #>  [741,] 0.9162674212 0.1659295421 0.8340704579 0.1998885735 8.001114e-01 #>  [742,] 0.9173663526 0.1639448554 0.8360551446 0.1975939286 8.024061e-01 #>  [743,] 0.9184521450 0.1619792974 0.8380207026 0.1953191950 8.046808e-01 #>  [744,] 0.9195249217 0.1600327940 0.8399672060 0.1930643476 8.069357e-01 #>  [745,] 0.9205848062 0.1581052687 0.8418947313 0.1908293580 8.091706e-01 #>  [746,] 0.9216319213 0.1561966424 0.8438033576 0.1886141938 8.113858e-01 #>  [747,] 0.9226663897 0.1543068337 0.8456931663 0.1864188195 8.135812e-01 #>  [748,] 0.9236883336 0.1524357591 0.8475642409 0.1842431958 8.157568e-01 #>  [749,] 0.9246978750 0.1505833328 0.8494166672 0.1820872803 8.179127e-01 #>  [750,] 0.9256951353 0.1487494667 0.8512505333 0.1799510272 8.200490e-01 #>  [751,] 0.9266802356 0.1469340709 0.8530659291 0.1778343874 8.221656e-01 #>  [752,] 0.9276532966 0.1451370533 0.8548629467 0.1757373088 8.242627e-01 #>  [753,] 0.9286144385 0.1433583201 0.8566416799 0.1736597363 8.263403e-01 #>  [754,] 0.9295637809 0.1415977754 0.8584022246 0.1716016115 8.283984e-01 #>  [755,] 0.9305014431 0.1398553217 0.8601446783 0.1695628734 8.304371e-01 #>  [756,] 0.9314275437 0.1381308596 0.8618691404 0.1675434581 8.324565e-01 #>  [757,] 0.9323422009 0.1364242883 0.8635757117 0.1655432987 8.344567e-01 #>  [758,] 0.9332455323 0.1347355051 0.8652644949 0.1635623259 8.364377e-01 #>  [759,] 0.9341376549 0.1330644060 0.8669355940 0.1616004677 8.383995e-01 #>  [760,] 0.9350186851 0.1314108854 0.8685891146 0.1596576494 8.403424e-01 #>  [761,] 0.9358887387 0.1297748365 0.8702251635 0.1577337940 8.422662e-01 #>  [762,] 0.9367479310 0.1281561508 0.8718438492 0.1558288221 8.441712e-01 #>  [763,] 0.9375963766 0.1265547189 0.8734452811 0.1539426518 8.460573e-01 #>  [764,] 0.9384341893 0.1249704300 0.8750295700 0.1520751990 8.479248e-01 #>  [765,] 0.9392614825 0.1234031721 0.8765968279 0.1502263776 8.497736e-01 #>  [766,] 0.9400783687 0.1218528321 0.8781471679 0.1483960992 8.516039e-01 #>  [767,] 0.9408849598 0.1203192960 0.8796807040 0.1465842734 8.534157e-01 #>  [768,] 0.9416813672 0.1188024486 0.8811975514 0.1447908078 8.552092e-01 #>  [769,] 0.9424677014 0.1173021740 0.8826978260 0.1430156081 8.569844e-01 #>  [770,] 0.9432440720 0.1158183552 0.8841816448 0.1412585781 8.587414e-01 #>  [771,] 0.9440105884 0.1143508745 0.8856491255 0.1395196200 8.604804e-01 #>  [772,] 0.9447673587 0.1128996133 0.8871003867 0.1377986342 8.622014e-01 #>  [773,] 0.9455144907 0.1114644524 0.8885355476 0.1360955192 8.639045e-01 #>  [774,] 0.9462520911 0.1100452720 0.8899547280 0.1344101724 8.655898e-01 #>  [775,] 0.9469802662 0.1086419514 0.8913580486 0.1327424893 8.672575e-01 #>  [776,] 0.9476991213 0.1072543696 0.8927456304 0.1310923642 8.689076e-01 #>  [777,] 0.9484087609 0.1058824048 0.8941175952 0.1294596897 8.705403e-01 #>  [778,] 0.9491092889 0.1045259350 0.8954740650 0.1278443574 8.721556e-01 #>  [779,] 0.9498008083 0.1031848376 0.8968151624 0.1262462575 8.737537e-01 #>  [780,] 0.9504834214 0.1018589897 0.8981410103 0.1246652789 8.753347e-01 #>  [781,] 0.9511572295 0.1005482678 0.8994517322 0.1231013095 8.768987e-01 #>  [782,] 0.9518223334 0.0992525484 0.9007474516 0.1215542360 8.784458e-01 #>  [783,] 0.9524788329 0.0979717077 0.9020282923 0.1200239442 8.799761e-01 #>  [784,] 0.9531268271 0.0967056214 0.9032943786 0.1185103186 8.814897e-01 #>  [785,] 0.9537664142 0.0954541653 0.9045458347 0.1170132433 8.829868e-01 #>  [786,] 0.9543976917 0.0942172150 0.9057827850 0.1155326009 8.844674e-01 #>  [787,] 0.9550207561 0.0929946458 0.9070053542 0.1140682737 8.859317e-01 #>  [788,] 0.9556357033 0.0917863333 0.9082136667 0.1126201431 8.873799e-01 #>  [789,] 0.9562426283 0.0905921526 0.9094078474 0.1111880895 8.888119e-01 #>  [790,] 0.9568416252 0.0894119792 0.9105880208 0.1097719931 8.902280e-01 #>  [791,] 0.9574327875 0.0882456884 0.9117543116 0.1083717330 8.916283e-01 #>  [792,] 0.9580162076 0.0870931556 0.9129068444 0.1069871882 8.930128e-01 #>  [793,] 0.9585919772 0.0859542565 0.9140457435 0.1056182368 8.943818e-01 #>  [794,] 0.9591601873 0.0848288666 0.9151711334 0.1042647567 8.957352e-01 #>  [795,] 0.9597209280 0.0837168617 0.9162831383 0.1029266251 8.970734e-01 #>  [796,] 0.9602742884 0.0826181180 0.9173818820 0.1016037191 8.983963e-01 #>  [797,] 0.9608203570 0.0815325116 0.9184674884 0.1002959152 8.997041e-01 #>  [798,] 0.9613592213 0.0804599190 0.9195400810 0.0990030898 9.009969e-01 #>  [799,] 0.9618909683 0.0794002169 0.9205997831 0.0977251190 9.022749e-01 #>  [800,] 0.9624156839 0.0783532825 0.9216467175 0.0964618786 9.035381e-01 #>  [801,] 0.9629334531 0.0773189930 0.9226810070 0.0952132443 9.047868e-01 #>  [802,] 0.9634443604 0.0762972263 0.9237027737 0.0939790916 9.060209e-01 #>  [803,] 0.9639484892 0.0752878604 0.9247121396 0.0927592960 9.072407e-01 #>  [804,] 0.9644459223 0.0742907738 0.9257092262 0.0915537327 9.084463e-01 #>  [805,] 0.9649367415 0.0733058455 0.9266941545 0.0903622772 9.096377e-01 #>  [806,] 0.9654210280 0.0723329548 0.9276670452 0.0891848047 9.108152e-01 #>  [807,] 0.9658988620 0.0713719816 0.9286280184 0.0880211908 9.119788e-01 #>  [808,] 0.9663703230 0.0704228060 0.9295771940 0.0868713107 9.131287e-01 #>  [809,] 0.9668354897 0.0694853091 0.9305146909 0.0857350401 9.142650e-01 #>  [810,] 0.9672944399 0.0685593720 0.9314406280 0.0846122547 9.153877e-01 #>  [811,] 0.9677472508 0.0676448766 0.9323551234 0.0835028303 9.164972e-01 #>  [812,] 0.9681939986 0.0667417054 0.9332582946 0.0824066430 9.175934e-01 #>  [813,] 0.9686347589 0.0658497413 0.9341502587 0.0813235690 9.186764e-01 #>  [814,] 0.9690696063 0.0649688680 0.9350311320 0.0802534849 9.197465e-01 #>  [815,] 0.9694986149 0.0640989696 0.9359010304 0.0791962676 9.208037e-01 #>  [816,] 0.9699218577 0.0632399309 0.9367600691 0.0781517940 9.218482e-01 #>  [817,] 0.9703394073 0.0623916373 0.9376083627 0.0771199418 9.228801e-01 #>  [818,] 0.9707513351 0.0615539749 0.9384460251 0.0761005885 9.238994e-01 #>  [819,] 0.9711577121 0.0607268305 0.9392731695 0.0750936126 9.249064e-01 #>  [820,] 0.9715586084 0.0599100915 0.9400899085 0.0740988924 9.259011e-01 #>  [821,] 0.9719540933 0.0591036459 0.9408963541 0.0731163071 9.268837e-01 #>  [822,] 0.9723442354 0.0583073825 0.9416926175 0.0721457360 9.278543e-01 #>  [823,] 0.9727291026 0.0575211908 0.9424788092 0.0711870592 9.288129e-01 #>  [824,] 0.9731087620 0.0567449610 0.9432550390 0.0702401569 9.297598e-01 #>  [825,] 0.9734832799 0.0559785840 0.9440214160 0.0693049101 9.306951e-01 #>  [826,] 0.9738527220 0.0552219514 0.9447780486 0.0683812003 9.316188e-01 #>  [827,] 0.9742171532 0.0544749557 0.9455250443 0.0674689094 9.325311e-01 #>  [828,] 0.9745766377 0.0537374900 0.9462625100 0.0665679199 9.334321e-01 #>  [829,] 0.9749312390 0.0530094481 0.9469905519 0.0656781149 9.343219e-01 #>  [830,] 0.9752810198 0.0522907248 0.9477092752 0.0647993782 9.352006e-01 #>  [831,] 0.9756260422 0.0515812155 0.9484187845 0.0639315940 9.360684e-01 #>  [832,] 0.9759663675 0.0508808163 0.9491191837 0.0630746472 9.369254e-01 #>  [833,] 0.9763020563 0.0501894242 0.9498105758 0.0622284235 9.377716e-01 #>  [834,] 0.9766331687 0.0495069371 0.9504930629 0.0613928089 9.386072e-01 #>  [835,] 0.9769597639 0.0488332534 0.9511667466 0.0605676904 9.394323e-01 #>  [836,] 0.9772819006 0.0481682725 0.9518317275 0.0597529556 9.402470e-01 #>  [837,] 0.9775996365 0.0475118946 0.9524881054 0.0589484925 9.410515e-01 #>  [838,] 0.9779130290 0.0468640207 0.9531359793 0.0581541902 9.418458e-01 #>  [839,] 0.9782221347 0.0462245524 0.9537754476 0.0573699382 9.426301e-01 #>  [840,] 0.9785270094 0.0455933924 0.9544066076 0.0565956270 9.434044e-01 #>  [841,] 0.9788277085 0.0449704440 0.9550295560 0.0558311474 9.441689e-01 #>  [842,] 0.9791242866 0.0443556115 0.9556443885 0.0550763914 9.449236e-01 #>  [843,] 0.9794167975 0.0437487999 0.9562512001 0.0543312515 9.456687e-01 #>  [844,] 0.9797052948 0.0431499150 0.9568500850 0.0535956210 9.464044e-01 #>  [845,] 0.9799898311 0.0425588635 0.9574411365 0.0528693938 9.471306e-01 #>  [846,] 0.9802704584 0.0419755528 0.9580244472 0.0521524648 9.478475e-01 #>  [847,] 0.9805472283 0.0413998913 0.9586001087 0.0514447296 9.485553e-01 #>  [848,] 0.9808201916 0.0408317880 0.9591682120 0.0507460845 9.492539e-01 #>  [849,] 0.9810893985 0.0402711529 0.9597288471 0.0500564267 9.499436e-01 #>  [850,] 0.9813548986 0.0397178968 0.9602821032 0.0493756541 9.506243e-01 #>  [851,] 0.9816167410 0.0391719313 0.9608280687 0.0487036653 9.512963e-01 #>  [852,] 0.9818749742 0.0386331687 0.9613668313 0.0480403600 9.519596e-01 #>  [853,] 0.9821296459 0.0381015223 0.9618984777 0.0473856383 9.526144e-01 #>  [854,] 0.9823808036 0.0375769061 0.9624230939 0.0467394015 9.532606e-01 #>  [855,] 0.9826284937 0.0370592350 0.9629407650 0.0461015515 9.538984e-01 #>  [856,] 0.9828727626 0.0365484247 0.9634515753 0.0454719909 9.545280e-01 #>  [857,] 0.9831136557 0.0360443917 0.9639556083 0.0448506233 9.551494e-01 #>  [858,] 0.9833512180 0.0355470532 0.9644529468 0.0442373531 9.557626e-01 #>  [859,] 0.9835854941 0.0350563274 0.9649436726 0.0436320855 9.563679e-01 #>  [860,] 0.9838165277 0.0345721332 0.9654278668 0.0430347264 9.569653e-01 #>  [861,] 0.9840443623 0.0340943904 0.9659056096 0.0424451827 9.575548e-01 #>  [862,] 0.9842690407 0.0336230194 0.9663769806 0.0418633620 9.581366e-01 #>  [863,] 0.9844906052 0.0331579417 0.9668420583 0.0412891728 9.587108e-01 #>  [864,] 0.9847090975 0.0326990793 0.9673009207 0.0407225243 9.592775e-01 #>  [865,] 0.9849245589 0.0322463551 0.9677536449 0.0401633266 9.598367e-01 #>  [866,] 0.9851370300 0.0317996930 0.9682003070 0.0396114907 9.603885e-01 #>  [867,] 0.9853465512 0.0313590173 0.9686409827 0.0390669283 9.609331e-01 #>  [868,] 0.9855531621 0.0309242534 0.9690757466 0.0385295520 9.614704e-01 #>  [869,] 0.9857569019 0.0304953273 0.9695046727 0.0379992751 9.620007e-01 #>  [870,] 0.9859578094 0.0300721659 0.9699278341 0.0374760119 9.625240e-01 #>  [871,] 0.9861559228 0.0296546968 0.9703453032 0.0369596774 9.630403e-01 #>  [872,] 0.9863512797 0.0292428484 0.9707571516 0.0364501874 9.635498e-01 #>  [873,] 0.9865439176 0.0288365498 0.9711634502 0.0359474586 9.640525e-01 #>  [874,] 0.9867338732 0.0284357309 0.9715642691 0.0354514084 9.645486e-01 #>  [875,] 0.9869211827 0.0280403225 0.9719596775 0.0349619551 9.650380e-01 #>  [876,] 0.9871058821 0.0276502558 0.9723497442 0.0344790178 9.655210e-01 #>  [877,] 0.9872880068 0.0272654631 0.9727345369 0.0340025164 9.659975e-01 #>  [878,] 0.9874675917 0.0268858773 0.9731141227 0.0335323716 9.664676e-01 #>  [879,] 0.9876446713 0.0265114320 0.9734885680 0.0330685048 9.669315e-01 #>  [880,] 0.9878192797 0.0261420616 0.9738579384 0.0326108383 9.673892e-01 #>  [881,] 0.9879914505 0.0257777012 0.9742222988 0.0321592952 9.678407e-01 #>  [882,] 0.9881612169 0.0254182865 0.9745817135 0.0317137995 9.682862e-01 #>  [883,] 0.9883286116 0.0250637542 0.9749362458 0.0312742757 9.687257e-01 #>  [884,] 0.9884936670 0.0247140415 0.9752859585 0.0308406492 9.691594e-01 #>  [885,] 0.9886564150 0.0243690864 0.9756309136 0.0304128463 9.695872e-01 #>  [886,] 0.9888168871 0.0240288274 0.9759711726 0.0299907941 9.700092e-01 #>  [887,] 0.9889751144 0.0236932040 0.9763067960 0.0295744202 9.704256e-01 #>  [888,] 0.9891311276 0.0233621563 0.9766378437 0.0291636531 9.708363e-01 #>  [889,] 0.9892849569 0.0230356249 0.9769643751 0.0287584223 9.712416e-01 #>  [890,] 0.9894366323 0.0227135512 0.9772864488 0.0283586576 9.716413e-01 #>  [891,] 0.9895861834 0.0223958774 0.9776041226 0.0279642901 9.720357e-01 #>  [892,] 0.9897336391 0.0220825463 0.9779174537 0.0275752511 9.724247e-01 #>  [893,] 0.9898790282 0.0217735011 0.9782264989 0.0271914730 9.728085e-01 #>  [894,] 0.9900223791 0.0214686862 0.9785313138 0.0268128889 9.731871e-01 #>  [895,] 0.9901637199 0.0211680460 0.9788319540 0.0264394325 9.735606e-01 #>  [896,] 0.9903030780 0.0208715262 0.9791284738 0.0260710383 9.739290e-01 #>  [897,] 0.9904404808 0.0205790726 0.9794209274 0.0257076417 9.742924e-01 #>  [898,] 0.9905759552 0.0202906321 0.9797093679 0.0253491784 9.746508e-01 #>  [899,] 0.9907095277 0.0200061517 0.9799938483 0.0249955853 9.750044e-01 #>  [900,] 0.9908412244 0.0197255796 0.9802744204 0.0246467997 9.753532e-01 #>  [901,] 0.9909710714 0.0194488642 0.9805511358 0.0243027598 9.756972e-01 #>  [902,] 0.9910990940 0.0191759547 0.9808240453 0.0239634042 9.760366e-01 #>  [903,] 0.9912253174 0.0189068008 0.9810931992 0.0236286725 9.763713e-01 #>  [904,] 0.9913497665 0.0186413530 0.9813586470 0.0232985048 9.767015e-01 #>  [905,] 0.9914724657 0.0183795623 0.9816204377 0.0229728421 9.770272e-01 #>  [906,] 0.9915934392 0.0181213801 0.9818786199 0.0226516259 9.773484e-01 #>  [907,] 0.9917127110 0.0178667586 0.9821332414 0.0223347985 9.776652e-01 #>  [908,] 0.9918303044 0.0176156506 0.9823843494 0.0220223026 9.779777e-01 #>  [909,] 0.9919462428 0.0173680094 0.9826319906 0.0217140818 9.782859e-01 #>  [910,] 0.9920605491 0.0171237889 0.9828762111 0.0214100805 9.785899e-01 #>  [911,] 0.9921732458 0.0168829435 0.9831170565 0.0211102434 9.788898e-01 #>  [912,] 0.9922843553 0.0166454281 0.9833545719 0.0208145160 9.791855e-01 #>  [913,] 0.9923938996 0.0164111985 0.9835888015 0.0205228445 9.794772e-01 #>  [914,] 0.9925019003 0.0161802106 0.9838197894 0.0202351758 9.797648e-01 #>  [915,] 0.9926083789 0.0159524212 0.9840475788 0.0199514571 9.800485e-01 #>  [916,] 0.9927133566 0.0157277874 0.9842722126 0.0196716366 9.803284e-01 #>  [917,] 0.9928168541 0.0155062669 0.9844937331 0.0193956630 9.806043e-01 #>  [918,] 0.9929188921 0.0152878180 0.9847121820 0.0191234854 9.808765e-01 #>  [919,] 0.9930194908 0.0150723994 0.9849276006 0.0188550539 9.811449e-01 #>  [920,] 0.9931186702 0.0148599705 0.9851400295 0.0185903189 9.814097e-01 #>  [921,] 0.9932164501 0.0146504910 0.9853495090 0.0183292314 9.816708e-01 #>  [922,] 0.9933128500 0.0144439212 0.9855560788 0.0180717432 9.819283e-01 #>  [923,] 0.9934078890 0.0142402219 0.9857597781 0.0178178065 9.821822e-01 #>  [924,] 0.9935015861 0.0140393544 0.9859606456 0.0175673742 9.824326e-01 #>  [925,] 0.9935939601 0.0138412805 0.9861587195 0.0173203997 9.826796e-01 #>  [926,] 0.9936850293 0.0136459624 0.9863540376 0.0170768370 9.829232e-01 #>  [927,] 0.9937748120 0.0134533629 0.9865466371 0.0168366407 9.831634e-01 #>  [928,] 0.9938633261 0.0132634452 0.9867365548 0.0165997657 9.834002e-01 #>  [929,] 0.9939505893 0.0130761730 0.9869238270 0.0163661680 9.836338e-01 #>  [930,] 0.9940366191 0.0128915105 0.9871084895 0.0161358035 9.838642e-01 #>  [931,] 0.9941214327 0.0127094222 0.9872905778 0.0159086291 9.840914e-01 #>  [932,] 0.9942050470 0.0125298731 0.9874701269 0.0156846021 9.843154e-01 #>  [933,] 0.9942874789 0.0123528289 0.9876471711 0.0154636803 9.845363e-01 #>  [934,] 0.9943687448 0.0121782554 0.9878217446 0.0152458221 9.847542e-01 #>  [935,] 0.9944488612 0.0120061190 0.9879938810 0.0150309862 9.849690e-01 #>  [936,] 0.9945278439 0.0118363866 0.9881636134 0.0148191322 9.851809e-01 #>  [937,] 0.9946057090 0.0116690253 0.9883309747 0.0146102198 9.853898e-01 #>  [938,] 0.9946824721 0.0115040030 0.9884959970 0.0144042095 9.855958e-01 #>  [939,] 0.9947581485 0.0113412876 0.9886587124 0.0142010622 9.857989e-01 #>  [940,] 0.9948327535 0.0111808476 0.9888191524 0.0140007393 9.859993e-01 #>  [941,] 0.9949063021 0.0110226520 0.9889773480 0.0138032025 9.861968e-01 #>  [942,] 0.9949788092 0.0108666701 0.9891333299 0.0136084144 9.863916e-01 #>  [943,] 0.9950502893 0.0107128716 0.9892871284 0.0134163376 9.865837e-01 #>  [944,] 0.9951207568 0.0105612265 0.9894387735 0.0132269356 9.867731e-01 #>  [945,] 0.9951902259 0.0104117055 0.9895882945 0.0130401721 9.869598e-01 #>  [946,] 0.9952587107 0.0102642794 0.9897357206 0.0128560113 9.871440e-01 #>  [947,] 0.9953262249 0.0101189194 0.9898810806 0.0126744180 9.873256e-01 #>  [948,] 0.9953927822 0.0099755973 0.9900244027 0.0124953572 9.875046e-01 #>  [949,] 0.9954583960 0.0098342849 0.9901657151 0.0123187946 9.876812e-01 #>  [950,] 0.9955230796 0.0096949548 0.9903050452 0.0121446961 9.878553e-01 #>  [951,] 0.9955868460 0.0095575796 0.9904424204 0.0119730284 9.880270e-01 #>  [952,] 0.9956497081 0.0094221324 0.9905778676 0.0118037582 9.881962e-01 #>  [953,] 0.9957116786 0.0092885868 0.9907114132 0.0116368528 9.883631e-01 #>  [954,] 0.9957727701 0.0091569165 0.9908430835 0.0114722802 9.885277e-01 #>  [955,] 0.9958329950 0.0090270957 0.9909729043 0.0113100083 9.886900e-01 #>  [956,] 0.9958923653 0.0088990989 0.9911009011 0.0111500059 9.888500e-01 #>  [957,] 0.9959508933 0.0087729008 0.9912270992 0.0109922418 9.890078e-01 #>  [958,] 0.9960085906 0.0086484768 0.9913515232 0.0108366855 9.891633e-01 #>  [959,] 0.9960654690 0.0085258023 0.9914741977 0.0106833068 9.893167e-01 #>  [960,] 0.9961215400 0.0084048531 0.9915951469 0.0105320758 9.894679e-01 #>  [961,] 0.9961768151 0.0082856054 0.9917143946 0.0103829632 9.896170e-01 #>  [962,] 0.9962313053 0.0081680356 0.9918319644 0.0102359398 9.897641e-01 #>  [963,] 0.9962850218 0.0080521206 0.9919478794 0.0100909771 9.899090e-01 #>  [964,] 0.9963379755 0.0079378374 0.9920621626 0.0099480467 9.900520e-01 #>  [965,] 0.9963901772 0.0078251634 0.9921748366 0.0098071208 9.901929e-01 #>  [966,] 0.9964416373 0.0077140763 0.9922859237 0.0096681717 9.903318e-01 #>  [967,] 0.9964923665 0.0076045541 0.9923954459 0.0095311724 9.904688e-01 #>  [968,] 0.9965423749 0.0074965752 0.9925034248 0.0093960959 9.906039e-01 #>  [969,] 0.9965916728 0.0073901180 0.9926098820 0.0092629159 9.907371e-01 #>  [970,] 0.9966402702 0.0072851616 0.9927148384 0.0091316061 9.908684e-01 #>  [971,] 0.9966881770 0.0071816849 0.9928183151 0.0090021409 9.909979e-01 #>  [972,] 0.9967354029 0.0070796676 0.9929203324 0.0088744947 9.911255e-01 #>  [973,] 0.9967819575 0.0069790892 0.9930209108 0.0087486425 9.912514e-01 #>  [974,] 0.9968278504 0.0068799298 0.9931200702 0.0086245596 9.913754e-01 #>  [975,] 0.9968730909 0.0067821697 0.9932178303 0.0085022214 9.914978e-01 #>  [976,] 0.9969176881 0.0066857893 0.9933142107 0.0083816039 9.916184e-01 #>  [977,] 0.9969616512 0.0065907695 0.9934092305 0.0082626833 9.917373e-01 #>  [978,] 0.9970049891 0.0064970913 0.9935029087 0.0081454361 9.918546e-01 #>  [979,] 0.9970477107 0.0064047360 0.9935952640 0.0080298392 9.919702e-01 #>  [980,] 0.9970898247 0.0063136852 0.9936863148 0.0079158697 9.920841e-01 #>  [981,] 0.9971313397 0.0062239206 0.9937760794 0.0078035051 9.921965e-01 #>  [982,] 0.9971722642 0.0061354244 0.9938645756 0.0076927231 9.923073e-01 #>  [983,] 0.9972126064 0.0060481789 0.9939518211 0.0075835017 9.924165e-01 #>  [984,] 0.9972523747 0.0059621665 0.9940378335 0.0074758195 9.925242e-01 #>  [985,] 0.9972915771 0.0058773701 0.9941226299 0.0073696549 9.926303e-01 #>  [986,] 0.9973302217 0.0057937727 0.9942062273 0.0072649869 9.927350e-01 #>  [987,] 0.9973683163 0.0057113575 0.9942886425 0.0071617948 9.928382e-01 #>  [988,] 0.9974058688 0.0056301081 0.9943698919 0.0070600579 9.929399e-01 #>  [989,] 0.9974428869 0.0055500080 0.9944499920 0.0069597562 9.930402e-01 #>  [990,] 0.9974793780 0.0054710412 0.9945289588 0.0068608696 9.931391e-01 #>  [991,] 0.9975153497 0.0053931919 0.9946068081 0.0067633785 9.932366e-01 #>  [992,] 0.9975508092 0.0053164444 0.9946835556 0.0066672633 9.933327e-01 #>  [993,] 0.9975857640 0.0052407833 0.9947592167 0.0065725051 9.934275e-01 #>  [994,] 0.9976202211 0.0051661934 0.9948338066 0.0064790848 9.935209e-01 #>  [995,] 0.9976541875 0.0050926597 0.9949073403 0.0063869838 9.936130e-01 #>  [996,] 0.9976876703 0.0050201673 0.9949798327 0.0062961837 9.937038e-01 #>  [997,] 0.9977206762 0.0049487017 0.9950512983 0.0062066665 9.937933e-01 #>  [998,] 0.9977532121 0.0048782485 0.9951217515 0.0061184141 9.938816e-01 #>  [999,] 0.9977852845 0.0048087935 0.9951912065 0.0060314090 9.939686e-01 #> [1000,] 0.9978169002 0.0047403226 0.9952596774 0.0059456337 9.940544e-01 #> [1001,] 0.9978480655 0.0046728221 0.9953271779 0.0058610710 9.941389e-01 #> [1002,] 0.9978787868 0.0046062783 0.9953937217 0.0057777041 9.942223e-01 #> [1003,] 0.9979090705 0.0045406778 0.9954593222 0.0056955162 9.943045e-01 #> [1004,] 0.9979389227 0.0044760074 0.9955239926 0.0056144908 9.943855e-01 #> [1005,] 0.9979683496 0.0044122540 0.9955877460 0.0055346117 9.944654e-01 #> [1006,] 0.9979973572 0.0043494046 0.9956505954 0.0054558627 9.945441e-01 #> [1007,] 0.9980259515 0.0042874467 0.9957125533 0.0053782283 9.946218e-01 #> [1008,] 0.9980541382 0.0042263676 0.9957736324 0.0053016926 9.946983e-01 #> [1009,] 0.9980819233 0.0041661549 0.9958338451 0.0052262403 9.947738e-01 #> [1010,] 0.9981093124 0.0041067966 0.9958932034 0.0051518563 9.948481e-01 #> [1011,] 0.9981363111 0.0040482806 0.9959517194 0.0050785256 9.949215e-01 #> [1012,] 0.9981629250 0.0039905950 0.9960094050 0.0050062335 9.949938e-01 #> [1013,] 0.9981891595 0.0039337282 0.9960662718 0.0049349652 9.950650e-01 #> [1014,] 0.9982150200 0.0038776685 0.9961223315 0.0048647066 9.951353e-01 #> [1015,] 0.9982405119 0.0038224047 0.9961775953 0.0047954435 9.952046e-01 #> [1016,] 0.9982656403 0.0037679255 0.9962320745 0.0047271618 9.952728e-01 #> [1017,] 0.9982904105 0.0037142200 0.9962857800 0.0046598478 9.953402e-01 #> [1018,] 0.9983148276 0.0036612770 0.9963387230 0.0045934879 9.954065e-01 #> [1019,] 0.9983388964 0.0036090860 0.9963909140 0.0045280688 9.954719e-01 #> [1020,] 0.9983626221 0.0035576363 0.9964423637 0.0044635771 9.955364e-01 #> [1021,] 0.9983860094 0.0035069175 0.9964930825 0.0043999999 9.956000e-01 #> [1022,] 0.9984090632 0.0034569192 0.9965430808 0.0043373244 9.956627e-01 #> [1023,] 0.9984317883 0.0034076314 0.9965923686 0.0042755378 9.957245e-01 #> [1024,] 0.9984541892 0.0033590439 0.9966409561 0.0042146276 9.957854e-01 #> [1025,] 0.9984762707 0.0033111468 0.9966888532 0.0041545815 9.958454e-01 #> [1026,] 0.9984980371 0.0032639305 0.9967360695 0.0040953875 9.959046e-01 #> [1027,] 0.9985194932 0.0032173854 0.9967826146 0.0040370333 9.959630e-01 #> [1028,] 0.9985406431 0.0031715018 0.9968284982 0.0039795074 9.960205e-01 #> [1029,] 0.9985614914 0.0031262706 0.9968737294 0.0039227979 9.960772e-01 #> [1030,] 0.9985820422 0.0030816824 0.9969183176 0.0038668934 9.961331e-01 #> [1031,] 0.9986022999 0.0030377283 0.9969622717 0.0038117826 9.961882e-01 #> [1032,] 0.9986222685 0.0029943992 0.9970056008 0.0037574542 9.962425e-01 #> [1033,] 0.9986419522 0.0029516862 0.9970483138 0.0037038973 9.962961e-01 #> [1034,] 0.9986613551 0.0029095808 0.9970904192 0.0036511010 9.963489e-01 #> [1035,] 0.9986804812 0.0028680743 0.9971319257 0.0035990545 9.964009e-01 #> [1036,] 0.9986993343 0.0028271582 0.9971728418 0.0035477474 9.964523e-01 #> [1037,] 0.9987179184 0.0027868242 0.9972131758 0.0034971690 9.965028e-01 #> [1038,] 0.9987362374 0.0027470640 0.9972529360 0.0034473093 9.965527e-01 #> [1039,] 0.9987542949 0.0027078696 0.9972921304 0.0033981579 9.966018e-01 #> [1040,] 0.9987720946 0.0026692329 0.9973307671 0.0033497050 9.966503e-01 #> [1041,] 0.9987896404 0.0026311460 0.9973688540 0.0033019407 9.966981e-01 #> [1042,] 0.9988069358 0.0025936011 0.9974063989 0.0032548553 9.967451e-01 #> [1043,] 0.9988239843 0.0025565906 0.9974434094 0.0032084391 9.967916e-01 #> [1044,] 0.9988407894 0.0025201069 0.9974798931 0.0031626828 9.968373e-01 #> [1045,] 0.9988573547 0.0024841426 0.9975158574 0.0031175769 9.968824e-01 #> [1046,] 0.9988736836 0.0024486903 0.9975513097 0.0030731124 9.969269e-01 #> [1047,] 0.9988897793 0.0024137426 0.9975862574 0.0030292801 9.969707e-01 #> [1048,] 0.9989056453 0.0023792926 0.9976207074 0.0029860711 9.970139e-01 #> [1049,] 0.9989212848 0.0023453331 0.9976546669 0.0029434766 9.970565e-01 #> [1050,] 0.9989367010 0.0023118572 0.9976881428 0.0029014880 9.970985e-01 #> [1051,] 0.9989518972 0.0022788579 0.9977211421 0.0028600966 9.971399e-01 #> [1052,] 0.9989668763 0.0022463287 0.9977536713 0.0028192940 9.971807e-01 #> [1053,] 0.9989816417 0.0022142628 0.9977857372 0.0027790718 9.972209e-01 #> [1054,] 0.9989961962 0.0021826536 0.9978173464 0.0027394220 9.972606e-01 #> [1055,] 0.9990105429 0.0021514946 0.9978485054 0.0027003363 9.972997e-01 #> [1056,] 0.9990246848 0.0021207796 0.9978792204 0.0026618067 9.973382e-01 #> [1057,] 0.9990386247 0.0020905021 0.9979094979 0.0026238255 9.973762e-01 #> [1058,] 0.9990523656 0.0020606559 0.9979393441 0.0025863849 9.974136e-01 #> [1059,] 0.9990659102 0.0020312350 0.9979687650 0.0025494771 9.974505e-01 #> [1060,] 0.9990792615 0.0020022334 0.9979977666 0.0025130947 9.974869e-01 #> [1061,] 0.9990924221 0.0019736449 0.9980263551 0.0024772301 9.975228e-01 #> [1062,] 0.9991053947 0.0019454639 0.9980545361 0.0024418762 9.975581e-01 #> [1063,] 0.9991181821 0.0019176845 0.9980823155 0.0024070256 9.975930e-01 #> [1064,] 0.9991307869 0.0018903010 0.9981096990 0.0023726712 9.976273e-01 #> [1065,] 0.9991432116 0.0018633079 0.9981366921 0.0023388060 9.976612e-01 #> [1066,] 0.9991554589 0.0018366994 0.9981633006 0.0023054230 9.976946e-01 #> [1067,] 0.9991675312 0.0018104702 0.9981895298 0.0022725154 9.977275e-01 #> [1068,] 0.9991794312 0.0017846150 0.9982153850 0.0022400765 9.977599e-01 #> [1069,] 0.9991911612 0.0017591283 0.9982408717 0.0022080996 9.977919e-01 #> [1070,] 0.9992027236 0.0017340050 0.9982659950 0.0021765782 9.978234e-01 #> [1071,] 0.9992141209 0.0017092398 0.9982907602 0.0021455058 9.978545e-01 #> [1072,] 0.9992253553 0.0016848278 0.9983151722 0.0021148761 9.978851e-01 #> [1073,] 0.9992364293 0.0016607639 0.9983392361 0.0020846827 9.979153e-01 #> [1074,] 0.9992473451 0.0016370430 0.9983629570 0.0020549194 9.979451e-01 #> [1075,] 0.9992581050 0.0016136605 0.9983863395 0.0020255803 9.979744e-01 #> [1076,] 0.9992687111 0.0015906114 0.9984093886 0.0019966592 9.980033e-01 #> [1077,] 0.9992791658 0.0015678910 0.9984321090 0.0019681502 9.980318e-01 #> [1078,] 0.9992894711 0.0015454946 0.9984545054 0.0019400475 9.980600e-01 #> [1079,] 0.9992996291 0.0015234177 0.9984765823 0.0019123453 9.980877e-01 #> [1080,] 0.9993096421 0.0015016556 0.9984983444 0.0018850379 9.981150e-01 #> [1081,] 0.9993195119 0.0014802040 0.9985197960 0.0018581197 9.981419e-01 #> [1082,] 0.9993292408 0.0014590584 0.9985409416 0.0018315852 9.981684e-01 #> [1083,] 0.9993388307 0.0014382144 0.9985617856 0.0018054290 9.981946e-01 #> [1084,] 0.9993482835 0.0014176677 0.9985823323 0.0017796456 9.982204e-01 #> [1085,] 0.9993576013 0.0013974142 0.9986025858 0.0017542297 9.982458e-01 #> [1086,] 0.9993667860 0.0013774497 0.9986225503 0.0017291763 9.982708e-01 #> [1087,] 0.9993758394 0.0013577699 0.9986422301 0.0017044800 9.982955e-01 #> [1088,] 0.9993847635 0.0013383710 0.9986616290 0.0016801358 9.983199e-01 #> [1089,] 0.9993935600 0.0013192489 0.9986807511 0.0016561387 9.983439e-01 #> [1090,] 0.9994022308 0.0013003996 0.9986996004 0.0016324839 9.983675e-01 #> [1091,] 0.9994107778 0.0012818193 0.9987181807 0.0016091663 9.983908e-01 #> [1092,] 0.9994192026 0.0012635041 0.9987364959 0.0015861813 9.984138e-01 #> [1093,] 0.9994275070 0.0012454503 0.9987545497 0.0015635241 9.984365e-01 #> [1094,] 0.9994356928 0.0012276541 0.9987723459 0.0015411900 9.984588e-01 #> [1095,] 0.9994437615 0.0012101119 0.9987898881 0.0015191745 9.984808e-01 #> [1096,] 0.9994517150 0.0011928201 0.9988071799 0.0014974730 9.985025e-01 #> [1097,] 0.9994595548 0.0011757751 0.9988242249 0.0014760810 9.985239e-01 #> [1098,] 0.9994672826 0.0011589734 0.9988410266 0.0014549942 9.985450e-01 #> [1099,] 0.9994748999 0.0011424115 0.9988575885 0.0014342082 9.985658e-01 #> [1100,] 0.9994824083 0.0011260860 0.9988739140 0.0014137187 9.985863e-01 #> [1101,] 0.9994898095 0.0011099935 0.9988900065 0.0013935215 9.986065e-01 #> [1102,] 0.9994971048 0.0010941308 0.9989058692 0.0013736125 9.986264e-01 #> [1103,] 0.9995042959 0.0010784945 0.9989215055 0.0013539875 9.986460e-01 #> [1104,] 0.9995113843 0.0010630814 0.9989369186 0.0013346425 9.986654e-01 #> [1105,] 0.9995183713 0.0010478884 0.9989521116 0.0013155736 9.986844e-01 #> [1106,] 0.9995252584 0.0010329122 0.9989670878 0.0012967767 9.987032e-01 #> [1107,] 0.9995320471 0.0010181499 0.9989818501 0.0012782481 9.987218e-01 #> [1108,] 0.9995387388 0.0010035984 0.9989964016 0.0012599839 9.987400e-01 #> [1109,] 0.9995453349 0.0009892546 0.9990107454 0.0012419803 9.987580e-01 #> [1110,] 0.9995518366 0.0009751156 0.9990248844 0.0012242337 9.987758e-01 #> [1111,] 0.9995582454 0.0009611786 0.9990388214 0.0012067404 9.987933e-01 #> [1112,] 0.9995645626 0.0009474405 0.9990525595 0.0011894967 9.988105e-01 #> [1113,] 0.9995707895 0.0009338986 0.9990661014 0.0011724991 9.988275e-01 #> [1114,] 0.9995769274 0.0009205501 0.9990794499 0.0011557441 9.988443e-01 #> [1115,] 0.9995829776 0.0009073922 0.9990926078 0.0011392283 9.988608e-01 #> [1116,] 0.9995889413 0.0008944222 0.9991055778 0.0011229482 9.988771e-01 #> [1117,] 0.9995948197 0.0008816374 0.9991183626 0.0011069006 9.988931e-01 #> [1118,] 0.9996006141 0.0008690352 0.9991309648 0.0010910820 9.989089e-01 #> [1119,] 0.9996063257 0.0008566130 0.9991433870 0.0010754892 9.989245e-01 #> [1120,] 0.9996119556 0.0008443683 0.9991556317 0.0010601190 9.989399e-01 #> [1121,] 0.9996175050 0.0008322984 0.9991677016 0.0010449683 9.989550e-01 #> [1122,] 0.9996229751 0.0008204009 0.9991795991 0.0010300338 9.989700e-01 #> [1123,] 0.9996283670 0.0008086733 0.9991913267 0.0010153126 9.989847e-01 #> [1124,] 0.9996336818 0.0007971132 0.9992028868 0.0010008016 9.989992e-01 #> [1125,] 0.9996389207 0.0007857183 0.9992142817 0.0009864978 9.990135e-01 #> [1126,] 0.9996440846 0.0007744861 0.9992255139 0.0009723982 9.990276e-01 #> [1127,] 0.9996491747 0.0007634144 0.9992365856 0.0009584999 9.990415e-01 #> [1128,] 0.9996541921 0.0007525008 0.9992474992 0.0009448001 9.990552e-01 #> [1129,] 0.9996591377 0.0007417432 0.9992582568 0.0009312959 9.990687e-01 #> [1130,] 0.9996640126 0.0007311392 0.9992688608 0.0009179845 9.990820e-01 #> [1131,] 0.9996688178 0.0007206867 0.9992793133 0.0009048633 9.990951e-01 #> [1132,] 0.9996735543 0.0007103835 0.9992896165 0.0008919294 9.991081e-01 #> [1133,] 0.9996782231 0.0007002275 0.9992997725 0.0008791802 9.991208e-01 #> [1134,] 0.9996828251 0.0006902166 0.9993097834 0.0008666131 9.991334e-01 #> [1135,] 0.9996873614 0.0006803488 0.9993196512 0.0008542255 9.991458e-01 #> [1136,] 0.9996918328 0.0006706219 0.9993293781 0.0008420148 9.991580e-01 #> [1137,] 0.9996962402 0.0006610340 0.9993389660 0.0008299785 9.991700e-01 #> [1138,] 0.9997005847 0.0006515830 0.9993484170 0.0008181142 9.991819e-01 #> [1139,] 0.9997048670 0.0006422672 0.9993577328 0.0008064193 9.991936e-01 #> [1140,] 0.9997090881 0.0006330844 0.9993669156 0.0007948914 9.992051e-01 #> [1141,] 0.9997132488 0.0006240328 0.9993759672 0.0007835282 9.992165e-01 #> [1142,] 0.9997173501 0.0006151106 0.9993848894 0.0007723273 9.992277e-01 #> [1143,] 0.9997213927 0.0006063158 0.9993936842 0.0007612864 9.992387e-01 #> [1144,] 0.9997253775 0.0005976468 0.9994023532 0.0007504033 9.992496e-01 #> [1145,] 0.9997293053 0.0005891016 0.9994108984 0.0007396756 9.992603e-01 #> [1146,] 0.9997331769 0.0005806785 0.9994193215 0.0007291011 9.992709e-01 #> [1147,] 0.9997369932 0.0005723758 0.9994276242 0.0007186777 9.992813e-01 #> [1148,] 0.9997407550 0.0005641917 0.9994358083 0.0007084032 9.992916e-01 #> [1149,] 0.9997444629 0.0005561246 0.9994438754 0.0006982756 9.993017e-01 #> [1150,] 0.9997481178 0.0005481727 0.9994518273 0.0006882926 9.993117e-01 #> [1151,] 0.9997517205 0.0005403346 0.9994596654 0.0006784522 9.993215e-01 #> [1152,] 0.9997552716 0.0005326084 0.9994673916 0.0006687524 9.993312e-01 #> [1153,] 0.9997587720 0.0005249926 0.9994750074 0.0006591912 9.993408e-01 #> [1154,] 0.9997622223 0.0005174857 0.9994825143 0.0006497666 9.993502e-01 #> [1155,] 0.9997656233 0.0005100861 0.9994899139 0.0006404767 9.993595e-01 #> [1156,] 0.9997689756 0.0005027922 0.9994972078 0.0006313195 9.993687e-01 #> [1157,] 0.9997722800 0.0004956026 0.9995043974 0.0006222931 9.993777e-01 #> [1158,] 0.9997755371 0.0004885157 0.9995114843 0.0006133958 9.993866e-01 #> [1159,] 0.9997787477 0.0004815301 0.9995184699 0.0006046255 9.993954e-01 #> [1160,] 0.9997819124 0.0004746444 0.9995253556 0.0005959806 9.994040e-01 #> [1161,] 0.9997850318 0.0004678570 0.9995321430 0.0005874592 9.994125e-01 #> [1162,] 0.9997881066 0.0004611667 0.9995388333 0.0005790596 9.994209e-01 #> [1163,] 0.9997911374 0.0004545721 0.9995454279 0.0005707800 9.994292e-01 #> [1164,] 0.9997941249 0.0004480716 0.9995519284 0.0005626187 9.994374e-01 #> [1165,] 0.9997970696 0.0004416641 0.9995583359 0.0005545741 9.994454e-01 #> [1166,] 0.9997999723 0.0004353482 0.9995646518 0.0005466444 9.994534e-01 #> [1167,] 0.9998028334 0.0004291226 0.9995708774 0.0005388281 9.994612e-01 #> [1168,] 0.9998056536 0.0004229859 0.9995770141 0.0005311234 9.994689e-01 #> [1169,] 0.9998084335 0.0004169370 0.9995830630 0.0005235289 9.994765e-01 #> [1170,] 0.9998111736 0.0004109746 0.9995890254 0.0005160429 9.994840e-01 #> [1171,] 0.9998138746 0.0004050973 0.9995949027 0.0005086639 9.994913e-01 #> [1172,] 0.9998165369 0.0003993041 0.9996006959 0.0005013903 9.994986e-01 #> [1173,] 0.9998191611 0.0003935937 0.9996064063 0.0004942207 9.995058e-01 #> [1174,] 0.9998217478 0.0003879650 0.9996120350 0.0004871536 9.995128e-01 #> [1175,] 0.9998242975 0.0003824167 0.9996175833 0.0004801875 9.995198e-01 #> [1176,] 0.9998268108 0.0003769477 0.9996230523 0.0004733209 9.995267e-01 #> [1177,] 0.9998292881 0.0003715569 0.9996284431 0.0004665525 9.995334e-01 #> [1178,] 0.9998317300 0.0003662432 0.9996337568 0.0004598809 9.995401e-01 #> [1179,] 0.9998341369 0.0003610054 0.9996389946 0.0004533046 9.995467e-01 #> [1180,] 0.9998365095 0.0003558425 0.9996441575 0.0004468223 9.995532e-01 #> [1181,] 0.9998388481 0.0003507534 0.9996492466 0.0004404326 9.995596e-01 #> [1182,] 0.9998411532 0.0003457371 0.9996542629 0.0004341343 9.995659e-01 #> [1183,] 0.9998434254 0.0003407925 0.9996592075 0.0004279260 9.995721e-01 #> [1184,] 0.9998456651 0.0003359186 0.9996640814 0.0004218065 9.995782e-01 #> [1185,] 0.9998478727 0.0003311144 0.9996688856 0.0004157744 9.995842e-01 #> [1186,] 0.9998500488 0.0003263788 0.9996736212 0.0004098286 9.995902e-01 #> [1187,] 0.9998521938 0.0003217110 0.9996782890 0.0004039677 9.995960e-01 #> [1188,] 0.9998543081 0.0003171099 0.9996828901 0.0003981907 9.996018e-01 #> [1189,] 0.9998563921 0.0003125746 0.9996874254 0.0003924962 9.996075e-01 #> [1190,] 0.9998584463 0.0003081041 0.9996918959 0.0003868831 9.996131e-01 #> [1191,] 0.9998604712 0.0003036976 0.9996963024 0.0003813503 9.996186e-01 #> [1192,] 0.9998624671 0.0002993540 0.9997006460 0.0003758966 9.996241e-01 #> [1193,] 0.9998644344 0.0002950726 0.9997049274 0.0003705208 9.996295e-01 #> [1194,] 0.9998663736 0.0002908523 0.9997091477 0.0003652219 9.996348e-01 #> [1195,] 0.9998682851 0.0002866925 0.9997133075 0.0003599987 9.996400e-01 #> [1196,] 0.9998701693 0.0002825921 0.9997174079 0.0003548502 9.996451e-01 #> [1197,] 0.9998720264 0.0002785503 0.9997214497 0.0003497753 9.996502e-01 #> [1198,] 0.9998738571 0.0002745663 0.9997254337 0.0003447730 9.996552e-01 #> [1199,] 0.9998756615 0.0002706393 0.9997293607 0.0003398422 9.996602e-01 #> [1200,] 0.9998774401 0.0002667684 0.9997332316 0.0003349819 9.996650e-01 #> [1201,] 0.9998791933 0.0002629529 0.9997370471 0.0003301910 9.996698e-01  # }"},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a group from a multiple group mirt object — extract.group","title":"Extract a group from a multiple group mirt object — extract.group","text":"Extract single group object defined multipleGroup, mixture model mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a group from a multiple group mirt object — extract.group","text":"","code":"extract.group(x, group)"},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a group from a multiple group mirt object — extract.group","text":"x model object class 'MultipleGroupClass' 'MixtureClass' group name group extract","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract a group from a multiple group mirt object — extract.group","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract a group from a multiple group mirt object — extract.group","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract a group from a multiple group mirt object — extract.group","text":"","code":"# \\donttest{ set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N)) models <- 'F1 = 1-15'  mod_configural <- multipleGroup(dat, models, group = group) #>  group.1 <- extract.group(mod_configural, 'D1') #extract first group summary(group.1) #>            F1     h2 #> Item_1  0.532 0.2835 #> Item_2  0.582 0.3383 #> Item_3  0.487 0.2371 #> Item_4  0.466 0.2176 #> Item_5  0.542 0.2935 #> Item_6  0.315 0.0992 #> Item_7  0.599 0.3592 #> Item_8  0.477 0.2280 #> Item_9  0.464 0.2148 #> Item_10 0.391 0.1529 #> Item_11 0.438 0.1923 #> Item_12 0.655 0.4291 #> Item_13 0.604 0.3650 #> Item_14 0.519 0.2699 #> Item_15 0.453 0.2048 #>  #> SS loadings:  3.885  #> Proportion Var:  0.259  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 plot(group.1)  # }"},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract an item object from mirt objects — extract.item","title":"Extract an item object from mirt objects — extract.item","text":"Extract internal mirt objects estimated model.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract an item object from mirt objects — extract.item","text":"","code":"extract.item(x, item, group = NULL, drop.zeros = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract an item object from mirt objects — extract.item","text":"x mirt model class 'SingleGroupClass', 'MultipleGroupClass', 'MixtureClass' item number character signifying item extract group number signifying group item extracted (applies 'MultipleGroupClass' 'MixtureClass' ) drop.zeros logical; drop slope values numerically close zero reduce dimensionality? Useful objects returned bfactor confirmatory models contain several zero slopes","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract an item object from mirt objects — extract.item","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/extract.item.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract an item object from mirt objects — extract.item","text":"","code":"# \\donttest{ mod <- mirt(Science, 1) #>  extr.1 <- extract.item(mod, 1) # }"},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract various elements from estimated model objects — extract.mirt","title":"Extract various elements from estimated model objects — extract.mirt","text":"generic function extract internal objects estimated models.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract various elements from estimated model objects — extract.mirt","text":"","code":"extract.mirt(x, what, item = 1)"},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract various elements from estimated model objects — extract.mirt","text":"x mirt model class 'SingleGroupClass', 'MultipleGroupClass', 'MixedClass' 'DiscreteGroupClass' string indicating extract item necessary, item extract information . Defaults 1 specified","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract various elements from estimated model objects — extract.mirt","text":"Objects can extracted mirt objects include: logLik observed log-likelihood logPrior log term contributed prior parameter distributions G2 goodness fit statistic df degrees freedom p p-value G2 statistic RMSEA root mean-square error approximation based G2 CFI CFI fit statistic TLI TLI fit statistic AIC AIC BIC BIC SABIC sample size adjusted BIC HQ HQ LLhistory EM log-likelihood history tabdata tabular version raw response data input. Frequencies stored     freq freq frequencies associated tabdata K integer vector indicating number unique elements item mins integer vector indicating lowest category found input data model input model syntax method estimation method used itemtype vector item types respective item (e.g., 'graded', '2PL', etc) itemnames vector item names input data factorNames vector factor names model definition rowID integer vector indicating valid row numbers used model estimation    (cases used 1:nrow(data)) data raw input data item responses covdata raw input data data used covariates tabdatalong similar tabdata, however responses transformed     dummy coded variables fulldatalong analogous tabdatafull, raw input data instead     tabulated frequencies EMhistory saved, extract EM iteration history exp_resp expected probability unique response patterns survey.weights supplied, vector survey weights used estimation (NULL missing) converged logical value indicating whether model terminated within     convergence criteria iterations number iterations took reach convergence criteria nest number freely estimated parameters parvec vector containing uniquely estimated parameters vcov parameter covariance matrix (associated parvec) condnum condition number Hessian (computed). Otherwise NA constrain list item parameter constraints indicate item parameters equal     estimation Prior prior density distribution latent traits thetaPosterior posterior distribution latent traits using EM algorithm key supplied, data scoring key nfact number latent traits/factors nitems number items ngroups number groups groupNames character vector unique group names group character vector indicating group membership invariance character vector indicating invariance input multipleGroup secondordertest logical indicating whether model passed second-order test     based Hessian matrix. Indicates whether model potential local maximum solution SEMconv logical; check whether supplemented EM information matrix converged. NA     applicable time estimation time, broken different sections","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract various elements from estimated model objects — extract.mirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract various elements from estimated model objects — extract.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/extract.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract various elements from estimated model objects — extract.mirt","text":"","code":"# \\donttest{ mod <- mirt(Science, 1) #>   extract.mirt(mod, 'logLik') #> [1] -1608.87 extract.mirt(mod, 'K')  # unique categories for each item #> [1] 4 4 4 4  #multiple group model grp <- rep(c('G1', 'G2'), each = nrow(Science)/2) mod2 <- multipleGroup(Science, 1, grp) #>   grp1 <- extract.group(mod2, 1) #extract single group model extract.mirt(mod2, 'parvec') #>  [1]  0.8316800  4.8913029  2.5597789 -1.3592138  0.8289135  2.4772334 #>  [7]  0.7025447 -2.1135580  2.8809926  5.4820292  2.2126281 -2.5451325 #> [13]  0.6920437  3.0133748  0.8608953 -1.5516666  1.1955161  4.8900152 #> [19]  2.6929286 -1.5545256  1.7621713  3.6416308  1.1724290 -2.5499919 #> [25]  2.4324588  6.4188352  2.6336468 -1.8297283  1.4875546  3.8081350 #> [31]  1.1473714 -1.8343958 extract.mirt(grp1, 'parvec') #>  [1]  0.8316800  4.8913029  2.5597789 -1.3592138  0.8289135  2.4772334 #>  [7]  0.7025447 -2.1135580  2.8809926  5.4820292  2.2126281 -2.5451325 #> [13]  0.6920437  3.0133748  0.8608953 -1.5516666  # }"},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixed-item calibration method — fixedCalib","title":"Fixed-item calibration method — fixedCalib","text":"Implements set fixed-item calibration methods described Kim (2006). initial calibrated model must fitted via mirt, currently limited unidimensional models , utilized new set responses obtained population similar distributional characteristics latent traits. flexible calibration items, including fixed-item calibration variant involving anchor items equating, see multipleGroup.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fixed-item calibration method — fixedCalib","text":"","code":"fixedCalib(   data,   model = 1,   old_mod,   PAU = \"MWU\",   NEMC = \"MEM\",   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fixed-item calibration method — fixedCalib","text":"data new data used calibration. Note consistent mod object, observed responses/NA placeholders must included link item names used original mod definition (.e., extract.mirt(mod, = 'itemnames')) model type model fit complete dataset (fixed items old_mod factor loadings/constraints specified potential mirt.model specification relevant) old_mod model class SingleGroupClass fitted using mirt PAU prior ability update (PAU) approach. Supports none (\"NWU\"), one (\"OWU\"), many (\"MWU\") NEMC number EM cycles (NEMC) use --estimated parameters. Supports one (\"OEM\") many (\"MEM\") technical list technical estimation arguments (see mirt details) ... additional arguments pass mirt","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fixed-item calibration method — fixedCalib","text":"Kim, S. (2006). comparative study IRT fixed parameter calibration methods. Journal Educational Measurement, 4(43), 355-381.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/fixedCalib.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fixed-item calibration method — fixedCalib","text":"","code":"# \\donttest{  # single factor set.seed(12345) J <- 50 a <- matrix(abs(rnorm(J,1,.3)), ncol=1) d <- matrix(rnorm(J,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a))  # calibration data theta ~ N(0,1) N <- 3000 dataset1 <- simdata(a, d, N = N, itemtype=itemtype)  # new data (again, theta ~ N(0,1)) dataset2 <- simdata(a, d, N = 1000, itemtype=itemtype)  # last 40% of experimental items not given to calibration group #     (unobserved; hence removed) dataset1 <- dataset1[,-c(J:(J*.6))] head(dataset1) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]      0      0      0      0      0      0      1      1      1       0 #> [2,]      0      0      0      1      0      1      0      0      0       0 #> [3,]      0      1      0      1      1      1      1      1      1       1 #> [4,]      0      1      1      0      1      0      0      0      1       0 #> [5,]      1      0      1      1      1      0      1      0      1       0 #> [6,]      1      1      0      1      0      1      0      1      1       0 #>      Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> [1,]       1       1       1       1       1       0       0       0       1 #> [2,]       0       0       1       0       0       0       1       1       0 #> [3,]       1       1       0       1       0       1       0       0       0 #> [4,]       0       0       1       1       0       0       1       1       0 #> [5,]       0       0       0       1       0       0       1       1       1 #> [6,]       1       0       1       1       0       0       1       0       1 #>      Item_20 Item_21 Item_22 Item_23 Item_24 Item_25 Item_26 Item_27 Item_28 #> [1,]       0       0       0       0       1       0       0       1       0 #> [2,]       0       1       0       0       1       0       0       1       1 #> [3,]       0       1       0       1       1       1       1       0       0 #> [4,]       0       0       0       0       0       1       0       1       0 #> [5,]       0       1       1       1       1       1       1       1       1 #> [6,]       0       0       0       1       1       1       0       0       0 #>      Item_29 #> [1,]       1 #> [2,]       1 #> [3,]       1 #> [4,]       1 #> [5,]       1 #> [6,]       1  #--------------------------------------  # calibrated model from dataset1 only mod <- mirt(dataset1, model = 1) #>  coef(mod, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # No Prior Weights Updating and One EM Cycle (NWU-OEM) NWU_OEM <- fixedCalib(dataset2, model=1, old_mod=mod, PAU='NWU', NEMC='OEM') #>  coef(NWU_OEM, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #> Item_30 0.750  1.329 0 1 #> Item_31 1.093  1.235 0 1 #> Item_32 1.380  1.740 0 1 #> Item_33 1.112  0.441 0 1 #> Item_34 1.164  2.443 0 1 #> Item_35 1.054  1.361 0 1 #> Item_36 0.863  1.818 0 1 #> Item_37 0.717  0.865 0 1 #> Item_38 0.379  0.044 0 1 #> Item_39 1.180  1.336 0 1 #> Item_40 0.713  0.967 0 1 #> Item_41 0.865  0.150 0 1 #> Item_42 0.205 -0.581 0 1 #> Item_43 0.587  1.914 0 1 #> Item_44 0.977  0.509 0 1 #> Item_45 0.944 -0.151 0 1 #> Item_46 1.239  1.288 0 1 #> Item_47 0.547  0.176 0 1 #> Item_48 0.811  2.059 0 1 #> Item_49 0.841  0.169 0 1 #> Item_50 0.631 -0.103 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  data.frame(coef(NWU_OEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) #>                a1           d    pop_a1       pop_d #> Item_1  1.1961890 -0.36582599 1.1756586 -0.37827025 #> Item_2  1.2180200  1.34513036 1.2128398  1.36338487 #> Item_3  1.0287076 -0.01749165 0.9672090  0.03751319 #> Item_4  0.8169838  0.22955350 0.8639508  0.24616399 #> Item_5  1.1477420 -0.46213650 1.1817662 -0.46968358 #> Item_6  0.4734409  0.15748181 0.4546132  0.19456759 #> Item_7  1.1723767  0.49084966 1.1890296  0.48381989 #> Item_8  0.8823964  0.59861143 0.9171448  0.57665673 #> Item_9  0.7320060  1.36669674 0.9147521  1.50154551 #> Item_10 0.7374958 -1.70288028 0.7242034 -1.64286078 #> Item_11 0.9877230  0.05684034 0.9651257  0.10471439 #> Item_12 1.6208445 -0.88830542 1.5451936 -0.93977204 #> Item_13 1.2113938  0.36247319 1.1111884  0.38731215 #> Item_14 1.2608594  1.10068854 1.1560649  1.11297399 #> Item_15 0.7483149 -0.31912299 0.7748404 -0.41081572 #> Item_16 1.1708992 -1.24683338 1.2450700 -1.28266411 #> Item_17 0.7422645  0.63674114 0.7340927  0.62169760 #> Item_18 0.9248296  1.12848731 0.9005267  1.11544193 #> Item_19 1.4767582  0.39539515 1.3362138  0.36179827 #> Item_20 1.0368814 -0.99330414 1.0896171 -0.90697018 #> Item_21 1.1357543  0.06752098 1.2338866  0.03823090 #> Item_22 1.4021119 -0.51282038 1.4367355 -0.54925456 #> Item_23 0.6786602 -0.68438097 0.8067015 -0.73454697 #> Item_24 0.4828002  1.68992778 0.5340588  1.63135837 #> Item_25 0.5011412  1.04812815 0.5206871  0.98189377 #> Item_26 1.6039924  0.63625385 1.5415293  0.65982060 #> Item_27 0.8328685  0.55938549 0.8555058  0.57838080 #> Item_28 1.1001393 -0.49299690 1.1861139 -0.56807834 #> Item_29 1.1996287  0.35417420 1.1836370  0.33337380 #> Item_30 0.7503191  1.32941502 0.9513067  0.71488089 #> Item_31 1.0934852  1.23450251 1.2435620  0.45176815 #> Item_32 1.3797225  1.73968930 1.6590501  0.73020049 #> Item_33 1.1122063  0.44125253 1.6147571 -0.21305838 #> Item_34 1.1635528  2.44296521 1.4897337  1.73397764 #> Item_35 1.0542788  1.36075678 1.0762814  0.67985447 #> Item_36 0.8625460  1.81754474 1.1473565  1.30696943 #> Item_37 0.7169594  0.86486730 0.9027740  0.47042973 #> Item_38 0.3789943  0.04394555 0.5013849 -0.21556737 #> Item_39 1.1801729  1.33626718 1.5303202  0.37556660 #> Item_40 0.7130625  0.96707202 1.0077403  0.57740905 #> Item_41 0.8654027  0.14975466 1.3385533 -0.67473104 #> Item_42 0.2054520 -0.58087717 0.2858926 -0.59855776 #> Item_43 0.5870526  1.91384494 0.6819203  1.32086286 #> Item_44 0.9773758  0.50918361 1.2811422 -0.27427356 #> Item_45 0.9438821 -0.15062731 1.2563355 -0.68644306 #> Item_46 1.2394331  1.28838231 1.4382188  0.48113247 #> Item_47 0.5466966  0.17590264 0.5760704 -0.35353046 #> Item_48 0.8112318  2.05870733 1.1702210  1.51040387 #> Item_49 0.8414788  0.16883149 1.1749563 -0.41985829 #> Item_50 0.6307197 -0.10310709 0.6079603 -0.48618269 plot(NWU_OEM, type = 'empiricalhist')   # No Prior Weights Updating and Multiple EM Cycles (NWU-MEM) NWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod, PAU = 'NWU') #>  coef(NWU_MEM, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #> Item_30 0.976  0.738 0 1 #> Item_31 1.355  0.436 0 1 #> Item_32 1.896  0.751 0 1 #> Item_33 1.483 -0.136 0 1 #> Item_34 1.566  1.615 0 1 #> Item_35 1.108  0.689 0 1 #> Item_36 1.027  1.297 0 1 #> Item_37 0.950  0.485 0 1 #> Item_38 0.636 -0.358 0 1 #> Item_39 1.561  0.369 0 1 #> Item_40 1.002  0.572 0 1 #> Item_41 1.293 -0.537 0 1 #> Item_42 0.237 -0.569 0 1 #> Item_43 0.759  1.528 0 1 #> Item_44 1.267 -0.198 0 1 #> Item_45 1.179 -0.719 0 1 #> Item_46 1.484  0.418 0 1 #> Item_47 0.517 -0.350 0 1 #> Item_48 1.204  1.560 0 1 #> Item_49 1.178 -0.381 0 1 #> Item_50 0.611 -0.485 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  data.frame(coef(NWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) #>                a1           d    pop_a1       pop_d #> Item_1  1.1961890 -0.36582599 1.1756586 -0.37827025 #> Item_2  1.2180200  1.34513036 1.2128398  1.36338487 #> Item_3  1.0287076 -0.01749165 0.9672090  0.03751319 #> Item_4  0.8169838  0.22955350 0.8639508  0.24616399 #> Item_5  1.1477420 -0.46213650 1.1817662 -0.46968358 #> Item_6  0.4734409  0.15748181 0.4546132  0.19456759 #> Item_7  1.1723767  0.49084966 1.1890296  0.48381989 #> Item_8  0.8823964  0.59861143 0.9171448  0.57665673 #> Item_9  0.7320060  1.36669674 0.9147521  1.50154551 #> Item_10 0.7374958 -1.70288028 0.7242034 -1.64286078 #> Item_11 0.9877230  0.05684034 0.9651257  0.10471439 #> Item_12 1.6208445 -0.88830542 1.5451936 -0.93977204 #> Item_13 1.2113938  0.36247319 1.1111884  0.38731215 #> Item_14 1.2608594  1.10068854 1.1560649  1.11297399 #> Item_15 0.7483149 -0.31912299 0.7748404 -0.41081572 #> Item_16 1.1708992 -1.24683338 1.2450700 -1.28266411 #> Item_17 0.7422645  0.63674114 0.7340927  0.62169760 #> Item_18 0.9248296  1.12848731 0.9005267  1.11544193 #> Item_19 1.4767582  0.39539515 1.3362138  0.36179827 #> Item_20 1.0368814 -0.99330414 1.0896171 -0.90697018 #> Item_21 1.1357543  0.06752098 1.2338866  0.03823090 #> Item_22 1.4021119 -0.51282038 1.4367355 -0.54925456 #> Item_23 0.6786602 -0.68438097 0.8067015 -0.73454697 #> Item_24 0.4828002  1.68992778 0.5340588  1.63135837 #> Item_25 0.5011412  1.04812815 0.5206871  0.98189377 #> Item_26 1.6039924  0.63625385 1.5415293  0.65982060 #> Item_27 0.8328685  0.55938549 0.8555058  0.57838080 #> Item_28 1.1001393 -0.49299690 1.1861139 -0.56807834 #> Item_29 1.1996287  0.35417420 1.1836370  0.33337380 #> Item_30 0.9762030  0.73762603 0.9513067  0.71488089 #> Item_31 1.3546278  0.43608060 1.2435620  0.45176815 #> Item_32 1.8963614  0.75072559 1.6590501  0.73020049 #> Item_33 1.4833684 -0.13615393 1.6147571 -0.21305838 #> Item_34 1.5661380  1.61503162 1.4897337  1.73397764 #> Item_35 1.1080231  0.68889209 1.0762814  0.67985447 #> Item_36 1.0265916  1.29656964 1.1473565  1.30696943 #> Item_37 0.9495227  0.48504809 0.9027740  0.47042973 #> Item_38 0.6357917 -0.35821345 0.5013849 -0.21556737 #> Item_39 1.5609002  0.36934080 1.5303202  0.37556660 #> Item_40 1.0017413  0.57214795 1.0077403  0.57740905 #> Item_41 1.2934463 -0.53663846 1.3385533 -0.67473104 #> Item_42 0.2365342 -0.56867576 0.2858926 -0.59855776 #> Item_43 0.7585749  1.52822491 0.6819203  1.32086286 #> Item_44 1.2665593 -0.19834384 1.2811422 -0.27427356 #> Item_45 1.1786531 -0.71904132 1.2563355 -0.68644306 #> Item_46 1.4839823  0.41813815 1.4382188  0.48113247 #> Item_47 0.5165255 -0.35006720 0.5760704 -0.35353046 #> Item_48 1.2040324  1.55971466 1.1702210  1.51040387 #> Item_49 1.1779999 -0.38145049 1.1749563 -0.41985829 #> Item_50 0.6105721 -0.48525352 0.6079603 -0.48618269 plot(NWU_MEM, type = 'empiricalhist')   # One Prior Weights Updating and One EM Cycle (OWU-OEM) OWU_OEM <- fixedCalib(dataset2, model=1, old_mod=mod, PAU='OWU', NEMC=\"OEM\") #>  coef(OWU_OEM, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #> Item_30 0.734  1.342 0 1 #> Item_31 1.081  1.235 0 1 #> Item_32 1.354  1.740 0 1 #> Item_33 1.087  0.449 0 1 #> Item_34 1.180  2.469 0 1 #> Item_35 1.080  1.352 0 1 #> Item_36 0.867  1.826 0 1 #> Item_37 0.736  0.845 0 1 #> Item_38 0.407  0.018 0 1 #> Item_39 1.192  1.330 0 1 #> Item_40 0.694  0.970 0 1 #> Item_41 0.876  0.141 0 1 #> Item_42 0.207 -0.593 0 1 #> Item_43 0.608  1.915 0 1 #> Item_44 0.948  0.525 0 1 #> Item_45 0.918 -0.150 0 1 #> Item_46 1.246  1.287 0 1 #> Item_47 0.541  0.194 0 1 #> Item_48 0.824  2.052 0 1 #> Item_49 0.881  0.150 0 1 #> Item_50 0.643 -0.109 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  data.frame(coef(OWU_OEM, simplify=TRUE)$items[,c('a1','d')], pop_a1=a, pop_d=d) #>                a1           d    pop_a1       pop_d #> Item_1  1.1961890 -0.36582599 1.1756586 -0.37827025 #> Item_2  1.2180200  1.34513036 1.2128398  1.36338487 #> Item_3  1.0287076 -0.01749165 0.9672090  0.03751319 #> Item_4  0.8169838  0.22955350 0.8639508  0.24616399 #> Item_5  1.1477420 -0.46213650 1.1817662 -0.46968358 #> Item_6  0.4734409  0.15748181 0.4546132  0.19456759 #> Item_7  1.1723767  0.49084966 1.1890296  0.48381989 #> Item_8  0.8823964  0.59861143 0.9171448  0.57665673 #> Item_9  0.7320060  1.36669674 0.9147521  1.50154551 #> Item_10 0.7374958 -1.70288028 0.7242034 -1.64286078 #> Item_11 0.9877230  0.05684034 0.9651257  0.10471439 #> Item_12 1.6208445 -0.88830542 1.5451936 -0.93977204 #> Item_13 1.2113938  0.36247319 1.1111884  0.38731215 #> Item_14 1.2608594  1.10068854 1.1560649  1.11297399 #> Item_15 0.7483149 -0.31912299 0.7748404 -0.41081572 #> Item_16 1.1708992 -1.24683338 1.2450700 -1.28266411 #> Item_17 0.7422645  0.63674114 0.7340927  0.62169760 #> Item_18 0.9248296  1.12848731 0.9005267  1.11544193 #> Item_19 1.4767582  0.39539515 1.3362138  0.36179827 #> Item_20 1.0368814 -0.99330414 1.0896171 -0.90697018 #> Item_21 1.1357543  0.06752098 1.2338866  0.03823090 #> Item_22 1.4021119 -0.51282038 1.4367355 -0.54925456 #> Item_23 0.6786602 -0.68438097 0.8067015 -0.73454697 #> Item_24 0.4828002  1.68992778 0.5340588  1.63135837 #> Item_25 0.5011412  1.04812815 0.5206871  0.98189377 #> Item_26 1.6039924  0.63625385 1.5415293  0.65982060 #> Item_27 0.8328685  0.55938549 0.8555058  0.57838080 #> Item_28 1.1001393 -0.49299690 1.1861139 -0.56807834 #> Item_29 1.1996287  0.35417420 1.1836370  0.33337380 #> Item_30 0.7338596  1.34171621 0.9513067  0.71488089 #> Item_31 1.0810934  1.23518942 1.2435620  0.45176815 #> Item_32 1.3536031  1.74007904 1.6590501  0.73020049 #> Item_33 1.0871425  0.44941021 1.6147571 -0.21305838 #> Item_34 1.1800858  2.46871234 1.4897337  1.73397764 #> Item_35 1.0803263  1.35175673 1.0762814  0.67985447 #> Item_36 0.8666080  1.82586462 1.1473565  1.30696943 #> Item_37 0.7358795  0.84485396 0.9027740  0.47042973 #> Item_38 0.4070019  0.01833533 0.5013849 -0.21556737 #> Item_39 1.1921382  1.33027311 1.5303202  0.37556660 #> Item_40 0.6941284  0.97027712 1.0077403  0.57740905 #> Item_41 0.8759719  0.14117791 1.3385533 -0.67473104 #> Item_42 0.2070009 -0.59318726 0.2858926 -0.59855776 #> Item_43 0.6082669  1.91531663 0.6819203  1.32086286 #> Item_44 0.9481219  0.52535227 1.2811422 -0.27427356 #> Item_45 0.9181546 -0.15002032 1.2563355 -0.68644306 #> Item_46 1.2461867  1.28672335 1.4382188  0.48113247 #> Item_47 0.5414343  0.19387196 0.5760704 -0.35353046 #> Item_48 0.8238261  2.05156006 1.1702210  1.51040387 #> Item_49 0.8809591  0.15027203 1.1749563 -0.41985829 #> Item_50 0.6425456 -0.10887582 0.6079603 -0.48618269 plot(OWU_OEM, type = 'empiricalhist')   # One Prior Weights Updating and Multiple EM Cycles (OWU-MEM) OWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod, PAU = 'OWU') #>  coef(OWU_MEM, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #> Item_30 0.975  0.738 0 1 #> Item_31 1.353  0.436 0 1 #> Item_32 1.892  0.749 0 1 #> Item_33 1.482 -0.137 0 1 #> Item_34 1.563  1.614 0 1 #> Item_35 1.107  0.689 0 1 #> Item_36 1.026  1.297 0 1 #> Item_37 0.949  0.485 0 1 #> Item_38 0.637 -0.358 0 1 #> Item_39 1.559  0.369 0 1 #> Item_40 1.001  0.572 0 1 #> Item_41 1.294 -0.537 0 1 #> Item_42 0.237 -0.569 0 1 #> Item_43 0.758  1.528 0 1 #> Item_44 1.266 -0.199 0 1 #> Item_45 1.179 -0.719 0 1 #> Item_46 1.482  0.418 0 1 #> Item_47 0.517 -0.350 0 1 #> Item_48 1.203  1.560 0 1 #> Item_49 1.178 -0.382 0 1 #> Item_50 0.611 -0.485 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  data.frame(coef(OWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) #>                a1           d    pop_a1       pop_d #> Item_1  1.1961890 -0.36582599 1.1756586 -0.37827025 #> Item_2  1.2180200  1.34513036 1.2128398  1.36338487 #> Item_3  1.0287076 -0.01749165 0.9672090  0.03751319 #> Item_4  0.8169838  0.22955350 0.8639508  0.24616399 #> Item_5  1.1477420 -0.46213650 1.1817662 -0.46968358 #> Item_6  0.4734409  0.15748181 0.4546132  0.19456759 #> Item_7  1.1723767  0.49084966 1.1890296  0.48381989 #> Item_8  0.8823964  0.59861143 0.9171448  0.57665673 #> Item_9  0.7320060  1.36669674 0.9147521  1.50154551 #> Item_10 0.7374958 -1.70288028 0.7242034 -1.64286078 #> Item_11 0.9877230  0.05684034 0.9651257  0.10471439 #> Item_12 1.6208445 -0.88830542 1.5451936 -0.93977204 #> Item_13 1.2113938  0.36247319 1.1111884  0.38731215 #> Item_14 1.2608594  1.10068854 1.1560649  1.11297399 #> Item_15 0.7483149 -0.31912299 0.7748404 -0.41081572 #> Item_16 1.1708992 -1.24683338 1.2450700 -1.28266411 #> Item_17 0.7422645  0.63674114 0.7340927  0.62169760 #> Item_18 0.9248296  1.12848731 0.9005267  1.11544193 #> Item_19 1.4767582  0.39539515 1.3362138  0.36179827 #> Item_20 1.0368814 -0.99330414 1.0896171 -0.90697018 #> Item_21 1.1357543  0.06752098 1.2338866  0.03823090 #> Item_22 1.4021119 -0.51282038 1.4367355 -0.54925456 #> Item_23 0.6786602 -0.68438097 0.8067015 -0.73454697 #> Item_24 0.4828002  1.68992778 0.5340588  1.63135837 #> Item_25 0.5011412  1.04812815 0.5206871  0.98189377 #> Item_26 1.6039924  0.63625385 1.5415293  0.65982060 #> Item_27 0.8328685  0.55938549 0.8555058  0.57838080 #> Item_28 1.1001393 -0.49299690 1.1861139 -0.56807834 #> Item_29 1.1996287  0.35417420 1.1836370  0.33337380 #> Item_30 0.9754835  0.73759996 0.9513067  0.71488089 #> Item_31 1.3529960  0.43565857 1.2435620  0.45176815 #> Item_32 1.8920655  0.74941926 1.6590501  0.73020049 #> Item_33 1.4823957 -0.13676561 1.6147571 -0.21305838 #> Item_34 1.5632963  1.61443582 1.4897337  1.73397764 #> Item_35 1.1070549  0.68876441 1.0762814  0.67985447 #> Item_36 1.0257494  1.29658002 1.1473565  1.30696943 #> Item_37 0.9487642  0.48500521 0.9027740  0.47042973 #> Item_38 0.6365371 -0.35814281 0.5013849 -0.21556737 #> Item_39 1.5587391  0.36866684 1.5303202  0.37556660 #> Item_40 1.0011701  0.57211468 1.0077403  0.57740905 #> Item_41 1.2936486 -0.53716279 1.3385533 -0.67473104 #> Item_42 0.2372635 -0.56862885 0.2858926 -0.59855776 #> Item_43 0.7581178  1.52829512 0.6819203  1.32086286 #> Item_44 1.2655570 -0.19867816 1.2811422 -0.27427356 #> Item_45 1.1789916 -0.71942555 1.2563355 -0.68644306 #> Item_46 1.4820218  0.41756426 1.4382188  0.48113247 #> Item_47 0.5174459 -0.34998852 0.5760704 -0.35353046 #> Item_48 1.2029294  1.55973508 1.1702210  1.51040387 #> Item_49 1.1780664 -0.38178278 1.1749563 -0.41985829 #> Item_50 0.6113326 -0.48518034 0.6079603 -0.48618269 plot(OWU_MEM, type = 'empiricalhist')   # Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM) MWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod) #>  coef(MWU_MEM, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #> Item_30 0.979  0.736 0 1 #> Item_31 1.356  0.434 0 1 #> Item_32 1.901  0.748 0 1 #> Item_33 1.486 -0.138 0 1 #> Item_34 1.571  1.614 0 1 #> Item_35 1.110  0.687 0 1 #> Item_36 1.033  1.297 0 1 #> Item_37 0.952  0.484 0 1 #> Item_38 0.642 -0.359 0 1 #> Item_39 1.565  0.367 0 1 #> Item_40 1.006  0.571 0 1 #> Item_41 1.299 -0.539 0 1 #> Item_42 0.241 -0.569 0 1 #> Item_43 0.763  1.528 0 1 #> Item_44 1.269 -0.200 0 1 #> Item_45 1.180 -0.720 0 1 #> Item_46 1.488  0.416 0 1 #> Item_47 0.523 -0.351 0 1 #> Item_48 1.209  1.559 0 1 #> Item_49 1.182 -0.383 0 1 #> Item_50 0.616 -0.486 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  data.frame(coef(MWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) #>                a1           d    pop_a1       pop_d #> Item_1  1.1961890 -0.36582599 1.1756586 -0.37827025 #> Item_2  1.2180200  1.34513036 1.2128398  1.36338487 #> Item_3  1.0287076 -0.01749165 0.9672090  0.03751319 #> Item_4  0.8169838  0.22955350 0.8639508  0.24616399 #> Item_5  1.1477420 -0.46213650 1.1817662 -0.46968358 #> Item_6  0.4734409  0.15748181 0.4546132  0.19456759 #> Item_7  1.1723767  0.49084966 1.1890296  0.48381989 #> Item_8  0.8823964  0.59861143 0.9171448  0.57665673 #> Item_9  0.7320060  1.36669674 0.9147521  1.50154551 #> Item_10 0.7374958 -1.70288028 0.7242034 -1.64286078 #> Item_11 0.9877230  0.05684034 0.9651257  0.10471439 #> Item_12 1.6208445 -0.88830542 1.5451936 -0.93977204 #> Item_13 1.2113938  0.36247319 1.1111884  0.38731215 #> Item_14 1.2608594  1.10068854 1.1560649  1.11297399 #> Item_15 0.7483149 -0.31912299 0.7748404 -0.41081572 #> Item_16 1.1708992 -1.24683338 1.2450700 -1.28266411 #> Item_17 0.7422645  0.63674114 0.7340927  0.62169760 #> Item_18 0.9248296  1.12848731 0.9005267  1.11544193 #> Item_19 1.4767582  0.39539515 1.3362138  0.36179827 #> Item_20 1.0368814 -0.99330414 1.0896171 -0.90697018 #> Item_21 1.1357543  0.06752098 1.2338866  0.03823090 #> Item_22 1.4021119 -0.51282038 1.4367355 -0.54925456 #> Item_23 0.6786602 -0.68438097 0.8067015 -0.73454697 #> Item_24 0.4828002  1.68992778 0.5340588  1.63135837 #> Item_25 0.5011412  1.04812815 0.5206871  0.98189377 #> Item_26 1.6039924  0.63625385 1.5415293  0.65982060 #> Item_27 0.8328685  0.55938549 0.8555058  0.57838080 #> Item_28 1.1001393 -0.49299690 1.1861139 -0.56807834 #> Item_29 1.1996287  0.35417420 1.1836370  0.33337380 #> Item_30 0.9791660  0.73649261 0.9513067  0.71488089 #> Item_31 1.3557620  0.43401149 1.2435620  0.45176815 #> Item_32 1.9007882  0.74806045 1.6590501  0.73020049 #> Item_33 1.4862529 -0.13819824 1.6147571 -0.21305838 #> Item_34 1.5713559  1.61388772 1.4897337  1.73397764 #> Item_35 1.1101719  0.68737052 1.0762814  0.67985447 #> Item_36 1.0330416  1.29655187 1.1473565  1.30696943 #> Item_37 0.9517934  0.48386436 0.9027740  0.47042973 #> Item_38 0.6415895 -0.35896158 0.5013849 -0.21556737 #> Item_39 1.5653049  0.36728263 1.5303202  0.37556660 #> Item_40 1.0055938  0.57108702 1.0077403  0.57740905 #> Item_41 1.2988445 -0.53887261 1.3385533 -0.67473104 #> Item_42 0.2407043 -0.56898111 0.2858926 -0.59855776 #> Item_43 0.7634191  1.52801497 0.6819203  1.32086286 #> Item_44 1.2688454 -0.20002553 1.2811422 -0.27427356 #> Item_45 1.1799250 -0.72019334 1.2563355 -0.68644306 #> Item_46 1.4880374  0.41618563 1.4382188  0.48113247 #> Item_47 0.5228163 -0.35071973 0.5760704 -0.35353046 #> Item_48 1.2091851  1.55916704 1.1702210  1.51040387 #> Item_49 1.1823034 -0.38320022 1.1749563 -0.41985829 #> Item_50 0.6156231 -0.48588671 0.6079603 -0.48618269 plot(MWU_MEM, type = 'empiricalhist')   # factor scores distribution check fs <- fscores(MWU_MEM) hist(fs)  c(mean_calib=mean(fs[1:N, ]), sd_calib=sd(fs[1:N, ])) #>    mean_calib      sd_calib  #> -0.0001434688  0.9215504578  c(mean_exper=mean(fs[-c(1:N), ]), sd_exper=sd(fs[-c(1:N), ])) #> mean_exper   sd_exper  #> 0.03352674 0.93335579    ############################ ## Item length constraint example for each participant in the experimental ## items group. In this example, all participants were forced to have a test ## length of J=30, though the item pool had J=50 total items.  # new experimental data (relatively extreme, theta ~ N(.5,1.5)) dataset2 <- simdata(a, d, N = 1000, itemtype=itemtype,     mu=.5, sigma=matrix(1.5))  # Add missing values to each participant in new dataset where individuals # were randomly administered 10 experimental items, subject to the constraint # that each participant received a test with J=30 items. dataset2 <- t(apply(dataset2, 1, function(x){    NA_precalib <- sample(1:30, 10)    NA_experimental <- sample(31:50, 10)    x[c(NA_precalib, NA_experimental)] <- NA    x })) head(dataset2) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]     NA      1      0      0     NA     NA      0     NA      1       0 #> [2,]     NA     NA     NA      1      1      1     NA      0      1      NA #> [3,]     NA     NA      0      1      1      1      1     NA      1       0 #> [4,]     NA      1      1     NA      0     NA      1      1      1       1 #> [5,]      1      1      1      1     NA     NA      0      1     NA      NA #> [6,]      1      0      0      1      1      1     NA     NA     NA       0 #>      Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> [1,]       1       0      NA       0      NA       0       0       1       0 #> [2,]       1       1       1      NA       0       0       1      NA       1 #> [3,]       1       1       0       1       1       1      NA      NA      NA #> [4,]      NA      NA       1      NA       0       0       1       0       0 #> [5,]       1      NA       0       1       1       0       1       1      NA #> [6,]       0       1       1       1       0       0      NA       1      NA #>      Item_20 Item_21 Item_22 Item_23 Item_24 Item_25 Item_26 Item_27 Item_28 #> [1,]       0       0      NA       0       1      NA       0       1       0 #> [2,]      NA       0       1      NA       1       1       1       1       0 #> [3,]       1       1      NA       0      NA      NA       1      NA       1 #> [4,]       1       1       1      NA      NA       1       1       1       1 #> [5,]       1      NA       1      NA       1      NA      NA       0       1 #> [6,]       1       1       0       0       0      NA      NA      NA       0 #>      Item_29 Item_30 Item_31 Item_32 Item_33 Item_34 Item_35 Item_36 Item_37 #> [1,]      NA      NA       0       1       1      NA       0      NA       0 #> [2,]      NA       1       1      NA      NA       1      NA       1       1 #> [3,]       1       1       1      NA      NA      NA      NA       1      NA #> [4,]      NA      NA      NA      NA      NA      NA       0      NA       1 #> [5,]       1       1      NA       1      NA       1       1      NA      NA #> [6,]      NA      NA      NA       1      NA      NA       1       1       0 #>      Item_38 Item_39 Item_40 Item_41 Item_42 Item_43 Item_44 Item_45 Item_46 #> [1,]       0      NA      NA      NA      NA       1       0      NA       0 #> [2,]      NA      NA      NA       1      NA       1       1       1       1 #> [3,]       1      NA      NA      NA       1       0       1      NA      NA #> [4,]       0       1      NA      NA      NA      NA       1       1       0 #> [5,]      NA       1       1      NA      NA       1      NA      NA       1 #> [6,]       1      NA      NA      NA      NA       1      NA      NA       1 #>      Item_47 Item_48 Item_49 Item_50 #> [1,]      NA      NA       0      NA #> [2,]      NA       1      NA      NA #> [3,]       0       0       1       1 #> [4,]      NA       1       0       1 #> [5,]      NA       1       1       1 #> [6,]       0       1      NA       1  # check that all individuals had 30 items all(rowSums(!is.na(dataset2)) == 30) #> [1] TRUE  # Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM) MWU_MEM <- fixedCalib(dataset2, model = 1, old_mod = mod) #>  coef(MWU_MEM, simplify=TRUE) #> $items #>            a1      d g u #> Item_1  1.196 -0.366 0 1 #> Item_2  1.218  1.345 0 1 #> Item_3  1.029 -0.017 0 1 #> Item_4  0.817  0.230 0 1 #> Item_5  1.148 -0.462 0 1 #> Item_6  0.473  0.157 0 1 #> Item_7  1.172  0.491 0 1 #> Item_8  0.882  0.599 0 1 #> Item_9  0.732  1.367 0 1 #> Item_10 0.737 -1.703 0 1 #> Item_11 0.988  0.057 0 1 #> Item_12 1.621 -0.888 0 1 #> Item_13 1.211  0.362 0 1 #> Item_14 1.261  1.101 0 1 #> Item_15 0.748 -0.319 0 1 #> Item_16 1.171 -1.247 0 1 #> Item_17 0.742  0.637 0 1 #> Item_18 0.925  1.128 0 1 #> Item_19 1.477  0.395 0 1 #> Item_20 1.037 -0.993 0 1 #> Item_21 1.136  0.068 0 1 #> Item_22 1.402 -0.513 0 1 #> Item_23 0.679 -0.684 0 1 #> Item_24 0.483  1.690 0 1 #> Item_25 0.501  1.048 0 1 #> Item_26 1.604  0.636 0 1 #> Item_27 0.833  0.559 0 1 #> Item_28 1.100 -0.493 0 1 #> Item_29 1.200  0.354 0 1 #> Item_30 1.074  1.010 0 1 #> Item_31 1.416  0.729 0 1 #> Item_32 2.098  0.853 0 1 #> Item_33 1.622  0.025 0 1 #> Item_34 1.242  1.731 0 1 #> Item_35 1.127  0.868 0 1 #> Item_36 1.212  1.155 0 1 #> Item_37 1.022  0.621 0 1 #> Item_38 0.654 -0.203 0 1 #> Item_39 1.333  0.685 0 1 #> Item_40 0.939  0.678 0 1 #> Item_41 1.833 -0.565 0 1 #> Item_42 0.387 -0.631 0 1 #> Item_43 0.691  1.108 0 1 #> Item_44 1.232 -0.054 0 1 #> Item_45 1.105 -0.460 0 1 #> Item_46 1.401  0.694 0 1 #> Item_47 0.532 -0.290 0 1 #> Item_48 1.122  1.509 0 1 #> Item_49 1.158 -0.318 0 1 #> Item_50 0.692 -0.432 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  data.frame(coef(MWU_MEM, simplify=TRUE)$items[,c('a1','d')],            pop_a1=a, pop_d=d) #>                a1           d    pop_a1       pop_d #> Item_1  1.1961890 -0.36582599 1.1756586 -0.37827025 #> Item_2  1.2180200  1.34513036 1.2128398  1.36338487 #> Item_3  1.0287076 -0.01749165 0.9672090  0.03751319 #> Item_4  0.8169838  0.22955350 0.8639508  0.24616399 #> Item_5  1.1477420 -0.46213650 1.1817662 -0.46968358 #> Item_6  0.4734409  0.15748181 0.4546132  0.19456759 #> Item_7  1.1723767  0.49084966 1.1890296  0.48381989 #> Item_8  0.8823964  0.59861143 0.9171448  0.57665673 #> Item_9  0.7320060  1.36669674 0.9147521  1.50154551 #> Item_10 0.7374958 -1.70288028 0.7242034 -1.64286078 #> Item_11 0.9877230  0.05684034 0.9651257  0.10471439 #> Item_12 1.6208445 -0.88830542 1.5451936 -0.93977204 #> Item_13 1.2113938  0.36247319 1.1111884  0.38731215 #> Item_14 1.2608594  1.10068854 1.1560649  1.11297399 #> Item_15 0.7483149 -0.31912299 0.7748404 -0.41081572 #> Item_16 1.1708992 -1.24683338 1.2450700 -1.28266411 #> Item_17 0.7422645  0.63674114 0.7340927  0.62169760 #> Item_18 0.9248296  1.12848731 0.9005267  1.11544193 #> Item_19 1.4767582  0.39539515 1.3362138  0.36179827 #> Item_20 1.0368814 -0.99330414 1.0896171 -0.90697018 #> Item_21 1.1357543  0.06752098 1.2338866  0.03823090 #> Item_22 1.4021119 -0.51282038 1.4367355 -0.54925456 #> Item_23 0.6786602 -0.68438097 0.8067015 -0.73454697 #> Item_24 0.4828002  1.68992778 0.5340588  1.63135837 #> Item_25 0.5011412  1.04812815 0.5206871  0.98189377 #> Item_26 1.6039924  0.63625385 1.5415293  0.65982060 #> Item_27 0.8328685  0.55938549 0.8555058  0.57838080 #> Item_28 1.1001393 -0.49299690 1.1861139 -0.56807834 #> Item_29 1.1996287  0.35417420 1.1836370  0.33337380 #> Item_30 1.0736650  1.01026900 0.9513067  0.71488089 #> Item_31 1.4162584  0.72856155 1.2435620  0.45176815 #> Item_32 2.0975461  0.85255109 1.6590501  0.73020049 #> Item_33 1.6216973  0.02486148 1.6147571 -0.21305838 #> Item_34 1.2421629  1.73077613 1.4897337  1.73397764 #> Item_35 1.1268922  0.86756137 1.0762814  0.67985447 #> Item_36 1.2121379  1.15479360 1.1473565  1.30696943 #> Item_37 1.0218142  0.62136695 0.9027740  0.47042973 #> Item_38 0.6544987 -0.20307537 0.5013849 -0.21556737 #> Item_39 1.3326681  0.68465299 1.5303202  0.37556660 #> Item_40 0.9387813  0.67776738 1.0077403  0.57740905 #> Item_41 1.8326249 -0.56461189 1.3385533 -0.67473104 #> Item_42 0.3866839 -0.63085106 0.2858926 -0.59855776 #> Item_43 0.6911816  1.10845312 0.6819203  1.32086286 #> Item_44 1.2321139 -0.05383912 1.2811422 -0.27427356 #> Item_45 1.1045328 -0.45957575 1.2563355 -0.68644306 #> Item_46 1.4012118  0.69353524 1.4382188  0.48113247 #> Item_47 0.5324164 -0.28980316 0.5760704 -0.35353046 #> Item_48 1.1215187  1.50886830 1.1702210  1.51040387 #> Item_49 1.1583841 -0.31781501 1.1749563 -0.41985829 #> Item_50 0.6916807 -0.43180765 0.6079603 -0.48618269 plot(MWU_MEM, type = 'empiricalhist')   ## factor scores check fs <- fscores(MWU_MEM) hist(fs)  c(mean_calib=mean(fs[1:N, ]), sd_calib=sd(fs[1:N, ])) #>    mean_calib      sd_calib  #> -0.0001434688  0.9215504578   ## shrinkage, but generally different from calibrated sample c(mean_exper=mean(fs[-c(1:N), ]), sd_exper=sd(fs[-c(1:N), ])) #> mean_exper   sd_exper  #>  0.3531216  1.0349737    # }"},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute latent regression fixed effect expected values — fixef","title":"Compute latent regression fixed effect expected values — fixef","text":"Create expected values fixed effects parameters latent regression models.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute latent regression fixed effect expected values — fixef","text":"","code":"fixef(x)"},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute latent regression fixed effect expected values — fixef","text":"x estimated model object mixedmirt mirt function","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute latent regression fixed effect expected values — fixef","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute latent regression fixed effect expected values — fixef","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fixef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute latent regression fixed effect expected values — fixef","text":"","code":"# \\donttest{  #simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  #items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  #conditional model using X1 and X2 as predictors of Theta mod1 <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) #>   #latent regression fixed effects (i.e., expected values) fe <- fixef(mod1) head(fe) #>              F1 #> [1,]  0.6128940 #> [2,] -0.1661763 #> [3,]  2.1652373 #> [4,] -1.8932285 #> [5,] -0.5021551 #> [6,]  2.2405531  # with mixedmirt() mod1b <- mixedmirt(dat, covdata, 1, lr.fixed = ~ X1 + X2, fixed = ~ 0 + items) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1965, Max-Change = 0.1716, Max-Change = 0.1474, Max-Change = 0.1256, Max-Change = 0.1060, Max-Change = 0.0884, Max-Change = 0.0838, Max-Change = 0.0746, Max-Change = 0.0642, Max-Change = 0.0512, Max-Change = 0.0449, Max-Change = 0.0425, Max-Change = 0.0340, Max-Change = 0.0309, Max-Change = 0.0248, Max-Change = 0.0231, Max-Change = 0.0157, Max-Change = 0.0173, Max-Change = 0.0177, Max-Change = 0.0151, Max-Change = 0.0149, Max-Change = 0.0139, Max-Change = 0.0103, Max-Change = 0.0071, Max-Change = 0.0092, Max-Change = 0.0086, Max-Change = 0.0073, Max-Change = 0.0079, Max-Change = 0.0073, Max-Change = 0.0063, Max-Change = 0.0070, Max-Change = 0.0069, Max-Change = 0.0032, Max-Change = 0.0047, Max-Change = 0.0042, Max-Change = 0.0033, Max-Change = 0.0047, Max-Change = 0.0034, Max-Change = 0.0043, Max-Change = 0.0048, Max-Change = 0.0044, Max-Change = 0.0080, Max-Change = 0.0022, Max-Change = 0.0017, Max-Change = 0.0045, Max-Change = 0.0037, Max-Change = 0.0041, Max-Change = 0.0038, Max-Change = 0.0040, Max-Change = 0.0035, Max-Change = 0.0043, Max-Change = 0.0025, Max-Change = 0.0057, Max-Change = 0.0039, Max-Change = 0.0038, Max-Change = 0.0032, Max-Change = 0.0017, Max-Change = 0.0055, Max-Change = 0.0042, Max-Change = 0.0036, Max-Change = 0.0026, Max-Change = 0.0024, Max-Change = 0.0054, Max-Change = 0.0044, Max-Change = 0.0109, Max-Change = 0.0031, Max-Change = 0.0054, Max-Change = 0.0019, Max-Change = 0.0011, Max-Change = 0.0019, Max-Change = 0.0055, Max-Change = 0.0013, Max-Change = 0.0055, Max-Change = 0.0033, Max-Change = 0.0044, Max-Change = 0.0044, Max-Change = 0.0031, Max-Change = 0.0014, Max-Change = 0.0081, Max-Change = 0.0021, Max-Change = 0.0045, Max-Change = 0.0032, Max-Change = 0.0042, Max-Change = 0.0034, Max-Change = 0.0071, Max-Change = 0.0059, Max-Change = 0.0019, Max-Change = 0.0014, Max-Change = 0.0050, Max-Change = 0.0038, Max-Change = 0.0012, Max-Change = 0.0046, Max-Change = 0.0034, Max-Change = 0.0024, Max-Change = 0.0047, Max-Change = 0.0046, Max-Change = 0.0034, Max-Change = 0.0041, Max-Change = 0.0044, Max-Change = 0.0024, Max-Change = 0.0054, Max-Change = 0.0059, Max-Change = 0.0032, Max-Change = 0.0045, Max-Change = 0.0028, Max-Change = 0.0024, Max-Change = 0.0044, Max-Change = 0.0050, Max-Change = 0.0011, Max-Change = 0.0037, Max-Change = 0.0037, Max-Change = 0.0026, Max-Change = 0.0029, Max-Change = 0.0040, Max-Change = 0.0037, Max-Change = 0.0056, Max-Change = 0.0046, Max-Change = 0.0020, Max-Change = 0.0016, Max-Change = 0.0041, Max-Change = 0.0064, Max-Change = 0.0059, Max-Change = 0.0042, Max-Change = 0.0026, Max-Change = 0.0036, Max-Change = 0.0028, Max-Change = 0.0044, Max-Change = 0.0035, Max-Change = 0.0026, Max-Change = 0.0034, Max-Change = 0.0037, Max-Change = 0.0045, Max-Change = 0.0049, Max-Change = 0.0034, Max-Change = 0.0028, Max-Change = 0.0026, Max-Change = 0.0077, Max-Change = 0.0028, Max-Change = 0.0037, Max-Change = 0.0035, Max-Change = 0.0021, Max-Change = 0.0026, Max-Change = 0.0023, Max-Change = 0.0033, Max-Change = 0.0049, Max-Change = 0.0058, Max-Change = 0.0024, Max-Change = 0.0040, Max-Change = 0.0035, Max-Change = 0.0030, Max-Change = 0.0035, Max-Change = 0.0052, Max-Change = 0.0016, Max-Change = 0.0026, Max-Change = 0.0044, Max-Change = 0.0045, Max-Change = 0.0029, Max-Change = 0.0046, Max-Change = 0.0050, Max-Change = 0.0030, Max-Change = 0.0010, Max-Change = 0.0043, Max-Change = 0.0055, Max-Change = 0.0051, Max-Change = 0.0041, Max-Change = 0.0045, Max-Change = 0.0042, Max-Change = 0.0023, Max-Change = 0.0017, Max-Change = 0.0029, Max-Change = 0.0010, Max-Change = 0.0035, Max-Change = 0.0013, Max-Change = 0.0021, Max-Change = 0.0036, Max-Change = 0.0040, Max-Change = 0.0047, Max-Change = 0.0043, Max-Change = 0.0035, Max-Change = 0.0026, Max-Change = 0.0032, Max-Change = 0.0013, Max-Change = 0.0048, Max-Change = 0.0029, Max-Change = 0.0019, Max-Change = 0.0034, Max-Change = 0.0019, Max-Change = 0.0031, Max-Change = 0.0015, Max-Change = 0.0041, Max-Change = 0.0040, Max-Change = 0.0041, Max-Change = 0.0038, Max-Change = 0.0033, Max-Change = 0.0021, Max-Change = 0.0025, Max-Change = 0.0032, Max-Change = 0.0031, Max-Change = 0.0047, Max-Change = 0.0022, Max-Change = 0.0030, Max-Change = 0.0035, Max-Change = 0.0071, Max-Change = 0.0041, Max-Change = 0.0028, Max-Change = 0.0055, Max-Change = 0.0067, Max-Change = 0.0018, Max-Change = 0.0019, Max-Change = 0.0058, Max-Change = 0.0030, Max-Change = 0.0064, Max-Change = 0.0038, Max-Change = 0.0062, Max-Change = 0.0029, Max-Change = 0.0028, Max-Change = 0.0040, Max-Change = 0.0042, Max-Change = 0.0031, Max-Change = 0.0026, Max-Change = 0.0022, Max-Change = 0.0069, Max-Change = 0.0058, Max-Change = 0.0021, Max-Change = 0.0035, Max-Change = 0.0068, Max-Change = 0.0051, Max-Change = 0.0015, Max-Change = 0.0036, Max-Change = 0.0043, Max-Change = 0.0034, Max-Change = 0.0013, Max-Change = 0.0022, Max-Change = 0.0038, Max-Change = 0.0036, Max-Change = 0.0039, Max-Change = 0.0021, Max-Change = 0.0030, Max-Change = 0.0031, Max-Change = 0.0058, Max-Change = 0.0060, Max-Change = 0.0024, Max-Change = 0.0018, Max-Change = 0.0020, Max-Change = 0.0038, Max-Change = 0.0064, Max-Change = 0.0051, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0053, gam = 0.1057, Max-Change = 0.0033, gam = 0.0780, Max-Change = 0.0010, gam = 0.0629, Max-Change = 0.0008, gam = 0.0532, Max-Change = 0.0017, gam = 0.0464, Max-Change = 0.0011, gam = 0.0413, Max-Change = 0.0007, gam = 0.0374, Max-Change = 0.0009, gam = 0.0342, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... fe2 <- fixef(mod1b) head(fe2) #>              F1 #> [1,]  0.6165760 #> [2,] -0.1671332 #> [3,]  2.1737979 #> [4,] -1.8995517 #> [5,] -0.5047064 #> [6,]  2.2499237  # }"},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"Computes MAP, EAP, ML (Embretson & Reise, 2000), EAP sum-scores (Thissen et al., 1995), WLE (Warm, 1989) factor scores multivariate normal prior distribution using equally spaced quadrature. EAP scores models three factors generally recommended since integration grid becomes large, resulting slower estimation less precision quadpts low. Therefore, MAP scores used instead EAP scores higher dimensional models. Multiple imputation variants possible estimator parameter information matrix computed, useful sample size/number items small. well, model contained latent regression predictors information used computing MAP EAP estimates (models, full.scores=TRUE always used). Finally, plausible value imputation also available, also account latent regression predictor effects.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"","code":"fscores(   object,   method = \"EAP\",   full.scores = TRUE,   rotate = \"oblimin\",   Target = NULL,   response.pattern = NULL,   append_response.pattern = FALSE,   na.rm = FALSE,   plausible.draws = 0,   plausible.type = \"normal\",   quadpts = NULL,   item_weights = rep(1, extract.mirt(object, \"nitems\")),   returnER = FALSE,   T_as_X = FALSE,   EAPsum.scores = FALSE,   return.acov = FALSE,   mean = NULL,   cov = NULL,   covdata = NULL,   verbose = TRUE,   full.scores.SE = FALSE,   theta_lim = c(-6, 6),   MI = 0,   use_dentype_estimate = FALSE,   QMC = FALSE,   custom_den = NULL,   custom_theta = NULL,   expected.info = FALSE,   min_expected = 1,   max_theta = 20,   start = NULL,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"object computed model object class SingleGroupClass, MultipleGroupClass, DiscreteClass method type factor score estimation method. Can : \"EAP\" expected -posteriori (default). models fit using       mdirt return posterior classification probabilities \"MAP\" maximum -posteriori (.e, Bayes modal) \"ML\" maximum likelihood \"WLE\" \"WML\" weighted maximum-likelihood estimation \"EAPsum\" expected -posteriori sum score \"plausible\" single plausible value imputation case.       equivalent setting plausible.draws = 1 \"classify\" posteriori classification probabilities (      applicable input model class MixtureClass) full.scores FALSE summary table factor scores unique pattern displayed formatted matrix object. Otherwise, matrix factor scores response pattern data returned (default) rotate prior rotation used estimating factor scores. See summary-method details. object exploratory model argument ignored Target target rotation; see summary-method details response.pattern optional argument used calculate factor scores standard errors given response vector matrix/data.frame append_response.pattern logical; inputs response.pattern also appended factor score output? na.rm logical; remove rows missing values? generally required due nature computing factors scores, however \"EAPsum\" method may necessary ensure sum-scores correspond composite score plausible.draws number plausible values draw future researchers perform secondary analyses latent trait scores. Typically used conjunction latent regression predictors (see mirt details), can also generated predictor variables modelled. plausible.draws greater 0 list plausible values returned plausible.type type plausible values obtain. Can either 'normal' (default) use normal approximation based ACOV matrix, 'MH' obtain Metropolis-Hastings samples posterior (silently passes object mirt, therefore arguments like technical can supplied increase number burn-draws discarded samples) quadpts number quadrature use per dimension. specified, suitable one created decreases number dimensions increases (therefore estimates EAP, less accurate). determined switch statement quadpts <- switch(.character(nfact), '1'=121, '2'=61, '3'=31, '4'=19, '5'=11, '6'=7, 5) item_weights user-defined weight vector used likelihood expressions add /less weight given observed response. Default vector 1's, indicating items receive weight returnER logical; return empirical reliability (also known marginal reliability) estimates numeric values? T_as_X logical; observed variance equal var(X) = var(T) + E(E^2) var(X) = var(T) computing empirical reliability estimates? Default (FALSE) uses former EAPsum.scores logical; include model-implied expected values variance item total scores using method = 'EAPsum' full.scores=FALSE? information included hidden 'fit' attribute can extracted via attr(., 'fit') later use return.acov logical; return list containing covariance matrices instead factors scores? impute = TRUE supported option mean vector custom latent variable means. NULL, default 'group' values computed mirt object used cov custom matrix latent variable covariance matrix. NULL, default 'group' values computed mirt object used covdata latent regression model fitted, response.pattern input used score individuals, argument used include latent regression covariate terms row vector supplied response.pattern verbose logical; print verbose output messages? full.scores.SE logical; full.scores == TRUE, also return standard errors associated respondent? Default FALSE theta_lim lower upper range evaluate latent trait integral dimension. omitted, range generated automatically based number dimensions MI number indicating many multiple imputation draws perform. Default 0, indicating MI draws performed use_dentype_estimate logical; density latent trait estimated model (e.g., via Davidian curves empirical histograms), information used compute latent trait estimates? applicable EAP-based estimates (EAP, EAPsum, plausible) QMC logical; use quasi-Monte Carlo integration? quadpts omitted default number nodes 5000 custom_den function used define integration density (required). NULL default   assumes multivariate normal distribution 'GroupPars' hyper-parameters   used. minimum must form: function(Theta, ...) Theta matrix latent trait values (grid values   method == 'EAPsum' method == 'EAP', otherwise Theta 1 row).   Additional arguments may included caught fscores(...) input.   function must return numeric vector density weights (one row Theta) custom_theta matrix custom integration nodes use instead default, column corresponds respective dimension model expected.info logical; instead using observed information method = 'ML' method = 'WLE' use expected information computed via testinfo? currently supported unidimensional models min_expected computing goodness fit tests method = 'EAPsum', value used collapse across conditioned total scores expected values greater value. Note affect goodness fit tests returned EAP sum scores table max_theta maximum/minimum value given factor score estimate achieve using modal estimator method (e.g., MAP, WLE, ML) start matrix starting values use iterative estimation methods. Default start vector 0's response pattern, start EAP estimates (unidimensional models ). Must form matches full.scores = FALSE (mostly used mirtCAT package) ... additional arguments passed nlm","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"function return either table computed scores standard errors, original data matrix scores appended rightmost column, scores . default latent means covariances determined estimated object, though can overwritten. Iterative estimation methods can estimated parallel decrease estimation times mirtCluster object available. input object discrete latent class object estimated mdirt returned results respect posterior classification individual. method inputs 'DiscreteClass' objects may 'EAP', posterior classification response pattern, 'EAPsum' posterior classification based raw sum-score. information algorithms refer mirtCAT package associated JSS paper (Chalmers, 2016).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2016). Generating Adaptive Non-Adaptive Test Interfaces Multidimensional Item Response Theory Applications. Journal Statistical Software, 71(5), 1-39. doi:10.18637/jss.v071.i05 Embretson, S. E. & Reise, S. P. (2000). Item Response Theory Psychologists. Erlbaum. Thissen, D., Pommerich, M., Billeaud, K., & Williams, V. S. L. (1995). Item Response Theory Scores Tests Including Polytomous Items Ordered Responses. Applied Psychological Measurement, 19, 39-49. Warm, T. . (1989). Weighted likelihood estimation ability item response theory. Psychometrika, 54, 427-450.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/fscores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc) — fscores","text":"","code":"mod <- mirt(Science) #>  tabscores <- fscores(mod, full.scores = FALSE) #>  #> Method:  EAP #>  #> Empirical Reliability: #>  #>     F1  #> 0.6666  head(tabscores) #>      Comfort Work Future Benefit     F1 SE_F1 #> [1,]       1    1      1       1 -2.749 0.629 #> [2,]       1    3      2       1 -1.420 0.577 #> [3,]       1    4      2       3 -0.714 0.620 #> [4,]       1    4      3       1 -0.447 0.651 #> [5,]       2    1      1       1 -2.544 0.591 #> [6,]       2    1      2       4 -1.248 0.584  # convert scores into expected total score information with 95% CIs E.total <- expected.test(mod, Theta=tabscores[,'F1']) E.total_2.5 <- expected.test(mod, Theta=tabscores[,'F1'] +                                        tabscores[,'SE_F1'] * qnorm(.05/2)) E.total_97.5 <- expected.test(mod, Theta=tabscores[,'F1'] +                                        tabscores[,'SE_F1'] * qnorm(1-.05/2))  data.frame(Total_score=rowSums(tabscores[,1:4]),            E.total, E.total_2.5, E.total_97.5) |> head() #>   Total_score   E.total E.total_2.5 E.total_97.5 #> 1           4  6.791606    5.321810     9.084082 #> 2           7  9.266018    7.128071    11.296189 #> 3          10 10.584682    8.296461    12.504975 #> 4           9 11.041648    8.691107    13.034195 #> 5           5  7.141179    5.576233     9.330947 #> 6           9  9.592533    7.415339    11.582060  # \\donttest{ fullscores <- fscores(mod) fullscores_with_SE <- fscores(mod, full.scores.SE=TRUE) head(fullscores) #>          F1 #> [1,]  0.402 #> [2,]  0.052 #> [3,] -0.891 #> [4,] -0.891 #> [5,]  0.765 #> [6,]  0.670 head(fullscores_with_SE) #>          F1 SE_F1 #> [1,]  0.402 0.598 #> [2,]  0.052 0.555 #> [3,] -0.891 0.542 #> [4,] -0.891 0.542 #> [5,]  0.765 0.639 #> [6,]  0.670 0.576  # convert scores into expected total score information with 95% CIs E.total <- expected.test(mod, Theta=fullscores[,'F1']) E.total_2.5 <- expected.test(mod, Theta=fullscores_with_SE[,'F1'] +                                  fullscores_with_SE[,'SE_F1'] * qnorm(.05/2)) E.total_97.5 <- expected.test(mod, Theta=fullscores_with_SE[,'F1'] +                                fullscores_with_SE[,'SE_F1'] * qnorm(1-.05/2))  data.frame(Total_score=rowSums(Science),            E.total, E.total_2.5, E.total_97.5) |> head() #>   Total_score  E.total E.total_2.5 E.total_97.5 #> 1          13 12.34882   10.484432     14.15621 #> 2          12 11.81643    9.994252     13.53226 #> 3          10 10.26478    8.250620     11.99721 #> 4          10 10.26478    8.250620     11.99721 #> 5          12 12.93068   10.976668     14.67563 #> 6          14 12.77499   11.020512     14.43522  # change method argument to use MAP estimates fullscores <- fscores(mod, method='MAP') head(fullscores) #>          F1 #> [1,]  0.421 #> [2,]  0.059 #> [3,] -0.919 #> [4,] -0.919 #> [5,]  0.790 #> [6,]  0.683  # calculate MAP for a given response vector fscores(mod, method='MAP', response.pattern = c(1,2,3,4)) #>         F1 SE_F1 #> [1,] -0.37 0.605 # or matrix fscores(mod, method='MAP', response.pattern = rbind(c(1,2,3,4), c(2,2,1,3))) #>          F1 SE_F1 #> [1,] -0.370 0.605 #> [2,] -1.694 0.577  # return only the scores and their SEs fscores(mod, method='MAP', response.pattern = c(1,2,3,4)) #>         F1 SE_F1 #> [1,] -0.37 0.605  # use custom latent variable properties (diffuse prior for MAP is very close to ML) fscores(mod, method='MAP', cov = matrix(1000), full.scores = FALSE) #>  #> Method:  MAP #>  #> Empirical Reliability: #>  #>     F1  #> 0.4207  #>       Comfort Work Future Benefit     F1  SE_F1 #>  [1,]       1    1      1       1 -9.340  9.636 #>  [2,]       1    3      2       1 -2.104  0.689 #>  [3,]       1    4      2       3 -1.151  0.705 #>  [4,]       1    4      3       1 -0.781  0.807 #>  [5,]       2    1      1       1 -4.394  1.179 #>  [6,]       2    1      2       4 -1.863  0.668 #>  [7,]       2    2      1       1 -3.248  0.812 #>  [8,]       2    2      2       2 -1.911  0.588 #>  [9,]       2    2      2       3 -1.606  0.608 #> [10,]       2    2      3       1 -1.468  0.714 #> [11,]       2    2      3       2 -1.168  0.635 #> [12,]       2    2      3       3 -0.797  0.639 #> [13,]       2    2      4       3  0.240  0.789 #> [14,]       2    3      1       3 -2.142  0.702 #> [15,]       2    3      2       2 -1.609  0.626 #> [16,]       2    3      2       3 -1.254  0.630 #> [17,]       2    3      3       2 -0.756  0.656 #> [18,]       2    3      3       3 -0.332  0.698 #> [19,]       2    3      3       4  0.083  0.761 #> [20,]       2    3      4       1  0.189  0.878 #> [21,]       2    3      4       3  0.763  0.681 #> [22,]       2    4      2       1 -1.822  0.694 #> [23,]       2    4      4       3  1.307  0.753 #> [24,]       2    4      4       4  2.095  1.039 #> [25,]       3    1      1       1 -3.538  1.001 #> [26,]       3    1      1       3 -2.510  0.697 #> [27,]       3    1      2       2 -1.926  0.615 #> [28,]       3    1      2       3 -1.587  0.643 #> [29,]       3    1      3       2 -1.088  0.674 #> [30,]       3    1      3       3 -0.658  0.696 #> [31,]       3    1      3       4 -0.281  0.807 #> [32,]       3    1      4       3  0.542  0.734 #> [33,]       3    1      4       4  1.038  0.736 #> [34,]       3    2      1       2 -2.348  0.625 #> [35,]       3    2      1       4 -1.913  0.709 #> [36,]       3    2      2       1 -1.861  0.616 #> [37,]       3    2      2       2 -1.577  0.594 #> [38,]       3    2      2       3 -1.255  0.602 #> [39,]       3    2      3       1 -1.025  0.663 #> [40,]       3    2      3       2 -0.798  0.629 #> [41,]       3    2      3       3 -0.409  0.668 #> [42,]       3    2      3       4 -0.037  0.744 #> [43,]       3    2      4       1  0.015  0.900 #> [44,]       3    2      4       2  0.205  0.789 #> [45,]       3    2      4       3  0.643  0.684 #> [46,]       3    2      4       4  1.102  0.718 #> [47,]       3    3      1       3 -1.629  0.780 #> [48,]       3    3      2       1 -1.518  0.659 #> [49,]       3    3      2       2 -1.239  0.617 #> [50,]       3    3      2       3 -0.882  0.630 #> [51,]       3    3      2       4 -0.621  0.708 #> [52,]       3    3      3       1 -0.549  0.711 #> [53,]       3    3      3       2 -0.347  0.687 #> [54,]       3    3      3       3  0.086  0.687 #> [55,]       3    3      3       4  0.490  0.676 #> [56,]       3    3      4       2  0.732  0.681 #> [57,]       3    3      4       3  1.048  0.650 #> [58,]       3    3      4       4  1.525  0.746 #> [59,]       3    4      1       3 -1.381  0.943 #> [60,]       3    4      2       3 -0.608  0.726 #> [61,]       3    4      3       2  0.099  0.768 #> [62,]       3    4      3       3  0.538  0.677 #> [63,]       3    4      3       4  0.961  0.675 #> [64,]       3    4      4       1  1.218  0.758 #> [65,]       3    4      4       2  1.272  0.749 #> [66,]       3    4      4       3  1.599  0.766 #> [67,]       3    4      4       4  2.422  1.040 #> [68,]       4    1      1       4 -2.106  0.772 #> [69,]       4    1      2       2 -1.638  0.654 #> [70,]       4    1      2       4 -1.014  0.724 #> [71,]       4    1      3       4  0.361  0.778 #> [72,]       4    2      2       1 -1.568  0.651 #> [73,]       4    2      2       3 -0.935  0.628 #> [74,]       4    2      3       3  0.054  0.711 #> [75,]       4    2      3       4  0.492  0.710 #> [76,]       4    2      4       2  0.762  0.723 #> [77,]       4    2      4       4  1.760  0.931 #> [78,]       4    3      2       3 -0.485  0.704 #> [79,]       4    3      3       2  0.139  0.718 #> [80,]       4    3      3       3  0.533  0.652 #> [81,]       4    3      3       4  0.929  0.655 #> [82,]       4    3      4       2  1.216  0.719 #> [83,]       4    3      4       3  1.527  0.734 #> [84,]       4    3      4       4  2.258  0.968 #> [85,]       4    4      3       2  0.640  0.707 #> [86,]       4    4      3       3  0.981  0.661 #> [87,]       4    4      3       4  1.465  0.749 #> [88,]       4    4      4       2  2.028  1.010 #> [89,]       4    4      4       3  2.390  1.015 #> [90,]       4    4      4       4  7.112 10.616 fscores(mod, method='ML', full.scores = FALSE) #>  #> Method:  ML #>  #> Empirical Reliability: #>  #>    F1  #> 0.716  #>       Comfort Work Future Benefit     F1 SE_F1 #>  [1,]       1    1      1       1   -Inf    NA #>  [2,]       1    3      2       1 -2.105 0.689 #>  [3,]       1    4      2       3 -1.151 0.705 #>  [4,]       1    4      3       1 -0.781 0.807 #>  [5,]       2    1      1       1 -4.400 1.182 #>  [6,]       2    1      2       4 -1.864 0.668 #>  [7,]       2    2      1       1 -3.250 0.813 #>  [8,]       2    2      2       2 -1.912 0.588 #>  [9,]       2    2      2       3 -1.606 0.609 #> [10,]       2    2      3       1 -1.469 0.714 #> [11,]       2    2      3       2 -1.169 0.635 #> [12,]       2    2      3       3 -0.797 0.639 #> [13,]       2    2      4       3  0.240 0.789 #> [14,]       2    3      1       3 -2.143 0.702 #> [15,]       2    3      2       2 -1.609 0.626 #> [16,]       2    3      2       3 -1.254 0.630 #> [17,]       2    3      3       2 -0.756 0.656 #> [18,]       2    3      3       3 -0.332 0.698 #> [19,]       2    3      3       4  0.083 0.762 #> [20,]       2    3      4       1  0.189 0.878 #> [21,]       2    3      4       3  0.763 0.681 #> [22,]       2    4      2       1 -1.823 0.694 #> [23,]       2    4      4       3  1.308 0.754 #> [24,]       2    4      4       4  2.097 1.041 #> [25,]       3    1      1       1 -3.542 1.004 #> [26,]       3    1      1       3 -2.511 0.698 #> [27,]       3    1      2       2 -1.926 0.615 #> [28,]       3    1      2       3 -1.588 0.644 #> [29,]       3    1      3       2 -1.088 0.674 #> [30,]       3    1      3       3 -0.658 0.696 #> [31,]       3    1      3       4 -0.281 0.808 #> [32,]       3    1      4       3  0.543 0.734 #> [33,]       3    1      4       4  1.038 0.736 #> [34,]       3    2      1       2 -2.349 0.625 #> [35,]       3    2      1       4 -1.914 0.709 #> [36,]       3    2      2       1 -1.862 0.616 #> [37,]       3    2      2       2 -1.577 0.594 #> [38,]       3    2      2       3 -1.255 0.602 #> [39,]       3    2      3       1 -1.026 0.663 #> [40,]       3    2      3       2 -0.798 0.629 #> [41,]       3    2      3       3 -0.409 0.668 #> [42,]       3    2      3       4 -0.037 0.744 #> [43,]       3    2      4       1  0.015 0.901 #> [44,]       3    2      4       2  0.206 0.789 #> [45,]       3    2      4       3  0.643 0.684 #> [46,]       3    2      4       4  1.102 0.719 #> [47,]       3    3      1       3 -1.630 0.780 #> [48,]       3    3      2       1 -1.518 0.659 #> [49,]       3    3      2       2 -1.240 0.617 #> [50,]       3    3      2       3 -0.883 0.630 #> [51,]       3    3      2       4 -0.621 0.708 #> [52,]       3    3      3       1 -0.549 0.711 #> [53,]       3    3      3       2 -0.348 0.688 #> [54,]       3    3      3       3  0.086 0.687 #> [55,]       3    3      3       4  0.490 0.676 #> [56,]       3    3      4       2  0.733 0.681 #> [57,]       3    3      4       3  1.048 0.650 #> [58,]       3    3      4       4  1.526 0.746 #> [59,]       3    4      1       3 -1.383 0.943 #> [60,]       3    4      2       3 -0.609 0.726 #> [61,]       3    4      3       2  0.099 0.768 #> [62,]       3    4      3       3  0.538 0.678 #> [63,]       3    4      3       4  0.962 0.675 #> [64,]       3    4      4       1  1.219 0.759 #> [65,]       3    4      4       2  1.273 0.749 #> [66,]       3    4      4       3  1.600 0.767 #> [67,]       3    4      4       4  2.425 1.042 #> [68,]       4    1      1       4 -2.107 0.772 #> [69,]       4    1      2       2 -1.639 0.654 #> [70,]       4    1      2       4 -1.015 0.724 #> [71,]       4    1      3       4  0.361 0.778 #> [72,]       4    2      2       1 -1.568 0.651 #> [73,]       4    2      2       3 -0.936 0.628 #> [74,]       4    2      3       3  0.054 0.711 #> [75,]       4    2      3       4  0.492 0.710 #> [76,]       4    2      4       2  0.763 0.723 #> [77,]       4    2      4       4  1.761 0.932 #> [78,]       4    3      2       3 -0.485 0.704 #> [79,]       4    3      3       2  0.139 0.718 #> [80,]       4    3      3       3  0.533 0.652 #> [81,]       4    3      3       4  0.929 0.656 #> [82,]       4    3      4       2  1.216 0.720 #> [83,]       4    3      4       3  1.527 0.735 #> [84,]       4    3      4       4  2.261 0.969 #> [85,]       4    4      3       2  0.640 0.707 #> [86,]       4    4      3       3  0.982 0.662 #> [87,]       4    4      3       4  1.465 0.749 #> [88,]       4    4      4       2  2.030 1.011 #> [89,]       4    4      4       3  2.392 1.016 #> [90,]       4    4      4       4    Inf    NA  # EAPsum table of values based on total scores (fs <- fscores(mod, method = 'EAPsum', full.scores = FALSE)) #>       df     X2  p.X2 SEM.alpha rxx.alpha rxx_F1 #> stats 10 16.312 0.091     1.262     0.616  0.624 #>  #>    Sum.Scores     F1 SE_F1 observed expected std.res #> 4           4 -2.749 0.629        2    0.124   5.324 #> 5           5 -2.431 0.617        1    0.790   0.236 #> 6           6 -2.081 0.610        2    2.760   0.457 #> 7           7 -1.718 0.602        1    7.252   2.322 #> 8           8 -1.364 0.598       11   15.893   1.227 #> 9           9 -1.012 0.604       32   29.674   0.427 #> 10         10 -0.649 0.610       58   48.363   1.386 #> 11         11 -0.287 0.605       70   68.485   0.183 #> 12         12  0.082 0.600       91   80.553   1.164 #> 13         13  0.487 0.613       56   65.668   1.193 #> 14         14  0.934 0.617       36   42.637   1.016 #> 15         15  1.384 0.622       20   22.331   0.493 #> 16         16  1.854 0.654       12    7.470   1.657  # convert expected counts back into marginal probability distribution within(fs,    `P(y)` <- expected / sum(observed)) #>    Sum.Scores     F1 SE_F1 observed expected std.res  P(y) #> 4           4 -2.749 0.629        2    0.124   5.324 0.000 #> 5           5 -2.431 0.617        1    0.790   0.236 0.002 #> 6           6 -2.081 0.610        2    2.760   0.457 0.007 #> 7           7 -1.718 0.602        1    7.252   2.322 0.018 #> 8           8 -1.364 0.598       11   15.893   1.227 0.041 #> 9           9 -1.012 0.604       32   29.674   0.427 0.076 #> 10         10 -0.649 0.610       58   48.363   1.386 0.123 #> 11         11 -0.287 0.605       70   68.485   0.183 0.175 #> 12         12  0.082 0.600       91   80.553   1.164 0.205 #> 13         13  0.487 0.613       56   65.668   1.193 0.168 #> 14         14  0.934 0.617       36   42.637   1.016 0.109 #> 15         15  1.384 0.622       20   22.331   0.493 0.057 #> 16         16  1.854 0.654       12    7.470   1.657 0.019  # list of error VCOV matrices for EAPsum (works for other estimators as well) acovs <- fscores(mod, method = 'EAPsum', full.scores = FALSE, return.acov = TRUE) acovs #> $`0` #>           [,1] #> [1,] 0.3960846 #>  #> $`1` #>           [,1] #> [1,] 0.3804011 #>  #> $`2` #>           [,1] #> [1,] 0.3723228 #>  #> $`3` #>           [,1] #> [1,] 0.3623228 #>  #> $`4` #>           [,1] #> [1,] 0.3575813 #>  #> $`5` #>           [,1] #> [1,] 0.3646464 #>  #> $`6` #>           [,1] #> [1,] 0.3722588 #>  #> $`7` #>          [,1] #> [1,] 0.365832 #>  #> $`8` #>           [,1] #> [1,] 0.3595964 #>  #> $`9` #>           [,1] #> [1,] 0.3762024 #>  #> $`10` #>           [,1] #> [1,] 0.3807206 #>  #> $`11` #>           [,1] #> [1,] 0.3866677 #>  #> $`12` #>           [,1] #> [1,] 0.4282521 #>   # WLE estimation, run in parallel using available cores if(interactive()) mirtCluster() head(fscores(mod, method='WLE', full.scores = FALSE)) #>  #> Method:  WLE #>  #> Empirical Reliability: #>  #>     F1  #> 0.7513  #>      Comfort Work Future Benefit     F1 SE_F1 #> [1,]       1    1      1       1 -5.698 1.578 #> [2,]       1    3      2       1 -2.119 0.633 #> [3,]       1    4      2       3 -1.139 0.656 #> [4,]       1    4      3       1 -0.849 0.700 #> [5,]       2    1      1       1 -4.011 1.142 #> [6,]       2    1      2       4 -1.896 0.670  # multiple imputation using 30 draws for EAP scores. Requires information matrix mod <- mirt(Science, 1, SE=TRUE) #>  #>  #> Calculating information matrix... fs <- fscores(mod, MI = 30) head(fs) #>          F1 #> [1,]  0.422 #> [2,]  0.074 #> [3,] -0.854 #> [4,] -0.854 #> [5,]  0.751 #> [6,]  0.700  # plausible values for future work pv <- fscores(mod, plausible.draws = 5) lapply(pv, function(x) c(mean=mean(x), var=var(x), min=min(x), max=max(x))) #> [[1]] #>        mean         var         min         max  #>  0.01119601  0.97160688 -3.36407149  3.33496059  #>  #> [[2]] #>        mean         var         min         max  #> -0.01773817  0.97991791 -3.02014045  3.22052784  #>  #> [[3]] #>        mean         var         min         max  #> -0.02384286  1.05093486 -3.40667209  2.69476617  #>  #> [[4]] #>        mean         var         min         max  #> -0.03735358  1.03924449 -3.30509002  2.62662348  #>  #> [[5]] #>        mean         var         min         max  #>  0.01349283  0.89886141 -3.43200655  2.81309938  #>   ## define a custom_den function (*must* return a numeric vector). #  EAP with a uniform prior between -3 and 3 fun <- function(Theta, ...) as.numeric(dunif(Theta, min = -3, max = 3)) head(fscores(mod, custom_den = fun)) #>          F1 #> [1,]  0.627 #> [2,]  0.074 #> [3,] -1.234 #> [4,] -1.234 #> [5,]  1.252 #> [6,]  1.007  # compare EAP estimators with same modified prior fun <- function(Theta, ...) as.numeric(dnorm(Theta, mean=.5)) head(fscores(mod, custom_den = fun)) #>          F1 #> [1,]  0.580 #> [2,]  0.206 #> [3,] -0.741 #> [4,] -0.741 #> [5,]  0.968 #> [6,]  0.836 head(fscores(mod, method = 'EAP', mean=.5)) #>          F1 #> [1,]  0.580 #> [2,]  0.206 #> [3,] -0.741 #> [4,] -0.741 #> [5,]  0.968 #> [6,]  0.836  if (FALSE) { # \\dontrun{ # custom MAP prior: standard truncated normal between 5 and -2 library(msm) # need the :: scope for parallel to see the function (not require if no mirtCluster() defined) fun <- function(Theta, ...) msm::dtnorm(Theta, mean = 0, sd = 1, lower = -2, upper = 5) head(fscores(mod, custom_den = fun, method = 'MAP', full.scores = FALSE)) } # }   #################### # scoring via response.pattern input (with latent regression structure) # simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  # items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  # conditional model using X1 and X2 as predictors of Theta mod <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) #>  coef(mod, simplify=TRUE) #> $items #>         a1      d g u #> Item_1   1 -0.409 0 1 #> Item_2   1  0.491 0 1 #> Item_3   1  0.313 0 1 #> Item_4   1  1.965 0 1 #> Item_5   1  1.753 0 1 #> Item_6   1 -0.246 0 1 #> Item_7   1 -1.077 0 1 #> Item_8   1  0.533 0 1 #> Item_9   1 -1.232 0 1 #> Item_10  1  0.603 0 1 #> Item_11  1 -0.404 0 1 #> Item_12  1  1.238 0 1 #> Item_13  1  1.033 0 1 #> Item_14  1  1.524 0 1 #> Item_15  1 -0.548 0 1 #> Item_16  1  2.075 0 1 #> Item_17  1 -0.695 0 1 #> Item_18  1 -1.200 0 1 #> Item_19  1  0.121 0 1 #> Item_20  1  0.523 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 0.215 #>  #> $lr.betas #>                 F1 #> (Intercept)  0.000 #> X1           0.527 #> X2          -1.036 #>   # all EAP estimates that include latent regression information fs <- fscores(mod, full.scores.SE=TRUE) head(fs) #>          F1 SE_F1 #> [1,]  0.309 0.344 #> [2,] -0.347 0.341 #> [3,]  2.048 0.390 #> [4,] -1.942 0.367 #> [5,] -0.763 0.343 #> [6,]  2.102 0.392  # score only two response patterns rp <- dat[1:2, ] cd <- covdata[1:2, ]  fscores(mod, response.pattern=rp, covdata=cd) #>          F1 SE_F1 #> [1,]  0.309 0.344 #> [2,] -0.347 0.341 fscores(mod, response.pattern=rp[2,], covdata=cd[2,]) # just one pattern #>          F1 SE_F1 #> [1,] -0.347 0.341  # }"},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized item difficulty summaries — gen.difficulty","title":"Generalized item difficulty summaries — gen.difficulty","text":"Function provides four generalized item difficulty representations polytomous response models described Ali, Chang, Anderson (2015). estimates used gauge difficult polytomous item may .","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized item difficulty summaries — gen.difficulty","text":"","code":"gen.difficulty(mod, type = \"IRF\", interval = c(-30, 30), ...)"},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized item difficulty summaries — gen.difficulty","text":"mod single factor model estimated mirt type type generalized difficulty parameter report. Can 'IRF' use item response function (default), 'mean' find average difficulty estimates, 'median' median difficulty estimates, 'trimmed' find trimmed mean removing first last difficulty estimates interval interval range search 'IRF' type ... additional arguments pass uniroot","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized item difficulty summaries — gen.difficulty","text":"Ali, U. S., Chang, H.-H., & Anderson, C. J. (2015). Location indices ordinal polytomous items based item response theory (Research Report . RR-15-20). Princeton, NJ: Educational Testing Service. http://dx.doi.org/10.1002/ets2.12065 Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized item difficulty summaries — gen.difficulty","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/gen.difficulty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized item difficulty summaries — gen.difficulty","text":"","code":"# \\donttest{  mod <- mirt(Science, 1) #>  coef(mod, simplify=TRUE, IRTpars = TRUE)$items #>                a        b1         b2        b3 #> Comfort 1.041755 -4.669193 -2.5341299 1.4072541 #> Work    1.225962 -2.385068 -0.7350678 1.8488053 #> Future  2.293372 -2.282226 -0.9652918 0.8562529 #> Benefit 1.094915 -3.057698 -0.9056673 1.5419094  gen.difficulty(mod) #>    Comfort       Work     Future    Benefit  #> -2.3089094 -0.5741303 -0.9207845 -0.8530161  gen.difficulty(mod, type = 'mean') #>    Comfort       Work     Future    Benefit  #> -1.9320231 -0.4237770 -0.7970883 -0.8071519   # also works for dichotomous items (though this is unnecessary) dat <- expand.table(LSAT7) mod <- mirt(dat, 1) #>  coef(mod, simplify=TRUE, IRTpars = TRUE)$items #>                a          b g u #> Item.1 0.9879254 -1.8787456 0 1 #> Item.2 1.0808847 -0.7475160 0 1 #> Item.3 1.7058006 -1.0576962 0 1 #> Item.4 0.7651853 -0.6351358 0 1 #> Item.5 0.7357980 -2.5204102 0 1  gen.difficulty(mod) #>     Item.1     Item.2     Item.3     Item.4     Item.5  #> -1.8787448 -0.7475182 -1.0576961 -0.6351601 -2.5204127  gen.difficulty(mod, type = 'mean') #>     Item.1     Item.2     Item.3     Item.4     Item.5  #> -1.8787456 -0.7475160 -1.0576962 -0.6351358 -2.5204102   # }"},{"path":"https://philchalmers.github.io/mirt/reference/head.mirt_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Head generic for customized matrix console output — head.mirt_matrix","title":"Head generic for customized matrix console output — head.mirt_matrix","text":"Provides nicer output printed matrix objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/head.mirt_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Head generic for customized matrix console output — head.mirt_matrix","text":"","code":"# S3 method for class 'mirt_matrix' head(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/head.mirt_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Head generic for customized matrix console output — head.mirt_matrix","text":"x object class 'mirt_matrix' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputing plausible data for missing values — imputeMissing","title":"Imputing plausible data for missing values — imputeMissing","text":"Given estimated model mirt's model fitting functions estimate latent trait, impute plausible missing data values. Returns original data data.frame without NA values. list Theta values supplied list complete datasets returned instead.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imputing plausible data for missing values — imputeMissing","text":"","code":"imputeMissing(x, Theta, warn = TRUE, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imputing plausible data for missing values — imputeMissing","text":"x estimated model x mirt package Theta matrix containing estimates latent trait scores (e.g., via fscores) warn logical; print warning messages? ... additional arguments pass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Imputing plausible data for missing values — imputeMissing","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Imputing plausible data for missing values — imputeMissing","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/imputeMissing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputing plausible data for missing values — imputeMissing","text":"","code":"# \\donttest{ dat <- expand.table(LSAT7) (original <- mirt(dat, 1)) #>  #>  #> Call: #> mirt(data = dat, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN NAperson <- sample(1:nrow(dat), 20, replace = TRUE) NAitem <- sample(1:ncol(dat), 20, replace = TRUE) for(i in 1:20)     dat[NAperson[i], NAitem[i]] <- NA (mod <- mirt(dat, 1)) #>  #>  #> Call: #> mirt(data = dat, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 25 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2652.1 #> Estimated parameters: 10  #> AIC = 5324.2 #> BIC = 5373.277; SABIC = 5341.517 #>  scores <- fscores(mod, method = 'MAP')  # re-estimate imputed dataset (good to do this multiple times and average over) fulldata <- imputeMissing(mod, scores) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’ (fullmod <- mirt(fulldata, 1)) #> Error: object 'fulldata' not found  # with multipleGroup set.seed(1) group <- sample(c('group1', 'group2'), 1000, TRUE) mod2 <- multipleGroup(dat, 1, group, TOL=1e-2) #>  fs <- fscores(mod2) fulldata2 <- imputeMissing(mod2, fs)  # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric smoothed regression lines for item response probability functions — itemGAM","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"function uses generalized additive model (GAM) estimate response curves items seem fit well given model. Using stable axillary model, traceline functions poorly fitting dichotomous polytomous items can inspected using point estimates (plausible values) latent trait. Plots tracelines associated standard errors available help interpret misfit. function may also useful adding new items existing, well established set items, especially parametric form items investigation unknown.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"","code":"itemGAM(   item,   Theta,   formula = resp ~ s(Theta, k = 10),   CI = 0.95,   theta_lim = c(-3, 3),   return.models = FALSE,   ... )  # S3 method for class 'itemGAM' plot(   x,   y = NULL,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"item single poorly fitting item investigated. Can vector matrix Theta list matrix latent trait estimates typically returned fscores formula R formula passed gam function. Default fits spline model 10 nodes. multidimensional models, traits assigned names 'Theta1', 'Theta2', ..., 'ThetaN' CI number ranging 0 1 indicating confidence interval range. Default provides 95 percent interval theta_lim range latent trait scores evaluated return.models logical; return list GAM models category? Useful GAMs inspected directly, also fitting multidimensional models (set TRUE automatically multidimensional models) ... additional arguments passed gam lattice x object class 'itemGAM' y NULL value ignored plotting function par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemGAM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric smoothed regression lines for item response probability functions — itemGAM","text":"","code":"# \\donttest{ set.seed(10) N <- 1000 J <- 30  a <- matrix(1, J) d <- matrix(rnorm(J)) Theta <- matrix(rnorm(N, 0, 1.5)) dat <- simdata(a, d, N, itemtype = '2PL', Theta=Theta)  # make a bad item ps <- exp(Theta^2 + Theta) / (1 + exp(Theta^2 + Theta)) item1 <- sapply(ps, function(x) sample(c(0,1), size = 1, prob = c(1-x, x)))  ps2 <- exp(2 * Theta^2 + Theta + .5 * Theta^3) / (1 + exp(2 * Theta^2 + Theta + .5 * Theta^3)) item2 <- sapply(ps2, function(x) sample(c(0,1), size = 1, prob = c(1-x, x)))  # how the actual item looks in the population plot(Theta, ps, ylim = c(0,1))  plot(Theta, ps2, ylim = c(0,1))   baditems <- cbind(item1, item2) newdat <- cbind(dat, baditems)  badmod <- mirt(newdat, 1) #>  itemfit(badmod) #clearly a bad fit for the last two items #>       item    S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1  26.608      24      0.010  0.323 #> 2   Item_2  14.613      26      0.000  0.964 #> 3   Item_3  35.063      25      0.020  0.087 #> 4   Item_4  30.993      26      0.014  0.229 #> 5   Item_5  20.266      25      0.000  0.733 #> 6   Item_6  26.641      24      0.010  0.321 #> 7   Item_7  25.524      25      0.005  0.433 #> 8   Item_8  29.095      24      0.015  0.217 #> 9   Item_9  29.228      25      0.013  0.254 #> 10 Item_10  34.572      24      0.021  0.075 #> 11 Item_11  32.517      24      0.019  0.115 #> 12 Item_12  43.634      25      0.027  0.012 #> 13 Item_13  19.525      24      0.000  0.723 #> 14 Item_14  24.384      25      0.000  0.497 #> 15 Item_15  24.072      25      0.000  0.515 #> 16 Item_16  33.682      25      0.019  0.115 #> 17 Item_17  58.681      26      0.035  0.000 #> 18 Item_18  28.826      24      0.014  0.227 #> 19 Item_19  19.221      23      0.000  0.688 #> 20 Item_20  38.570      25      0.023  0.041 #> 21 Item_21  24.132      26      0.000  0.568 #> 22 Item_22  28.951      23      0.016  0.182 #> 23 Item_23  22.083      26      0.000  0.684 #> 24 Item_24  29.721      24      0.015  0.194 #> 25 Item_25  22.775      26      0.000  0.646 #> 26 Item_26  27.243      24      0.012  0.293 #> 27 Item_27  22.161      26      0.000  0.680 #> 28 Item_28  22.798      26      0.000  0.644 #> 29 Item_29  30.499      24      0.016  0.169 #> 30 Item_30  31.316      24      0.017  0.145 #> 31   item1 185.602      28      0.075  0.000 #> 32   item2 135.647      28      0.062  0.000 mod <- mirt(dat, 1) #fit a model that does not contain the bad items #>  itemfit(mod) #>       item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1 29.980      24      0.016  0.185 #> 2   Item_2 21.004      26      0.000  0.742 #> 3   Item_3 26.195      24      0.010  0.343 #> 4   Item_4 24.582      25      0.000  0.486 #> 5   Item_5 27.717      24      0.012  0.272 #> 6   Item_6 34.249      23      0.022  0.062 #> 7   Item_7 34.346      25      0.019  0.101 #> 8   Item_8 25.295      23      0.010  0.335 #> 9   Item_9 21.434      25      0.000  0.668 #> 10 Item_10 30.231      23      0.018  0.143 #> 11 Item_11 23.284      23      0.004  0.444 #> 12 Item_12 18.241      24      0.000  0.791 #> 13 Item_13 19.337      24      0.000  0.734 #> 14 Item_14 26.281      24      0.010  0.339 #> 15 Item_15 15.675      24      0.000  0.899 #> 16 Item_16 25.369      24      0.008  0.386 #> 17 Item_17 51.496      25      0.033  0.001 #> 18 Item_18 17.211      23      0.000  0.799 #> 19 Item_19 20.136      23      0.000  0.634 #> 20 Item_20 37.402      24      0.024  0.040 #> 21 Item_21 30.726      25      0.015  0.198 #> 22 Item_22 23.889      22      0.009  0.353 #> 23 Item_23 13.622      25      0.000  0.968 #> 24 Item_24 43.777      24      0.029  0.008 #> 25 Item_25 27.211      25      0.009  0.345 #> 26 Item_26 17.295      24      0.000  0.836 #> 27 Item_27 27.196      25      0.009  0.346 #> 28 Item_28 16.918      25      0.000  0.885 #> 29 Item_29 15.302      24      0.000  0.912 #> 30 Item_30 21.808      23      0.000  0.532  if (FALSE) { # \\dontrun{ #### Pure non-parametric way of investigating the items library(KernSmoothIRT) ks <- ksIRT(newdat, rep(1, ncol(newdat)), 1) plot(ks, item=c(1,31,32)) par(ask=FALSE) } # }  # Using point estimates from the model Theta <- fscores(mod) IG0 <- itemGAM(dat[,1], Theta) #good item IG1 <- itemGAM(baditems[,1], Theta) IG2 <- itemGAM(baditems[,2], Theta) plot(IG0)  plot(IG1)  plot(IG2)   # same as above, but with plausible values to obtain the standard errors set.seed(4321) ThetaPV <- fscores(mod, plausible.draws=10) IG0 <- itemGAM(dat[,1], ThetaPV) #good item IG1 <- itemGAM(baditems[,1], ThetaPV) IG2 <- itemGAM(baditems[,2], ThetaPV) plot(IG0)  plot(IG1)  plot(IG2)   ## for polytomous test items SAT12[SAT12 == 8] <- NA dat <- key2binary(SAT12,                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) dat <- dat[,-32] mod <- mirt(dat, 1) #>   if (FALSE) { # \\dontrun{ # Kernal smoothing is very sensitive to which category is selected as 'correct' # 5th category as correct ks <- ksIRT(cbind(dat, SAT12[,32]), c(rep(1, 31), 5), 1) plot(ks, items = c(1,2,32))  # 3rd category as correct ks <- ksIRT(cbind(dat, SAT12[,32]), c(rep(1, 31), 3), 1) plot(ks, items = c(1,2,32)) } # }  # splines approach Theta <- fscores(mod) IG <- itemGAM(SAT12[,32], Theta) plot(IG)   set.seed(1423) ThetaPV <- fscores(mod, plausible.draws=10) IG2 <- itemGAM(SAT12[,32], ThetaPV) plot(IG2)   # assuming a simple increasing parametric form (like in a standard IRT model) IG3 <- itemGAM(SAT12[,32], Theta, formula = resp ~ Theta) plot(IG3)  IG3 <- itemGAM(SAT12[,32], ThetaPV, formula = resp ~ Theta) plot(IG3)   ### multidimensional example by returning the GAM objects mod2 <- mirt(dat, 2) #>  Theta <- fscores(mod2) IG4 <- itemGAM(SAT12[,32], Theta, formula = resp ~ s(Theta1, k=10) + s(Theta2, k=10),    return.models=TRUE) names(IG4) #> [1] \"cat_1\" \"cat_2\" \"cat_3\" \"cat_4\" \"cat_5\" plot(IG4[[1L]], main = 'Category 1')   plot(IG4[[2L]], main = 'Category 2')   plot(IG4[[3L]], main = 'Category 3')    # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Item fit statistics — itemfit","title":"Item fit statistics — itemfit","text":"Computes item-fit statistics variety unidimensional multidimensional models. Poorly fitting items inspected empirical plots/tables unidimensional models, otherwise itemGAM can used diagnose functional form IRT model misspecified, models can refit using flexible semi-parametric response models (e.g., itemtype = 'spline'). latent trait density approximated (e.g., Davidian curves, Empirical histograms, etc) passing use_dentype_estimate = TRUE use internally saved quadrature density components (applicable). Currently, S-X2 statistic supported mixture IRT models. Finally, applicable root mean-square error approximation (RMSEA) reported help gauge magnitude item misfit.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item fit statistics — itemfit","text":"","code":"itemfit(   x,   fit_stats = \"S_X2\",   which.items = 1:extract.mirt(x, \"nitems\"),   na.rm = FALSE,   p.adjust = \"none\",   group.bins = 10,   group.size = NA,   group.fun = mean,   mincell = 1,   mincell.X2 = 2,   return.tables = FALSE,   pv_draws = 30,   boot = 1000,   boot_dfapprox = 200,   S_X2.plot = NULL,   S_X2.plot_raw.score = TRUE,   ETrange = c(-2, 2),   ETpoints = 11,   empirical.plot = NULL,   empirical.CI = 0.95,   empirical.poly.collapse = FALSE,   method = \"EAP\",   Theta = NULL,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Item fit statistics — itemfit","text":"x computed model object class SingleGroupClass, MultipleGroupClass, DiscreteClass fit_stats character vector indicating fit statistics computed.   Supported inputs : 'S_X2' : Orlando Thissen (2000, 2003)     Kang Chen's (2007) signed chi-squared test (default) 'Zh' : Drasgow, Levine, & Williams (1985) Zh 'X2' : Bock's (1972) chi-squared method.     default inputs compute Yen's (1981) Q1 variant X2 statistic     (.e., uses fixed group.bins = 10). However, Bock's group-size variable     median-based method can computed passing group.fun = median     modifying group.size input desired number bins 'G2' : McKinley & Mills (1985) G2 statistic (similar method Q1,     likelihood-ratio test). 'PV_Q1' : Chalmers Ng's (2017) plausible-value variant     Q1 statistic. 'PV_Q1*' : Chalmers Ng's (2017) plausible-value variant     Q1 statistic uses parametric bootstrapping obtain suitable empirical     distribution. 'X2*' : Stone's (2000) fit statistics require parametric     bootstrapping 'X2*_df' : Stone's (2000) fit statistics require parametric     bootstrapping obtain scaled versions X2* degrees freedom 'infit' : Compute infit outfit statistics Note 'S_X2' 'Zh' computed missing response data (.e., require multiple-imputation/row-removal techniques). .items integer vector indicating items test fit. Default tests possible items na.rm logical; remove rows missing values? required methods S-X2 require \"EAPsum\" method fscores p.adjust method use adjusting p-values respective item fit statistic (see p.adjust available options). Default 'none' group.bins number bins use X2 G2. example, setting group.bins = 10 compute Yen's (1981) Q1 statistic 'X2' requested group.size approximate size group used calculating \\(\\chi^2\\) statistic. default NA disables command instead uses group.bins input try construct equally sized bins group.fun function used 'X2' 'G2' computed. Determines central tendency measure within partitioned group. E.g., setting group.fun = median obtain median respective ability estimate subgroup (used Bock, 1972) mincell minimum expected cell size used S-X2 computations. Tables collapsed across items first polytomous, across scores necessary mincell.X2 minimum expected cell size used X2 computations. Tables collapsed polytomous, however condition can met group block omitted computations return.tables logical; return tables investigating 'X2', 'S_X2', 'X2*'? pv_draws number plausible-value draws obtain PV_Q1 PV_Q1* boot number parametric bootstrap samples create PV_Q1* X2* boot_dfapprox number parametric bootstrap samples create X2*_df statistic approximate scaling factor X2* well scaled degrees freedom estimates S_X2.plot argument input empirical.plot, however resulting image constructed according S-X2 statistic's conditional sum-score information S_X2.plot_raw.score logical; use raw-score information plot stead latent trait scale score? Default FALSE ETrange range integration nodes Stone's X2* statistic ETpoints number integration nodes use Stone's X2* statistic empirical.plot single numeric value character item name indicating item plot (via itemplot) overlay empirical \\(\\theta\\) groupings (see empirical.CI). Useful plotting expected bins based 'X2' 'G2' method empirical.CI numeric value indicating width empirical confidence interval ranging 0 1 (default 0 plots interval). example, 95 interval plotted empirical.CI = .95. applicable dichotomous items empirical.poly.collapse logical; collapse polytomous item categories expected scoring functions empirical plots? Default FALSE method type factor score estimation method. See fscores detail Theta matrix factor scores person used statistics require empirical estimates. supplied, arguments typically passed fscores() ignored values used instead. Also required estimating statistics missing data via imputation par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed fscores() lattice","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Item fit statistics — itemfit","text":"Bock, R. D. (1972). Estimating item parameters latent ability responses scored two nominal categories. Psychometrika, 37, 29-51. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. & Ng, V. (2017). Plausible-Value Imputation Statistics Detecting Item Misfit. Applied Psychological Measurement, 41, 372-387. doi:10.1177/0146621617692079 Drasgow, F., Levine, M. V., & Williams, E. . (1985). Appropriateness measurement polychotomous item response models standardized indices. British Journal Mathematical Statistical Psychology, 38, 67-86. Kang, T. & Chen, Troy, T. (2007). investigation performance generalized S-X2 item-fit index polytomous IRT models. ACT McKinley, R., & Mills, C. (1985). comparison several goodness--fit statistics. Applied Psychological Measurement, 9, 49-57. Orlando, M. & Thissen, D. (2000). Likelihood-based item fit indices dichotomous item response theory models. Applied Psychological Measurement, 24, 50-64. Reise, S. P. (1990). comparison item- person-fit methods assessing model-data fit IRT. Applied Psychological Measurement, 14, 127-137. Stone, C. . (2000). Monte Carlo Based Null Distribution Alternative Goodness--Fit Test Statistics IRT Models. Journal Educational Measurement, 37, 58-75. Wright B. D. & Masters, G. N. (1982). Rating scale analysis. MESA Press. Yen, W. M. (1981). Using simulation results choose latent trait model. Applied Psychological Measurement, 5, 245-262.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Item fit statistics — itemfit","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Item fit statistics — itemfit","text":"","code":"# \\donttest{  P <- function(Theta){exp(Theta^2 * 1.2 - 1) / (1 + exp(Theta^2 * 1.2 - 1))}  #make some data set.seed(1234) a <- matrix(rlnorm(20, meanlog=0, sdlog = .1),ncol=1) d <- matrix(rnorm(20),ncol=1) Theta <- matrix(rnorm(2000)) items <- rep('2PL', 20) ps <- P(Theta) baditem <- numeric(2000) for(i in 1:2000)    baditem[i] <- sample(c(0,1), 1, prob = c(1-ps[i], ps[i])) data <- cbind(simdata(a,d, 2000, items, Theta=Theta), baditem=baditem)  x <- mirt(data, 1) #>  raschfit <- mirt(data, 1, itemtype='Rasch') #>  fit <- itemfit(x) fit #>       item    S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1  16.519      15      0.007  0.348 #> 2   Item_2  11.718      15      0.000  0.700 #> 3   Item_3  22.835      15      0.016  0.088 #> 4   Item_4  11.703      16      0.000  0.764 #> 5   Item_5  15.241      15      0.003  0.434 #> 6   Item_6  11.983      16      0.000  0.745 #> 7   Item_7  23.912      16      0.016  0.091 #> 8   Item_8  12.744      15      0.000  0.622 #> 9   Item_9  16.931      15      0.008  0.323 #> 10 Item_10   9.199      16      0.000  0.905 #> 11 Item_11  17.630      15      0.009  0.283 #> 12 Item_12  12.198      15      0.000  0.664 #> 13 Item_13  17.487      15      0.009  0.291 #> 14 Item_14  19.117      15      0.012  0.208 #> 15 Item_15  11.542      16      0.000  0.775 #> 16 Item_16  12.534      16      0.000  0.706 #> 17 Item_17  29.453      15      0.022  0.014 #> 18 Item_18  15.064      16      0.000  0.520 #> 19 Item_19  17.125      15      0.008  0.311 #> 20 Item_20  10.064      15      0.000  0.816 #> 21 baditem 233.224      18      0.077  0.000  # p-value adjustment itemfit(x, p.adjust='fdr') #>       item    S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1  16.519      15      0.007  0.732 #> 2   Item_2  11.718      15      0.000  0.856 #> 3   Item_3  22.835      15      0.016  0.480 #> 4   Item_4  11.703      16      0.000  0.856 #> 5   Item_5  15.241      15      0.003  0.829 #> 6   Item_6  11.983      16      0.000  0.856 #> 7   Item_7  23.912      16      0.016  0.480 #> 8   Item_8  12.744      15      0.000  0.856 #> 9   Item_9  16.931      15      0.008  0.732 #> 10 Item_10   9.199      16      0.000  0.905 #> 11 Item_11  17.630      15      0.009  0.732 #> 12 Item_12  12.198      15      0.000  0.856 #> 13 Item_13  17.487      15      0.009  0.732 #> 14 Item_14  19.117      15      0.012  0.732 #> 15 Item_15  11.542      16      0.000  0.856 #> 16 Item_16  12.534      16      0.000  0.856 #> 17 Item_17  29.453      15      0.022  0.148 #> 18 Item_18  15.064      16      0.000  0.856 #> 19 Item_19  17.125      15      0.008  0.732 #> 20 Item_20  10.064      15      0.000  0.856 #> 21 baditem 233.224      18      0.077  0.000  # two different fit stats (with/without p-value adjustment) itemfit(x, c('S_X2' ,'X2'), p.adjust='fdr') #>       item      X2 df.X2 RMSEA.X2  p.X2    S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1  30.842     8    0.038 0.000  16.519      15      0.007  0.732 #> 2   Item_2  27.970     8    0.035 0.001  11.718      15      0.000  0.856 #> 3   Item_3  43.995     8    0.047 0.000  22.835      15      0.016  0.480 #> 4   Item_4  33.272     8    0.040 0.000  11.703      16      0.000  0.856 #> 5   Item_5  29.469     8    0.037 0.001  15.241      15      0.003  0.829 #> 6   Item_6  21.325     8    0.029 0.007  11.983      16      0.000  0.856 #> 7   Item_7  23.127     8    0.031 0.004  23.912      16      0.016  0.480 #> 8   Item_8  25.332     8    0.033 0.002  12.744      15      0.000  0.856 #> 9   Item_9  33.778     8    0.040 0.000  16.931      15      0.008  0.732 #> 10 Item_10  22.972     8    0.031 0.004   9.199      16      0.000  0.905 #> 11 Item_11  27.300     8    0.035 0.001  17.630      15      0.009  0.732 #> 12 Item_12  23.256     8    0.031 0.004  12.198      15      0.000  0.856 #> 13 Item_13  31.523     8    0.038 0.000  17.487      15      0.009  0.732 #> 14 Item_14  27.924     8    0.035 0.001  19.117      15      0.012  0.732 #> 15 Item_15  18.462     8    0.026 0.020  11.542      16      0.000  0.856 #> 16 Item_16  25.057     8    0.033 0.002  12.534      16      0.000  0.856 #> 17 Item_17  14.828     8    0.021 0.063  29.453      15      0.022  0.148 #> 18 Item_18  17.676     8    0.025 0.025  15.064      16      0.000  0.856 #> 19 Item_19  32.585     8    0.039 0.000  17.125      15      0.008  0.732 #> 20 Item_20  37.207     8    0.043 0.000  10.064      15      0.000  0.856 #> 21 baditem 228.367     8    0.117 0.000 233.224      18      0.077  0.000 itemfit(x, c('S_X2' ,'X2')) #>       item      X2 df.X2 RMSEA.X2  p.X2    S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1  30.842     8    0.038 0.000  16.519      15      0.007  0.348 #> 2   Item_2  27.970     8    0.035 0.000  11.718      15      0.000  0.700 #> 3   Item_3  43.995     8    0.047 0.000  22.835      15      0.016  0.088 #> 4   Item_4  33.272     8    0.040 0.000  11.703      16      0.000  0.764 #> 5   Item_5  29.469     8    0.037 0.000  15.241      15      0.003  0.434 #> 6   Item_6  21.325     8    0.029 0.006  11.983      16      0.000  0.745 #> 7   Item_7  23.127     8    0.031 0.003  23.912      16      0.016  0.091 #> 8   Item_8  25.332     8    0.033 0.001  12.744      15      0.000  0.622 #> 9   Item_9  33.778     8    0.040 0.000  16.931      15      0.008  0.323 #> 10 Item_10  22.972     8    0.031 0.003   9.199      16      0.000  0.905 #> 11 Item_11  27.300     8    0.035 0.001  17.630      15      0.009  0.283 #> 12 Item_12  23.256     8    0.031 0.003  12.198      15      0.000  0.664 #> 13 Item_13  31.523     8    0.038 0.000  17.487      15      0.009  0.291 #> 14 Item_14  27.924     8    0.035 0.000  19.117      15      0.012  0.208 #> 15 Item_15  18.462     8    0.026 0.018  11.542      16      0.000  0.775 #> 16 Item_16  25.057     8    0.033 0.002  12.534      16      0.000  0.706 #> 17 Item_17  14.828     8    0.021 0.063  29.453      15      0.022  0.014 #> 18 Item_18  17.676     8    0.025 0.024  15.064      16      0.000  0.520 #> 19 Item_19  32.585     8    0.039 0.000  17.125      15      0.008  0.311 #> 20 Item_20  37.207     8    0.043 0.000  10.064      15      0.000  0.816 #> 21 baditem 228.367     8    0.117 0.000 233.224      18      0.077  0.000  # Conditional sum-score plot from S-X2 information itemfit(x, S_X2.plot = 1) # good fit  itemfit(x, S_X2.plot = 2) # good fit  itemfit(x, S_X2.plot = 21) # bad fit   itemfit(x, 'X2') # just X2 #>       item      X2 df.X2 RMSEA.X2  p.X2 #> 1   Item_1  30.842     8    0.038 0.000 #> 2   Item_2  27.970     8    0.035 0.000 #> 3   Item_3  43.995     8    0.047 0.000 #> 4   Item_4  33.272     8    0.040 0.000 #> 5   Item_5  29.469     8    0.037 0.000 #> 6   Item_6  21.325     8    0.029 0.006 #> 7   Item_7  23.127     8    0.031 0.003 #> 8   Item_8  25.332     8    0.033 0.001 #> 9   Item_9  33.778     8    0.040 0.000 #> 10 Item_10  22.972     8    0.031 0.003 #> 11 Item_11  27.300     8    0.035 0.001 #> 12 Item_12  23.256     8    0.031 0.003 #> 13 Item_13  31.523     8    0.038 0.000 #> 14 Item_14  27.924     8    0.035 0.000 #> 15 Item_15  18.462     8    0.026 0.018 #> 16 Item_16  25.057     8    0.033 0.002 #> 17 Item_17  14.828     8    0.021 0.063 #> 18 Item_18  17.676     8    0.025 0.024 #> 19 Item_19  32.585     8    0.039 0.000 #> 20 Item_20  37.207     8    0.043 0.000 #> 21 baditem 228.367     8    0.117 0.000 itemfit(x, 'X2', method = 'ML') # X2 with maximum-likelihood estimates for traits #> Warning: The following factor score estimates failed to converge successfully: #>     311,315,352,518,677,748,909,927,1081,1243,1277,1305,1415,1480,1620,1893 #>       item      X2 df.X2 RMSEA.X2  p.X2 #> 1   Item_1  35.941     8    0.042 0.000 #> 2   Item_2  53.226     8    0.053 0.000 #> 3   Item_3  47.010     8    0.049 0.000 #> 4   Item_4  85.852     8    0.070 0.000 #> 5   Item_5  85.280     8    0.070 0.000 #> 6   Item_6   8.632     8    0.006 0.374 #> 7   Item_7  57.623     8    0.056 0.000 #> 8   Item_8  42.952     8    0.047 0.000 #> 9   Item_9  55.180     8    0.054 0.000 #> 10 Item_10  32.456     8    0.039 0.000 #> 11 Item_11 131.613     8    0.088 0.000 #> 12 Item_12  50.094     8    0.051 0.000 #> 13 Item_13  55.846     8    0.055 0.000 #> 14 Item_14  18.717     8    0.026 0.016 #> 15 Item_15  12.402     8    0.017 0.134 #> 16 Item_16  38.229     8    0.043 0.000 #> 17 Item_17   4.413     8    0.000 0.818 #> 18 Item_18  16.165     8    0.023 0.040 #> 19 Item_19  14.190     8    0.020 0.077 #> 20 Item_20  21.215     8    0.029 0.007 #> 21 baditem 227.191     8    0.117 0.000 itemfit(x, group.bins=15, empirical.plot = 1, method = 'ML') #empirical item plot with 15 points #> Warning: The following factor score estimates failed to converge successfully: #>     311,315,352,518,677,748,909,927,1081,1243,1277,1305,1415,1480,1620,1893  itemfit(x, group.bins=15, empirical.plot = 21, method = 'ML') #> Warning: The following factor score estimates failed to converge successfully: #>     311,315,352,518,677,748,909,927,1081,1243,1277,1305,1415,1480,1620,1893   # PV and X2* statistics (parametric bootstrap stats not run to save time) itemfit(x, 'PV_Q1') #>       item   PV_Q1 df.PV_Q1 RMSEA.PV_Q1 p.PV_Q1 #> 1   Item_1   8.984        8       0.008   0.344 #> 2   Item_2   9.441        8       0.009   0.306 #> 3   Item_3   7.162        8       0.000   0.519 #> 4   Item_4   8.463        8       0.005   0.390 #> 5   Item_5   8.755        8       0.007   0.363 #> 6   Item_6   9.411        8       0.009   0.309 #> 7   Item_7   8.678        8       0.007   0.370 #> 8   Item_8   8.269        8       0.004   0.408 #> 9   Item_9   9.005        8       0.008   0.342 #> 10 Item_10   6.873        8       0.000   0.550 #> 11 Item_11   9.871        8       0.011   0.274 #> 12 Item_12   9.214        8       0.009   0.325 #> 13 Item_13   8.889        8       0.007   0.352 #> 14 Item_14   9.088        8       0.008   0.335 #> 15 Item_15   8.583        8       0.006   0.379 #> 16 Item_16   8.848        8       0.007   0.355 #> 17 Item_17   8.408        8       0.005   0.395 #> 18 Item_18   8.000        8       0.000   0.433 #> 19 Item_19   8.742        8       0.007   0.365 #> 20 Item_20   7.823        8       0.000   0.451 #> 21 baditem 118.597        8       0.083   0.000  if(interactive()) mirtCluster() # improve speed of bootstrap samples by running in parallel # itemfit(x, 'PV_Q1*') # itemfit(x, 'X2*') # Stone's 1993 statistic # itemfit(x, 'X2*_df') # Stone's 2000 scaled statistic with df estimate  # empirical tables for X2 statistic tabs <- itemfit(x, 'X2', return.tables=TRUE, which.items = 1) tabs #> $`theta = -1.4531` #>       Observed  Expected z.Residual #> cat_0      183 158.63869   1.934176 #> cat_1       17  41.36131  -3.787943 #>  #> $`theta = -0.9416` #>       Observed  Expected z.Residual #> cat_0      149 138.43172  0.8982277 #> cat_1       51  61.56828 -1.3468702 #>  #> $`theta = -0.6475` #>       Observed  Expected z.Residual #> cat_0      132 124.64146  0.6591135 #> cat_1       68  75.35854 -0.8476670 #>  #> $`theta = -0.3921` #>       Observed  Expected  z.Residual #> cat_0      112 111.77447  0.02133235 #> cat_1       88  88.22553 -0.02401114 #>  #> $`theta = -0.1393` #>       Observed  Expected z.Residual #> cat_0       88  98.63125  -1.070476 #> cat_1      112 101.36875   1.055923 #>  #> $`theta = 0.0936` #>       Observed Expected  z.Residual #> cat_0       86  86.5533 -0.05947283 #> cat_1      114 113.4467  0.05194748 #>  #> $`theta = 0.346` #>       Observed  Expected z.Residual #> cat_0       61  73.91477  -1.502177 #> cat_1      139 126.08523   1.150150 #>  #> $`theta = 0.6087` #>       Observed  Expected z.Residual #> cat_0       54  61.64828 -0.9740998 #> cat_1      146 138.35172  0.6502370 #>  #> $`theta = 0.9646` #>       Observed Expected z.Residual #> cat_0       41  47.0127 -0.8769235 #> cat_1      159 152.9873  0.4861179 #>  #> $`theta = 1.5621` #>       Observed  Expected z.Residual #> cat_0       24  28.27768 -0.8044264 #> cat_1      176 171.72232  0.3264336 #>   #infit/outfit statistics. method='ML' agrees better with eRm package itemfit(raschfit, 'infit', method = 'ML') #infit and outfit stats #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’  #same as above, but inputting ML estimates instead (saves time for re-use) Theta <- fscores(raschfit, method = 'ML') itemfit(raschfit, 'infit', Theta=Theta) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’ itemfit(raschfit, empirical.plot=1, Theta=Theta)  itemfit(raschfit, 'X2', return.tables=TRUE, Theta=Theta, which.items=1) #> $`theta = -1.7718` #>       Observed  Expected z.Residual #> cat_0      178 166.44926  0.8953008 #> cat_1       22  33.55074 -1.9941546 #>  #> $`theta = -1.0782` #>       Observed  Expected z.Residual #> cat_0      147 142.51602  0.3756054 #> cat_1       53  57.48398 -0.5914121 #>  #> $`theta = -0.7497` #>       Observed  Expected z.Residual #> cat_0      138 128.19072  0.8663808 #> cat_1       62  71.80928 -1.1575688 #>  #> $`theta = -0.4577` #>       Observed Expected z.Residual #> cat_0      109 114.2782 -0.4937469 #> cat_1       91  85.7218  0.5700861 #>  #> $`theta = -0.193` #>       Observed  Expected z.Residual #> cat_0       91 101.13957  -1.008228 #> cat_1      109  98.86043   1.019784 #>  #> $`theta = 0.0765` #>       Observed Expected z.Residual #> cat_0       77  87.7275  -1.145330 #> cat_1      123 112.2725   1.012423 #>  #> $`theta = 0.3374` #>       Observed  Expected z.Residual #> cat_0       74  75.15333 -0.1330391 #> cat_1      126 124.84667  0.1032203 #>  #> $`theta = 0.6728` #>       Observed  Expected z.Residual #> cat_0       47  60.18187  -1.699199 #> cat_1      153 139.81813   1.114796 #>  #> $`theta = 1.0787` #>       Observed  Expected z.Residual #> cat_0       47  44.57924  0.3625653 #> cat_1      153 155.42076 -0.1941771 #>  #> $`theta = 1.9249` #>       Observed  Expected   z.Residual #> cat_0       22  21.91506  0.018144094 #> cat_1      178 178.08494 -0.006364921 #>   # fit a new more flexible model for the mis-fitting item itemtype <- c(rep('2PL', 20), 'spline') x2 <- mirt(data, 1, itemtype=itemtype) #>  #> Warning: EM cycles terminated after 500 iterations. itemfit(x2) #>       item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1 13.109      15      0.000  0.594 #> 2   Item_2 13.513      15      0.000  0.563 #> 3   Item_3 21.887      15      0.015  0.111 #> 4   Item_4  9.894      15      0.000  0.826 #> 5   Item_5 16.248      15      0.006  0.366 #> 6   Item_6 10.218      16      0.000  0.855 #> 7   Item_7 18.279      15      0.010  0.248 #> 8   Item_8 13.587      16      0.000  0.629 #> 9   Item_9 13.485      15      0.000  0.565 #> 10 Item_10 10.569      16      0.000  0.835 #> 11 Item_11 16.325      15      0.007  0.361 #> 12 Item_12  9.663      15      0.000  0.840 #> 13 Item_13 19.394      16      0.010  0.249 #> 14 Item_14 16.357      15      0.007  0.359 #> 15 Item_15  9.410      16      0.000  0.896 #> 16 Item_16 13.578      16      0.000  0.630 #> 17 Item_17 29.945      16      0.021  0.018 #> 18 Item_18 15.058      16      0.000  0.520 #> 19 Item_19 15.663      15      0.005  0.405 #> 20 Item_20  9.333      15      0.000  0.859 #> 21 baditem 11.473      13      0.000  0.571 itemplot(x2, 21)  anova(x, x2) #>         AIC    SABIC       HQ      BIC    logLik     X2 df p #> x  49477.85 49579.65 49564.23 49713.09 -24696.93             #> x2 49214.97 49321.62 49305.46 49461.41 -24563.49 266.88  2 0  #------------------------------------------------------------  #similar example to Kang and Chen 2007 a <- matrix(c(.8,.4,.7, .8, .4, .7, 1, 1, 1, 1)) d <- matrix(rep(c(2.0,0.0,-1,-1.5),10), ncol=4, byrow=TRUE) dat <- simdata(a,d,2000, itemtype = rep('graded', 10)) head(dat) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]      4      0      1      4      1      4      3      2      1       4 #> [2,]      2      1      1      3      2      4      2      1      4       2 #> [3,]      2      2      3      0      0      0      4      4      4       4 #> [4,]      1      2      4      1      2      2      2      2      0       4 #> [5,]      1      3      0      2      1      4      4      4      3       1 #> [6,]      1      3      3      2      3      1      1      2      0       1  mod <- mirt(dat, 1) #>  itemfit(mod) #>       item    S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1 143.021     103      0.014  0.006 #> 2   Item_2  85.589     109      0.000  0.953 #> 3   Item_3 110.835     105      0.005  0.330 #> 4   Item_4 121.145     103      0.009  0.107 #> 5   Item_5 107.875     111      0.000  0.566 #> 6   Item_6  93.905     102      0.000  0.704 #> 7   Item_7 113.544      99      0.009  0.151 #> 8   Item_8 100.858      99      0.003  0.429 #> 9   Item_9  83.214      98      0.000  0.857 #> 10 Item_10 104.402      99      0.005  0.336 itemfit(mod, 'X2') # less useful given inflated Type I error rates #>       item      X2 df.X2 RMSEA.X2  p.X2 #> 1   Item_1  93.925    35    0.029 0.000 #> 2   Item_2  43.667    35    0.011 0.149 #> 3   Item_3  81.354    35    0.026 0.000 #> 4   Item_4  90.490    35    0.028 0.000 #> 5   Item_5  36.169    35    0.004 0.414 #> 6   Item_6  97.559    35    0.030 0.000 #> 7   Item_7 129.917    35    0.037 0.000 #> 8   Item_8 130.263    35    0.037 0.000 #> 9   Item_9 141.266    35    0.039 0.000 #> 10 Item_10 117.650    35    0.034 0.000 itemfit(mod, empirical.plot = 1)  itemfit(mod, empirical.plot = 1, empirical.poly.collapse=TRUE)   # collapsed tables (see mincell.X2) for X2 and G2 itemfit(mod, 'X2', return.tables = TRUE, which.items = 1) #> $`theta = -1.4692` #>       Observed  Expected z.Residual #> cat_0       98 65.020718  4.0899247 #> cat_1       76 88.468143 -1.3255872 #> cat_2       12 26.774054 -2.8552400 #> cat_3        7  6.656543  0.1331215 #> cat_4        7 13.080542 -1.6812388 #>  #> $`theta = -0.8519` #>       Observed  Expected z.Residual #> cat_0       65 45.508938  2.8892636 #> cat_1       87 88.222767 -0.1301827 #> cat_2       29 35.896766 -1.1511126 #> cat_3        6  9.834511 -1.2227385 #> cat_4       13 20.537019 -1.6631481 #>  #> $`theta = -0.5476` #>       Observed Expected z.Residual #> cat_0       35 37.54994 -0.4161270 #> cat_1       97 85.03642  1.2973549 #> cat_2       34 40.25662 -0.9861003 #> cat_3        5 11.70198 -1.9591763 #> cat_4       29 25.45504  0.7026267 #>  #> $`theta = -0.3145` #>       Observed Expected z.Residual #> cat_0       27 32.21053 -0.9180857 #> cat_1       91 81.40120  1.0639013 #> cat_2       40 43.28252 -0.4989437 #> cat_3       15 13.23174  0.4861130 #> cat_4       27 29.87400 -0.5258232 #>  #> $`theta = -0.0993` #>       Observed Expected z.Residual #> cat_0       23 27.84181 -0.9176111 #> cat_1       73 77.27754 -0.4865943 #> cat_2       60 45.69537  2.1161218 #> cat_3       12 14.68759 -0.7012737 #> cat_4       32 34.49770 -0.4252515 #>  #> $`theta = 0.1116` #>       Observed Expected  z.Residual #> cat_0       23 24.05321 -0.21474860 #> cat_1       73 72.66989  0.03872444 #> cat_2       50 47.59720  0.34827910 #> cat_3       16 16.11821 -0.02944308 #> cat_4       38 39.56149 -0.24825845 #>  #> $`theta = 0.3293` #>       Observed Expected   z.Residual #> cat_0       18 20.61824 -0.576612407 #> cat_1       69 67.48888  0.183942450 #> cat_2       49 48.98546  0.002077898 #> cat_3       24 17.55297  1.538809131 #> cat_4       40 45.35445 -0.795069543 #>  #> $`theta = 0.5568` #>       Observed Expected  z.Residual #> cat_0        6 17.49926 -2.74890777 #> cat_1       60 61.79242 -0.22801909 #> cat_2       56 49.73600  0.88821096 #> cat_3       19 18.94936  0.01163316 #> cat_4       59 52.02296  0.96732827 #>  #> $`theta = 0.8512` #>       Observed Expected z.Residual #> cat_0        7 14.09896 -1.8906068 #> cat_1       45 54.28449 -1.2601441 #> cat_2       48 49.58044 -0.2244513 #> cat_3       26 20.49440  1.2161493 #> cat_4       74 61.54171  1.5880848 #>  #> $`theta = 1.4358` #>       Observed  Expected z.Residual #> cat_0        6  9.087564 -1.0242177 #> cat_1       25 40.094053 -2.3837784 #> cat_2       44 45.694100 -0.2506161 #> cat_3       21 22.208083 -0.2563547 #> cat_4      104 82.916200  2.3154169 #>   mod2 <- mirt(dat, 1, 'Rasch') #>  itemfit(mod2, 'infit', method = 'ML') #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"gpcm\", Theta = \"mirt_matrix\"’  # massive list of tables for S-X2 tables <- itemfit(mod, return.tables = TRUE)  #observed and expected total score patterns for item 1 (post collapsing) tables$O[[1]] #>     0  1  2  3  4 #> 4  12  3  0  0  0 #> 5   6  1  0  0  0 #> 6   8 17  1  0  0 #> 7  12 16  5  0  0 #> 8  22  8  0  0  0 #> 9  30 20  3  3  1 #> 10 19 27  9  1  7 #> 11 16 32  9  4  0 #> 12 17 40 17  1  5 #> 13 25 51 15  4  8 #> 14 22 44 14  3  8 #> 15 22 46 22  5 14 #> 16 14 41 32  8 24 #> 17 11 42 31  8 10 #> 18 11 57 25  7 25 #> 19 17 41 37 11 15 #> 20 11 35 28 12 26 #> 21 10 32 32  8 22 #> 22  5 32 18 15 29 #> 23  2 23 17  7 33 #> 24  2 30 22  9 23 #> 25  3 15 19  7 28 #> 26  3 12 16 11 23 #> 27  4 13 12  4 19 #> 28  3  6  9  5 18 #> 29  3  6  2 17  0 #> 30  3 10  2 21  0 #> 31  1  2  1 13  0 #> 32  1  4  5  6  0 #> 33  3  4  4  5  0 #> 34  1  3  1 11  0 #> 35  2  6  0  0  0 #> 36  2  6  0  0  0 tables$E[[1]] #>            [,1]      [,2]      [,3]      [,4]      [,5] #>  [1,] 11.023325  3.976675        NA        NA        NA #>  [2,]  4.102366  2.897634        NA        NA        NA #>  [3,] 13.498246 10.610902  1.890852        NA        NA #>  [4,] 15.184304 14.492730  3.322965        NA        NA #>  [5,] 12.249443 13.799872  3.950685        NA        NA #>  [6,] 20.682046 26.920288  6.923239  1.157706  1.316720 #>  [7,] 20.332439 30.097150  8.830861  1.641385  2.098165 #>  [8,] 17.517441 29.135716  9.625822  1.958940  2.762080 #>  [9,] 20.446921 37.829468 13.940499  3.072836  4.710276 #> [10,] 23.437800 47.811327 19.504466  4.622495  7.623912 #> [11,] 18.436615 41.167389 18.467918  4.679944  8.248134 #> [12,] 19.651227 47.756678 23.431406  6.318731 11.841957 #> [13,] 19.076413 50.199010 26.830125  7.670547 15.223905 #> [14,] 14.528071 41.195659 23.904020  7.227464 15.144786 #> [15,] 15.799085 48.086720 30.192468  9.636968 21.284760 #> [16,] 13.544069 44.116503 29.895563 10.055666 23.388198 #> [17,] 11.078348 38.500292 28.110440  9.952500 24.358420 #> [18,]  9.068050 33.529616 26.330542  9.809752 25.262041 #> [19,]  7.581094 29.780090 25.109651  9.840833 26.688332 #> [20,]  5.489874 22.880802 20.702905  8.532437 24.393982 #> [21,]  5.010515 22.116677 21.467501  9.311108 28.094199 #> [22,]  3.626463 16.954931 17.637672  8.059013 25.721921 #> [23,]  2.805419 13.907880 15.517623  7.472196 25.296882 #> [24,]  1.907017 10.013898 12.004816  6.104317 21.969952 #> [25,]  1.261885  7.039995  9.063539  4.881523 18.753058 #> [26,]  4.944641  5.875443  3.354204 13.825711        NA #> [27,]  5.454637  7.095249  4.313860 19.136254        NA #> [28,]  2.176787  3.093386  2.019117  9.710709        NA #> [29,]  1.685470  2.659415  1.858932  9.796184        NA #> [30,]  1.334541  2.384692  1.813140 10.467628        NA #> [31,]  1.040082  2.042086  1.733955 11.183876        NA #> [32,]  2.050562  5.949438        NA        NA        NA #> [33,]  1.369048  6.630952        NA        NA        NA  # can also select specific items # itemfit(mod, return.tables = TRUE, which.items=1)  # fit stats with missing data (run in parallel using all cores) dat[sample(1:prod(dim(dat)), 100)] <- NA raschfit <- mirt(dat, 1, itemtype='Rasch') #>   # use only valid data by removing rows with missing terms itemfit(raschfit, c('S_X2', 'infit'), na.rm = TRUE) #> Sample size after row-wise response data removal: 1901 #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"gpcm\", Theta = \"mirt_matrix\"’  # note that X2, G2, PV-Q1, and X2* do not require complete datasets thetas <- fscores(raschfit, method = 'ML') # save for faster computations itemfit(raschfit, c('X2', 'G2'), Theta=thetas) #>       item      X2 df.X2 RMSEA.X2  p.X2     G2 df.G2 RMSEA.G2  p.G2 #> 1   Item_1  56.082    36    0.017 0.018 57.138    36    0.017 0.014 #> 2   Item_2  72.433    36    0.023 0.000 68.605    36    0.021 0.001 #> 3   Item_3  51.674    36    0.015 0.044 52.944    36    0.015 0.034 #> 4   Item_4  42.209    36    0.009 0.220 40.864    36    0.008 0.265 #> 5   Item_5 108.433    36    0.032 0.000 93.285    36    0.028 0.000 #> 6   Item_6  37.478    36    0.005 0.401 39.799    36    0.007 0.305 #> 7   Item_7  61.895    36    0.019 0.005 68.502    35    0.022 0.001 #> 8   Item_8  56.125    36    0.017 0.017 59.579    36    0.018 0.008 #> 9   Item_9  66.332    36    0.021 0.002 69.041    36    0.021 0.001 #> 10 Item_10  47.281    36    0.013 0.099 51.188    36    0.015 0.048 itemfit(raschfit, empirical.plot=1, Theta=thetas)  itemfit(raschfit, 'X2', return.tables=TRUE, which.items=1, Theta=thetas) #> $`theta = -0.9751` #>       Observed  Expected z.Residual #> cat_0       96 89.203274  0.7196302 #> cat_1       81 87.319279 -0.6762581 #> cat_2       14 20.552190 -1.4452982 #> cat_3        5  2.584993  1.5020654 #> cat_4        6  2.340264  2.3923098 #>  #> $`theta = -0.4747` #>       Observed  Expected z.Residual #> cat_0       52 55.810605 -0.5100768 #> cat_1       98 90.111135  0.8310464 #> cat_2       34 34.983142 -0.1662214 #> cat_3        6  7.257589 -0.4668126 #> cat_4        9 10.837528 -0.5581731 #>  #> $`theta = -0.2825` #>       Observed Expected z.Residual #> cat_0       45 43.95405  0.1577652 #> cat_1       95 86.00287  0.9701688 #> cat_2       34 40.46184 -1.0158593 #> cat_3        9 10.17259 -0.3676465 #> cat_4       16 18.40864 -0.5613857 #>  #> $`theta = -0.151` #>       Observed Expected z.Residual #> cat_0       33 36.30398 -0.5483529 #> cat_1       74 81.02032 -0.7799379 #> cat_2       45 43.47628  0.2310896 #> cat_3       11 12.46706 -0.4154939 #> cat_4       36 25.73237  2.0240925 #>  #> $`theta = -0.0334` #>       Observed Expected z.Residual #> cat_0       19 29.93222 -1.9981990 #> cat_1       90 75.13532  1.7148795 #> cat_2       48 45.34903  0.3936594 #> cat_3       12 14.62666 -0.6868010 #> cat_4       30 33.95678 -0.6790139 #>  #> $`theta = 0.0651` #>       Observed Expected z.Residual #> cat_0       23 25.02007 -0.4038516 #> cat_1       62 69.30476 -0.8774538 #> cat_2       63 46.15898  2.4787928 #> cat_3       17 16.42868  0.1409549 #> cat_4       34 42.08752 -1.2466326 #>  #> $`theta = 0.1642` #>       Observed Expected  z.Residual #> cat_0       19 20.52933 -0.33753058 #> cat_1       63 62.79341  0.02607073 #> cat_2       45 46.18193 -0.17392181 #> cat_3       23 18.15027  1.13834925 #> cat_4       49 51.34506 -0.32726919 #>  #> $`theta = 0.2767` #>       Observed Expected   z.Residual #> cat_0        4 16.04548 -3.007099726 #> cat_1       66 54.92379  1.494551513 #> cat_2       47 45.20504  0.266969704 #> cat_3       19 19.88229 -0.197868736 #> cat_4       63 62.94340  0.007134114 #>  #> $`theta = 0.4164` #>       Observed Expected z.Residual #> cat_0       11 11.43297 -0.1280506 #> cat_1       44 45.00327 -0.1495531 #> cat_2       48 42.59391  0.8283409 #> cat_3       26 21.54290  0.9602843 #> cat_4       70 78.42694 -0.9515622 #>  #> $`theta = 0.7405` #>       Observed   Expected z.Residual #> cat_0        4   4.631286 -0.2933428 #> cat_1       23  25.205901 -0.4393746 #> cat_2       43  32.985379  1.7437081 #> cat_3       22  23.067149 -0.2221919 #> cat_4      110 116.110285 -0.5670562 #>   # }"},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate item information — iteminfo","title":"Function to calculate item information — iteminfo","text":"Given internal mirt item object extracted using extract.item, compute item information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate item information — iteminfo","text":"","code":"iteminfo(x, Theta, degrees = NULL, total.info = TRUE, multidim_matrix = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate item information — iteminfo","text":"x extracted internal mirt object containing item information (see extract.item) Theta vector (unidimensional) matrix (multidimensional) latent trait values degrees vector angles degrees 0 90. applicable input object multidimensional total.info logical; return total information curve item? FALSE, information curves category returned matrix multidim_matrix logical; compute information matrix row Theta? Theta contains 1 row list matrices returned, otherwise Theta exactly one row matrix returned","code":""},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate item information — iteminfo","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate item information — iteminfo","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/iteminfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate item information — iteminfo","text":"","code":"mod <- mirt(Science, 1) #>  extr.2 <- extract.item(mod, 2) Theta <- matrix(seq(-4,4, by = .1)) info.2 <- iteminfo(extr.2, Theta)  #do something with the info? plot(Theta, info.2, type = 'l', main = 'Item information')   # \\donttest{  #category information curves cat.info <- iteminfo(extr.2, Theta, total.info = FALSE) plot(Theta, cat.info[,1], type = 'l', ylim = c(0, max(cat.info)),      ylab = 'info', main = 'Category information') for(i in 2:ncol(cat.info))    lines(Theta, cat.info[,i], col = i)   ## Customized test information plot T1 <- T2 <- 0 dat <- expand.table(LSAT7) mod1 <- mirt(dat, 1) #>  mod2 <- mirt(dat, 1, 'Rasch') #>  for(i in 1:5){   T1 <- T1 + iteminfo(extract.item(mod1, i), Theta)   T2 <- T2 + iteminfo(extract.item(mod2, i), Theta) } plot(Theta, T2/T1, type = 'l', ylab = 'Relative Test Information', las = 1) lines(Theta, T1/T1, col = 'red')   # multidimensional mod <- mirt(dat, 2, TOL=1e-2) #>  ii <- extract.item(mod, 1) Theta <- as.matrix(expand.grid(-4:4, -4:4))  iteminfo(ii, Theta, degrees=c(45,45)) # equal angle #>  [1] 9.135853e-04 3.804627e-03 1.534609e-02 5.457783e-02 1.280846e-01 #>  [6] 1.263872e-01 5.292862e-02 1.479382e-02 3.661942e-03 6.367175e-04 #> [11] 2.659764e-03 1.086462e-02 4.056306e-02 1.103087e-01 1.394001e-01 #> [16] 6.967460e-02 2.076774e-02 5.230188e-03 4.436266e-04 1.857138e-03 #> [21] 7.653659e-03 2.959372e-02 9.036811e-02 1.443711e-01 8.885547e-02 #> [26] 2.887817e-02 7.452148e-03 3.090296e-04 1.295613e-03 5.372790e-03 #> [31] 2.130057e-02 7.105538e-02 1.400859e-01 1.088343e-01 3.962912e-02 #> [36] 1.058186e-02 2.152390e-04 9.033338e-04 3.762362e-03 1.518269e-02 #> [41] 5.409208e-02 1.275949e-01 1.268897e-01 5.340700e-02 1.495328e-02 #> [46] 1.498990e-04 6.295660e-04 2.630098e-03 1.074696e-02 4.017519e-02 #> [51] 1.097011e-01 1.396891e-01 7.024317e-02 2.098631e-02 1.043871e-04 #> [56] 4.386406e-04 1.836367e-03 7.569796e-03 2.929632e-02 8.974279e-02 #> [61] 1.443776e-01 8.947966e-02 2.917186e-02 7.268993e-05 3.055547e-04 #> [66] 1.281094e-03 5.313435e-03 2.107900e-02 7.048336e-02 1.398084e-01 #> [71] 1.094447e-01 4.001273e-02 5.061591e-05 2.128179e-04 8.931970e-04 #> [76] 3.720561e-03 1.502092e-02 5.360938e-02 1.270998e-01 1.273870e-01 #> [81] 5.388842e-02 iteminfo(ii, Theta, degrees=c(90,0)) # first dimension only #>  [1] 2.073184e-04 8.633775e-04 3.482462e-03 1.238525e-02 2.906603e-02 #>  [6] 2.868083e-02 1.201100e-02 3.357135e-03 8.309983e-04 1.444892e-04 #> [11] 6.035756e-04 2.465490e-03 9.204906e-03 2.503218e-02 3.163384e-02 #> [16] 1.581114e-02 4.712787e-03 1.186878e-03 1.006714e-04 4.214372e-04 #> [21] 1.736832e-03 6.715652e-03 2.050708e-02 3.276188e-02 2.016382e-02 #> [26] 6.553273e-03 1.691103e-03 7.012756e-05 2.940112e-04 1.219238e-03 #> [31] 4.833701e-03 1.612448e-02 3.178946e-02 2.469758e-02 8.992970e-03 #> [36] 2.401323e-03 4.884381e-05 2.049920e-04 8.537865e-04 3.445381e-03 #> [41] 1.227502e-02 2.895489e-02 2.879486e-02 1.211956e-02 3.393322e-03 #> [46] 3.401633e-05 1.428663e-04 5.968437e-04 2.438790e-03 9.116887e-03 #> [51] 2.489429e-02 3.169942e-02 1.594016e-02 4.762389e-03 2.368839e-05 #> [56] 9.953996e-05 4.167236e-04 1.717801e-03 6.648164e-03 2.036518e-02 #> [61] 3.276337e-02 2.030547e-02 6.619919e-03 1.649540e-05 6.933901e-05 #> [66] 2.907165e-04 1.205769e-03 4.783421e-03 1.599467e-02 3.172649e-02 #> [71] 2.483609e-02 9.080022e-03 1.148618e-05 4.829441e-05 2.026917e-04 #> [76] 8.443006e-04 3.408672e-03 1.216548e-02 2.884253e-02 2.890771e-02 #> [81] 1.222881e-02  # information matrices iteminfo(ii, Theta, multidim_matrix = TRUE) #> [[1]] #>               [,1]          [,2] #> [1,]  0.0032654333 -0.0008227905 #> [2,] -0.0008227905  0.0002073184 #>  #> [[2]] #>              [,1]          [,2] #> [1,]  0.013598901 -0.0034265121 #> [2,] -0.003426512  0.0008633775 #>  #> [[3]] #>             [,1]         [,2] #> [1,]  0.05485162 -0.013820952 #> [2,] -0.01382095  0.003482462 #>  #> [[4]] #>             [,1]        [,2] #> [1,]  0.19507785 -0.04915373 #> [2,] -0.04915373  0.01238525 #>  #> [[5]] #>            [,1]        [,2] #> [1,]  0.4578137 -0.11535522 #> [2,] -0.1153552  0.02906603 #>  #> [[6]] #>            [,1]        [,2] #> [1,]  0.4517464 -0.11382645 #> [2,] -0.1138265  0.02868083 #>  #> [[7]] #>             [,1]        [,2] #> [1,]  0.18918306 -0.04766842 #> [2,] -0.04766842  0.01201100 #>  #> [[8]] #>             [,1]         [,2] #> [1,]  0.05287762 -0.013323563 #> [2,] -0.01332356  0.003357135 #>  #> [[9]] #>              [,1]          [,2] #> [1,]  0.013088902 -0.0032980078 #> [2,] -0.003298008  0.0008309983 #>  #> [[10]] #>               [,1]          [,2] #> [1,]  0.0022758231 -0.0005734387 #> [2,] -0.0005734387  0.0001444892 #>  #> [[11]] #>              [,1]          [,2] #> [1,]  0.009506809 -0.0023954286 #> [2,] -0.002395429  0.0006035756 #>  #> [[12]] #>              [,1]         [,2] #> [1,]  0.038833480 -0.009784864 #> [2,] -0.009784864  0.002465490 #>  #> [[13]] #>             [,1]         [,2] #> [1,]  0.14498478 -0.036531784 #> [2,] -0.03653178  0.009204906 #>  #> [[14]] #>             [,1]        [,2] #> [1,]  0.39427721 -0.09934594 #> [2,] -0.09934594  0.02503218 #>  #> [[15]] #>            [,1]        [,2] #> [1,]  0.4982588 -0.12554615 #> [2,] -0.1255462  0.03163384 #>  #> [[16]] #>             [,1]        [,2] #> [1,]  0.24903832 -0.06275013 #> [2,] -0.06275013  0.01581114 #>  #> [[17]] #>             [,1]         [,2] #> [1,]  0.07423024 -0.018703779 #> [2,] -0.01870378  0.004712787 #>  #> [[18]] #>              [,1]         [,2] #> [1,]  0.018694291 -0.004710397 #> [2,] -0.004710397  0.001186878 #>  #> [[19]] #>               [,1]          [,2] #> [1,]  0.0015856573 -0.0003995377 #> [2,] -0.0003995377  0.0001006714 #>  #> [[20]] #>              [,1]          [,2] #> [1,]  0.006637979 -0.0016725702 #> [2,] -0.001672570  0.0004214372 #>  #> [[21]] #>              [,1]         [,2] #> [1,]  0.027356520 -0.006893016 #> [2,] -0.006893016  0.001736832 #>  #> [[22]] #>             [,1]         [,2] #> [1,]  0.10577700 -0.026652608 #> [2,] -0.02665261  0.006715652 #>  #> [[23]] #>             [,1]        [,2] #> [1,]  0.32300327 -0.08138706 #> [2,] -0.08138706  0.02050708 #>  #> [[24]] #>            [,1]        [,2] #> [1,]  0.5160263 -0.13002305 #> [2,] -0.1300230  0.03276188 #>  #> [[25]] #>             [,1]        [,2] #> [1,]  0.31759663 -0.08002475 #> [2,] -0.08002475  0.02016382 #>  #> [[26]] #>             [,1]         [,2] #> [1,]  0.10321940 -0.026008170 #> [2,] -0.02600817  0.006553273 #>  #> [[27]] #>              [,1]         [,2] #> [1,]  0.026636258 -0.006711532 #> [2,] -0.006711532  0.001691103 #>  #> [[28]] #>               [,1]          [,2] #> [1,]  0.0011045662 -2.783173e-04 #> [2,] -0.0002783173  7.012756e-05 #>  #> [[29]] #>              [,1]          [,2] #> [1,]  0.004630917 -0.0011668512 #> [2,] -0.001166851  0.0002940112 #>  #> [[30]] #>              [,1]         [,2] #> [1,]  0.019203995 -0.004838826 #> [2,] -0.004838826  0.001219238 #>  #> [[31]] #>             [,1]         [,2] #> [1,]  0.07613474 -0.019183655 #> [2,] -0.01918365  0.004833701 #>  #> [[32]] #>             [,1]        [,2] #> [1,]  0.25397366 -0.06399369 #> [2,] -0.06399369  0.01612448 #>  #> [[33]] #>            [,1]        [,2] #> [1,]  0.5007100 -0.12616378 #> [2,] -0.1261638  0.03178946 #>  #> [[34]] #>             [,1]        [,2] #> [1,]  0.38900703 -0.09801802 #> [2,] -0.09801802  0.02469758 #>  #> [[35]] #>             [,1]        [,2] #> [1,]  0.14164661 -0.03569067 #> [2,] -0.03569067  0.00899297 #>  #> [[36]] #>              [,1]         [,2] #> [1,]  0.037822803 -0.009530204 #> [2,] -0.009530204  0.002401323 #>  #> [[37]] #>               [,1]          [,2] #> [1,]  0.0007693299 -1.938479e-04 #> [2,] -0.0001938479  4.884381e-05 #>  #> [[38]] #>               [,1]          [,2] #> [1,]  0.0032287914 -0.0008135579 #> [2,] -0.0008135579  0.0002049920 #>  #> [[39]] #>              [,1]          [,2] #> [1,]  0.013447834 -0.0033884478 #> [2,] -0.003388448  0.0008537865 #>  #> [[40]] #>             [,1]         [,2] #> [1,]  0.05426756 -0.013673786 #> [2,] -0.01367379  0.003445381 #>  #> [[41]] #>             [,1]        [,2] #> [1,]  0.19334166 -0.04871626 #> [2,] -0.04871626  0.01227502 #>  #> [[42]] #>            [,1]        [,2] #> [1,]  0.4560631 -0.11491412 #> [2,] -0.1149141  0.02895489 #>  #> [[43]] #>            [,1]        [,2] #> [1,]  0.4535425 -0.11427901 #> [2,] -0.1142790  0.02879486 #>  #> [[44]] #>             [,1]        [,2] #> [1,]  0.19089294 -0.04809925 #> [2,] -0.04809925  0.01211956 #>  #> [[45]] #>             [,1]         [,2] #> [1,]  0.05344759 -0.013467177 #> [2,] -0.01346718  0.003393322 #>  #> [[46]] #>               [,1]          [,2] #> [1,]  0.0005357850 -1.350016e-04 #> [2,] -0.0001350016  3.401633e-05 #>  #> [[47]] #>               [,1]          [,2] #> [1,]  0.0022502615 -0.0005669979 #> [2,] -0.0005669979  0.0001428663 #>  #> [[48]] #>              [,1]          [,2] #> [1,]  0.009400776 -0.0023687115 #> [2,] -0.002368711  0.0005968437 #>  #> [[49]] #>             [,1]        [,2] #> [1,]  0.03841294 -0.00967890 #> [2,] -0.00967890  0.00243879 #>  #> [[50]] #>             [,1]         [,2] #> [1,]  0.14359841 -0.036182461 #> [2,] -0.03618246  0.009116887 #>  #> [[51]] #>             [,1]        [,2] #> [1,]  0.39210544 -0.09879872 #> [2,] -0.09879872  0.02489429 #>  #> [[52]] #>            [,1]        [,2] #> [1,]  0.4992917 -0.12580642 #> [2,] -0.1258064  0.03169942 #>  #> [[53]] #>            [,1]        [,2] #> [1,]  0.2510706 -0.06326220 #> [2,] -0.0632622  0.01594016 #>  #> [[54]] #>             [,1]         [,2] #> [1,]  0.07501151 -0.018900633 #> [2,] -0.01890063  0.004762389 #>  #> [[55]] #>               [,1]          [,2] #> [1,]  3.731115e-04 -9.401283e-05 #> [2,] -9.401283e-05  2.368839e-05 #>  #> [[56]] #>               [,1]          [,2] #> [1,]  0.0015678356 -3.950472e-04 #> [2,] -0.0003950472  9.953996e-05 #>  #> [[57]] #>              [,1]          [,2] #> [1,]  0.006563736 -0.0016538632 #> [2,] -0.001653863  0.0004167236 #>  #> [[58]] #>              [,1]         [,2] #> [1,]  0.027056766 -0.006817487 #> [2,] -0.006817487  0.001717801 #>  #> [[59]] #>             [,1]         [,2] #> [1,]  0.10471401 -0.026384768 #> [2,] -0.02638477  0.006648164 #>  #> [[60]] #>             [,1]        [,2] #> [1,]  0.32076818 -0.08082389 #> [2,] -0.08082389  0.02036518 #>  #> [[61]] #>            [,1]        [,2] #> [1,]  0.5160498 -0.13002897 #> [2,] -0.1300290  0.03276337 #>  #> [[62]] #>             [,1]        [,2] #> [1,]  0.31982769 -0.08058691 #> [2,] -0.08058691  0.02030547 #>  #> [[63]] #>             [,1]         [,2] #> [1,]  0.10426913 -0.026272671 #> [2,] -0.02627267  0.006619919 #>  #> [[64]] #>               [,1]          [,2] #> [1,]  2.598160e-04 -6.546579e-05 #> [2,] -6.546579e-05  1.649540e-05 #>  #> [[65]] #>               [,1]          [,2] #> [1,]  0.0010921460 -2.751878e-04 #> [2,] -0.0002751878  6.933901e-05 #>  #> [[66]] #>              [,1]          [,2] #> [1,]  0.004579021 -0.0011537750 #> [2,] -0.001153775  0.0002907165 #>  #> [[67]] #>             [,1]         [,2] #> [1,]  0.01899184 -0.004785370 #> [2,] -0.00478537  0.001205769 #>  #> [[68]] #>             [,1]         [,2] #> [1,]  0.07534278 -0.018984105 #> [2,] -0.01898410  0.004783421 #>  #> [[69]] #>             [,1]        [,2] #> [1,]  0.25192908 -0.06347852 #> [2,] -0.06347852  0.01599467 #>  #> [[70]] #>            [,1]        [,2] #> [1,]  0.4997181 -0.12591387 #> [2,] -0.1259139  0.03172649 #>  #> [[71]] #>             [,1]        [,2] #> [1,]  0.39118867 -0.09856773 #> [2,] -0.09856773  0.02483609 #>  #> [[72]] #>             [,1]         [,2] #> [1,]  0.14301775 -0.036036152 #> [2,] -0.03603615  0.009080022 #>  #> [[73]] #>               [,1]          [,2] #> [1,]  1.809167e-04 -4.558555e-05 #> [2,] -4.558555e-05  1.148618e-05 #>  #> [[74]] #>               [,1]          [,2] #> [1,]  0.0007606764 -1.916675e-04 #> [2,] -0.0001916675  4.829441e-05 #>  #> [[75]] #>               [,1]          [,2] #> [1,]  0.0031925594 -0.0008044285 #> [2,] -0.0008044285  0.0002026917 #>  #> [[76]] #>              [,1]          [,2] #> [1,]  0.013298423 -0.0033508008 #> [2,] -0.003350801  0.0008443006 #>  #> [[77]] #>             [,1]         [,2] #> [1,]  0.05368936 -0.013528096 #> [2,] -0.01352810  0.003408672 #>  #> [[78]] #>             [,1]        [,2] #> [1,]  0.19161632 -0.04828152 #> [2,] -0.04828152  0.01216548 #>  #> [[79]] #>            [,1]        [,2] #> [1,]  0.4542934 -0.11446821 #> [2,] -0.1144682  0.02884253 #>  #> [[80]] #>            [,1]        [,2] #> [1,]  0.4553201 -0.11472690 #> [2,] -0.1147269  0.02890771 #>  #> [[81]] #>             [,1]        [,2] #> [1,]  0.19261370 -0.04853283 #> [2,] -0.04853283  0.01222881 #>  iteminfo(ii, Theta[1, , drop=FALSE], multidim_matrix = TRUE) #>               [,1]          [,2] #> [1,]  0.0032654333 -0.0008227905 #> [2,] -0.0008227905  0.0002073184  # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Displays item surface and information plots — itemplot","title":"Displays item surface and information plots — itemplot","text":"itemplot displays various item based IRT plots, special options plotting items contain several 0 slope parameters. Supports three dimensional models.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Displays item surface and information plots — itemplot","text":"","code":"itemplot(   object,   item,   type = \"trace\",   degrees = 45,   CE = FALSE,   CEalpha = 0.05,   CEdraws = 1000,   drop.zeros = FALSE,   theta_lim = c(-6, 6),   shiny = FALSE,   rot = list(xaxis = -70, yaxis = 30, zaxis = 10),   par.strip.text = list(cex = 0.7),   npts = 200,   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Displays item surface and information plots — itemplot","text":"object computed model object class SingleGroupClass MultipleGroupClass. Input may also list comparing similar item types (e.g., 1PL vs 2PL) item single numeric value, item name, indicating item plot type plot type use, information ('info'), standard errors ('SE'), item trace lines ('trace'), cumulative probability plots indicate thresholds ('threshold'), information standard errors ('infoSE') information trace lines ('infotrace'), category total information ('infocat'), relative efficiency lines ('RE'), expected score 'score', information trace line contours ('infocontour' 'tracecontour'; supported MultipleGroupClass objects) degrees degrees argument used two three factors. See iteminfo detail. new vector required three dimensional models override default CE logical; plot confidence envelope? CEalpha area remaining tail confidence envelope. Default gives 95% confidence region CEdraws draws number draws use confidence envelope drop.zeros logical; drop slope values numerically close zero reduce dimensionality? Useful objects returned bfactor confirmatory models contain several zero slopes theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts. Default uses c(-6,6) shiny logical; run interactive display item plots using shiny interface. primarily instructive tool demonstrating item response curves behave adjusting parameters rot list rotation coordinates used 3 dimensional plots par.strip.text plotting argument passed lattice npts number quadrature points used plotting features. Larger values make plots look smoother par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed lattice coef()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Displays item surface and information plots — itemplot","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Displays item surface and information plots — itemplot","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Displays item surface and information plots — itemplot","text":"","code":"# \\donttest{  data(LSAT7) fulldata <- expand.table(LSAT7) mod1 <- mirt(fulldata,1,SE=TRUE) #>  #>  #> Calculating information matrix... mod2 <- mirt(fulldata,1, itemtype = 'Rasch') #>  mod3 <- mirt(fulldata,2) #>   itemplot(mod1, 2)  itemplot(mod1, 2, CE = TRUE)  itemplot(mod1, 2, type = 'info')  itemplot(mod1, 2, type = 'info', CE = TRUE)   mods <- list(twoPL = mod1, onePL = mod2) itemplot(mods, 1, type = 'RE')   # multidimensional itemplot(mod3, 4, type = 'info')  itemplot(mod3, 4, type = 'info',   col.regions = colorRampPalette(c(\"white\", \"red\"))(100))  itemplot(mod3, 4, type = 'infocontour')  itemplot(mod3, 4, type = 'tracecontour')   # polytomous items pmod <- mirt(Science, 1, SE=TRUE) #>  #>  #> Calculating information matrix... itemplot(pmod, 3)  itemplot(pmod, 3, type = 'threshold')  itemplot(pmod, 3, CE = TRUE)  itemplot(pmod, 3, type = 'score')  itemplot(pmod, 3, type = 'score', CE = TRUE)  itemplot(pmod, 3, type = 'infotrace')  itemplot(pmod, 3, type = 'infocat')    # use the directlabels package to put labels on tracelines library(directlabels) plt <- itemplot(pmod, 3) direct.label(plt, 'top.points')   # change colour theme of plots bwtheme <- standard.theme(\"pdf\", color=FALSE) plot(pmod, type='trace', par.settings=bwtheme)  itemplot(pmod, 1, type = 'trace', par.settings=bwtheme)   # additional modifications can be made via update(). # See ?update.trellis for further documentation (plt <- itemplot(pmod, 1))  update(plt, ylab = expression(Prob(theta))) # ylab changed   # infoSE plot itemplot(pmod, 1, type = 'infoSE')   # uncomment to run interactive shiny applet # itemplot(shiny = TRUE)     # }"},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic item summary statistics — itemstats","title":"Generic item summary statistics — itemstats","text":"Function compute generic item summary statistics require prior fitting IRT models. Contains information sample sizes (N), number observed categories (K), coefficient alpha (alpha item deleted), mean/SD frequency total scores, reduced item-total correlations, average/sd correlation items, response frequencies, conditional mean/sd information given unweighted sum scores. Summary information involving total scores included responses missing data ensure metric meaningful, however standardized statistics (e.g., correlations) utilize possible response information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic item summary statistics — itemstats","text":"","code":"itemstats(   data,   group = NULL,   use_ts = TRUE,   itemfreq = \"proportions\",   ts.tables = FALSE )"},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic item summary statistics — itemstats","text":"data object class data.frame matrix response patterns group optional grouping variable condition computing summary information use_ts logical; include information conditional meaningful total score? itemfreq character vector indicting whether include item response \"proportions\" \"counts\" item. set 'none' omitted ts.tables logical; include mean/sd summary information pertaining unweighted total score?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic item summary statistics — itemstats","text":"Returns list containing summary statistics","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generic item summary statistics — itemstats","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic item summary statistics — itemstats","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/itemstats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic item summary statistics — itemstats","text":"","code":"# dichotomous data example LSAT7full <- expand.table(LSAT7) head(LSAT7full) #>   Item.1 Item.2 Item.3 Item.4 Item.5 #> 1      0      0      0      0      0 #> 2      0      0      0      0      0 #> 3      0      0      0      0      0 #> 4      0      0      0      0      0 #> 5      0      0      0      0      0 #> 6      0      0      0      0      0 itemstats(LSAT7full) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 2 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 2 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 2 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 2 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 2 0.843 0.364   0.461         0.175       0.438 #>  #> $proportions #>            0     1 #> Item.1 0.172 0.828 #> Item.2 0.342 0.658 #> Item.3 0.228 0.772 #> Item.4 0.394 0.606 #> Item.5 0.157 0.843 #>  itemstats(LSAT7full, itemfreq='counts') #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 2 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 2 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 2 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 2 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 2 0.843 0.364   0.461         0.175       0.438 #>  #> $counts #>          0   1 #> Item.1 172 828 #> Item.2 342 658 #> Item.3 228 772 #> Item.4 394 606 #> Item.5 157 843 #>   # behaviour with missing data LSAT7full[1:5,1] <- NA itemstats(LSAT7full) #> $overall #>  N.complete    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>         995 1000            3.726          1.172 0.137 0.052 0.426     0.888 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  995 2 0.832 0.374   0.515         0.222       0.396 #> Item.2 1000 2 0.658 0.475   0.600         0.247       0.364 #> Item.3 1000 2 0.772 0.420   0.611         0.313       0.316 #> Item.4 1000 2 0.606 0.489   0.592         0.223       0.384 #> Item.5 1000 2 0.843 0.364   0.461         0.175       0.418 #>  #> $proportions #>            0     1  <NA> #> Item.1 0.167 0.828 0.005 #> Item.2 0.342 0.658    NA #> Item.3 0.228 0.772    NA #> Item.4 0.394 0.606    NA #> Item.5 0.157 0.843    NA #>   # data with no meaningful total score head(SAT12) #>   Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> 1      1      4      5      2      3      1      2      1      3       1 #> 2      3      4      2      8      3      3      2      8      3       1 #> 3      1      4      5      4      3      2      2      3      3       2 #> 4      2      4      4      2      3      3      2      4      3       2 #> 5      2      4      5      2      3      2      2      1      1       2 #> 6      1      4      3      1      3      2      2      3      3       1 #>   Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> 1       2       4       2       1       5       3       4       4       1 #> 2       2       8       2       1       5       2       4       1       1 #> 3       2       1       3       1       5       5       4       1       3 #> 4       2       4       2       1       5       2       4       1       3 #> 5       2       4       2       1       5       4       4       5       1 #> 6       2       3       2       1       5       5       4       4       1 #>   Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> 1       4       3       3       4       1       3       5       1       3 #> 2       4       3       3       8       1       8       4       1       4 #> 3       4       3       3       1       1       3       4       1       3 #> 4       4       3       1       5       2       5       4       1       3 #> 5       4       3       3       3       1       1       5       1       3 #> 6       4       3       3       4       1       1       4       1       4 #>   Item.29 Item.30 Item.31 Item.32 #> 1       1       5       4       5 #> 2       5       8       4       8 #> 3       4       4       4       1 #> 4       4       2       4       2 #> 5       1       2       4       1 #> 6       2       3       4       3 itemstats(SAT12, use_ts=FALSE) #> $overall #>     N #> 1 600 #>  #> $itemstats #>           N K  mean    sd #> Item.1  600 6 2.497 1.188 #> Item.2  600 6 3.385 1.356 #> Item.3  600 6 3.212 1.534 #> Item.4  600 6 2.762 1.370 #> Item.5  600 6 2.868 0.911 #> Item.6  600 5 2.358 1.135 #> Item.7  600 6 2.422 0.908 #> Item.8  600 6 2.925 1.370 #> Item.9  600 5 2.907 0.567 #> Item.10 600 6 2.320 1.490 #> Item.11 600 5 2.017 0.199 #> Item.12 600 6 3.642 1.184 #> Item.13 600 5 2.317 0.956 #> Item.14 600 6 1.798 1.432 #> Item.15 600 6 4.535 1.087 #> Item.16 600 6 3.368 1.135 #> Item.17 600 5 3.968 0.343 #> Item.18 600 6 3.020 1.514 #> Item.19 600 5 1.900 1.053 #> Item.20 600 6 3.870 0.483 #> Item.21 600 6 2.937 0.554 #> Item.22 600 5 2.985 0.442 #> Item.23 600 6 2.755 1.437 #> Item.24 600 6 1.502 1.037 #> Item.25 600 6 2.740 1.380 #> Item.26 600 6 3.923 1.265 #> Item.27 600 6 1.240 0.766 #> Item.28 600 6 3.262 0.937 #> Item.29 600 6 2.285 1.306 #> Item.30 600 6 3.703 1.553 #> Item.31 600 6 3.788 0.899 #> Item.32 600 6 3.023 1.303 #>  #> $proportions #>             1     2     3     4     5     8 #> Item.1  0.283 0.203 0.267 0.232 0.013 0.002 #> Item.2  0.212 0.022 0.070 0.568 0.127 0.002 #> Item.3  0.165 0.183 0.260 0.098 0.280 0.013 #> Item.4  0.165 0.378 0.148 0.172 0.128 0.008 #> Item.5  0.093 0.143 0.620 0.093 0.048 0.002 #> Item.6  0.160 0.582 0.107 0.043 0.108    NA #> Item.7  0.025 0.760 0.007 0.190 0.017 0.002 #> Item.8  0.202 0.205 0.207 0.250 0.133 0.003 #> Item.9  0.065 0.010 0.885 0.033 0.007    NA #> Item.10 0.422 0.215 0.165 0.028 0.167 0.003 #> Item.11 0.003 0.983 0.008 0.003 0.002    NA #> Item.12 0.072 0.082 0.218 0.415 0.205 0.008 #> Item.13 0.110 0.662 0.070 0.118 0.040    NA #> Item.14 0.723 0.027 0.108 0.022 0.117 0.003 #> Item.15 0.035 0.062 0.060 0.025 0.817 0.002 #> Item.16 0.070 0.105 0.413 0.215 0.195 0.002 #> Item.17 0.008 0.005 0.010 0.963 0.013    NA #> Item.18 0.303 0.033 0.165 0.352 0.142 0.005 #> Item.19 0.548 0.053 0.358 0.030 0.010    NA #> Item.20 0.012 0.002 0.105 0.873 0.007 0.002 #> Item.21 0.050 0.008 0.915 0.013 0.012 0.002 #> Item.22 0.028 0.005 0.935 0.017 0.015    NA #> Item.23 0.290 0.177 0.128 0.313 0.087 0.005 #> Item.24 0.728 0.162 0.042 0.022 0.045 0.002 #> Item.25 0.240 0.170 0.375 0.065 0.142 0.008 #> Item.26 0.020 0.227 0.030 0.262 0.460 0.002 #> Item.27 0.862 0.093 0.012 0.020 0.010 0.003 #> Item.28 0.082 0.010 0.530 0.337 0.037 0.005 #> Item.29 0.340 0.295 0.205 0.085 0.067 0.008 #> Item.30 0.150 0.110 0.107 0.183 0.440 0.010 #> Item.31 0.075 0.020 0.012 0.833 0.058 0.002 #> Item.32 0.125 0.183 0.443 0.075 0.162 0.012 #>   # extra total scores tables dat <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,                            5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) itemstats(dat, ts.tables=TRUE) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  600           18.202          5.054 0.108 0.075 0.798     2.272 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  600 2 0.283 0.451   0.380         0.300       0.793 #> Item.2  600 2 0.568 0.496   0.539         0.464       0.785 #> Item.3  600 2 0.280 0.449   0.446         0.371       0.789 #> Item.4  600 2 0.378 0.485   0.325         0.235       0.796 #> Item.5  600 2 0.620 0.486   0.424         0.340       0.791 #> Item.6  600 2 0.160 0.367   0.414         0.351       0.791 #> Item.7  600 2 0.760 0.427   0.366         0.289       0.793 #> Item.8  600 2 0.202 0.402   0.307         0.233       0.795 #> Item.9  600 2 0.885 0.319   0.189         0.127       0.798 #> Item.10 600 2 0.422 0.494   0.465         0.383       0.789 #> Item.11 600 2 0.983 0.128   0.181         0.156       0.797 #> Item.12 600 2 0.415 0.493   0.173         0.076       0.803 #> Item.13 600 2 0.662 0.474   0.438         0.358       0.790 #> Item.14 600 2 0.723 0.448   0.411         0.333       0.791 #> Item.15 600 2 0.817 0.387   0.393         0.325       0.792 #> Item.16 600 2 0.413 0.493   0.367         0.278       0.794 #> Item.17 600 2 0.963 0.188   0.238         0.202       0.796 #> Item.18 600 2 0.352 0.478   0.576         0.508       0.783 #> Item.19 600 2 0.548 0.498   0.401         0.314       0.792 #> Item.20 600 2 0.873 0.333   0.376         0.318       0.792 #> Item.21 600 2 0.915 0.279   0.190         0.136       0.798 #> Item.22 600 2 0.935 0.247   0.284         0.238       0.795 #> Item.23 600 2 0.313 0.464   0.338         0.253       0.795 #> Item.24 600 2 0.728 0.445   0.422         0.346       0.791 #> Item.25 600 2 0.375 0.485   0.383         0.297       0.793 #> Item.26 600 2 0.460 0.499   0.562         0.489       0.783 #> Item.27 600 2 0.862 0.346   0.425         0.367       0.791 #> Item.28 600 2 0.530 0.500   0.465         0.383       0.789 #> Item.29 600 2 0.340 0.474   0.407         0.324       0.791 #> Item.30 600 2 0.440 0.497   0.255         0.159       0.799 #> Item.31 600 2 0.833 0.373   0.479         0.419       0.788 #> Item.32 600 2 0.162 0.368   0.110         0.037       0.802 #>  #> $proportions #>             0     1 #> Item.1  0.717 0.283 #> Item.2  0.432 0.568 #> Item.3  0.720 0.280 #> Item.4  0.622 0.378 #> Item.5  0.380 0.620 #> Item.6  0.840 0.160 #> Item.7  0.240 0.760 #> Item.8  0.798 0.202 #> Item.9  0.115 0.885 #> Item.10 0.578 0.422 #> Item.11 0.017 0.983 #> Item.12 0.585 0.415 #> Item.13 0.338 0.662 #> Item.14 0.277 0.723 #> Item.15 0.183 0.817 #> Item.16 0.587 0.413 #> Item.17 0.037 0.963 #> Item.18 0.648 0.352 #> Item.19 0.452 0.548 #> Item.20 0.127 0.873 #> Item.21 0.085 0.915 #> Item.22 0.065 0.935 #> Item.23 0.687 0.313 #> Item.24 0.272 0.728 #> Item.25 0.625 0.375 #> Item.26 0.540 0.460 #> Item.27 0.138 0.862 #> Item.28 0.470 0.530 #> Item.29 0.660 0.340 #> Item.30 0.560 0.440 #> Item.31 0.167 0.833 #> Item.32 0.838 0.162 #>  #> $total.score_frequency #>      4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #> Freq 1 2 2 2 5 7 14 14 17 35 51 45 41 46 50 44 44 20 35 31 18 18 18 19  7  7  3 #>      31 32 #> Freq  1  3 #>  #> $total.score_means #>                0        1 #> Item.1  16.99535 21.25294 #> Item.2  15.07722 20.57478 #> Item.3  16.79630 21.81548 #> Item.4  16.92225 20.30396 #> Item.5  15.46930 19.87634 #> Item.6  17.28968 22.98958 #> Item.7  14.91667 19.23904 #> Item.8  17.42171 21.28926 #> Item.9  15.55072 18.54614 #> Item.10 16.19597 20.95257 #> Item.11 11.20000 18.32034 #> Item.12 17.46724 19.23695 #> Item.13 15.10837 19.78338 #> Item.14 14.84940 19.48387 #> Item.15 14.01818 19.14082 #> Item.16 16.64773 20.40726 #> Item.17 12.04545 18.43599 #> Item.18 16.05913 22.15166 #> Item.19 15.97048 20.03951 #> Item.20 13.21053 18.92557 #> Item.21 15.05882 18.49362 #> Item.22 12.76923 18.57932 #> Item.23 17.04854 20.72872 #> Item.24 14.71166 19.50343 #> Item.25 16.70400 20.69778 #> Item.26 15.58025 21.27899 #> Item.27 12.84337 19.06190 #> Item.28 15.70567 20.41509 #> Item.29 16.72727 21.06373 #> Item.30 17.06250 19.65152 #> Item.31 12.79000 19.28400 #> Item.32 17.95825 19.46392 #>  #> $total.score_sds #>                0        1 #> Item.1  4.495009 5.115311 #> Item.2  3.791287 4.583007 #> Item.3  4.322840 5.013323 #> Item.4  4.333771 5.444014 #> Item.5  4.280262 4.756698 #> Item.6  4.448894 5.353788 #> Item.7  4.313744 4.825059 #> Item.8  4.575452 5.661917 #> Item.9  5.007454 4.961288 #> Item.10 4.278821 4.736481 #> Item.11 4.184628 4.985966 #> Item.12 4.861326 5.147431 #> Item.13 4.274965 4.679466 #> Item.14 4.008502 4.822098 #> Item.15 4.212219 4.744448 #> Item.16 4.361290 5.155818 #> Item.17 4.613410 4.923352 #> Item.18 3.955174 4.446051 #> Item.19 4.349442 4.854746 #> Item.20 3.714174 4.809188 #> Item.21 5.092786 4.954396 #> Item.22 3.923355 4.906759 #> Item.23 4.505479 5.276912 #> Item.24 3.896380 4.816172 #> Item.25 4.379749 5.124107 #> Item.26 3.761839 4.627003 #> Item.27 3.775666 4.692898 #> Item.28 4.340725 4.593648 #> Item.29 4.241013 5.281332 #> Item.30 4.817161 4.984363 #> Item.31 3.364386 4.622779 #> Item.32 4.901850 5.638524 #>   # grouping information group <- gl(2, 300, labels=c('G1', 'G2')) itemstats(dat, group=group) #> $G1 #> $G1$overall #>    N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>  300           17.987          5.051 0.107 0.09 0.796     2.282 #>  #> $G1$itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  300 2 0.290 0.455   0.410         0.331       0.789 #> Item.2  300 2 0.573 0.495   0.534         0.458       0.783 #> Item.3  300 2 0.290 0.455   0.458         0.382       0.787 #> Item.4  300 2 0.353 0.479   0.342         0.255       0.793 #> Item.5  300 2 0.630 0.484   0.480         0.401       0.786 #> Item.6  300 2 0.130 0.337   0.398         0.340       0.789 #> Item.7  300 2 0.727 0.446   0.383         0.303       0.790 #> Item.8  300 2 0.213 0.410   0.352         0.277       0.791 #> Item.9  300 2 0.897 0.305   0.203         0.144       0.796 #> Item.10 300 2 0.403 0.491   0.433         0.349       0.788 #> Item.11 300 2 0.993 0.082   0.154         0.138       0.796 #> Item.12 300 2 0.413 0.493   0.123         0.026       0.803 #> Item.13 300 2 0.647 0.479   0.441         0.359       0.788 #> Item.14 300 2 0.727 0.446   0.394         0.316       0.790 #> Item.15 300 2 0.793 0.406   0.407         0.337       0.789 #> Item.16 300 2 0.377 0.485   0.338         0.249       0.793 #> Item.17 300 2 0.957 0.204   0.220         0.181       0.795 #> Item.18 300 2 0.360 0.481   0.567         0.497       0.781 #> Item.19 300 2 0.537 0.499   0.432         0.347       0.788 #> Item.20 300 2 0.863 0.344   0.355         0.293       0.791 #> Item.21 300 2 0.910 0.287   0.202         0.147       0.795 #> Item.22 300 2 0.927 0.261   0.260         0.211       0.794 #> Item.23 300 2 0.260 0.439   0.323         0.242       0.793 #> Item.24 300 2 0.707 0.456   0.421         0.342       0.789 #> Item.25 300 2 0.370 0.484   0.406         0.321       0.790 #> Item.26 300 2 0.473 0.500   0.539         0.463       0.783 #> Item.27 300 2 0.857 0.351   0.474         0.418       0.787 #> Item.28 300 2 0.537 0.499   0.435         0.350       0.788 #> Item.29 300 2 0.343 0.476   0.378         0.293       0.791 #> Item.30 300 2 0.440 0.497   0.245         0.149       0.798 #> Item.31 300 2 0.810 0.393   0.518         0.457       0.784 #> Item.32 300 2 0.180 0.385   0.036        -0.041       0.803 #>  #> $G1$proportions #>             0     1 #> Item.1  0.710 0.290 #> Item.2  0.427 0.573 #> Item.3  0.710 0.290 #> Item.4  0.647 0.353 #> Item.5  0.370 0.630 #> Item.6  0.870 0.130 #> Item.7  0.273 0.727 #> Item.8  0.787 0.213 #> Item.9  0.103 0.897 #> Item.10 0.597 0.403 #> Item.11 0.007 0.993 #> Item.12 0.587 0.413 #> Item.13 0.353 0.647 #> Item.14 0.273 0.727 #> Item.15 0.207 0.793 #> Item.16 0.623 0.377 #> Item.17 0.043 0.957 #> Item.18 0.640 0.360 #> Item.19 0.463 0.537 #> Item.20 0.137 0.863 #> Item.21 0.090 0.910 #> Item.22 0.073 0.927 #> Item.23 0.740 0.260 #> Item.24 0.293 0.707 #> Item.25 0.630 0.370 #> Item.26 0.527 0.473 #> Item.27 0.143 0.857 #> Item.28 0.463 0.537 #> Item.29 0.657 0.343 #> Item.30 0.560 0.440 #> Item.31 0.190 0.810 #> Item.32 0.820 0.180 #>  #>  #> $G2 #> $G2$overall #>    N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>  300           18.417          5.056  0.11 0.08   0.8     2.262 #>  #> $G2$itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  300 2 0.277 0.448   0.352         0.271       0.796 #> Item.2  300 2 0.563 0.497   0.547         0.472       0.787 #> Item.3  300 2 0.270 0.445   0.438         0.363       0.792 #> Item.4  300 2 0.403 0.491   0.305         0.213       0.799 #> Item.5  300 2 0.610 0.489   0.371         0.283       0.796 #> Item.6  300 2 0.190 0.393   0.426         0.360       0.792 #> Item.7  300 2 0.793 0.406   0.344         0.270       0.796 #> Item.8  300 2 0.190 0.393   0.265         0.190       0.799 #> Item.9  300 2 0.873 0.333   0.180         0.116       0.801 #> Item.10 300 2 0.440 0.497   0.495         0.415       0.789 #> Item.11 300 2 0.973 0.161   0.215         0.184       0.799 #> Item.12 300 2 0.417 0.494   0.222         0.127       0.803 #> Item.13 300 2 0.677 0.469   0.434         0.354       0.792 #> Item.14 300 2 0.720 0.450   0.428         0.351       0.792 #> Item.15 300 2 0.840 0.367   0.375         0.310       0.794 #> Item.16 300 2 0.450 0.498   0.391         0.303       0.795 #> Item.17 300 2 0.970 0.171   0.258         0.226       0.798 #> Item.18 300 2 0.343 0.476   0.588         0.522       0.784 #> Item.19 300 2 0.560 0.497   0.369         0.279       0.796 #> Item.20 300 2 0.883 0.322   0.398         0.343       0.794 #> Item.21 300 2 0.920 0.272   0.175         0.123       0.800 #> Item.22 300 2 0.943 0.232   0.309         0.266       0.797 #> Item.23 300 2 0.367 0.483   0.348         0.260       0.797 #> Item.24 300 2 0.750 0.434   0.421         0.347       0.793 #> Item.25 300 2 0.380 0.486   0.360         0.272       0.796 #> Item.26 300 2 0.447 0.498   0.590         0.520       0.784 #> Item.27 300 2 0.867 0.341   0.374         0.314       0.794 #> Item.28 300 2 0.523 0.500   0.498         0.418       0.789 #> Item.29 300 2 0.337 0.473   0.437         0.357       0.792 #> Item.30 300 2 0.440 0.497   0.265         0.170       0.801 #> Item.31 300 2 0.857 0.351   0.435         0.376       0.792 #> Item.32 300 2 0.143 0.351   0.196         0.128       0.800 #>  #> $G2$proportions #>             0     1 #> Item.1  0.723 0.277 #> Item.2  0.437 0.563 #> Item.3  0.730 0.270 #> Item.4  0.597 0.403 #> Item.5  0.390 0.610 #> Item.6  0.810 0.190 #> Item.7  0.207 0.793 #> Item.8  0.810 0.190 #> Item.9  0.127 0.873 #> Item.10 0.560 0.440 #> Item.11 0.027 0.973 #> Item.12 0.583 0.417 #> Item.13 0.323 0.677 #> Item.14 0.280 0.720 #> Item.15 0.160 0.840 #> Item.16 0.550 0.450 #> Item.17 0.030 0.970 #> Item.18 0.657 0.343 #> Item.19 0.440 0.560 #> Item.20 0.117 0.883 #> Item.21 0.080 0.920 #> Item.22 0.057 0.943 #> Item.23 0.633 0.367 #> Item.24 0.250 0.750 #> Item.25 0.620 0.380 #> Item.26 0.553 0.447 #> Item.27 0.133 0.867 #> Item.28 0.477 0.523 #> Item.29 0.663 0.337 #> Item.30 0.560 0.440 #> Item.31 0.143 0.857 #> Item.32 0.857 0.143 #>  #>    ##### # polytomous data example itemstats(Science) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  392           11.668          2.003 0.275 0.098 0.598      1.27 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 392 4 3.120 0.588   0.596         0.352       0.552 #> Work    392 4 2.722 0.807   0.666         0.332       0.567 #> Future  392 4 2.990 0.757   0.748         0.488       0.437 #> Benefit 392 4 2.837 0.802   0.684         0.363       0.541 #>  #> $proportions #>             1     2     3     4 #> Comfort 0.013 0.082 0.679 0.227 #> Work    0.084 0.250 0.526 0.140 #> Future  0.036 0.184 0.536 0.245 #> Benefit 0.054 0.255 0.492 0.199 #>   # polytomous data with missing newScience <- Science newScience[1:5,1] <- NA itemstats(newScience) #> $overall #>  N.complete   N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>         387 392           11.672          2.011 0.276  0.1 0.605     1.264 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 387 4 3.119 0.590   0.596         0.352       0.552 #> Work    392 4 2.722 0.807   0.646         0.311       0.576 #> Future  392 4 2.990 0.757   0.740         0.481       0.449 #> Benefit 392 4 2.837 0.802   0.684         0.370       0.538 #>  #> $proportions #>             1     2     3     4  <NA> #> Comfort 0.013 0.082 0.668 0.224 0.013 #> Work    0.084 0.250 0.526 0.140    NA #> Future  0.036 0.184 0.536 0.245    NA #> Benefit 0.054 0.255 0.492 0.199    NA #>   # unequal categories newScience[,1] <- ifelse(Science[,1] == 1, NA, Science[,1]) itemstats(newScience) #> $overall #>  N.complete   N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>         387 392           11.731          1.917  0.26 0.092 0.572     1.254 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 387 3 3.147 0.540   0.556         0.314       0.552 #> Work    392 4 2.722 0.807   0.656         0.325       0.517 #> Future  392 4 2.990 0.757   0.746         0.490       0.409 #> Benefit 392 4 2.837 0.802   0.684         0.370       0.525 #>  #> $proportions #>             1     2     3     4  <NA> #> Comfort    NA 0.082 0.679 0.227 0.013 #> Work    0.084 0.250 0.526 0.140    NA #> Future  0.036 0.184 0.536 0.245    NA #> Benefit 0.054 0.255 0.492 0.199    NA #>   merged <- data.frame(LSAT7full[1:392,], Science) itemstats(merged) #> $overall #>  N.complete   N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>         387 392           14.331          2.231 0.037 0.167 0.379     1.759 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  387 2 0.568 0.496   0.193        -0.030       0.417 #> Item.2  392 2 0.232 0.423   0.041        -0.146       0.443 #> Item.3  392 2 0.605 0.490   0.231         0.014       0.405 #> Item.4  392 2 0.467 0.500   0.272         0.051       0.392 #> Item.5  392 2 0.760 0.428   0.201         0.011       0.402 #> Comfort 392 4 3.120 0.588   0.519         0.288       0.286 #> Work    392 4 2.722 0.807   0.608         0.299       0.251 #> Future  392 4 2.990 0.757   0.676         0.418       0.185 #> Benefit 392 4 2.837 0.802   0.600         0.291       0.261 #>  #> $proportions #>             0     1     2     3     4  <NA> #> Item.1  0.426 0.561    NA    NA    NA 0.013 #> Item.2  0.768 0.232    NA    NA    NA    NA #> Item.3  0.395 0.605    NA    NA    NA    NA #> Item.4  0.533 0.467    NA    NA    NA    NA #> Item.5  0.240 0.760    NA    NA    NA    NA #> Comfort    NA 0.013 0.082 0.679 0.227    NA #> Work       NA 0.084 0.250 0.526 0.140    NA #> Future     NA 0.036 0.184 0.536 0.245    NA #> Benefit    NA 0.054 0.255 0.492 0.199    NA #>"},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Score a test by converting response patterns to binary data — key2binary","title":"Score a test by converting response patterns to binary data — key2binary","text":"key2binary function convert response pattern data dichotomous format, given response key.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score a test by converting response patterns to binary data — key2binary","text":"","code":"key2binary(fulldata, key, score_missing = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score a test by converting response patterns to binary data — key2binary","text":"fulldata object class data.frame, matrix, table response patterns key vector matrix consisting 'correct' response items. value/row corresponds column fulldata. input matrix, multiple scoring keys can supplied item. NA values used indicate scoring key (case matrix input, additional scoring keys) score_missing logical; missing data elements returned incorrect (.e., 0)? FALSE, missing data terms kept missing","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score a test by converting response patterns to binary data — key2binary","text":"Returns numeric matrix response patterns   dichotomous format","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Score a test by converting response patterns to binary data — key2binary","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Score a test by converting response patterns to binary data — key2binary","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/key2binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Score a test by converting response patterns to binary data — key2binary","text":"","code":"data(SAT12) head(SAT12) #>   Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> 1      1      4      5      2      3      1      2      1      3       1 #> 2      3      4      2      8      3      3      2      8      3       1 #> 3      1      4      5      4      3      2      2      3      3       2 #> 4      2      4      4      2      3      3      2      4      3       2 #> 5      2      4      5      2      3      2      2      1      1       2 #> 6      1      4      3      1      3      2      2      3      3       1 #>   Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> 1       2       4       2       1       5       3       4       4       1 #> 2       2       8       2       1       5       2       4       1       1 #> 3       2       1       3       1       5       5       4       1       3 #> 4       2       4       2       1       5       2       4       1       3 #> 5       2       4       2       1       5       4       4       5       1 #> 6       2       3       2       1       5       5       4       4       1 #>   Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> 1       4       3       3       4       1       3       5       1       3 #> 2       4       3       3       8       1       8       4       1       4 #> 3       4       3       3       1       1       3       4       1       3 #> 4       4       3       1       5       2       5       4       1       3 #> 5       4       3       3       3       1       1       5       1       3 #> 6       4       3       3       4       1       1       4       1       4 #>   Item.29 Item.30 Item.31 Item.32 #> 1       1       5       4       5 #> 2       5       8       4       8 #> 3       4       4       4       1 #> 4       4       2       4       2 #> 5       1       2       4       1 #> 6       2       3       4       3 key <- c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)  dicho.SAT12 <- key2binary(SAT12, key) head(dicho.SAT12) #>      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> [1,]      1      1      1      1      1      1      1      1      1       1 #> [2,]      0      1      0      0      1      0      1      0      1       1 #> [3,]      1      1      1      0      1      0      1      0      1       0 #> [4,]      0      1      0      1      1      0      1      0      1       0 #> [5,]      0      1      1      1      1      0      1      1      0       0 #> [6,]      1      1      0      0      1      0      1      0      1       1 #>      Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       0       1       1       1       0       1       0       1 #> [3,]       1       0       0       1       1       0       1       0       0 #> [4,]       1       1       1       1       1       0       1       0       0 #> [5,]       1       1       1       1       1       0       1       0       1 #> [6,]       1       0       1       1       1       0       1       1       1 #>      Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> [1,]       1       1       1       1       1       1       1       1       1 #> [2,]       1       1       1       0       1       0       0       1       0 #> [3,]       1       1       1       0       1       1       0       1       1 #> [4,]       1       1       0       0       0       0       0       1       1 #> [5,]       1       1       1       0       1       0       1       1       1 #> [6,]       1       1       1       1       1       0       0       1       0 #>      Item.29 Item.30 Item.31 Item.32 #> [1,]       1       1       1       1 #> [2,]       0       0       1       0 #> [3,]       0       0       1       0 #> [4,]       0       0       1       0 #> [5,]       1       0       1       0 #> [6,]       0       0       1       0  # multiple scoring keys key2 <- cbind(c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5),               c(2,3,NA,1,rep(NA, 28))) dicho.SAT12 <- key2binary(SAT12, key2)  # keys from raw character responses resp <- as.data.frame(matrix(c(   \"B\",\"B\",\"D\",\"D\",\"E\",   \"B\",\"A\",\"D\",\"D\",\"E\",   \"B\",\"A\",\"D\",\"C\",\"E\",   \"D\",\"D\",\"D\",\"C\",\"E\",   \"B\",\"C\",\"A\",\"D\",\"A\"), ncol=5, byrow=TRUE))  key <- c(\"B\", \"D\", \"D\", \"C\", \"E\")  d01 <- key2binary(resp, key) head(d01) #>      V1 V2 V3 V4 V5 #> [1,]  1  0  1  0  1 #> [2,]  1  0  1  0  1 #> [3,]  1  0  1  1  1 #> [4,]  0  1  1  1  1 #> [5,]  1  0  0  0  0  # score/don't score missing values resp[1,1] <- NA d01NA <- key2binary(resp, key) # without scoring d01NA #>      V1 V2 V3 V4 V5 #> [1,] NA  0  1  0  1 #> [2,]  1  0  1  0  1 #> [3,]  1  0  1  1  1 #> [4,]  0  1  1  1  1 #> [5,]  1  0  0  0  0  d01 <- key2binary(resp, key, score_missing = TRUE) # with scoring d01 #>      V1 V2 V3 V4 V5 #> [1,]  0  0  1  0  1 #> [2,]  1  0  1  0  1 #> [3,]  1  0  1  1  1 #> [4,]  0  1  1  1  1 #> [5,]  1  0  0  0  0"},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":null,"dir":"Reference","previous_headings":"","what":"Lagrange test for freeing parameters — lagrange","title":"Lagrange test for freeing parameters — lagrange","text":"Lagrange (.e., score) test test whether parameters freed constrained baseline model.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lagrange test for freeing parameters — lagrange","text":"","code":"lagrange(mod, parnum, SE.type = \"Oakes\", type = \"Richardson\", ...)"},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lagrange test for freeing parameters — lagrange","text":"mod estimated model parnum vector, list vectors, containing one parameter locations/sets locations tested. See objects returned mod2values locations SE.type type information matrix estimator use. See mirt details type type numerical algorithm passed numerical_deriv obtain gradient terms ... additional arguments pass mirt","code":""},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lagrange test for freeing parameters — lagrange","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lagrange test for freeing parameters — lagrange","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/lagrange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lagrange test for freeing parameters — lagrange","text":"","code":"# \\donttest{ dat <- expand.table(LSAT7) mod <- mirt(dat, 1, 'Rasch') #>  (values <- mod2values(mod)) #>    group   item     class   name parnum value lbound ubound   est const nconst #> 1    all Item.1      dich     a1      1 1.000   -Inf    Inf FALSE  none   none #> 2    all Item.1      dich      d      2 1.868   -Inf    Inf  TRUE  none   none #> 3    all Item.1      dich      g      3 0.000      0      1 FALSE  none   none #> 4    all Item.1      dich      u      4 1.000      0      1 FALSE  none   none #> 5    all Item.2      dich     a1      5 1.000   -Inf    Inf FALSE  none   none #> 6    all Item.2      dich      d      6 0.791   -Inf    Inf  TRUE  none   none #> 7    all Item.2      dich      g      7 0.000      0      1 FALSE  none   none #> 8    all Item.2      dich      u      8 1.000      0      1 FALSE  none   none #> 9    all Item.3      dich     a1      9 1.000   -Inf    Inf FALSE  none   none #> 10   all Item.3      dich      d     10 1.461   -Inf    Inf  TRUE  none   none #> 11   all Item.3      dich      g     11 0.000      0      1 FALSE  none   none #> 12   all Item.3      dich      u     12 1.000      0      1 FALSE  none   none #> 13   all Item.4      dich     a1     13 1.000   -Inf    Inf FALSE  none   none #> 14   all Item.4      dich      d     14 0.521   -Inf    Inf  TRUE  none   none #> 15   all Item.4      dich      g     15 0.000      0      1 FALSE  none   none #> 16   all Item.4      dich      u     16 1.000      0      1 FALSE  none   none #> 17   all Item.5      dich     a1     17 1.000   -Inf    Inf FALSE  none   none #> 18   all Item.5      dich      d     18 1.993   -Inf    Inf  TRUE  none   none #> 19   all Item.5      dich      g     19 0.000      0      1 FALSE  none   none #> 20   all Item.5      dich      u     20 1.000      0      1 FALSE  none   none #> 21   all  GROUP GroupPars MEAN_1     21 0.000   -Inf    Inf FALSE  none   none #> 22   all  GROUP GroupPars COV_11     22 1.022      0    Inf  TRUE  none   none #>    prior.type prior_1 prior_2 #> 1        none     NaN     NaN #> 2        none     NaN     NaN #> 3        none     NaN     NaN #> 4        none     NaN     NaN #> 5        none     NaN     NaN #> 6        none     NaN     NaN #> 7        none     NaN     NaN #> 8        none     NaN     NaN #> 9        none     NaN     NaN #> 10       none     NaN     NaN #> 11       none     NaN     NaN #> 12       none     NaN     NaN #> 13       none     NaN     NaN #> 14       none     NaN     NaN #> 15       none     NaN     NaN #> 16       none     NaN     NaN #> 17       none     NaN     NaN #> 18       none     NaN     NaN #> 19       none     NaN     NaN #> 20       none     NaN     NaN #> 21       none     NaN     NaN #> 22       none     NaN     NaN  # test all fixed slopes individually parnum <- values$parnum[values$name == 'a1'] lagrange(mod, parnum) #>            X2 df          p #> 1  0.36714267  1 0.54456589 #> 5  0.04789243  1 0.82677204 #> 9  4.69717570  1 0.03021223 #> 13 1.44960175  1 0.22859187 #> 17 2.55408012  1 0.11000983  # compare to LR test for first two slopes mod2 <- mirt(dat, 'F = 1-5                    FREE = (1, a1)', 'Rasch') #>  coef(mod2, simplify=TRUE)$items #>              a1         d g u #> Item.1 1.157956 1.9393358 0 1 #> Item.2 1.000000 0.7850452 0 1 #> Item.3 1.000000 1.4501952 0 1 #> Item.4 1.000000 0.5175858 0 1 #> Item.5 1.000000 1.9787464 0 1 anova(mod, mod2) #>           AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod  5341.802 5352.192 5352.994 5371.248 -2664.901                #> mod2 5343.264 5355.386 5356.321 5377.618 -2664.632 0.538  1 0.463  mod2 <- mirt(dat, 'F = 1-5                    FREE = (2, a1)', 'Rasch') #>  coef(mod2, simplify=TRUE)$items #>               a1         d g u #> Item.1 1.0000000 1.8746626 0 1 #> Item.2 0.9464702 0.7810629 0 1 #> Item.3 1.0000000 1.4661198 0 1 #> Item.4 1.0000000 0.5234068 0 1 #> Item.5 1.0000000 1.9997347 0 1 anova(mod, mod2) #>           AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod  5341.802 5352.192 5352.994 5371.248 -2664.901                #> mod2 5343.720 5355.842 5356.777 5378.075 -2664.860 0.081  1 0.775  mod2 <- mirt(dat, 'F = 1-5                    FREE = (3, a1)', 'Rasch') #>  coef(mod2, simplify=TRUE)$items #>              a1         d g u #> Item.1 1.000000 1.8101732 0 1 #> Item.2 1.000000 0.7649559 0 1 #> Item.3 1.848252 1.7774916 0 1 #> Item.4 1.000000 0.5042538 0 1 #> Item.5 1.000000 1.9316244 0 1 anova(mod, mod2) #>           AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod  5341.802 5352.192 5352.994 5371.248 -2664.901                #> mod2 5335.130 5347.252 5348.187 5369.485 -2660.565 8.671  1 0.003  # test slopes first two slopes and last three slopes jointly lagrange(mod, list(parnum[1:2], parnum[3:5])) #>                X2 df          p #> 1.5     0.4591775  2 0.79486042 #> 9.13.17 9.1527189  3 0.02732783  # test all 5 slopes and first + last jointly lagrange(mod, list(parnum[1:5], parnum[c(1, 5)])) #>                   X2 df          p #> 1.5.9.13.17 9.861713  5 0.07924974 #> 1.17        2.898233  2 0.23477762  # }"},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"Given matrix data.frame object consisting Likert responses return object dimensions integer values.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"","code":"likert2int(x, levels = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"x matrix character values data.frame character/factor vectors levels named character vector indicating integer values assigned elements. omitted, order elements determined converting column x factor variable","code":""},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/likert2int.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert ordered Likert-scale responses (character or factors) to integers — likert2int","text":"","code":"# \\donttest{  # simulate data  dat1 <- matrix(sample(c('Disagree', 'Strongly Disagree', 'Agree',                         'Neutral', 'Strongly Agree'), 1000*5, replace=TRUE),                nrow=1000, ncol=5) dat1[2,2] <- dat1[3,3] <- dat1[1,3] <- NA # NAs added for flavour dat2 <- matrix(sample(c('D', 'SD', 'A', 'N', 'SA'), 1000*5, replace=TRUE),                nrow=1000, ncol=5) dat <- cbind(dat1, dat2)  # separately intdat1 <- likert2int(dat1) head(dat1) #>      [,1]             [,2]                [,3]             [,4]                #> [1,] \"Strongly Agree\" \"Strongly Disagree\" NA               \"Neutral\"           #> [2,] \"Disagree\"       NA                  \"Agree\"          \"Disagree\"          #> [3,] \"Disagree\"       \"Neutral\"           NA               \"Disagree\"          #> [4,] \"Disagree\"       \"Neutral\"           \"Disagree\"       \"Neutral\"           #> [5,] \"Neutral\"        \"Strongly Agree\"    \"Agree\"          \"Strongly Disagree\" #> [6,] \"Strongly Agree\" \"Agree\"             \"Strongly Agree\" \"Strongly Agree\"    #>      [,5]                #> [1,] \"Strongly Agree\"    #> [2,] \"Strongly Agree\"    #> [3,] \"Strongly Disagree\" #> [4,] \"Neutral\"           #> [5,] \"Strongly Agree\"    #> [6,] \"Agree\"             head(intdat1) #>   V1 V2 V3 V4 V5 #> 1 NA NA NA NA NA #> 2 NA NA NA NA NA #> 3 NA NA NA NA NA #> 4 NA NA NA NA NA #> 5 NA NA NA NA NA #> 6 NA NA NA NA NA  # more useful with explicit levels lvl1 <- c('Strongly Disagree'=1, 'Disagree'=2, 'Neutral'=3, 'Agree'=4,           'Strongly Agree'=5) intdat1 <- likert2int(dat1, levels = lvl1) head(dat1) #>      [,1]             [,2]                [,3]             [,4]                #> [1,] \"Strongly Agree\" \"Strongly Disagree\" NA               \"Neutral\"           #> [2,] \"Disagree\"       NA                  \"Agree\"          \"Disagree\"          #> [3,] \"Disagree\"       \"Neutral\"           NA               \"Disagree\"          #> [4,] \"Disagree\"       \"Neutral\"           \"Disagree\"       \"Neutral\"           #> [5,] \"Neutral\"        \"Strongly Agree\"    \"Agree\"          \"Strongly Disagree\" #> [6,] \"Strongly Agree\" \"Agree\"             \"Strongly Agree\" \"Strongly Agree\"    #>      [,5]                #> [1,] \"Strongly Agree\"    #> [2,] \"Strongly Agree\"    #> [3,] \"Strongly Disagree\" #> [4,] \"Neutral\"           #> [5,] \"Strongly Agree\"    #> [6,] \"Agree\"             head(intdat1) #>   V1 V2 V3 V4 V5 #> 1  5  1 NA  3  5 #> 2  2 NA  4  2  5 #> 3  2  3 NA  2  1 #> 4  2  3  2  3  3 #> 5  3  5  4  1  5 #> 6  5  4  5  5  4  # second data lvl2 <- c('SD'=1, 'D'=2, 'N'=3, 'A'=4, 'SA'=5) intdat2 <- likert2int(dat2, levels = lvl2) head(dat2) #>      [,1] [,2] [,3] [,4] [,5] #> [1,] \"SA\" \"A\"  \"SA\" \"N\"  \"D\"  #> [2,] \"D\"  \"D\"  \"SD\" \"SD\" \"D\"  #> [3,] \"N\"  \"N\"  \"SD\" \"A\"  \"N\"  #> [4,] \"SD\" \"A\"  \"SA\" \"SD\" \"SA\" #> [5,] \"SA\" \"N\"  \"N\"  \"SD\" \"A\"  #> [6,] \"A\"  \"D\"  \"SD\" \"SD\" \"SA\" head(intdat2) #>   V1 V2 V3 V4 V5 #> 1  5  4  5  3  2 #> 2  2  2  1  1  2 #> 3  3  3  1  4  3 #> 4  1  4  5  1  5 #> 5  5  3  3  1  4 #> 6  4  2  1  1  5  # full dataset (using both mapping schemes) intdat <- likert2int(dat, levels = c(lvl1, lvl2)) head(dat) #>      [,1]             [,2]                [,3]             [,4]                #> [1,] \"Strongly Agree\" \"Strongly Disagree\" NA               \"Neutral\"           #> [2,] \"Disagree\"       NA                  \"Agree\"          \"Disagree\"          #> [3,] \"Disagree\"       \"Neutral\"           NA               \"Disagree\"          #> [4,] \"Disagree\"       \"Neutral\"           \"Disagree\"       \"Neutral\"           #> [5,] \"Neutral\"        \"Strongly Agree\"    \"Agree\"          \"Strongly Disagree\" #> [6,] \"Strongly Agree\" \"Agree\"             \"Strongly Agree\" \"Strongly Agree\"    #>      [,5]                [,6] [,7] [,8] [,9] [,10] #> [1,] \"Strongly Agree\"    \"SA\" \"A\"  \"SA\" \"N\"  \"D\"   #> [2,] \"Strongly Agree\"    \"D\"  \"D\"  \"SD\" \"SD\" \"D\"   #> [3,] \"Strongly Disagree\" \"N\"  \"N\"  \"SD\" \"A\"  \"N\"   #> [4,] \"Neutral\"           \"SD\" \"A\"  \"SA\" \"SD\" \"SA\"  #> [5,] \"Strongly Agree\"    \"SA\" \"N\"  \"N\"  \"SD\" \"A\"   #> [6,] \"Agree\"             \"A\"  \"D\"  \"SD\" \"SD\" \"SA\"  head(intdat) #>   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 #> 1  5  1 NA  3  5  5  4  5  3   2 #> 2  2 NA  4  2  5  2  2  1  1   2 #> 3  2  3 NA  2  1  3  3  1  4   3 #> 4  2  3  2  3  3  1  4  5  1   5 #> 5  3  5  4  1  5  5  3  3  1   4 #> 6  5  4  5  5  4  4  2  1  1   5   ##### # data.frame as input with ordered factors  dat1 <- data.frame(dat1) dat2 <- data.frame(dat2) dat.old <- cbind(dat1, dat2) colnames(dat.old) <- paste0('Item_', 1:10) str(dat.old) # factors are leveled alphabetically by default #> 'data.frame':\t1000 obs. of  10 variables: #>  $ Item_1 : chr  \"Strongly Agree\" \"Disagree\" \"Disagree\" \"Disagree\" ... #>  $ Item_2 : chr  \"Strongly Disagree\" NA \"Neutral\" \"Neutral\" ... #>  $ Item_3 : chr  NA \"Agree\" NA \"Disagree\" ... #>  $ Item_4 : chr  \"Neutral\" \"Disagree\" \"Disagree\" \"Neutral\" ... #>  $ Item_5 : chr  \"Strongly Agree\" \"Strongly Agree\" \"Strongly Disagree\" \"Neutral\" ... #>  $ Item_6 : chr  \"SA\" \"D\" \"N\" \"SD\" ... #>  $ Item_7 : chr  \"A\" \"D\" \"N\" \"A\" ... #>  $ Item_8 : chr  \"SA\" \"SD\" \"SD\" \"SA\" ... #>  $ Item_9 : chr  \"N\" \"SD\" \"A\" \"SD\" ... #>  $ Item_10: chr  \"D\" \"D\" \"N\" \"SA\" ...  # create explicit ordering in factor variables for(i in 1:ncol(dat1))    levels(dat1[[i]]) <- c('Strongly Disagree', 'Disagree', 'Neutral', 'Agree',                           'Strongly Agree')  for(i in 1:ncol(dat2))    levels(dat2[[i]]) <- c('SD', 'D', 'N', 'A', 'SA')  dat <- cbind(dat1, dat2) colnames(dat) <- colnames(dat.old) str(dat) # note ordering #> 'data.frame':\t1000 obs. of  10 variables: #>  $ Item_1 : chr  \"Strongly Agree\" \"Disagree\" \"Disagree\" \"Disagree\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ... #>  $ Item_2 : chr  \"Strongly Disagree\" NA \"Neutral\" \"Neutral\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ... #>  $ Item_3 : chr  NA \"Agree\" NA \"Disagree\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ... #>  $ Item_4 : chr  \"Neutral\" \"Disagree\" \"Disagree\" \"Neutral\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ... #>  $ Item_5 : chr  \"Strongly Agree\" \"Strongly Agree\" \"Strongly Disagree\" \"Neutral\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"Strongly Disagree\" \"Disagree\" \"Neutral\" \"Agree\" ... #>  $ Item_6 : chr  \"SA\" \"D\" \"N\" \"SD\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"SD\" \"D\" \"N\" \"A\" ... #>  $ Item_7 : chr  \"A\" \"D\" \"N\" \"A\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"SD\" \"D\" \"N\" \"A\" ... #>  $ Item_8 : chr  \"SA\" \"SD\" \"SD\" \"SA\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"SD\" \"D\" \"N\" \"A\" ... #>  $ Item_9 : chr  \"N\" \"SD\" \"A\" \"SD\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"SD\" \"D\" \"N\" \"A\" ... #>  $ Item_10: chr  \"D\" \"D\" \"N\" \"SA\" ... #>   ..- attr(*, \"levels\")= chr [1:5] \"SD\" \"D\" \"N\" \"A\" ...  intdat <- likert2int(dat) head(dat) #>           Item_1            Item_2         Item_3            Item_4 #> 1 Strongly Agree Strongly Disagree           <NA>           Neutral #> 2       Disagree              <NA>          Agree          Disagree #> 3       Disagree           Neutral           <NA>          Disagree #> 4       Disagree           Neutral       Disagree           Neutral #> 5        Neutral    Strongly Agree          Agree Strongly Disagree #> 6 Strongly Agree             Agree Strongly Agree    Strongly Agree #>              Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> 1    Strongly Agree     SA      A     SA      N       D #> 2    Strongly Agree      D      D     SD     SD       D #> 3 Strongly Disagree      N      N     SD      A       N #> 4           Neutral     SD      A     SA     SD      SA #> 5    Strongly Agree     SA      N      N     SD       A #> 6             Agree      A      D     SD     SD      SA head(intdat) #>   Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> 1      5      1     NA      3      5      5      4      5      3       2 #> 2      2     NA      4      2      5      2      2      1      1       2 #> 3      2      3     NA      2      1      3      3      1      4       3 #> 4      2      3      2      3      3      1      4      5      1       5 #> 5      3      5      4      1      5      5      3      3      1       4 #> 6      5      4      5      5      4      4      2      1      1       5  # }"},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract log-likelihood — logLik-method","title":"Extract log-likelihood — logLik-method","text":"Extract observed-data log-likelihood.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract log-likelihood — logLik-method","text":"","code":"# S4 method for class 'SingleGroupClass' logLik(object)"},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract log-likelihood — logLik-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract log-likelihood — logLik-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/logLik-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract log-likelihood — logLik-method","text":"","code":"# \\donttest{ x <- mirt(Science, 1) #>  logLik(x) #> [1] -1608.87  # }"},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the marginal reliability — marginal_rxx","title":"Function to calculate the marginal reliability — marginal_rxx","text":"Given estimated model prior density function, compute marginal reliability (Thissen Wainer, 2001). available unidimensional tests.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the marginal reliability — marginal_rxx","text":"","code":"marginal_rxx(mod, density = dnorm, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the marginal reliability — marginal_rxx","text":"mod object class 'SingleGroupClass' density density function use integration. Default assumes latent traits normal (Gaussian) distribution ... additional arguments passed density function","code":""},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate the marginal reliability — marginal_rxx","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Thissen, D. Wainer, H. (2001). Test Scoring. Lawrence Erlbaum Associates.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate the marginal reliability — marginal_rxx","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/marginal_rxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate the marginal reliability — marginal_rxx","text":"","code":"dat <- expand.table(deAyala) mod <- mirt(dat) #>   # marginal estimate treating item parameters as known marginal_rxx(mod) #> [1] 0.6092894  # compare to alpha itemstats(dat)$overall$alpha #> [1] 0.6077281  # \\donttest{  # empirical estimate (assuming the same prior) fscores(mod, returnER = TRUE) #>        F1  #> 0.6200703   # empirical rxx the alternative way, given theta scores and SEs fs <- fscores(mod, full.scores.SE=TRUE) head(fs) #>         F1 SE_F1 #> [1,] -1.58  0.67 #> [2,] -1.58  0.67 #> [3,] -1.58  0.67 #> [4,] -1.58  0.67 #> [5,] -1.58  0.67 #> [6,] -1.58  0.67 empirical_rxx(fs) #>        F1  #> 0.6200703   ############# # example demonstrating correlation attenuation  theta <- rnorm(1000) X <- theta + rnorm(1000, sd=2) cor(X, theta)    # correlation without measurement error (what you want) #> [1] 0.4644682  # measured with a 10 item GRM test nitems <- 10 a <- matrix(rlnorm(nitems,.2,.3)) diffs <- t(apply(matrix(runif(nitems*4, .3, 1), nitems), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(nitems) dat <- simdata(a, d, itemtype = 'graded', Theta=matrix(theta))  # correlation with total score (attenuated) cor(rowSums(dat), X) #> [1] 0.4279283  # fit single group model mod <- mirt(dat) #>   # EAP correlation (also attenuated) fs <- fscores(mod) cor(fs, X) #>         [,1] #> F1 0.4302499  # correction for attenuation, r_x.theta = r_x.theta.hat / sqrt(rxx_theta.hat) (rxx <- marginal_rxx(mod))  # alternatively, could use empirical_rxx() #> [1] 0.8095505 cor(fs, X) / sqrt(rxx)  # correction estimate #>         [,1] #> F1 0.4781881 cor(X, theta)           # compare to true correlation #> [1] 0.4644682  # }"},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Multidimensional discrete item response theory — mdirt","title":"Multidimensional discrete item response theory — mdirt","text":"mdirt fits variety item response models discrete latent variables. include, limited , latent class analysis, multidimensional latent class models, multidimensional discrete latent class models, DINA/DINO models, grade measurement models, C-RUM, . response models defined explicitly customized models can defined using createItem function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multidimensional discrete item response theory — mdirt","text":"","code":"mdirt(   data,   model,   customTheta = NULL,   structure = NULL,   item.Q = NULL,   nruns = 1,   method = \"EM\",   covdata = NULL,   formula = NULL,   itemtype = \"lca\",   optimizer = \"nlminb\",   return_max = TRUE,   group = NULL,   GenRandomPars = FALSE,   verbose = TRUE,   pars = NULL,   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multidimensional discrete item response theory — mdirt","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA model number mutually exclusive classes fit, alternatively specific mirt.model definition (reflects -called Q-matrix). Note using mirt.model, order syntax factors/attributes defined associated columns customTheta input customTheta input passed technical = list(customTheta = ...), included directly function convenience. input interesting discrete latent models allows customized patterns latent classes (.e., defines possible combinations latent attribute profile). default builds pattern customTheta = diag(model), typical pattern traditional latent class analysis whereby class membership mutually distinct exhaustive. See thetaComb quick method generate matrix possible combinations structure R formula allowing profile probability patterns (.e., structural component model) fitted according log-linear model. NULL, profile probabilities (except one) estimated. Use input requires customTheta input supplied, column names matrix match names found within formula item.Q list item-level Q-matrices indicating respective categories modeled underlying attributes. matrix must represent \\(K_i \\times \\) matrix, \\(K_i\\) represents number categories ith item, \\(\\) number attributes included Theta matrix; otherwise, value ofNULL default matrix consisting 1's \\(K_i \\times \\) element except first row, contains 0's proper identification. Incidentally, first row matrix must contain 0's first category represents reference category identification nruns numeric value indicating many times model fit data using random starting values. greater 1, GenRandomPars set true default method estimation method. Can 'EM' 'BL' (see mirt details) covdata data.frame data used latent regression models formula R formula (list formulas) indicating latent traits can regressed using external covariates covdata. named list formulas supplied (names correspond latent trait/attribute names model) specific regression effects can estimated factor. Supplying single formula estimate regression parameters latent variables default itemtype vector indicating itemtype associated item. discrete models limited 'lca' items defined using createItem definition optimizer optimizer used M-step, set 'nlminb' default. See mirt details return_max logical; nruns > 1, return model optimal maximum likelihood criteria? FALSE, returns list estimated objects group factor variable indicating group membership used multiple group analyses GenRandomPars logical; use random starting values verbose logical; turn messages R console pars used modifying starting values; see mirt details technical list lower-level inputs. See mirt details ... additional arguments passed estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multidimensional discrete item response theory — mdirt","text":"Posterior classification accuracy response pattern may obtained via fscores function. summary() function display category probability values given class membership, can also displayed graphically plot(), coef() displays raw coefficient values (standard errors, estimated). Finally, anova() used compare nested models, M2 itemfit may used model fitting purposes.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"-lca-model-definition","dir":"Reference","previous_headings":"","what":"'lca' model definition","title":"Multidimensional discrete item response theory — mdirt","text":"latent class IRT model two latent classes form $$P(x = k|\\theta_1, \\theta_2, a1, a2) = \\frac{exp(a1 \\theta_1 + a2 \\theta_2)}{   \\sum_j^K exp(a1 \\theta_1 + a2 \\theta_2)}$$ \\(\\theta\\) values generally take discrete points (0 1). proper identification, first category slope parameters (\\(a1\\) \\(a2\\)) never freely estimated. Alternatively, supplying different grid \\(\\theta\\) values allow estimation similar models (multidimensional discrete models, grade membership, etc.). See examples . item.Q utilized, equation can understood $$P(x = k|\\theta_1, \\theta_2, a1, a2) = \\frac{exp(a1 \\theta_1 Q_{j1} + a2 \\theta_2 Q_{j2})}{   \\sum_j^K exp(a1 \\theta_1 Q_{j1} + a2 \\theta_2 Q_{j2})}$$ construction Q \\(K_i \\times \\) matrix indicating whether category modeled according latent class structure. standard latent class model, Q-matrix many rows categories, many columns number classes/attributes modeled, consist 0's first row 1's elsewhere. course can -written passing alternative item.Q definition respective item.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multidimensional discrete item response theory — mdirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. Proctor, C. H. (1970). probabilistic formulation statistical analysis Guttman scaling.   Psychometrika, 35, 73-78. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multidimensional discrete item response theory — mdirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mdirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multidimensional discrete item response theory — mdirt","text":"","code":"# LSAT6 dataset dat <- expand.table(LSAT6)  # fit with 2-3 latent classes (mod2 <- mdirt(dat, 2)) #>  #>  #> Call: #> mdirt(data = dat, model = 2) #>  #> Latent class model with 2 classes and 2 profiles. #> Converged within 1e-04 tolerance after 363 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay #> Latent density type: discrete #>  #> Log-likelihood = -2467.408 #> Estimated parameters: 11  #> AIC = 4956.816 #> BIC = 5010.802; SABIC = 4975.865 #> G2 (20) = 22.74, p = 0.3018, RMSEA = 0.012 # \\donttest{ (mod3 <- mdirt(dat, 3)) #>  #> Warning: EM cycles terminated after 500 iterations. #>  #> Call: #> mdirt(data = dat, model = 3) #>  #> Latent class model with 3 classes and 3 profiles. #> FAILED TO CONVERGE within 1e-04 tolerance after 500 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay #> Latent density type: discrete #>  #> Log-likelihood = -2465.249 #> Estimated parameters: 17  #> AIC = 4964.499 #> BIC = 5047.931; SABIC = 4993.938 #> G2 (14) = 18.42, p = 0.1882, RMSEA = 0.018 summary(mod2) #> $Item_1 #>        category_1 category_2 #> P[1 0]      0.156      0.844 #> P[0 1]      0.037      0.963 #>  #> $Item_2 #>        category_1 category_2 #> P[1 0]      0.485      0.515 #> P[0 1]      0.196      0.804 #>  #> $Item_3 #>        category_1 category_2 #> P[1 0]      0.713      0.287 #> P[0 1]      0.317      0.683 #>  #> $Item_4 #>        category_1 category_2 #> P[1 0]      0.401      0.599 #> P[0 1]      0.157      0.843 #>  #> $Item_5 #>        category_1 category_2 #> P[1 0]      0.232      0.768 #> P[0 1]      0.080      0.920 #>  #> $Class.Probability #>           F1 F2  prob #> Profile_1  1  0 0.329 #> Profile_2  0  1 0.671 #>  residuals(mod2) #>        Item_1 Item_2 Item_3 Item_4 Item_5 #> Item_1     NA  0.010  0.020 -0.011 -0.018 #> Item_2  0.109     NA  0.003 -0.018  0.022 #> Item_3  0.412  0.009     NA  0.008 -0.026 #> Item_4  0.132  0.313  0.060     NA  0.040 #> Item_5  0.331  0.487  0.680  1.566     NA residuals(mod2, type = 'exp') #>    Item_1 Item_2 Item_3 Item_4 Item_5 freq     exp std.res #> 1       0      0      0      0      0    3   1.662   1.038 #> 2       0      0      0      0      1    6   5.673   0.137 #> 3       0      0      0      1      0    2   2.556  -0.348 #> 4       0      0      0      1      1   11   9.333   0.546 #> 5       0      0      1      0      0    1   0.702   0.356 #> 6       0      0      1      0      1    1   2.670  -1.022 #> 7       0      0      1      1      0    3   1.211   1.626 #> 8       0      0      1      1      1    4   5.855  -0.767 #> 9       0      1      0      0      0    1   1.826  -0.611 #> 10      0      1      0      0      1    8   6.708   0.499 #> 11      0      1      0      1      1   16  13.561   0.662 #> 12      0      1      1      0      1    3   4.297  -0.625 #> 13      0      1      1      1      0    2   1.972   0.020 #> 14      0      1      1      1      1   15  14.075   0.247 #> 15      1      0      0      0      0   10   9.422   0.188 #> 16      1      0      0      0      1   29  35.372  -1.071 #> 17      1      0      0      1      0   14  16.027  -0.506 #> 18      1      0      0      1      1   81  75.302   0.657 #> 19      1      0      1      0      0    3   4.672  -0.773 #> 20      1      0      1      0      1   28  24.369   0.736 #> 21      1      0      1      1      0   15  11.213   1.131 #> 22      1      0      1      1      1   80  84.968  -0.539 #> 23      1      1      0      0      0   16  11.551   1.309 #> 24      1      1      0      0      1   56  55.154   0.114 #> 25      1      1      0      1      0   21  25.287  -0.853 #> 26      1      1      0      1      1  173 174.541  -0.117 #> 27      1      1      1      0      0   11   8.273   0.948 #> 28      1      1      1      0      1   61  63.783  -0.348 #> 29      1      1      1      1      0   28  29.723  -0.316 #> 30      1      1      1      1      1  298 294.334   0.214 anova(mod2, mod3) #>           AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod2 4956.816 4975.865 4977.335 5010.802 -2467.408                #> mod3 4964.499 4993.938 4996.209 5047.931 -2465.249 4.317  6 0.634 M2(mod2) #>             M2 df         p      RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI #> stats 4.603509  4 0.3304498 0.01228935       0 0.05069941 0.02122285 0.973442 #>             CFI #> stats 0.9893768 itemfit(mod2) #>     item  S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1 Item_1 0.433       2          0  0.805 #> 2 Item_2 1.702       2          0  0.427 #> 3 Item_3 0.747       1          0  0.387 #> 4 Item_4 0.184       2          0  0.912 #> 5 Item_5 0.145       2          0  0.930  # generate classification plots plot(mod2)  plot(mod2, facet_items = FALSE)  plot(mod2, profile = TRUE)   # available for polytomous data mod <- mdirt(Science, 2) #>  summary(mod) #> $Comfort #>        category_1 category_2 category_3 category_4 #> P[1 0]      0.021      0.097      0.773      0.109 #> P[0 1]      0.000      0.059      0.535      0.407 #>  #> $Work #>        category_1 category_2 category_3 category_4 #> P[1 0]      0.125      0.339      0.504      0.033 #> P[0 1]      0.023      0.115      0.559      0.303 #>  #> $Future #>        category_1 category_2 category_3 category_4 #> P[1 0]      0.058      0.305      0.637      0.000 #> P[0 1]      0.001      0.000      0.382      0.616 #>  #> $Benefit #>        category_1 category_2 category_3 category_4 #> P[1 0]      0.074      0.339      0.508      0.079 #> P[0 1]      0.022      0.128      0.469      0.382 #>  #> $Class.Probability #>           F1 F2  prob #> Profile_1  1  0 0.603 #> Profile_2  0  1 0.397 #>  plot(mod)  plot(mod, profile=TRUE)   # classification based on response patterns fscores(mod2, full.scores = FALSE) #>       Item_1 Item_2 Item_3 Item_4 Item_5    Class_1    Class_2 #>  [1,]      0      0      0      0      0 0.98832539 0.01167461 #>  [2,]      0      0      0      0      1 0.96080421 0.03919579 #>  [3,]      0      0      0      1      0 0.95911420 0.04088580 #>  [4,]      0      0      0      1      1 0.87167305 0.12832695 #>  [5,]      0      0      1      0      0 0.94030147 0.05969853 #>  [6,]      0      0      1      0      1 0.82016986 0.17983014 #>  [7,]      0      0      1      1      0 0.81359256 0.18640744 #>  [8,]      0      0      1      1      1 0.55826672 0.44173328 #>  [9,]      0      1      0      0      0 0.95646627 0.04353373 #> [10,]      0      1      0      0      1 0.86416411 0.13583589 #> [11,]      0      1      0      1      1 0.63805843 0.36194157 #> [12,]      0      1      1      0      1 0.54205358 0.45794642 #> [13,]      0      1      1      1      0 0.53111944 0.46888056 #> [14,]      0      1      1      1      1 0.24698538 0.75301462 #> [15,]      1      0      0      0      0 0.94648118 0.05351882 #> [16,]      1      0      0      0      1 0.83662440 0.16337560 #> [17,]      1      0      0      1      0 0.83052457 0.16947543 #> [18,]      1      0      0      1      1 0.58660671 0.41339329 #> [19,]      1      0      1      0      0 0.76692257 0.23307743 #> [20,]      1      0      1      0      1 0.48790756 0.51209244 #> [21,]      1      0      1      1      0 0.47692814 0.52307186 #> [22,]      1      0      1      1      1 0.20887048 0.79112952 #> [23,]      1      1      0      0      0 0.82110202 0.17889798 #> [24,]      1      1      0      0      1 0.57063375 0.42936625 #> [25,]      1      1      0      1      0 0.55982786 0.44017214 #> [26,]      1      1      0      1      1 0.26915168 0.73084832 #> [27,]      1      1      1      0      0 0.46061404 0.53938596 #> [28,]      1      1      1      0      1 0.19825043 0.80174957 #> [29,]      1      1      1      1      0 0.19135355 0.80864645 #> [30,]      1      1      1      1      1 0.06412585 0.93587415  # classify individuals either with the largest posterior probability..... fs <- fscores(mod2) head(fs) #>     Class_1    Class_2 #> 1 0.9883254 0.01167461 #> 2 0.9883254 0.01167461 #> 3 0.9883254 0.01167461 #> 4 0.9608042 0.03919579 #> 5 0.9608042 0.03919579 #> 6 0.9608042 0.03919579 classes <- 1:2 class_max <- classes[apply(apply(fs, 1, max) == fs, 1, which)] table(class_max) #> class_max #>   1   2  #> 291 709   # ... or by probability sampling (i.e., plausible value draws) class_prob <- apply(fs, 1, function(x) sample(1:2, 1, prob=x)) table(class_prob) #> class_prob #>   1   2  #> 345 655   # plausible value imputations for stochastic classification in both classes pvs <- fscores(mod2, plausible.draws=10) tabs <- lapply(pvs, function(x) apply(x, 2, table)) tabs[[1]] #>   [,1] [,2] #> 0  693  328 #> 1  307  672   # fit with random starting points (run in parallel to save time) if(interactive()) mirtCluster() mod <- mdirt(dat, 2, nruns=10) #> Model log-likelihoods: #>  [1] -2467.406 -2467.408 -2467.408 -2467.408 -2467.408 -2467.408 -2467.408 #>  [8] -2467.408 -2467.408 -2467.408  #-------------------------- # Grade of measurement model  # define a custom Theta grid for including a 'fuzzy' class membership (Theta <- matrix(c(1, 0, .5, .5, 0, 1), nrow=3 , ncol=2, byrow=TRUE)) #>      [,1] [,2] #> [1,]  1.0  0.0 #> [2,]  0.5  0.5 #> [3,]  0.0  1.0 (mod_gom <- mdirt(dat, 2, customTheta = Theta)) #>  #> Warning: EM cycles terminated after 500 iterations. #>  #> Call: #> mdirt(data = dat, model = 2, customTheta = Theta) #>  #> Latent class model with 2 classes and 3 profiles. #> FAILED TO CONVERGE within 1e-04 tolerance after 500 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay #> Latent density type: discrete #>  #> Log-likelihood = -2466.602 #> Estimated parameters: 12  #> AIC = 4957.205 #> BIC = 5016.098; SABIC = 4977.985 #> G2 (19) = 21.13, p = 0.3298, RMSEA = 0.011 summary(mod_gom) #> $Item_1 #>            category_1 category_2 #> P[1 0]          0.322      0.678 #> P[0.5 0.5]      0.102      0.898 #> P[0 1]          0.026      0.974 #>  #> $Item_2 #>            category_1 category_2 #> P[1 0]          0.692      0.308 #> P[0.5 0.5]      0.386      0.614 #> P[0 1]          0.150      0.850 #>  #> $Item_3 #>            category_1 category_2 #> P[1 0]          0.866      0.134 #> P[0.5 0.5]      0.592      0.408 #> P[0 1]          0.247      0.753 #>  #> $Item_4 #>            category_1 category_2 #> P[1 0]          0.603      0.397 #> P[0.5 0.5]      0.313      0.687 #> P[0 1]          0.120      0.880 #>  #> $Item_5 #>            category_1 category_2 #> P[1 0]          0.398      0.602 #> P[0.5 0.5]      0.171      0.829 #> P[0 1]          0.061      0.939 #>  #> $Class.Probability #>            F1  F2  prob #> Profile_1 1.0 0.0 0.037 #> Profile_2 0.5 0.5 0.513 #> Profile_3 0.0 1.0 0.450 #>   #----------------- # Multidimensional discrete latent class model  dat <- key2binary(SAT12,      key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  # define Theta grid for three latent classes (Theta <- thetaComb(0:1, 3)) #>      [,1] [,2] [,3] #> [1,]    0    0    0 #> [2,]    1    0    0 #> [3,]    0    1    0 #> [4,]    1    1    0 #> [5,]    0    0    1 #> [6,]    1    0    1 #> [7,]    0    1    1 #> [8,]    1    1    1 (mod_discrete <- mdirt(dat, 3, customTheta = Theta)) #>  #>  #> Call: #> mdirt(data = dat, model = 3, customTheta = Theta) #>  #> Latent class model with 3 classes and 8 profiles. #> Converged within 1e-04 tolerance after 142 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay #> Latent density type: discrete #>  #> Log-likelihood = -9429.715 #> Estimated parameters: 103  #> AIC = 19065.43 #> BIC = 19518.31; SABIC = 19191.32 #> G2 (4294967192) = 11189.71, p = 1, RMSEA = 0 summary(mod_discrete) #> $Item.1 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.868      0.132 #> P[0 1 0]      0.460      0.540 #> P[1 1 0]      0.849      0.151 #> P[0 0 1]      0.341      0.659 #> P[1 0 1]      0.773      0.227 #> P[0 1 1]      0.306      0.694 #> P[1 1 1]      0.744      0.256 #>  #> $Item.2 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.945      0.055 #> P[0 1 0]      0.165      0.835 #> P[1 1 0]      0.774      0.226 #> P[0 0 1]      0.072      0.928 #> P[1 0 1]      0.575      0.425 #> P[0 1 1]      0.015      0.985 #> P[1 1 1]      0.211      0.789 #>  #> $Item.3 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.929      0.071 #> P[0 1 0]      0.337      0.663 #> P[1 1 0]      0.870      0.130 #> P[0 0 1]      0.271      0.729 #> P[1 0 1]      0.830      0.170 #> P[0 1 1]      0.159      0.841 #> P[1 1 1]      0.713      0.287 #>  #> $Item.4 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.844      0.156 #> P[0 1 0]      0.223      0.777 #> P[1 1 0]      0.609      0.391 #> P[0 0 1]      0.428      0.572 #> P[1 0 1]      0.802      0.198 #> P[0 1 1]      0.177      0.823 #> P[1 1 1]      0.538      0.462 #>  #> $Item.5 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.837      0.163 #> P[0 1 0]      0.263      0.737 #> P[1 1 0]      0.647      0.353 #> P[0 0 1]      0.137      0.863 #> P[1 0 1]      0.449      0.551 #> P[0 1 1]      0.053      0.947 #> P[1 1 1]      0.225      0.775 #>  #> $Item.6 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.943      0.057 #> P[0 1 0]      0.334      0.666 #> P[1 1 0]      0.893      0.107 #> P[0 0 1]      0.473      0.527 #> P[1 0 1]      0.937      0.063 #> P[0 1 1]      0.311      0.689 #> P[1 1 1]      0.882      0.118 #>  #> $Item.7 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.766      0.234 #> P[0 1 0]      0.283      0.717 #> P[1 1 0]      0.563      0.437 #> P[0 0 1]      0.088      0.912 #> P[1 0 1]      0.240      0.760 #> P[0 1 1]      0.037      0.963 #> P[1 1 1]      0.111      0.889 #>  #> $Item.8 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.866      0.134 #> P[0 1 0]      0.573      0.427 #> P[1 1 0]      0.897      0.103 #> P[0 0 1]      0.422      0.578 #> P[1 0 1]      0.825      0.175 #> P[0 1 1]      0.495      0.505 #> P[1 1 1]      0.864      0.136 #>  #> $Item.9 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.457      0.543 #> P[0 1 0]      0.252      0.748 #> P[1 1 0]      0.221      0.779 #> P[0 0 1]      0.144      0.856 #> P[1 0 1]      0.124      0.876 #> P[0 1 1]      0.054      0.946 #> P[1 1 1]      0.046      0.954 #>  #> $Item.10 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.904      0.096 #> P[0 1 0]      0.298      0.702 #> P[1 1 0]      0.800      0.200 #> P[0 0 1]      0.189      0.811 #> P[1 0 1]      0.686      0.314 #> P[0 1 1]      0.090      0.910 #> P[1 1 1]      0.482      0.518 #>  #> $Item.11 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.989      0.011 #> P[0 1 0]      0.000      1.000 #> P[1 1 0]      0.039      0.961 #> P[0 0 1]      0.000      1.000 #> P[1 0 1]      0.014      0.986 #> P[0 1 1]      0.000      1.000 #> P[1 1 1]      0.000      1.000 #>  #> $Item.12 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.621      0.379 #> P[0 1 0]      0.434      0.566 #> P[1 1 0]      0.557      0.443 #> P[0 0 1]      0.523      0.477 #> P[1 0 1]      0.643      0.357 #> P[0 1 1]      0.457      0.543 #> P[1 1 1]      0.580      0.420 #>  #> $Item.13 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.849      0.151 #> P[0 1 0]      0.316      0.684 #> P[1 1 0]      0.722      0.278 #> P[0 0 1]      0.087      0.913 #> P[1 0 1]      0.348      0.652 #> P[0 1 1]      0.042      0.958 #> P[1 1 1]      0.198      0.802 #>  #> $Item.14 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.857      0.143 #> P[0 1 0]      0.108      0.892 #> P[1 1 0]      0.421      0.579 #> P[0 0 1]      0.112      0.888 #> P[1 0 1]      0.432      0.568 #> P[0 1 1]      0.015      0.985 #> P[1 1 1]      0.085      0.915 #>  #> $Item.15 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.742      0.258 #> P[0 1 0]      0.289      0.711 #> P[1 1 0]      0.539      0.461 #> P[0 0 1]      0.054      0.946 #> P[1 0 1]      0.141      0.859 #> P[0 1 1]      0.023      0.977 #> P[1 1 1]      0.062      0.938 #>  #> $Item.16 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.846      0.154 #> P[0 1 0]      0.298      0.702 #> P[1 1 0]      0.700      0.300 #> P[0 0 1]      0.315      0.685 #> P[1 0 1]      0.716      0.284 #> P[0 1 1]      0.164      0.836 #> P[1 1 1]      0.517      0.483 #>  #> $Item.17 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.695      0.305 #> P[0 1 0]      0.061      0.939 #> P[1 1 0]      0.130      0.870 #> P[0 0 1]      0.008      0.992 #> P[1 0 1]      0.018      0.982 #> P[0 1 1]      0.001      0.999 #> P[1 1 1]      0.001      0.999 #>  #> $Item.18 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.977      0.023 #> P[0 1 0]      0.217      0.783 #> P[1 1 0]      0.922      0.078 #> P[0 0 1]      0.090      0.910 #> P[1 0 1]      0.808      0.192 #> P[0 1 1]      0.027      0.973 #> P[1 1 1]      0.539      0.461 #>  #> $Item.19 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.830      0.170 #> P[0 1 0]      0.291      0.709 #> P[1 1 0]      0.668      0.332 #> P[0 0 1]      0.200      0.800 #> P[1 0 1]      0.550      0.450 #> P[0 1 1]      0.093      0.907 #> P[1 1 1]      0.334      0.666 #>  #> $Item.20 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.918      0.082 #> P[0 1 0]      0.038      0.962 #> P[1 1 0]      0.306      0.694 #> P[0 0 1]      0.017      0.983 #> P[1 0 1]      0.164      0.836 #> P[0 1 1]      0.001      0.999 #> P[1 1 1]      0.008      0.992 #>  #> $Item.21 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.434      0.566 #> P[0 1 0]      0.223      0.777 #> P[1 1 0]      0.180      0.820 #> P[0 0 1]      0.110      0.890 #> P[1 0 1]      0.086      0.914 #> P[0 1 1]      0.034      0.966 #> P[1 1 1]      0.026      0.974 #>  #> $Item.22 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.997      0.003 #> P[0 1 0]      0.001      0.999 #> P[1 1 0]      0.209      0.791 #> P[0 0 1]      0.000      1.000 #> P[1 0 1]      0.055      0.945 #> P[0 1 1]      0.000      1.000 #> P[1 1 1]      0.000      1.000 #>  #> $Item.23 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.864      0.136 #> P[0 1 0]      0.284      0.716 #> P[1 1 0]      0.717      0.283 #> P[0 0 1]      0.422      0.578 #> P[1 0 1]      0.823      0.177 #> P[0 1 1]      0.225      0.775 #> P[1 1 1]      0.649      0.351 #>  #> $Item.24 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.825      0.175 #> P[0 1 0]      0.300      0.700 #> P[1 1 0]      0.668      0.332 #> P[0 0 1]      0.068      0.932 #> P[1 0 1]      0.256      0.744 #> P[0 1 1]      0.030      0.970 #> P[1 1 1]      0.129      0.871 #>  #> $Item.25 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.869      0.131 #> P[0 1 0]      0.350      0.650 #> P[1 1 0]      0.782      0.218 #> P[0 0 1]      0.280      0.720 #> P[1 0 1]      0.721      0.279 #> P[0 1 1]      0.174      0.826 #> P[1 1 1]      0.583      0.417 #>  #> $Item.26 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.967      0.033 #> P[0 1 0]      0.140      0.860 #> P[1 1 0]      0.825      0.175 #> P[0 0 1]      0.093      0.907 #> P[1 0 1]      0.748      0.252 #> P[0 1 1]      0.016      0.984 #> P[1 1 1]      0.326      0.674 #>  #> $Item.27 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.839      0.161 #> P[0 1 0]      0.136      0.864 #> P[1 1 0]      0.451      0.549 #> P[0 0 1]      0.023      0.977 #> P[1 0 1]      0.110      0.890 #> P[0 1 1]      0.004      0.996 #> P[1 1 1]      0.019      0.981 #>  #> $Item.28 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.888      0.112 #> P[0 1 0]      0.222      0.778 #> P[1 1 0]      0.693      0.307 #> P[0 0 1]      0.163      0.837 #> P[1 0 1]      0.606      0.394 #> P[0 1 1]      0.053      0.947 #> P[1 1 1]      0.305      0.695 #>  #> $Item.29 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.893      0.107 #> P[0 1 0]      0.292      0.708 #> P[1 1 0]      0.774      0.226 #> P[0 0 1]      0.323      0.677 #> P[1 0 1]      0.799      0.201 #> P[0 1 1]      0.164      0.836 #> P[1 1 1]      0.620      0.380 #>  #> $Item.30 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.698      0.302 #> P[0 1 0]      0.455      0.545 #> P[1 1 0]      0.659      0.341 #> P[0 0 1]      0.378      0.622 #> P[1 0 1]      0.584      0.416 #> P[0 1 1]      0.336      0.664 #> P[1 1 1]      0.540      0.460 #>  #> $Item.31 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.977      0.023 #> P[0 1 0]      0.024      0.976 #> P[1 1 0]      0.509      0.491 #> P[0 0 1]      0.005      0.995 #> P[1 0 1]      0.166      0.834 #> P[0 1 1]      0.000      1.000 #> P[1 1 1]      0.005      0.995 #>  #> $Item.32 #>          category_1 category_2 #> P[0 0 0]      0.500      0.500 #> P[1 0 0]      0.728      0.272 #> P[0 1 0]      0.568      0.432 #> P[1 1 0]      0.779      0.221 #> P[0 0 1]      0.702      0.298 #> P[1 0 1]      0.863      0.137 #> P[0 1 1]      0.755      0.245 #> P[1 1 1]      0.892      0.108 #>  #> $Class.Probability #>           F1 F2 F3  prob #> Profile_1  0  0  0 0.000 #> Profile_2  1  0  0 0.004 #> Profile_3  0  1  0 0.002 #> Profile_4  1  1  0 0.194 #> Profile_5  0  0  1 0.084 #> Profile_6  1  0  1 0.368 #> Profile_7  0  1  1 0.058 #> Profile_8  1  1  1 0.290 #>   # Located latent class model model <- mirt.model('C1 = 1-32                      C2 = 1-32                      C3 = 1-32                      CONSTRAIN = (1-32, a1), (1-32, a2), (1-32, a3)') (mod_located <- mdirt(dat, model, customTheta = diag(3))) #>  #>  #> Call: #> mdirt(data = dat, model = model, customTheta = diag(3)) #>  #> Latent class model with 3 classes and 3 profiles. #> Converged within 1e-04 tolerance after 364 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay #> Latent density type: discrete #>  #> Log-likelihood = -12771.08 #> Estimated parameters: 5  #> AIC = 25552.15 #> BIC = 25574.14; SABIC = 25558.26 #> G2 (4294967290) = 17872.43, p = 1, RMSEA = 0 summary(mod_located) #> $Item.1 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.2 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.3 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.4 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.5 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.6 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.7 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.8 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.9 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.10 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.11 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.12 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.13 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.14 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.15 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.16 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.17 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.18 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.19 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.20 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.21 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.22 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.23 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.24 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.25 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.26 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.27 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.28 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.29 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.30 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.31 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Item.32 #>          category_1 category_2 #> P[1 0 0]      0.578      0.422 #> P[0 1 0]      0.410      0.590 #> P[0 0 1]      0.190      0.810 #>  #> $Class.Probability #>           C1 C2 C3  prob #> Profile_1  1  0  0 0.339 #> Profile_2  0  1  0 0.498 #> Profile_3  0  0  1 0.164 #>   #----------------- ### DINA model example # generate some suitable data for a two dimensional DINA application #     (first columns are intercepts) set.seed(1) Theta <- expand.table(matrix(c(1,0,0,0,                                1,1,0,0,                                1,0,1,0,                                1,1,1,1), 4, 4, byrow=TRUE),                       freq = c(200,200,100,500)) a <- matrix(c(rnorm(15, -1.5, .5), rlnorm(5, .2, .3), numeric(15), rlnorm(5, .2, .3),               numeric(15), rlnorm(5, .2, .3)), 15, 4)  guess <- plogis(a[11:15,1]) # population guess slip <- 1 - plogis(rowSums(a[11:15,])) # population slip  dat <- simdata(a, Theta=Theta, itemtype = 'lca')  # first column is the intercept, 2nd and 3rd are attributes theta <- cbind(1, thetaComb(0:1, 2)) theta <- cbind(theta, theta[,2] * theta[,3]) #DINA interaction of main attributes model <- mirt.model('Intercept = 1-15                      A1 = 1-5                      A2 = 6-10                      A1A2 = 11-15')  # last 5 items are DINA (first 10 are unidimensional C-RUMs) DINA <- mdirt(dat, model, customTheta = theta) #>  coef(DINA, simplify=TRUE) #> $items #>             a1    a2    a3    a4 #> Item_1  -1.630 1.115 0.000 0.000 #> Item_2  -1.052 0.841 0.000 0.000 #> Item_3  -1.582 1.271 0.000 0.000 #> Item_4  -0.388 1.229 0.000 0.000 #> Item_5  -1.054 1.340 0.000 0.000 #> Item_6  -2.569 0.000 2.500 0.000 #> Item_7  -1.100 0.000 1.435 0.000 #> Item_8  -1.103 0.000 1.054 0.000 #> Item_9  -1.474 0.000 1.041 0.000 #> Item_10 -1.620 0.000 1.359 0.000 #> Item_11 -0.542 0.000 0.000 0.997 #> Item_12 -1.584 0.000 0.000 1.609 #> Item_13 -1.881 0.000 0.000 0.934 #> Item_14 -2.663 0.000 0.000 0.912 #> Item_15 -0.813 0.000 0.000 1.005 #>  #> $group.intercepts #>         c1    c2     c3 #> par -0.545 -1.53 -1.468 #>  summary(DINA) #> $Item_1 #>            category_1 category_2 #> P[1 0 0 0]      0.836      0.164 #> P[1 1 0 0]      0.626      0.374 #> P[1 0 1 0]      0.836      0.164 #> P[1 1 1 1]      0.626      0.374 #>  #> $Item_2 #>            category_1 category_2 #> P[1 0 0 0]      0.741      0.259 #> P[1 1 0 0]      0.553      0.447 #> P[1 0 1 0]      0.741      0.259 #> P[1 1 1 1]      0.553      0.447 #>  #> $Item_3 #>            category_1 category_2 #> P[1 0 0 0]      0.829      0.171 #> P[1 1 0 0]      0.577      0.423 #> P[1 0 1 0]      0.829      0.171 #> P[1 1 1 1]      0.577      0.423 #>  #> $Item_4 #>            category_1 category_2 #> P[1 0 0 0]      0.596      0.404 #> P[1 1 0 0]      0.301      0.699 #> P[1 0 1 0]      0.596      0.404 #> P[1 1 1 1]      0.301      0.699 #>  #> $Item_5 #>            category_1 category_2 #> P[1 0 0 0]      0.742      0.258 #> P[1 1 0 0]      0.429      0.571 #> P[1 0 1 0]      0.742      0.258 #> P[1 1 1 1]      0.429      0.571 #>  #> $Item_6 #>            category_1 category_2 #> P[1 0 0 0]      0.929      0.071 #> P[1 1 0 0]      0.929      0.071 #> P[1 0 1 0]      0.517      0.483 #> P[1 1 1 1]      0.517      0.483 #>  #> $Item_7 #>            category_1 category_2 #> P[1 0 0 0]      0.750      0.250 #> P[1 1 0 0]      0.750      0.250 #> P[1 0 1 0]      0.417      0.583 #> P[1 1 1 1]      0.417      0.583 #>  #> $Item_8 #>            category_1 category_2 #> P[1 0 0 0]      0.751      0.249 #> P[1 1 0 0]      0.751      0.249 #> P[1 0 1 0]      0.512      0.488 #> P[1 1 1 1]      0.512      0.488 #>  #> $Item_9 #>            category_1 category_2 #> P[1 0 0 0]      0.814      0.186 #> P[1 1 0 0]      0.814      0.186 #> P[1 0 1 0]      0.607      0.393 #> P[1 1 1 1]      0.607      0.393 #>  #> $Item_10 #>            category_1 category_2 #> P[1 0 0 0]      0.835      0.165 #> P[1 1 0 0]      0.835      0.165 #> P[1 0 1 0]      0.565      0.435 #> P[1 1 1 1]      0.565      0.435 #>  #> $Item_11 #>            category_1 category_2 #> P[1 0 0 0]      0.632      0.368 #> P[1 1 0 0]      0.632      0.368 #> P[1 0 1 0]      0.632      0.368 #> P[1 1 1 1]      0.388      0.612 #>  #> $Item_12 #>            category_1 category_2 #> P[1 0 0 0]      0.830      0.170 #> P[1 1 0 0]      0.830      0.170 #> P[1 0 1 0]      0.830      0.170 #> P[1 1 1 1]      0.494      0.506 #>  #> $Item_13 #>            category_1 category_2 #> P[1 0 0 0]      0.868      0.132 #> P[1 1 0 0]      0.868      0.132 #> P[1 0 1 0]      0.868      0.132 #> P[1 1 1 1]      0.720      0.280 #>  #> $Item_14 #>            category_1 category_2 #> P[1 0 0 0]      0.935      0.065 #> P[1 1 0 0]      0.935      0.065 #> P[1 0 1 0]      0.935      0.065 #> P[1 1 1 1]      0.852      0.148 #>  #> $Item_15 #>            category_1 category_2 #> P[1 0 0 0]      0.693      0.307 #> P[1 1 0 0]      0.693      0.307 #> P[1 0 1 0]      0.693      0.307 #> P[1 1 1 1]      0.452      0.548 #>  #> $Class.Probability #>           Intercept A1 A2 A1A2  prob #> Profile_1         1  0  0    0 0.286 #> Profile_2         1  1  0    0 0.107 #> Profile_3         1  0  1    0 0.114 #> Profile_4         1  1  1    1 0.493 #>  M2(DINA) # fits well (as it should) #>             M2 df         p      RMSEA RMSEA_5   RMSEA_95      SRMSR       TLI #> stats 96.49206 87 0.2281074 0.01045052       0 0.02080658 0.02972262 0.9655028 #>             CFI #> stats 0.9714166  cfs <- coef(DINA, simplify=TRUE)$items[11:15,] cbind(guess, estguess = plogis(cfs[,1])) #>              guess   estguess #> Item_11 0.32210618 0.36762331 #> Item_12 0.21331157 0.17019244 #> Item_13 0.14056317 0.13232904 #> Item_14 0.06866689 0.06517149 #> Item_15 0.28139862 0.30727217 cbind(slip, estslip = 1 - plogis(rowSums(cfs))) #>              slip   estslip #> Item_11 0.3877218 0.3883873 #> Item_12 0.5348058 0.4937323 #> Item_13 0.7359368 0.7203743 #> Item_14 0.8247931 0.8520713 #> Item_15 0.3900682 0.4520799   ### DINO model example theta <- cbind(1, thetaComb(0:1, 2)) # define theta matrix with negative interaction term (theta <- cbind(theta, -theta[,2] * theta[,3])) #>      [,1] [,2] [,3] [,4] #> [1,]    1    0    0    0 #> [2,]    1    1    0    0 #> [3,]    1    0    1    0 #> [4,]    1    1    1   -1  model <- mirt.model('Intercept = 1-15                      A1 = 1-5, 11-15                      A2 = 6-15                      Yoshi = 11-15                      CONSTRAIN = (11,a2,a3,a4), (12,a2,a3,a4), (13,a2,a3,a4),                                  (14,a2,a3,a4), (15,a2,a3,a4)')  # last five items are DINOs (first 10 are unidimensional C-RUMs) DINO <- mdirt(dat, model, customTheta = theta) #>  coef(DINO, simplify=TRUE) #> $items #>             a1     a2    a3    a4 #> Item_1  -0.742 -1.828 0.000 0.000 #> Item_2  -0.402 -1.136 0.000 0.000 #> Item_3  -0.548 -3.194 0.000 0.000 #> Item_4   0.579 -2.116 0.000 0.000 #> Item_5  -0.046 -1.620 0.000 0.000 #> Item_6  -2.818  0.000 2.659 0.000 #> Item_7  -1.187  0.000 1.457 0.000 #> Item_8  -1.154  0.000 1.055 0.000 #> Item_9  -1.583  0.000 1.121 0.000 #> Item_10 -1.736  0.000 1.427 0.000 #> Item_11 -0.937  1.163 1.163 1.163 #> Item_12 -1.957  1.577 1.577 1.577 #> Item_13 -2.088  0.915 0.915 0.915 #> Item_14 -3.713  1.840 1.840 1.840 #> Item_15 -1.130  1.075 1.075 1.075 #>  #> $group.intercepts #>        c1    c2    c3 #> par 2.029 1.084 2.947 #>  summary(DINO) #> $Item_1 #>             category_1 category_2 #> P[1 0 0 0]       0.678      0.322 #> P[1 1 0 0]       0.929      0.071 #> P[1 0 1 0]       0.678      0.322 #> P[1 1 1 -1]      0.929      0.071 #>  #> $Item_2 #>             category_1 category_2 #> P[1 0 0 0]       0.599      0.401 #> P[1 1 0 0]       0.823      0.177 #> P[1 0 1 0]       0.599      0.401 #> P[1 1 1 -1]      0.823      0.177 #>  #> $Item_3 #>             category_1 category_2 #> P[1 0 0 0]       0.634      0.366 #> P[1 1 0 0]       0.977      0.023 #> P[1 0 1 0]       0.634      0.366 #> P[1 1 1 -1]      0.977      0.023 #>  #> $Item_4 #>             category_1 category_2 #> P[1 0 0 0]       0.359      0.641 #> P[1 1 0 0]       0.823      0.177 #> P[1 0 1 0]       0.359      0.641 #> P[1 1 1 -1]      0.823      0.177 #>  #> $Item_5 #>             category_1 category_2 #> P[1 0 0 0]       0.511      0.489 #> P[1 1 0 0]       0.841      0.159 #> P[1 0 1 0]       0.511      0.489 #> P[1 1 1 -1]      0.841      0.159 #>  #> $Item_6 #>             category_1 category_2 #> P[1 0 0 0]       0.944      0.056 #> P[1 1 0 0]       0.944      0.056 #> P[1 0 1 0]       0.540      0.460 #> P[1 1 1 -1]      0.540      0.460 #>  #> $Item_7 #>             category_1 category_2 #> P[1 0 0 0]       0.766      0.234 #> P[1 1 0 0]       0.766      0.234 #> P[1 0 1 0]       0.433      0.567 #> P[1 1 1 -1]      0.433      0.567 #>  #> $Item_8 #>             category_1 category_2 #> P[1 0 0 0]       0.760      0.240 #> P[1 1 0 0]       0.760      0.240 #> P[1 0 1 0]       0.525      0.475 #> P[1 1 1 -1]      0.525      0.475 #>  #> $Item_9 #>             category_1 category_2 #> P[1 0 0 0]       0.830      0.170 #> P[1 1 0 0]       0.830      0.170 #> P[1 0 1 0]       0.613      0.387 #> P[1 1 1 -1]      0.613      0.387 #>  #> $Item_10 #>             category_1 category_2 #> P[1 0 0 0]       0.850      0.150 #> P[1 1 0 0]       0.850      0.150 #> P[1 0 1 0]       0.577      0.423 #> P[1 1 1 -1]      0.577      0.423 #>  #> $Item_11 #>             category_1 category_2 #> P[1 0 0 0]       0.718      0.282 #> P[1 1 0 0]       0.444      0.556 #> P[1 0 1 0]       0.444      0.556 #> P[1 1 1 -1]      0.444      0.556 #>  #> $Item_12 #>             category_1 category_2 #> P[1 0 0 0]       0.876      0.124 #> P[1 1 0 0]       0.594      0.406 #> P[1 0 1 0]       0.594      0.406 #> P[1 1 1 -1]      0.594      0.406 #>  #> $Item_13 #>             category_1 category_2 #> P[1 0 0 0]       0.890      0.110 #> P[1 1 0 0]       0.764      0.236 #> P[1 0 1 0]       0.764      0.236 #> P[1 1 1 -1]      0.764      0.236 #>  #> $Item_14 #>             category_1 category_2 #> P[1 0 0 0]       0.976      0.024 #> P[1 1 0 0]       0.867      0.133 #> P[1 0 1 0]       0.867      0.133 #> P[1 1 1 -1]      0.867      0.133 #>  #> $Item_15 #>             category_1 category_2 #> P[1 0 0 0]       0.756      0.244 #> P[1 1 0 0]       0.514      0.486 #> P[1 0 1 0]       0.514      0.486 #> P[1 1 1 -1]      0.514      0.486 #>  #> $Class.Probability #>           Intercept A1 A2 Yoshi  prob #> Profile_1         1  0  0     0 0.249 #> Profile_2         1  1  0     0 0.097 #> Profile_3         1  0  1     0 0.622 #> Profile_4         1  1  1    -1 0.033 #>  M2(DINO) #doesn't fit as well, because not the generating model #>            M2 df           p      RMSEA    RMSEA_5   RMSEA_95      SRMSR #> stats 146.478 87 6.93916e-05 0.02615988 0.01856199 0.03336756 0.04140113 #>             TLI       CFI #> stats 0.7838382 0.8208945  ## C-RUM (analogous to MIRT model) theta <- cbind(1, thetaComb(0:1, 2)) model <- mirt.model('Intercept = 1-15                      A1 = 1-5, 11-15                      A2 = 6-15')  CRUM <- mdirt(dat, model, customTheta = theta) #>  coef(CRUM, simplify=TRUE) #> $items #>             a1     a2    a3 #> Item_1  -1.405  0.996 0.000 #> Item_2  -0.950  0.876 0.000 #> Item_3  -1.328  1.145 0.000 #> Item_4  -0.235  1.309 0.000 #> Item_5  -0.855  1.342 0.000 #> Item_6  -2.592  0.000 2.479 #> Item_7  -1.095  0.000 1.388 #> Item_8  -1.127  0.000 1.061 #> Item_9  -1.505  0.000 1.058 #> Item_10 -1.674  0.000 1.399 #> Item_11 -0.589  0.491 0.500 #> Item_12 -1.730  1.049 0.743 #> Item_13 -2.052  0.255 0.820 #> Item_14 -3.276 -0.695 1.963 #> Item_15 -0.989 -0.008 1.069 #>  #> $group.intercepts #>         c1     c2     c3 #> par -0.225 -2.397 -0.726 #>  summary(CRUM) #> $Item_1 #>          category_1 category_2 #> P[1 0 0]      0.803      0.197 #> P[1 1 0]      0.601      0.399 #> P[1 0 1]      0.803      0.197 #> P[1 1 1]      0.601      0.399 #>  #> $Item_2 #>          category_1 category_2 #> P[1 0 0]      0.721      0.279 #> P[1 1 0]      0.519      0.481 #> P[1 0 1]      0.721      0.279 #> P[1 1 1]      0.519      0.481 #>  #> $Item_3 #>          category_1 category_2 #> P[1 0 0]      0.791      0.209 #> P[1 1 0]      0.546      0.454 #> P[1 0 1]      0.791      0.209 #> P[1 1 1]      0.546      0.454 #>  #> $Item_4 #>          category_1 category_2 #> P[1 0 0]      0.559      0.441 #> P[1 1 0]      0.255      0.745 #> P[1 0 1]      0.559      0.441 #> P[1 1 1]      0.255      0.745 #>  #> $Item_5 #>          category_1 category_2 #> P[1 0 0]      0.702      0.298 #> P[1 1 0]      0.381      0.619 #> P[1 0 1]      0.702      0.298 #> P[1 1 1]      0.381      0.619 #>  #> $Item_6 #>          category_1 category_2 #> P[1 0 0]      0.930      0.070 #> P[1 1 0]      0.930      0.070 #> P[1 0 1]      0.528      0.472 #> P[1 1 1]      0.528      0.472 #>  #> $Item_7 #>          category_1 category_2 #> P[1 0 0]      0.749      0.251 #> P[1 1 0]      0.749      0.251 #> P[1 0 1]      0.427      0.573 #> P[1 1 1]      0.427      0.573 #>  #> $Item_8 #>          category_1 category_2 #> P[1 0 0]      0.755      0.245 #> P[1 1 0]      0.755      0.245 #> P[1 0 1]      0.517      0.483 #> P[1 1 1]      0.517      0.483 #>  #> $Item_9 #>          category_1 category_2 #> P[1 0 0]      0.818      0.182 #> P[1 1 0]      0.818      0.182 #> P[1 0 1]      0.610      0.390 #> P[1 1 1]      0.610      0.390 #>  #> $Item_10 #>          category_1 category_2 #> P[1 0 0]      0.842      0.158 #> P[1 1 0]      0.842      0.158 #> P[1 0 1]      0.568      0.432 #> P[1 1 1]      0.568      0.432 #>  #> $Item_11 #>          category_1 category_2 #> P[1 0 0]      0.643      0.357 #> P[1 1 0]      0.525      0.475 #> P[1 0 1]      0.522      0.478 #> P[1 1 1]      0.401      0.599 #>  #> $Item_12 #>          category_1 category_2 #> P[1 0 0]      0.849      0.151 #> P[1 1 0]      0.664      0.336 #> P[1 0 1]      0.729      0.271 #> P[1 1 1]      0.485      0.515 #>  #> $Item_13 #>          category_1 category_2 #> P[1 0 0]      0.886      0.114 #> P[1 1 0]      0.858      0.142 #> P[1 0 1]      0.774      0.226 #> P[1 1 1]      0.727      0.273 #>  #> $Item_14 #>          category_1 category_2 #> P[1 0 0]      0.964      0.036 #> P[1 1 0]      0.981      0.019 #> P[1 0 1]      0.788      0.212 #> P[1 1 1]      0.882      0.118 #>  #> $Item_15 #>          category_1 category_2 #> P[1 0 0]      0.729      0.271 #> P[1 1 0]      0.730      0.270 #> P[1 0 1]      0.480      0.520 #> P[1 1 1]      0.482      0.518 #>  #> $Class.Probability #>           Intercept A1 A2  prob #> Profile_1         1  0  0 0.337 #> Profile_2         1  1  0 0.038 #> Profile_3         1  0  1 0.204 #> Profile_4         1  1  1 0.421 #>   # good fit, but over-saturated (main effects for items 11-15 can be set to 0) M2(CRUM) #>            M2 df         p       RMSEA RMSEA_5   RMSEA_95      SRMSR       TLI #> stats 85.5485 82 0.3725544 0.006581616       0 0.01905772 0.02788709 0.9863173 #>             CFI #> stats 0.9893144  #------------------ # multidimensional latent class model  dat <- key2binary(SAT12,      key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  # 5 latent classes within 2 different sets of items model <- mirt.model('C1 = 1-16                      C2 = 1-16                      C3 = 1-16                      C4 = 1-16                      C5 = 1-16                      C6 = 17-32                      C7 = 17-32                      C8 = 17-32                      C9 = 17-32                      C10 = 17-32                      CONSTRAIN = (1-16, a1), (1-16, a2), (1-16, a3), (1-16, a4), (1-16, a5),                        (17-32, a6), (17-32, a7), (17-32, a8), (17-32, a9), (17-32, a10)')  theta <- diag(10) # defined explicitly. Otherwise, this profile is assumed mod <- mdirt(dat, model, customTheta = theta) #>  coef(mod, simplify=TRUE) #> $items #>             a1     a2     a3     a4     a5   a6    a7    a8    a9   a10 #> Item.1  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.2  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.3  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.4  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.5  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.6  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.7  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.8  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.9  -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.10 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.11 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.12 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.13 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.14 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.15 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.16 -0.921 -0.679 -0.574 -0.542 -0.363 0.00 0.000 0.000 0.000 0.000 #> Item.17  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.18  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.19  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.20  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.21  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.22  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.23  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.24  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.25  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.26  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.27  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.28  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.29  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.30  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.31  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #> Item.32  0.000  0.000  0.000  0.000  0.000 0.31 0.443 1.389 1.396 1.419 #>  #> $group.intercepts #>         c1     c2    c3    c4    c5    c6    c7    c8    c9 #> par -2.737 -1.478 0.137 1.489 2.185 2.882 2.315 2.144 1.112 #>  summary(mod) #> $Item.1 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.2 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.3 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.4 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.5 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.6 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.7 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.8 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.9 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.10 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.11 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.12 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.13 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.14 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.15 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.16 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.715      0.285 #> P[0 1 0 0 0 0 0 0 0 0]      0.663      0.337 #> P[0 0 1 0 0 0 0 0 0 0]      0.640      0.360 #> P[0 0 0 1 0 0 0 0 0 0]      0.632      0.368 #> P[0 0 0 0 1 0 0 0 0 0]      0.590      0.410 #> P[0 0 0 0 0 1 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 1 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 1 0 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 1 0]      0.500      0.500 #> P[0 0 0 0 0 0 0 0 0 1]      0.500      0.500 #>  #> $Item.17 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.18 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.19 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.20 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.21 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.22 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.23 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.24 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.25 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.26 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.27 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.28 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.29 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.30 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.31 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Item.32 #>                        category_1 category_2 #> P[1 0 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 1 0 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 1 0 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 1 0 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 1 0 0 0 0 0]      0.500      0.500 #> P[0 0 0 0 0 1 0 0 0 0]      0.423      0.577 #> P[0 0 0 0 0 0 1 0 0 0]      0.391      0.609 #> P[0 0 0 0 0 0 0 1 0 0]      0.200      0.800 #> P[0 0 0 0 0 0 0 0 1 0]      0.198      0.802 #> P[0 0 0 0 0 0 0 0 0 1]      0.195      0.805 #>  #> $Class.Probability #>            C1 C2 C3 C4 C5 C6 C7 C8 C9 C10  prob #> Profile_1   1  0  0  0  0  0  0  0  0   0 0.001 #> Profile_2   0  1  0  0  0  0  0  0  0   0 0.004 #> Profile_3   0  0  1  0  0  0  0  0  0   0 0.021 #> Profile_4   0  0  0  1  0  0  0  0  0   0 0.080 #> Profile_5   0  0  0  0  1  0  0  0  0   0 0.161 #> Profile_6   0  0  0  0  0  1  0  0  0   0 0.323 #> Profile_7   0  0  0  0  0  0  1  0  0   0 0.183 #> Profile_8   0  0  0  0  0  0  0  1  0   0 0.154 #> Profile_9   0  0  0  0  0  0  0  0  1   0 0.055 #> Profile_10  0  0  0  0  0  0  0  0  0   1 0.018 #>   #------------------ # multiple group with constrained group probabilities  dat <- key2binary(SAT12,    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) group <- rep(c('G1', 'G2'), each = nrow(SAT12)/2) Theta <- diag(2)  # the latent class parameters are technically located in the (nitems + 1) location model <- mirt.model('A1 = 1-32                      A2 = 1-32                      CONSTRAINB = (33, c1)') mod <- mdirt(dat, model, group = group, customTheta = Theta) #>  coef(mod, simplify=TRUE) #> $G1 #> $items #>             a1     a2 #> Item.1  -1.462 -0.238 #> Item.2  -0.522  1.905 #> Item.3  -1.639 -0.087 #> Item.4  -1.181  0.114 #> Item.5  -0.149  1.966 #> Item.6  -2.913 -1.120 #> Item.7   0.469  2.107 #> Item.8  -1.833 -0.731 #> Item.9   1.888  2.722 #> Item.10 -0.972  0.380 #> Item.11  4.484  9.810 #> Item.12 -0.381 -0.305 #> Item.13  0.008  1.820 #> Item.14  0.411  2.339 #> Item.15  0.737  3.359 #> Item.16 -0.997  0.141 #> Item.17  2.648  4.629 #> Item.18 -1.588  0.582 #> Item.19 -0.415  1.056 #> Item.20  1.253  4.570 #> Item.21  1.959  3.169 #> Item.22  1.965  9.847 #> Item.23 -1.633 -0.393 #> Item.24  0.270  2.349 #> Item.25 -1.224  0.328 #> Item.26 -0.973  1.196 #> Item.27  1.151  9.631 #> Item.28 -0.478  1.176 #> Item.29 -1.235  0.071 #> Item.30 -0.514  0.150 #> Item.31  0.761  9.640 #> Item.32 -1.380 -1.742 #>  #> $group.intercepts #>        c1 #> par 0.416 #>  #>  #> $G2 #> $items #>             a1     a2 #> Item.1  -1.384 -0.426 #> Item.2  -0.490  1.719 #> Item.3  -1.885 -0.062 #> Item.4  -0.826  0.229 #> Item.5   0.001  1.267 #> Item.6  -2.386 -0.601 #> Item.7   0.857  2.666 #> Item.8  -1.887 -0.942 #> Item.9   1.627  2.611 #> Item.10 -1.047  0.943 #> Item.11  3.082  9.727 #> Item.12 -0.487 -0.110 #> Item.13  0.251  1.767 #> Item.14  0.380  2.385 #> Item.15  1.233  2.786 #> Item.16 -0.740  0.606 #> Item.17  2.958  9.692 #> Item.18 -1.969  0.782 #> Item.19 -0.235  1.065 #> Item.20  1.454  5.474 #> Item.21  2.271  2.770 #> Item.22  2.280  6.826 #> Item.23 -1.107  0.202 #> Item.24  0.553  2.564 #> Item.25 -0.869  0.045 #> Item.26 -1.272  1.388 #> Item.27  1.381  3.529 #> Item.28 -0.607  1.313 #> Item.29 -1.391  0.200 #> Item.30 -0.476  0.112 #> Item.31  1.208  4.732 #> Item.32 -2.027 -1.482 #>  #> $group.intercepts #>        c1 #> par 0.416 #>  #>  summary(mod) #> $G1 #> $Item.1 #>        category_1 category_2 #> P[1 0]      0.812      0.188 #> P[0 1]      0.559      0.441 #>  #> $Item.2 #>        category_1 category_2 #> P[1 0]      0.628      0.372 #> P[0 1]      0.130      0.870 #>  #> $Item.3 #>        category_1 category_2 #> P[1 0]      0.837      0.163 #> P[0 1]      0.522      0.478 #>  #> $Item.4 #>        category_1 category_2 #> P[1 0]      0.765      0.235 #> P[0 1]      0.472      0.528 #>  #> $Item.5 #>        category_1 category_2 #> P[1 0]      0.537      0.463 #> P[0 1]      0.123      0.877 #>  #> $Item.6 #>        category_1 category_2 #> P[1 0]      0.948      0.052 #> P[0 1]      0.754      0.246 #>  #> $Item.7 #>        category_1 category_2 #> P[1 0]      0.385      0.615 #> P[0 1]      0.108      0.892 #>  #> $Item.8 #>        category_1 category_2 #> P[1 0]      0.862      0.138 #> P[0 1]      0.675      0.325 #>  #> $Item.9 #>        category_1 category_2 #> P[1 0]      0.131      0.869 #> P[0 1]      0.062      0.938 #>  #> $Item.10 #>        category_1 category_2 #> P[1 0]      0.726      0.274 #> P[0 1]      0.406      0.594 #>  #> $Item.11 #>        category_1 category_2 #> P[1 0]      0.011      0.989 #> P[0 1]      0.000      1.000 #>  #> $Item.12 #>        category_1 category_2 #> P[1 0]      0.594      0.406 #> P[0 1]      0.576      0.424 #>  #> $Item.13 #>        category_1 category_2 #> P[1 0]      0.498      0.502 #> P[0 1]      0.139      0.861 #>  #> $Item.14 #>        category_1 category_2 #> P[1 0]      0.399      0.601 #> P[0 1]      0.088      0.912 #>  #> $Item.15 #>        category_1 category_2 #> P[1 0]      0.324      0.676 #> P[0 1]      0.034      0.966 #>  #> $Item.16 #>        category_1 category_2 #> P[1 0]      0.731      0.269 #> P[0 1]      0.465      0.535 #>  #> $Item.17 #>        category_1 category_2 #> P[1 0]      0.066      0.934 #> P[0 1]      0.010      0.990 #>  #> $Item.18 #>        category_1 category_2 #> P[1 0]      0.830      0.170 #> P[0 1]      0.358      0.642 #>  #> $Item.19 #>        category_1 category_2 #> P[1 0]      0.602      0.398 #> P[0 1]      0.258      0.742 #>  #> $Item.20 #>        category_1 category_2 #> P[1 0]      0.222      0.778 #> P[0 1]      0.010      0.990 #>  #> $Item.21 #>        category_1 category_2 #> P[1 0]      0.124      0.876 #> P[0 1]      0.040      0.960 #>  #> $Item.22 #>        category_1 category_2 #> P[1 0]      0.123      0.877 #> P[0 1]      0.000      1.000 #>  #> $Item.23 #>        category_1 category_2 #> P[1 0]      0.837      0.163 #> P[0 1]      0.597      0.403 #>  #> $Item.24 #>        category_1 category_2 #> P[1 0]      0.433      0.567 #> P[0 1]      0.087      0.913 #>  #> $Item.25 #>        category_1 category_2 #> P[1 0]      0.773      0.227 #> P[0 1]      0.419      0.581 #>  #> $Item.26 #>        category_1 category_2 #> P[1 0]      0.726      0.274 #> P[0 1]      0.232      0.768 #>  #> $Item.27 #>        category_1 category_2 #> P[1 0]       0.24       0.76 #> P[0 1]       0.00       1.00 #>  #> $Item.28 #>        category_1 category_2 #> P[1 0]      0.617      0.383 #> P[0 1]      0.236      0.764 #>  #> $Item.29 #>        category_1 category_2 #> P[1 0]      0.775      0.225 #> P[0 1]      0.482      0.518 #>  #> $Item.30 #>        category_1 category_2 #> P[1 0]      0.626      0.374 #> P[0 1]      0.463      0.537 #>  #> $Item.31 #>        category_1 category_2 #> P[1 0]      0.318      0.682 #> P[0 1]      0.000      1.000 #>  #> $Item.32 #>        category_1 category_2 #> P[1 0]      0.799      0.201 #> P[0 1]      0.851      0.149 #>  #> $Class.Probability #>           A1 A2  prob #> Profile_1  1  0 0.602 #> Profile_2  0  1 0.398 #>  #>  #> $G2 #> $Item.1 #>        category_1 category_2 #> P[1 0]      0.800      0.200 #> P[0 1]      0.605      0.395 #>  #> $Item.2 #>        category_1 category_2 #> P[1 0]      0.620      0.380 #> P[0 1]      0.152      0.848 #>  #> $Item.3 #>        category_1 category_2 #> P[1 0]      0.868      0.132 #> P[0 1]      0.515      0.485 #>  #> $Item.4 #>        category_1 category_2 #> P[1 0]      0.696      0.304 #> P[0 1]      0.443      0.557 #>  #> $Item.5 #>        category_1 category_2 #> P[1 0]       0.50       0.50 #> P[0 1]       0.22       0.78 #>  #> $Item.6 #>        category_1 category_2 #> P[1 0]      0.916      0.084 #> P[0 1]      0.646      0.354 #>  #> $Item.7 #>        category_1 category_2 #> P[1 0]      0.298      0.702 #> P[0 1]      0.065      0.935 #>  #> $Item.8 #>        category_1 category_2 #> P[1 0]      0.868      0.132 #> P[0 1]      0.719      0.281 #>  #> $Item.9 #>        category_1 category_2 #> P[1 0]      0.164      0.836 #> P[0 1]      0.068      0.932 #>  #> $Item.10 #>        category_1 category_2 #> P[1 0]       0.74       0.26 #> P[0 1]       0.28       0.72 #>  #> $Item.11 #>        category_1 category_2 #> P[1 0]      0.044      0.956 #> P[0 1]      0.000      1.000 #>  #> $Item.12 #>        category_1 category_2 #> P[1 0]      0.619      0.381 #> P[0 1]      0.527      0.473 #>  #> $Item.13 #>        category_1 category_2 #> P[1 0]      0.438      0.562 #> P[0 1]      0.146      0.854 #>  #> $Item.14 #>        category_1 category_2 #> P[1 0]      0.406      0.594 #> P[0 1]      0.084      0.916 #>  #> $Item.15 #>        category_1 category_2 #> P[1 0]      0.226      0.774 #> P[0 1]      0.058      0.942 #>  #> $Item.16 #>        category_1 category_2 #> P[1 0]      0.677      0.323 #> P[0 1]      0.353      0.647 #>  #> $Item.17 #>        category_1 category_2 #> P[1 0]      0.049      0.951 #> P[0 1]      0.000      1.000 #>  #> $Item.18 #>        category_1 category_2 #> P[1 0]      0.878      0.122 #> P[0 1]      0.314      0.686 #>  #> $Item.19 #>        category_1 category_2 #> P[1 0]      0.558      0.442 #> P[0 1]      0.256      0.744 #>  #> $Item.20 #>        category_1 category_2 #> P[1 0]      0.189      0.811 #> P[0 1]      0.004      0.996 #>  #> $Item.21 #>        category_1 category_2 #> P[1 0]      0.094      0.906 #> P[0 1]      0.059      0.941 #>  #> $Item.22 #>        category_1 category_2 #> P[1 0]      0.093      0.907 #> P[0 1]      0.001      0.999 #>  #> $Item.23 #>        category_1 category_2 #> P[1 0]      0.752      0.248 #> P[0 1]      0.450      0.550 #>  #> $Item.24 #>        category_1 category_2 #> P[1 0]      0.365      0.635 #> P[0 1]      0.072      0.928 #>  #> $Item.25 #>        category_1 category_2 #> P[1 0]      0.705      0.295 #> P[0 1]      0.489      0.511 #>  #> $Item.26 #>        category_1 category_2 #> P[1 0]      0.781      0.219 #> P[0 1]      0.200      0.800 #>  #> $Item.27 #>        category_1 category_2 #> P[1 0]      0.201      0.799 #> P[0 1]      0.028      0.972 #>  #> $Item.28 #>        category_1 category_2 #> P[1 0]      0.647      0.353 #> P[0 1]      0.212      0.788 #>  #> $Item.29 #>        category_1 category_2 #> P[1 0]      0.801      0.199 #> P[0 1]      0.450      0.550 #>  #> $Item.30 #>        category_1 category_2 #> P[1 0]      0.617      0.383 #> P[0 1]      0.472      0.528 #>  #> $Item.31 #>        category_1 category_2 #> P[1 0]      0.230      0.770 #> P[0 1]      0.009      0.991 #>  #> $Item.32 #>        category_1 category_2 #> P[1 0]      0.884      0.116 #> P[0 1]      0.815      0.185 #>  #> $Class.Probability #>           A1 A2  prob #> Profile_1  1  0 0.602 #> Profile_2  0  1 0.398 #>  #>    #------------------ # Probabilistic Guttman Model (Proctor, 1970)  # example analysis can also be found in the sirt package (see ?prob.guttman) data(data.read, package = 'sirt') head(data.read) #>    A1 A2 A3 A4 B1 B2 B3 B4 C1 C2 C3 C4 #> 2   1  1  1  1  1  1  1  1  1  1  1  0 #> 22  1  1  0  0  1  0  1  1  1  0  1  0 #> 23  1  1  0  1  1  0  1  1  1  1  1  1 #> 41  1  1  1  1  1  1  1  1  1  1  1  1 #> 43  1  0  0  1  0  0  1  1  1  0  1  0 #> 63  1  1  0  0  1  0  1  1  1  1  1  1  Theta <- matrix(c(1,0,0,0,                   1,1,0,0,                   1,1,1,0,                   1,1,1,1), 4, byrow=TRUE)  model <- mirt.model(\"INTERCEPT = 1-12                      C1 = 1,7,9,11                      C2 = 2,5,8,10,12                      C3 = 3,4,6\")  mod <- mdirt(data.read, model, customTheta=Theta) #>  summary(mod) #> $A1 #>            category_1 category_2 #> P[1 0 0 0]      0.331      0.669 #> P[1 1 0 0]      0.037      0.963 #> P[1 1 1 0]      0.037      0.963 #> P[1 1 1 1]      0.037      0.963 #>  #> $A2 #>            category_1 category_2 #> P[1 0 0 0]      0.544      0.456 #> P[1 1 0 0]      0.544      0.456 #> P[1 1 1 0]      0.041      0.959 #> P[1 1 1 1]      0.041      0.959 #>  #> $A3 #>            category_1 category_2 #> P[1 0 0 0]      0.687      0.313 #> P[1 1 0 0]      0.687      0.313 #> P[1 1 1 0]      0.687      0.313 #> P[1 1 1 1]      0.097      0.903 #>  #> $A4 #>            category_1 category_2 #> P[1 0 0 0]      0.709      0.291 #> P[1 1 0 0]      0.709      0.291 #> P[1 1 1 0]      0.709      0.291 #> P[1 1 1 1]      0.315      0.685 #>  #> $B1 #>            category_1 category_2 #> P[1 0 0 0]      0.438      0.562 #> P[1 1 0 0]      0.438      0.562 #> P[1 1 1 0]      0.168      0.832 #> P[1 1 1 1]      0.168      0.832 #>  #> $B2 #>            category_1 category_2 #> P[1 0 0 0]      0.628      0.372 #> P[1 1 0 0]      0.628      0.372 #> P[1 1 1 0]      0.628      0.372 #> P[1 1 1 1]      0.317      0.683 #>  #> $B3 #>            category_1 category_2 #> P[1 0 0 0]      0.205      0.795 #> P[1 1 0 0]      0.021      0.979 #> P[1 1 1 0]      0.021      0.979 #> P[1 1 1 1]      0.021      0.979 #>  #> $B4 #>            category_1 category_2 #> P[1 0 0 0]      0.543      0.457 #> P[1 1 0 0]      0.543      0.457 #> P[1 1 1 0]      0.140      0.860 #> P[1 1 1 1]      0.140      0.860 #>  #> $C1 #>            category_1 category_2 #> P[1 0 0 0]      0.175      0.825 #> P[1 1 0 0]      0.000      1.000 #> P[1 1 1 0]      0.000      1.000 #> P[1 1 1 1]      0.000      1.000 #>  #> $C2 #>            category_1 category_2 #> P[1 0 0 0]      0.526      0.474 #> P[1 1 0 0]      0.526      0.474 #> P[1 1 1 0]      0.098      0.902 #> P[1 1 1 1]      0.098      0.902 #>  #> $C3 #>            category_1 category_2 #> P[1 0 0 0]      0.292      0.708 #> P[1 1 0 0]      0.026      0.974 #> P[1 1 1 0]      0.026      0.974 #> P[1 1 1 1]      0.026      0.974 #>  #> $C4 #>            category_1 category_2 #> P[1 0 0 0]      0.425      0.575 #> P[1 1 0 0]      0.425      0.575 #> P[1 1 1 0]      0.140      0.860 #> P[1 1 1 1]      0.140      0.860 #>  #> $Class.Probability #>           INTERCEPT C1 C2 C3  prob #> Profile_1         1  0  0  0 0.383 #> Profile_2         1  1  0  0 0.057 #> Profile_3         1  1  1  0 0.130 #> Profile_4         1  1  1  1 0.431 #>   M2(mod) #>             M2 df            p      RMSEA    RMSEA_5   RMSEA_95      SRMSR #> stats 145.0553 51 5.876977e-11 0.07509875 0.06080295 0.08947343 0.09158964 #>             TLI       CFI #> stats 0.8130941 0.8555727 itemfit(mod) #>    item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1    A1 27.808       7      0.095  0.000 #> 2    A2  2.984       6      0.000  0.811 #> 3    A3 10.219       6      0.046  0.116 #> 4    A4  5.575       6      0.000  0.472 #> 5    B1  8.168       7      0.023  0.318 #> 6    B2  7.176       6      0.024  0.305 #> 7    B3  9.351       7      0.032  0.228 #> 8    B4  2.359       6      0.000  0.884 #> 9    C1  6.260       5      0.028  0.282 #> 10   C2  6.914       6      0.022  0.329 #> 11   C3 11.734       7      0.045  0.110 #> 12   C4  5.585       7      0.000  0.589   # }"},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Full information maximum likelihood estimation of IRT models. — mirt-package","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Full information maximum likelihood estimation multidimensional IRT models","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Analysis dichotomous polytomous response data using unidimensional multidimensional latent trait models Item Response Theory (IRT) paradigm. Exploratory confirmatory models can estimated quadrature (EM) stochastic (MHRM) methods. Confirmatory bi-factor two-tier analyses available modeling item testlets. Multiple group analysis mixed effects designs also available detecting differential item test functioning well modeling item person covariates. Finally, latent class models DINA, DINO, multidimensional latent class, mixture zero-inflated IRT models, several discrete variable models supported. Users interested recent version package can visit https://github.com/philchalmers/mirt follow instructions installing package source. Questions regarding package can sent mirt-package Google Group, located https://groups.google.com/forum/#!forum/mirt-package. User contributed files, workshop files, evaluated help files also available package wiki (https://github.com/philchalmers/mirt/wiki).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Full information maximum likelihood estimation of IRT models. — mirt-package","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"mirt fits maximum likelihood (maximum posteriori) factor analysis model mixture dichotomous polytomous data multidimensional item response theory paradigm using either Cai's (2010) Metropolis-Hastings Robbins-Monro (MHRM) algorithm, EM algorithm approach outlined Bock Aitkin (1981) using rectangular quasi-Monte Carlo integration grids, stochastic EM (.e., first two stages MH-RM algorithm). Unidimensional multidimensional dominance/compensatory response models unfolding/pairwise comparison models can specified independently via itemtype argument.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"","code":"mirt(   data,   model = 1,   itemtype = NULL,   guess = 0,   upper = 1,   SE = FALSE,   covdata = NULL,   formula = NULL,   itemdesign = NULL,   item.formula = NULL,   SE.type = \"Oakes\",   method = \"EM\",   optimizer = NULL,   dentype = \"Gaussian\",   pars = NULL,   constrain = NULL,   calcNull = FALSE,   draws = 5000,   survey.weights = NULL,   quadpts = NULL,   TOL = NULL,   gpcm_mats = list(),   grsm.block = NULL,   rsm.block = NULL,   monopoly.k = 1L,   key = NULL,   large = FALSE,   GenRandomPars = FALSE,   accelerate = \"Ramsay\",   verbose = TRUE,   solnp_args = list(),   nloptr_args = list(),   spline_args = list(),   control = list(),   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA (convert ordered factor data.frame see data.matrix) model string passed (object returned ) mirt.model, declaring IRT model estimated (loadings, constraints, priors, etc). exploratory IRT models, single numeric value indicating number factors extract also supported. Default 1, indicating unidimensional model fit unless otherwise specified itemtype type items modeled, declared either ) single value   recycled item, b) vector respective item, c) applicable,   matrix columns equal number items rows equal number   latent classes. NULL default assumes items follow graded   2PL structure, however may changed following: 'Rasch' - Rasch/partial credit model constraining slopes 1 freely estimating       variance parameters (alternatively, can specified applying equality constraints       slope parameters 'gpcm' '2PL'; Rasch, 1960) '1PL', '2PL', '3PL', '3PLu', '4PL' - 1-4 parameter logistic model,       3PL estimates lower asymptote 3PLu estimates upper asymptote       (Lord Novick, 1968; Lord, 1980). Note specifying '1PL' automatically estimate       variance latent trait compared 'Rasch' type '5PL' - 5 parameter logistic model estimate asymmetric logistic      response curves. Currently restricted unidimensional models 'CLL' - complementary log-log link model.       Currently restricted unidimensional models 'ULL' - unipolar log-logistic model (Lucke, 2015). Note use itemtype       automatically use log-normal distribution latent traits 'graded' - graded response model (Samejima, 1969) 'grsm' - graded ratings scale model       classical IRT parameterization (restricted unidimensional models; Muraki, 1992) 'gpcm' 'gpcmIRT' - generalized partial credit model slope-intercept       classical parameterization. 'gpcmIRT' restricted unidimensional models. Note       optional scoring matrices 'gpcm' available gpcm_mats input (Muraki, 1992) 'rsm' - Rasch rating scale model using 'gpcmIRT' structure       (unidimensional ; Andrich, 1978) 'nominal' - nominal response model (Bock, 1972) 'ideal' - dichotomous ideal point model (Maydeu-Olivares, 2006) 'ggum' - generalized graded unfolding model (Roberts, Donoghue, & Laughlin, 2000)       multidimensional extension 'hcm' 'ghcm' - (generalized) hyperbolic cosine model (Andrich Luo, 1993; Andrich, 1996)      dichotomous ordered polytomous items (see Luo, 2001) 'alm' 'galm' - (generalized) absolute logistic model (Luo Andrich, 2005) dichotomous      ordered polytomous items 'sslm' 'gsslm' - (generalized) simple squared logistic model (Andrich, 1988)      dichotomous ordered polytomous items (see Luo, 2001) 'paralla' 'gparalla' - (generalized) parallellogram analysis model (Hoijtink, 1990)      dichotomous ordered polytomous items (see Luo, 2001) 'sequential' - multidimensional sequential response model (Tutz, 1990) slope-intercept form 'Tutz' - 'sequential' itemtype, except slopes fixed 1       latent variance terms freely estimated (similar 'Rasch' itemtype input) 'PC1PL', 'PC2PL', 'PC3PL' - 1-3 parameter partially compensatory model.       Note constraining slopes equal across items also reduce model       Embretson's (.k.. Whitely's) multicomponent model (1980), 'PC1PL'       slopes fixed 1 latent trait variance terms estimated '2PLNRM', '3PLNRM', '3PLuNRM', '4PLNRM' - 2-4 parameter nested       logistic model, 3PLNRM estimates lower asymptote 3PLuNRM estimates       upper asymptote (Suh Bolt, 2010) 'spline' - spline response model bs (default)       ns function (Winsberg, Thissen, Wainer, 1984) 'monopoly' - monotonic polynomial model unidimensional tests       dichotomous polytomous response data (Falk Cai, 2016) Additionally, user defined item classes can also defined using createItem function guess fixed pseudo-guessing parameters. Can entered single value assign global guessing parameter may entered numeric vector corresponding item upper fixed upper bound parameters 4-PL model. Can entered single value assign global guessing parameter may entered numeric vector corresponding item SE logical; estimate standard errors computing parameter information matrix? See SE.type type estimates available covdata data.frame data used latent regression models formula R formula (list formulas) indicating latent traits can regressed using external covariates covdata. named list formulas supplied (names correspond latent trait names model) specific regression effects can estimated factor. Supplying single formula estimate regression parameters latent traits default itemdesign data.frame rows equal number items columns containing item-design effects. items included design structure (.e., left canonical structure) fewer rows can used, however rownames must defined matched colnames data input. item design matrix constructed use item.formula. Providing input fix associated 'd' intercepts 0, applicable item.formula R formula used specify intercept decomposition (e.g.,   LLTM; Fischer, 1983). Note right-hand side formula required   compensatory models. non-compensatory itemtypes (e.g., 'PC1PL') formula must include   name latent trait left hand side expression indicate   trait specification intercepts decomposed (see MLTM; Embretson, 1984) SE.type type estimation method use calculating parameter information matrix   computing standard errors wald tests. Can :  'Richardson', 'forward', 'central' numerical Richardson,       forward difference, central difference evaluation observed Hessian matrix 'crossprod' 'Louis' standard error computations based variance       Fisher scores well Louis' (1982) exact computation observed information matrix.       Note Louis' estimates can take long time obtain large sample sizes long tests 'sandwich' sandwich covariance estimate based       'crossprod' 'Oakes' estimates (see Chalmers, 2018, details) 'sandwich.Louis' sandwich covariance estimate based       'crossprod' 'Louis' estimates 'Oakes' Oakes' (1999) method using central difference approximation       (see Chalmers, 2018, details) 'SEM' supplemented EM (disables accelerate option automatically; EM ) 'Fisher' expected information, 'complete' information based       complete-data Hessian used EM algorithm 'MHRM' 'FMHRM' stochastic approximations observed information matrix       based Robbins-Monro filter fixed number MHRM draws without RM filter.       options supported method = 'MHRM' 'numerical' obtain numerical estimate call optim       method = 'BL' Note 'SEM' method becomes sensitive ML solution   reached sufficient precision, may sensitive   history EM cycles stable/sufficient convergence respective estimates.   Increasing number iterations (increasing NCYCLES decreasing   TOL, see ) help improve accuracy, can   run parallel mirtCluster object defined (  used Oakes' method well). Additionally,   inspecting symmetry ACOV matrix convergence issues passing   technical = list(symmetric = FALSE) can helpful determine sufficient   solution reached method character object specifying estimation algorithm used. default   'EM', standard EM algorithm fixed quadrature, 'QMCEM'   quasi-Monte Carlo EM estimation, 'MCEM' Monte Carlo EM estimation.   option 'MHRM' may also passed use MH-RM algorithm,   'SEM' Stochastic EM algorithm (first   two stages MH-RM stage using optimizer single Newton-Raphson iteration),   'BL' Bock Lieberman   approach (generally recommended longer tests). 'EM' generally effective 1-3 factors, methods 'QMCEM',   'MCEM', 'SEM', 'MHRM' used dimensions 3 . Note   optimizer stochastic associated SE.type automatically changed   SE.type = 'MHRM' default avoid use quadrature optimizer character indicating numerical optimizer use. default, EM   algorithm use 'BFGS' upper lower bounds box-constraints   'nlminb' . options include Newton-Raphson ('NR'),   can efficient 'BFGS' stable complex   IRT models (nominal nested logit models)   related 'NR1' also Newton-Raphson   consists 1 update coupled RM Hessian (  applicable MH-RM algorithm used). MH-RM algorithm uses 'NR1' default,   though currently 'BFGS', 'L-BFGS-B', 'NR'   also supported method (  fewer iterations default) emulate stochastic EM updates.   well, 'Nelder-Mead' 'SANN'   estimators available, routine use generally required recommended. Additionally, estimation subroutines Rsolnp nloptr   packages available passing arguments 'solnp' 'nloptr',   respectively. used conjunction solnp_args   nloptr_args specified . equality constraints specified   model definition parameter lowest parnum   pars = 'values' data.frame used estimation vector passed   objective function, group hyper-parameters omitted.   Equality inequality functions form function(p, optim_args),   optim_args list internally parameters largely can ignored   defining constraints (though use browser() may helpful) dentype type density form use latent trait parameters. Current options include  'Gaussian' (default) assumes multivariate Gaussian distribution associated       mean vector variance-covariance matrix 'empiricalhist' 'EH' estimates latent distribution using empirical histogram described       Bock Aitkin (1981). applicable unidimensional models estimated EM algorithm.       option, number cycles, TOL, quadpts adjusted accommodate       less precision estimation (namely: TOL = 3e-5, NCYCLES = 2000, quadpts = 121) 'empiricalhist_Woods' 'EHW' estimates latent distribution using empirical histogram described       Bock Aitkin (1981), specifications dentype = 'empiricalhist',       extrapolation-interpolation method described Woods (2007). NOTE: improve stability       presence extreme response styles (.e., highest lowest item) technical option       zeroExtreme = TRUE may required -weight contribution problematic patterns 'Davidian-#' estimates semi-parametric Davidian curves described Woods Lin (2009),       # placeholder represents number Davidian parameters estimate       (e.g., 'Davidian-6' estimate 6 smoothing parameters). default, number       quadpts increased 121, method applicable       unidimensional models estimated EM algorithm Note itemtype = 'ULL' log-normal(0,1) density used support unipolar scaling pars data.frame structure starting values, parameter numbers, estimation logical values, etc, defined. user may observe model defines values using pars = 'values', object can turn modified input back estimation pars = mymodifiedpars constrain list user declared equality constraints. see define parameters correctly use pars = 'values' initially see parameters labeled. constrain parameters equal create list separate concatenated vectors signifying parameters constrain. example, set parameters 1 5 equal, also set parameters 2, 6, 10 equal use constrain = list(c(1,5), c(2,6,10)). Constraints can also specified using mirt.model syntax (recommended) calcNull logical; calculate Null model additional fit statistics (e.g., TLI)? applicable data contains NA's data overly sparse draws number Monte Carlo draws estimate log-likelihood MH-RM algorithm. Default 5000 survey.weights optional numeric vector survey weights apply case data (EM estimation ). specified, cases weighted equally (standard IRT approach). sum survey.weights must equal total sample size proper weighting applied quadpts number quadrature points per dimension (must larger 2). default number quadrature uses following scheme: switch(.character(nfact), '1'=61, '2'=31, '3'=15, '4'=9, '5'=7, 3). However, method input set 'QMCEM' argument left blank default number quasi-Monte Carlo integration nodes set 5000 total TOL convergence threshold EM MH-RM; defaults .0001 .001. SE.type = 'SEM' value specified, default set 1e-5. evaluate model using starting values pass TOL = NaN, evaluate starting values without log-likelihood pass TOL = NA gpcm_mats list matrices specifying scoring coefficients (generalized) partial credit model constructed. omitted, standard gpcm format used (.e., seq(0, k, = 1) trait). input used traits scored different category (e.g., matrix(c(0:3, 1,0,0,0), 4, 2) two-dimensional model first trait scored like gpcm, second trait positively indicated first category selected). Can used itemtypes 'gpcm' 'Rasch', respective element gpcm_mats NULL grsm.block optional numeric vector indicating blocking occur using grsm, NA represents items belong grsm block (items may estimated test data). example, specify two blocks 3 2PL item last item: grsm.block = c(rep(1,3), rep(2,3), NA). NULL items assumed within group therefore number item categories rsm.block grsm.block, 'rsm' blocks monopoly.k vector values (single value repeated item) indicate degree monotone polynomial fitted, monotone polynomial corresponds monopoly.k * 2 + 1 (e.g., monopoly.k = 2 fits 5th degree polynomial). Default monopoly.k = 1, fits 3rd degree polynomial key numeric vector response scoring key. Required using nested logit item types, must length number items used. Items nested logit ignore vector, use NA item locations applicable large logical indicating whether unique response patterns obtained prior   performing estimation avoid repeating computations identical patterns.   default TRUE provides correct degrees freedom model since unique patterns   tallied (typically affects goodness fit statistics G2, also influence   nested model comparison methods anova(mod1, mod2)), FALSE use   number rows data placeholder total degrees freedom. , model   objects compared flags set TRUE set FALSE Alternatively, collapse table frequencies desired purpose saving computations   (.e., computing collapsed frequencies data onte-time) character vector can   passed arguement large = 'return' return list desired   table information used mirt. list object can reused passing back   large argument avoid re-tallying data   (, useful dataset large computing tabulated data   computationally burdensome). strategy shown : Compute organized data e.g., internaldat <- mirt(Science, 1, large = 'return') Pass organized data estimation functions e.g.,   mod <- mirt(Science, 1, large = internaldat) GenRandomPars logical; generate random starting values prior optimization instead using fixed internal starting values? accelerate character vector indicating type acceleration use. Default 'Ramsay', may also 'squarem' SQUAREM procedure (specifically, gSqS3 approach) described Varadhan Roldand (2008). disable acceleration, pass 'none' verbose logical; print observed- (EM) complete-data (MHRM) log-likelihood iteration cycle? Default TRUE solnp_args list arguments passed solnp::solnp() function equality constraints, inequality constraints, etc nloptr_args list arguments passed nloptr::nloptr() function equality constraints, inequality constraints, etc spline_args named list lists containing information passed bs (default)   ns spline itemtype. element must refer name itemtype   spline, internal list names refer arguments passed. example, item 2 called   'read2', item 5 called 'read5', itemtype 'spline' item 5 use   ns form, modified list input might form: spline_args = list(read2 = list(degree = 4),                            read5 = list(fun = 'ns', knots = c(-2, 2))) code input changes bs() splines function degree = 4 input,   second element changes ns() function knots set c(-2, 2) control list passed respective optimizers (.e., optim(), nlminb(), etc). Additional arguments included 'NR' optimizer: 'tol' convergence tolerance M-step (default TOL/1000), default number iterations Newton-Raphson optimizer 50 (modified 'maxit' control input) technical list containing lower level technical parameters estimation. May : NCYCLES maximum number EM MH-RM cycles; defaults 500 2000 MAXQUAD maximum number quadratures, can increase     4GB RAM PC; default 20000 theta_lim range integration grid dimension; default c(-6, 6). Note     itemtype = 'ULL' log-normal distribution used range change     c(.01, 6^2), second term square theta_lim input instead set.seed seed number used estimation. Default 12345 SEtol standard error tolerance criteria S-EM MHRM computation     information matrix. Default 1e-3 symmetric logical; force S-EM/Oakes information matrix estimates symmetric? Default TRUE     computation standard errors stable. Setting FALSE can help     detect solutions reached ML estimate SEM_window ratio values used define S-EM window based     observed likelihood differences across EM iterations. default     c(0, 1 - SEtol), provides nearly full S-EM window (.e.,     nearly EM cycles used). use smaller SEM window change window     something like c(.9, .999) start point farther EM history warn logical; include warning messages estimation? Default TRUE message logical; include general messages estimation? Default TRUE customK numeric vector used explicitly declare number response     categories item. used constructing mirt model     reasons parameter estimation (obtain factor scores), requires     input data 0 lowest category. format     extract.mirt(mod, 'K') slot converged models customPriorFun custom function used determine normalized density     integration EM algorithm. Must form function(Theta, Etable){...},     return numeric vector length number rows Theta.     Etable input contains aggregated table generated current E-step     computations. proper integration, returned vector sum     1 (.e., normalized). Note using Etable NULL     first call, therefore prior deal issue accordingly zeroExtreme logical; assign extreme response patterns survey.weight 0     (formally equivalent removing data vectors estimation)?     dentype = 'EHW', Woods' extrapolation utilized,     option may required extrapolation causes expected densities tend towards     positive negative infinity. default FALSE customTheta custom Theta grid, matrix form, used integration.     defined, grid determined internally based number quadpts nconstrain specification constrain list argument,     however imposes negative equality constraint instead (e.g., \\(a12 = -a21\\),     specified nconstrain = list(c(12, 21))). Note specification     list must length 2, second element taken -1 times     first element delta deviation term used numerical estimates computing ACOV matrix     'forward' 'central' numerical approaches, well Oakes' method     Richardson extrapolation. Default 1e-5 parallel logical; use parallel cluster defined mirtCluster?     Default TRUE storeEMhistory logical; store iteration history using EM algorithm?    Default FALSE. TRUE, use extract.mirt extract internal_constraints logical; include internal constraints using certain     IRT models (e.g., 'grsm' itemtype). Disable want use special optimizers     solnp. Default TRUE gain vector two values specifying numerator exponent        values RM gain function \\((val1 / cycle)^val2\\).        Default c(0.10, 0.75) BURNIN number burn cycles (stage 1) MH-RM; default 150 SEMCYCLES number SEM cycles (stage 2) MH-RM; default 100 MHDRAWS number Metropolis-Hasting draws use MH-RM iteration; default 5 MHcand vector values used tune MH sampler. Larger values     cause acceptance ratio decrease. One value required group     unconditional item factor analysis (mixedmirt() requires additional values     random effect). null, values determined internally, attempting     tune acceptance draws .1 .4 MHRM_SE_draws number fixed draws use SE=TRUE SE.type = 'FMHRM'     maximum number draws SE.type = 'MHRM'. Default 2000 MCEM_draws function used determine number quadrature points draw     'MCEM' method. Must include one argument indicates iteration number     EM cycle. Default function(cycles) 500 + (cycles - 1)*2, starts number     draws 500 increases 2 full EM iteration info_if_converged logical; compute information matrix using MH-RM algorithm     model converged within suitable number iterations? Default TRUE logLik_if_converged logical; compute observed log-likelihood using MH-RM algorithm     model converged within suitable number iterations? Default TRUE keep_vcov_PD logical; attempt keep variance-covariance matrix latent traits     positive definite estimation EM algorithm? generally improves convergence     properties traits highly correlated. Default TRUE ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"function returns object class SingleGroupClass   (SingleGroupClass-class)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Models containing 'explanatory' person item level predictors can included using mixedmirt function, though latent regression models can fit using formula input function. Tests form two-tier bi-factor structure estimated bfactor function, uses dimension reduction EM algorithm modeling item parcels.  Multiple group analyses (useful DIF DTF testing) also available using multipleGroup function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"confirmatory-and-exploratory-irt","dir":"Reference","previous_headings":"","what":"Confirmatory and Exploratory IRT","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Specification confirmatory item factor analysis model follows many rules structural equation modeling framework confirmatory factor analysis. variances latent factors automatically fixed 1 help facilitate model identification. parameters may fixed constant values set equal parameters using appropriate declarations. Confirmatory models may also contain 'explanatory' person item level predictors, though including predictors currently limited mixedmirt function. specifying single number greater 1 model input mirt exploratory IRT model estimated. Rotation target matrix options available passed generic functions summary-method fscores. Factor means variances fixed ensure proper identification. model exploratory item factor analysis estimation begin computing matrix quasi-polychoric correlations. factor analysis nfact extracted item parameters estimated \\(a_{ij} = f_{ij}/u_j\\), \\(f_{ij}\\) factor loading jth item ith factor, \\(u_j\\) square root factor uniqueness, \\(\\sqrt{1 - h_j^2}\\). initial intercept parameters determined calculating inverse normal item facility (.e., item easiness), \\(q_j\\), obtain \\(d_j = q_j / u_j\\). similar implementation also used obtaining initial values polytomous items.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"a-note-on-upper-and-lower-bound-parameters","dir":"Reference","previous_headings":"","what":"A note on upper and lower bound parameters","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Internally \\(g\\) \\(u\\) parameters transformed using logit transformation (\\(log(x/(1-x))\\)), can reversed using \\(1 / (1 + exp(-x))\\) following convergence. also applies computing confidence intervals parameters, done automatically coef(mod, rawug = FALSE). , applying prior distributions parameters recommended use prior ranges negative infinity positive infinity, normally distributed prior via 'norm' input (see mirt.model).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"convergence-for-quadrature-methods","dir":"Reference","previous_headings":"","what":"Convergence for quadrature methods","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Unrestricted full-information factor analysis known problems convergence, items may need constrained removed entirely allow acceptable solution. general rule dichotomous items means greater .95, items .05 greater guessing parameter, considered removal analysis treated prior parameter distributions. type reasoning applicable including upper bound parameters well. polytomous items, categories rarely endorsed cause similar issues. Also, increasing number quadrature points per dimension, using quasi-Monte Carlo integration method, may help stabilize estimation process higher dimensions. Finally, solutions well defined also difficulty converging, can indicate model misspecified (e.g., extracting many dimensions).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"convergence-for-mh-rm-method","dir":"Reference","previous_headings":"","what":"Convergence for MH-RM method","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"MH-RM algorithm, number iterations grows high (e.g., greater 1500) Max Change = .2500 values repeatedly printed console often (indicating parameters constrained since naturally moving steps greater 0.25) model may either ill defined flat likelihood surface, genuine maximum-likelihood parameter estimates may difficult find. Standard errors computed following model convergence passing SE = TRUE, perform addition MH-RM stage treating maximum-likelihood estimates fixed points.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"additional-helper-functions","dir":"Reference","previous_headings":"","what":"Additional helper functions","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Additional functions available package can useful pre- post-estimation. : mirt.model Define IRT model specification use special syntax. Useful defining within     group parameter constraints, prior parameter distributions, specifying slope     coefficients factor coef-method Extract raw coefficients model, along standard errors confidence     intervals summary-method Extract standardized loadings model. Accepts rotate argument exploratory     item response model anova-method Compare nested models using likelihood ratio statistics well information criteria     AIC BIC residuals-method Compute pairwise residuals item using methods LD statistic     (Chen & Thissen, 1997), well response pattern residuals plot-method Plot various types test level plots including test score information functions     itemplot Plot various types item level plots, including score, standard error, information     functions, createItem Create customized itemtype currently exist package imputeMissing Impute missing data given computed Theta matrix fscores Find predicted scores latent traits using estimation methods EAP, MAP, ML,     WLE, EAPsum wald Compute Wald statistics follow convergence model suitable information matrix M2 Limited information goodness fit test statistic based determine well model fits     data itemfit personfit Goodness fit statistics item person levels, S-X2, infit, outfit,     boot.mirt Compute estimated parameter confidence intervals via bootstrap methods mirtCluster Define cluster package functions use capitalizing multi-core architecture     utilize available CPUs possible. help decrease estimation times tasks     can run parallel","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"irt-models","dir":"Reference","previous_headings":"","what":"IRT Models","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"parameter labels use follow convention, using two factors \\(K\\) total number categories (using \\(k\\) specific category instances). Rasch one intercept estimated, latent variance \\(\\theta\\) freely estimated.     data two categories partial credit model used instead (see     'gpcm' ).      $$P(x = 1|\\theta, d) = \\frac{1}{1 + exp(-(\\theta + d))}$$ 1-4PL Depending model \\(u\\) may equal 1 (e.g., 3PL), \\(g\\) may equal 0 (e.g., 2PL),     may fixed 1 (e.g., 1PL).     $$P(x = 1|\\theta, \\psi) = g + \\frac{(u - g)}{       1 + exp(-(a_1 * \\theta_1 + a_2 * \\theta_2 + d))}$$ 5PL Currently restricted unidimensional models     $$P(x = 1|\\theta, \\psi) = g + \\frac{(u - g)}{       1 + exp(-(a_1 * \\theta_1 + d))^S}$$     \\(S\\) allows asymmetry response function     transformation constrained greater 0 (.e., log(S) estimated rather S) CLL Complementary log-log model (see Shim, Bonifay, Wiedermann, 2022)     $$P(x = 1|\\theta, b) = 1 - exp(-exp(\\theta - b))$$     Currently restricted unidimensional dichotomous data. graded graded model consists sequential 2PL models,     $$P(x = k | \\theta, \\psi) = P(x \\ge k | \\theta, \\phi) - P(x \\ge k + 1 | \\theta, \\phi)$$     Note \\(P(x \\ge 1 | \\theta, \\phi) = 1\\) \\(P(x \\ge K + 1 | \\theta, \\phi) = 0\\) ULL unipolar log-logistic model (ULL; Lucke, 2015) defined     graded response model, however     $$P(x \\le k | \\theta, \\psi) = \\frac{\\lambda_k\\theta^\\eta}{1 + \\lambda_k\\theta^\\eta}$$.     Internally \\(\\lambda\\) parameters exponentiated keep positive,     therefore reported estimates interpreted log units grsm constrained version graded model graded spacing equal across item     blocks adjusted single 'difficulty' parameter (c) latent variance     \\(\\theta\\) freely estimated (see Muraki, 1990 exact form).     restricted unidimensional models . gpcm/nominal gpcm \\(d\\) values treated fixed ordered values     \\(0:(K-1)\\) (nominal model \\(d_0\\) also set 0). Additionally,     identification nominal model \\(ak_0 = 0\\), \\(ak_{(K-1)} = (K - 1)\\).     $$P(x = k | \\theta, \\psi) =     \\frac{exp(ak_{k-1} * (a_1 * \\theta_1 + a_2 * \\theta_2) + d_{k-1})}     {\\sum_{k=1}^K exp(ak_{k-1} * (a_1 * \\theta_1 + a_2 * \\theta_2) + d_{k-1})}$$ partial credit model (itemtype = 'Rasch'; unidimensional )     model constrained \\(ak = (0,1,\\ldots, K-1)\\), \\(a_1 = 1\\),     latent variance \\(\\theta_1\\) freely estimated. Alternatively, partial credit model     can obtained containing slope parameters gpcms equal.     specific scoring function may included passing suitable list matrices     gpcm_mats input argument. nominal model parametrization helps identify empirical ordering     categories inspecting \\(ak\\) values. Larger values indicate item category     positively related latent trait(s) measured. instance, item     truly ordinal (Likert scale), 4 response categories, expect     see \\(ak_0 < ak_1 < ak_2 < ak_3\\) following estimation. hand     \\(ak_0 > ak_1\\) appear second category less related     trait first, therefore second category understood     'lowest score'. NOTE: nominal model can become numerical unstable poor choices high low     values chosen, resulting ak values greater abs(10) .     recommended choose high low anchors cause estimated parameters fall     0 \\(K - 1\\) either theoretical means re-estimating     model better values following convergence. gpcmIRT rsm gpcmIRT model classical generalized partial credit model unidimensional response      data. obtain fit gpcm presented , however parameterization      allows Rasch/generalized rating scale model special case. E.g., K = 4 category response model, $$P(x = 0 | \\theta, \\psi) = exp(0) / G$$      $$P(x = 1 | \\theta, \\psi) = exp((\\theta - b1) + c) / G$$      $$P(x = 2 | \\theta, \\psi) = exp((2\\theta - b1 - b2) + 2c) / G$$      $$P(x = 3 | \\theta, \\psi) = exp((3\\theta - b1 - b2 - b3) + 3c) / G$$           $$G = exp(0) + exp((\\theta - b1) + c) + exp((2\\theta - b1 - b2) + 2c) +        exp((3\\theta - b1 - b2 - b3) + 3c)$$      \\(\\) slope parameter, \\(b\\) parameters threshold      values adjacent category, \\(c\\) -called difficulty parameter      rating scale model fitted (otherwise, \\(c = 0\\) drops computations). gpcmIRT can constrained partial credit IRT model either constraining      slopes equal, setting slopes 1 freeing latent variance parameter. Finally, rsm constrained version (generalized) partial      credit model spacing equal      across item blocks adjusted single 'difficulty' parameter (c). Note      analogous relationship graded model grsm (additional      constraint regarding fixed discrimination parameters). sequential/Tutz multidimensional sequential response model form     $$P(x = k | \\theta, \\psi) = \\prod (1 - F(a_1 \\theta_1 + a_2 \\theta_2 + d_{sk}))       F(a_1 \\theta_1 + a_2 \\theta_2 + d_{jk})$$     \\(F(\\cdot)\\) cumulative logistic function.     Tutz variant model (Tutz, 1990) (via itemtype = 'Tutz')     assumes slope terms equal 1 latent     variance terms estimated (.e., Rasch variant).  ideal ideal point model form, upper bound constraint \\(d\\) set 0:     $$P(x = 1 | \\theta, \\psi) = exp(-0.5 * (a_1 * \\theta_1 + a_2 * \\theta_2 + d)^2)$$ partcomp Partially compensatory models consist product 2PL probability curves.     $$P(x = 1 | \\theta, \\psi) = g + (1 - g) (\\frac{1}{1 + exp(-(a_1 * \\theta_1 + d_1))}^c_1 *     \\frac{1}{1 + exp(-(a_2 * \\theta_2 + d_2))}^c_2)$$ \\(c_1\\) \\(c_2\\) binary indicator variables reflecting whether item include     select compensatory component (1) (0). Note constraining slopes     equal across items reduce model Embretson's (Whitely's) multicomponent model (1980). 2-4PLNRM Nested logistic curves modeling distractor items. Requires scoring key.     model broken two components probability endorsement. successful     endorsement probability trace 1-4PL model, unsuccessful endorsement:     $$P(x = 0 | \\theta, \\psi) =     (1 - P_{1-4PL}(x = 1 | \\theta, \\psi)) * P_{nominal}(x = k | \\theta, \\psi)$$     product complement dichotomous trace line nominal     response model. nominal model, slope parameters defined constrained     1's, last value \\(ak\\) freely estimated. ggum (multidimensional) generalized graded unfolding model     class ideal point models useful ordinal response data. form     $$P(z=k|\\theta,\\psi)=\\frac{exp\\left[\\left(z\\sqrt{\\sum_{d=1}^{D}     a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+\\sum_{k=0}^{z}\\psi_{ik}\\right]+     exp\\left[\\left((M-z)\\sqrt{\\sum_{d=1}^{D}a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+     \\sum_{k=0}^{z}\\psi_{ik}\\right]}{\\sum_{w=0}^{C}\\left(exp\\left[\\left(w     \\sqrt{\\sum_{d=1}^{D}a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+     \\sum_{k=0}^{z}\\psi_{ik}\\right]+exp\\left[\\left((M-w)     \\sqrt{\\sum_{d=1}^{D}a_{id}^{2}(\\theta_{jd}-b_{id})^{2}}\\right)+     \\sum_{k=0}^{z}\\psi_{ik}\\right]\\right)}$$     \\(\\theta_{jd}\\) location \\(j\\)th individual \\(d\\)th dimension,     \\(b_{id}\\) difficulty location \\(\\)th item \\(d\\)th dimension,     \\(a_{id}\\) discrimination \\(j\\)th individual \\(d\\)th dimension     (discrimination values constrained positive),     \\(\\psi_{ik}\\) \\(k\\)th subjective response category threshold \\(\\)th item,     assumed symmetric item constant across dimensions,     \\(\\psi_{ik} = \\sum_{d=1}^D a_{id} t_{ik}\\)     \\(z = 1,2,\\ldots, C\\) (\\(C\\) number categories minus 1),     \\(M = 2C + 1\\). (g)hcm, (g)alm, (g)sslm, (g)paralla Following Luo (2001), family response models     can characterized ordinal response functioning structure, differing     linking functions (\\(\\psi(x)\\)). example, two-dimensional model equation used     $$p_k =       \\frac{\\psi (\\rho_k)}{\\psi (\\rho_k) + \\psi (a_1 \\theta_1 + a_2 \\theta_2 + d)} $$     expressed slope-intercept form accommodate multidimensionality.     \"generalized\" versions family estimate slope rho     parameters, allow item     differ steepness unfolding model functions; otherwise, slopes fixed     value 1, though rho parameters must set 0 manually.     ordered polytomous items response function follows Guttman-scaling logic     $$P_1 = q_1\\cdot q_2 \\cdot q_3 \\cdots q_k$$     $$P_2 = p_1\\cdot q_2 \\cdot q_3 \\cdots q_k$$     $$P_3 = p_1\\cdot p_2 \\cdot q_3 \\cdots q_k$$     $$\\cdots$$     $$P_K = p_1\\cdot p_2 \\cdot p_3 \\cdots p_k$$     Note estimation purposes rho parameters expressed log units     remain positive estimation. Hence, parameterization used herein     $$p_k =       \\frac{\\psi (exp(\\rho^*_k))}{\\psi (exp(\\rho^*_k))) + \\psi (a_1 \\theta_1 + a_2 \\theta_2 + d)} $$     \\(\\rho^*_k\\) natural log units. Currently supported models family : (generalized) hyperbolic cosine model (\\(\\psi (x) = cosh(x)\\)), (generalized) absolute logistic model (\\(\\psi (x) = exp(|x|)\\)), (generalized) simple squared logistic model (\\(\\psi (x) = exp(x^2)\\)), (generalized) parallellogram analysis model (\\(\\psi (x) = x^2\\)), respectively. available dichotomous ordered polytomous response option items. spline Spline response models attempt model response curves uses non-linear potentially     non-monotonic patterns. form     $$P(x = 1|\\theta, \\eta) = \\frac{1}{1 + exp(-(\\eta_1 * X_1 + \\eta_2 * X_2 + \\cdots + \\eta_n * X_n))}$$     \\(X_n\\) spline design matrix \\(X\\) organized grid \\(\\theta\\)     values. B-splines natural polynomial basis supported, intercept input     set TRUE default. monopoly Monotone polynomial model polytomous response data form     $$P(x = k | \\theta, \\psi) =     \\frac{exp(\\sum_1^k (m^*(\\psi) + \\xi_{c-1})}     {\\sum_1^C exp(\\sum_1^K (m^*(\\psi) + \\xi_{c-1}))}$$     \\(m^*(\\psi)\\) monotone polynomial function without intercept.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"html-help-files-exercises-and-examples","dir":"Reference","previous_headings":"","what":"HTML help files, exercises, and examples","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"access examples, vignettes, exercise files generated knitr please visit https://github.com/philchalmers/mirt/wiki.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Andrich, D. (1978). rating scale formulation ordered response categories. Psychometrika, 43, 561-573. Andrich, D. (1996). Hyperbolic cosine latent trait models unfolding direct-responses pairwise preferences. Applied Psychological Measurement, 20, 269-290. Andrich, D., Luo, G. (1993). hyperbolic cosine latent trait model unfolding dichotomous single-     stimulus responses. Applied Psychological Measurement, 17, 253-276. Andrich, D. (1988). application unfolding model PIRT type measurement attitude. Applied Psychological Measurement, 12, 33-51. Bock, R. D., & Aitkin, M. (1981). Marginal maximum likelihood estimation item parameters: Application EM algorithm. Psychometrika, 46(4), 443-459. Bock, R. D., Gibbons, R., & Muraki, E. (1988). Full-Information Item Factor Analysis. Applied Psychological Measurement, 12(3), 261-280. Bock, R. D. & Lieberman, M. (1970). Fitting response model n dichotomously scored items. Psychometrika, 35, 179-197. Cai, L. (2010a). High-Dimensional exploratory item factor analysis Metropolis-Hastings Robbins-Monro algorithm. Psychometrika, 75, 33-57. Cai, L. (2010b). Metropolis-Hastings Robbins-Monro algorithm confirmatory item factor analysis. Journal Educational Behavioral Statistics, 35, 307-335. Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072 Chalmers, R. P. (2018). Numerical Approximation Observed Information Matrix Oakes' Identity. British Journal Mathematical Statistical Psychology DOI: 10.1111/bmsp.12127 Chalmers, R., P. & Flora, D. (2014). Maximum-likelihood Estimation Noncompensatory IRT Models MH-RM Algorithm. Applied Psychological Measurement, 38, 339-358. doi:10.1177/0146621614520958 Chen, W. H. & Thissen, D. (1997). Local dependence indices item pairs using item response theory. Journal Educational Behavioral Statistics, 22, 265-289. Embretson, S. E. (1984). general latent trait model response processes. Psychometrika, 49, 175-186. Falk, C. F. & Cai, L. (2016). Maximum Marginal Likelihood Estimation Monotonic Polynomial Generalized Partial Credit Model Applications Multiple Group Analysis. Psychometrika, 81, 434-460. Fischer, G. H. (1983). Logistic latent trait models linear constraints. Psychometrika, 48, 3-26. Hoijtink H. (1990). PARELLA: Measurement latent traits proximity items. Netherlands: University Groningen. Lord, F. M. & Novick, M. R. (1968). Statistical theory mental test scores. Addison-Wesley. Lucke, J. F. (2015). Unipolar item response models. S. P. Reise & D. . Revicki (Eds.), Handbook item response theory modeling: Applications typical performance assessment (pp. 272-284). New York, NY:  Routledge/Taylor & Francis Group. Luo G. (2001). class probabilistic unfolding models polytomous responses. Journal Mathematical Psychology. 45(2):224-248. 10.1006/jmps.2000.1310 Luo G, Andrich D. (2005). Information functions general dichotomous unfolding model. : Alagumalai S, Curtis D.D., & Hungi N., editor. Applied Rasch Measurement: Book Exemplars: Dordrecht, Netherlands: Springer. Maydeu-Olivares, ., Hernandez, . & McDonald, R. P. (2006). Multidimensional Ideal Point Item Response Theory Model Binary Data. Multivariate Behavioral Research, 41, 445-471. Muraki, E. (1990). Fitting polytomous item response model Likert-type data. Applied Psychological Measurement, 14, 59-71. Muraki, E. (1992). generalized partial credit model: Application EM algorithm. Applied Psychological Measurement, 16, 159-176. Muraki, E. & Carlson, E. B. (1995). Full-information factor analysis polytomous item responses. Applied Psychological Measurement, 19, 73-90. Ramsay, J. O. (1975). Solving implicit equations psychometric data analysis. Psychometrika, 40, 337-360. Rasch, G. (1960). Probabilistic models intelligence attainment tests. Danish Institute Educational Research. Roberts, J. S., Donoghue, J. R., & Laughlin, J. E. (2000). General Item Response Theory Model Unfolding Unidimensional Polytomous Responses. Applied Psychological Measurement, 24, 3-32. Samejima, F. (1969). Estimation latent ability using response pattern graded scores. Psychometrika Monographs, 34. Shim, H., Bonifay, W., & Wiedermann, W. (2022). Parsimonious asymmetric item response theory modeling complementary log-log link. Behavior Research Methods, 55, 200-219. Suh, Y. & Bolt, D. (2010). Nested logit models multiple-choice item response data. Psychometrika, 75, 454-473. Sympson, J. B. (1977). model testing multidimensional items. Proceedings 1977 Computerized Adaptive Testing Conference. Thissen, D. (1982). Marginal maximum likelihood estimation one-parameter logistic model. Psychometrika, 47, 175-186. Tutz, G. (1990). Sequential item response models ordered response. British Journal Mathematical Statistical Psychology, 43, 39-55. Varadhan, R. & Roland, C. (2008). Simple Globally Convergent Methods Accelerating Convergence EM Algorithm. Scandinavian Journal Statistics, 35, 335-353. Whitely, S. E. (1980). Multicomponent latent trait models ability tests. Psychometrika, 45(4), 470-494. Wood, R., Wilson, D. T., Gibbons, R. D., Schilling, S. G., Muraki, E., & Bock, R. D. (2003). TESTFACT 4 Windows: Test Scoring, Item Statistics, Full-information Item Factor Analysis [Computer software]. Lincolnwood, IL: Scientific Software International. Woods, C. M., Lin, N. (2009). Item Response Theory Estimation Latent Density Using Davidian Curves. Applied Psychological Measurement,33(2), 102-117.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full-Information Item Factor Analysis (Multidimensional Item Response Theory) — mirt","text":"","code":"# load LSAT section 7 data and compute 1 and 2 factor models data <- expand.table(LSAT7) itemstats(data) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            3.707          1.199 0.143 0.052 0.453     0.886 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1 1000 2 0.828 0.378   0.530         0.246       0.396 #> Item.2 1000 2 0.658 0.475   0.600         0.247       0.394 #> Item.3 1000 2 0.772 0.420   0.611         0.313       0.345 #> Item.4 1000 2 0.606 0.489   0.592         0.223       0.415 #> Item.5 1000 2 0.843 0.364   0.461         0.175       0.438 #>  #> $proportions #>            0     1 #> Item.1 0.172 0.828 #> Item.2 0.342 0.658 #> Item.3 0.228 0.772 #> Item.4 0.394 0.606 #> Item.5 0.157 0.843 #>   (mod1 <- mirt(data, 1)) #>  #>  #> Call: #> mirt(data = data, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN coef(mod1) #> $Item.1 #>        a1     d g u #> par 0.988 1.856 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.081 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.804 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.765 0.486 0 1 #>  #> $Item.5 #>        a1     d g u #> par 0.736 1.855 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  summary(mod1) #>           F1    h2 #> Item.1 0.502 0.252 #> Item.2 0.536 0.287 #> Item.3 0.708 0.501 #> Item.4 0.410 0.168 #> Item.5 0.397 0.157 #>  #> SS loadings:  1.366  #> Proportion Var:  0.273  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 plot(mod1)  plot(mod1, type = 'trace')   # \\donttest{ (mod2 <- mirt(data, 1, SE = TRUE)) #standard errors via the Oakes method #>  #>  #> Calculating information matrix... #>  #> Call: #> mirt(data = data, model = 1, SE = TRUE) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Information matrix estimated with method: Oakes #> Second-order test: model is a possible local maximum #> Condition number of information matrix =  30.23088 #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN (mod2 <- mirt(data, 1, SE = TRUE, SE.type = 'SEM')) #standard errors with SEM method #>  #>  #> Calculating information matrix... #>  #> Call: #> mirt(data = data, model = 1, SE = TRUE, SE.type = \"SEM\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-05 tolerance after 74 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: none  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Information matrix estimated with method: SEM #> Second-order test: model is a possible local maximum #> Condition number of information matrix =  30.12751 #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN coef(mod2) #> $Item.1 #>            a1     d  g  u #> par     0.988 1.856  0  1 #> CI_2.5  0.639 1.599 NA NA #> CI_97.5 1.336 2.112 NA NA #>  #> $Item.2 #>            a1     d  g  u #> par     1.081 0.808  0  1 #> CI_2.5  0.755 0.629 NA NA #> CI_97.5 1.407 0.987 NA NA #>  #> $Item.3 #>            a1     d  g  u #> par     1.707 1.805  0  1 #> CI_2.5  1.086 1.395 NA NA #> CI_97.5 2.329 2.215 NA NA #>  #> $Item.4 #>            a1     d  g  u #> par     0.765 0.486  0  1 #> CI_2.5  0.500 0.339 NA NA #> CI_97.5 1.030 0.633 NA NA #>  #> $Item.5 #>            a1     d  g  u #> par     0.736 1.854  0  1 #> CI_2.5  0.437 1.630 NA NA #> CI_97.5 1.034 2.079 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0      1 #> CI_2.5      NA     NA #> CI_97.5     NA     NA #>  (mod3 <- mirt(data, 1, SE = TRUE, SE.type = 'Richardson')) #with numerical Richardson method #>  #>  #> Calculating information matrix... #>  #> Call: #> mirt(data = data, model = 1, SE = TRUE, SE.type = \"Richardson\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Information matrix estimated with method: Richardson #> Second-order test: model is a possible local maximum #> Condition number of information matrix =  30.23102 #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN residuals(mod1) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.037  -0.020  -0.007   0.001   0.024   0.051  #>  #>        Item.1 Item.2 Item.3 Item.4 Item.5 #> Item.1        -0.021 -0.029  0.051  0.049 #> Item.2  0.453         0.033 -0.016 -0.037 #> Item.3  0.854  1.060        -0.012 -0.002 #> Item.4  2.572  0.267  0.153         0.000 #> Item.5  2.389  1.384  0.003  0.000        plot(mod1) #test score function  plot(mod1, type = 'trace') #trace lines  plot(mod2, type = 'info') #test information  plot(mod2, MI=200) #expected total score with 95% confidence intervals   # estimated 3PL model for item 5 only (mod1.3PL <- mirt(data, 1, itemtype = c('2PL', '2PL', '2PL', '2PL', '3PL'))) #>  #>  #> Call: #> mirt(data = data, model = 1, itemtype = c(\"2PL\", \"2PL\", \"2PL\",  #>     \"2PL\", \"3PL\")) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 43 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.794 #> Estimated parameters: 11  #> AIC = 5339.587 #> BIC = 5393.573; SABIC = 5358.636 #> G2 (20) = 31.68, p = 0.0469 #> RMSEA = 0.024, CFI = NaN, TLI = NaN coef(mod1.3PL) #> $Item.1 #>        a1     d g u #> par 0.987 1.855 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.082 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.805 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.764 0.486 0 1 #>  #> $Item.5 #>        a1     d     g u #> par 0.778 1.643 0.161 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   # internally g and u pars are stored as logits, so usually a good idea to include normal prior #  to help stabilize the parameters. For a value around .182 use a mean #  of -1.5 (since 1 / (1 + exp(-(-1.5))) == .182) model <- 'F = 1-5          PRIOR = (5, g, norm, -1.5, 3)' mod1.3PL.norm <- mirt(data, model, itemtype = c('2PL', '2PL', '2PL', '2PL', '3PL')) #>  coef(mod1.3PL.norm) #> $Item.1 #>        a1     d g u #> par 0.987 1.855 0 1 #>  #> $Item.2 #>        a1     d g u #> par 1.083 0.808 0 1 #>  #> $Item.3 #>        a1     d g u #> par 1.706 1.804 0 1 #>  #> $Item.4 #>        a1     d g u #> par 0.764 0.486 0 1 #>  #> $Item.5 #>        a1   d    g u #> par 0.788 1.6 0.19 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  #limited information fit statistics M2(mod1.3PL.norm) #>             M2 df          p      RMSEA RMSEA_5   RMSEA_95      SRMSR       TLI #> stats 8.800082  4 0.06629543 0.03465864       0 0.06610847 0.03207363 0.9454563 #>             CFI #> stats 0.9781825  # unidimensional ideal point model idealpt <- mirt(data, 1, itemtype = 'ideal') #>  plot(idealpt, type = 'trace', facet_items = TRUE)  plot(idealpt, type = 'trace', facet_items = FALSE)   # two factors (exploratory) mod2 <- mirt(data, 2) #>  coef(mod2) #> $Item.1 #>         a1   a2     d g u #> par -2.007 0.87 2.648 0 1 #>  #> $Item.2 #>         a1     a2     d g u #> par -0.849 -0.522 0.788 0 1 #>  #> $Item.3 #>         a1     a2     d g u #> par -2.153 -1.836 2.483 0 1 #>  #> $Item.4 #>         a1     a2     d g u #> par -0.756 -0.028 0.485 0 1 #>  #> $Item.5 #>         a1 a2     d g u #> par -0.757  0 1.864 0 1 #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0      0      1      0      1 #>  summary(mod2, rotate = 'oblimin') #oblimin rotation #>  #> Rotation:  oblimin  #>  #> Rotated factor loadings:  #>  #>             F1      F2    h2 #> Item.1  0.7944 -0.0111 0.623 #> Item.2  0.0804  0.4630 0.255 #> Item.3 -0.0129  0.8628 0.734 #> Item.4  0.2794  0.1925 0.165 #> Item.5  0.2929  0.1772 0.165 #>  #> Rotated SS loadings:  0.802 1.027  #>  #> Factor correlations:  #>  #>       F1 F2 #> F1 1.000    #> F2 0.463  1 residuals(mod2) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.018  -0.001   0.000   0.000   0.002   0.011  #>  #>        Item.1 Item.2 Item.3 Item.4 Item.5 #> Item.1        -0.001  0.001  0.002  0.003 #> Item.2  0.001         0.000  0.011 -0.018 #> Item.3  0.001  0.000        -0.002  0.006 #> Item.4  0.002  0.111  0.004        -0.001 #> Item.5  0.008  0.325  0.041  0.001        plot(mod2)  plot(mod2, rotate = 'oblimin')   anova(mod1, mod2) #compare the two models #>           AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mod1 5337.610 5354.927 5356.263 5386.688 -2658.805                 #> mod2 5335.039 5359.283 5361.153 5403.748 -2653.520 10.571  4 0.032 scoresfull <- fscores(mod2) #factor scores for each response pattern head(scoresfull) #>          F1     F2 #> [1,] -1.701 -1.712 #> [2,] -1.701 -1.712 #> [3,] -1.701 -1.712 #> [4,] -1.701 -1.712 #> [5,] -1.701 -1.712 #> [6,] -1.701 -1.712 scorestable <- fscores(mod2, full.scores = FALSE) #save factor score table #>  #> Method:  EAP #> Rotate:  oblimin #>  #> Empirical Reliability: #>  #>     F1     F2  #> 0.2717 0.3565  head(scorestable) #>      Item.1 Item.2 Item.3 Item.4 Item.5     F1     F2 SE_F1 SE_F2 #> [1,]      0      0      0      0      0 -1.701 -1.712 0.823 0.771 #> [2,]      0      0      0      0      1 -1.442 -1.532 0.829 0.769 #> [3,]      0      0      0      1      0 -1.449 -1.525 0.829 0.769 #> [4,]      0      0      0      1      1 -1.186 -1.343 0.838 0.771 #> [5,]      0      0      1      0      0 -1.369 -0.708 0.834 0.796 #> [6,]      0      0      1      0      1 -1.099 -0.510 0.846 0.810  # confirmatory (as an example, model is not identified since you need 3 items per factor) # Two ways to define a confirmatory model: with mirt.model, or with a string  # these model definitions are equivalent cmodel <- mirt.model('    F1 = 1,4,5    F2 = 2,3') cmodel2 <- 'F1 = 1,4,5             F2 = 2,3'  cmod <- mirt(data, cmodel) #>  # cmod <- mirt(data, cmodel2) # same as above coef(cmod) #> $Item.1 #>        a1 a2     d g u #> par 1.792  0 2.358 0 1 #>  #> $Item.2 #>     a1    a2   d g u #> par  0 1.427 0.9 0 1 #>  #> $Item.3 #>     a1    a2     d g u #> par  0 1.559 1.725 0 1 #>  #> $Item.4 #>        a1 a2     d g u #> par 0.743  0 0.483 0 1 #>  #> $Item.5 #>        a1 a2     d g u #> par 0.763  0 1.867 0 1 #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0      0      1      0      1 #>  anova(cmod, mod2) #>           AIC    SABIC       HQ      BIC    logLik     X2 df p #> cmod 5392.596 5409.913 5411.249 5441.674 -2686.298             #> mod2 5335.039 5359.283 5361.153 5403.748 -2653.520 65.557  4 0 # check if identified by computing information matrix (cmod <- mirt(data, cmodel, SE = TRUE)) #>  #>  #> Calculating information matrix... #> Warning: Could not invert information matrix; model may not be (empirically) identified. #>  #> Call: #> mirt(data = data, model = cmodel, SE = TRUE) #>  #> Full-information item factor analysis with 2 factor(s). #> Converged within 1e-04 tolerance after 125 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 31 #> Latent density type: Gaussian  #>  #> Information matrix estimated with method: Oakes #> Second-order test: model is not a maximum or the information matrix is too inaccurate #>  #> Log-likelihood = -2686.298 #> Estimated parameters: 10  #> AIC = 5392.596 #> BIC = 5441.674; SABIC = 5409.913 #> G2 (21) = 86.69, p = 0 #> RMSEA = 0.056, CFI = NaN, TLI = NaN  ########### # data from the 'ltm' package in numeric format itemstats(Science) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  392           11.668          2.003 0.275 0.098 0.598      1.27 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Comfort 392 4 3.120 0.588   0.596         0.352       0.552 #> Work    392 4 2.722 0.807   0.666         0.332       0.567 #> Future  392 4 2.990 0.757   0.748         0.488       0.437 #> Benefit 392 4 2.837 0.802   0.684         0.363       0.541 #>  #> $proportions #>             1     2     3     4 #> Comfort 0.013 0.082 0.679 0.227 #> Work    0.084 0.250 0.526 0.140 #> Future  0.036 0.184 0.536 0.245 #> Benefit 0.054 0.255 0.492 0.199 #>   pmod1 <- mirt(Science, 1) #>  plot(pmod1)  plot(pmod1, type = 'trace')  plot(pmod1, type = 'itemscore')  summary(pmod1) #>            F1    h2 #> Comfort 0.522 0.273 #> Work    0.584 0.342 #> Future  0.803 0.645 #> Benefit 0.541 0.293 #>  #> SS loadings:  1.552  #> Proportion Var:  0.388  #>  #> Factor correlations:  #>  #>    F1 #> F1  1  # Constrain all slopes to be equal with the constrain = list() input or mirt.model() syntax # first obtain parameter index values <- mirt(Science,1, pars = 'values') values #note that slopes are numbered 1,5,9,13, or index with values$parnum[values$name == 'a1'] #>    group    item     class   name parnum  value lbound ubound   est const #> 1    all Comfort    graded     a1      1  0.851   -Inf    Inf  TRUE  none #> 2    all Comfort    graded     d1      2  4.390   -Inf    Inf  TRUE  none #> 3    all Comfort    graded     d2      3  2.583   -Inf    Inf  TRUE  none #> 4    all Comfort    graded     d3      4 -1.471   -Inf    Inf  TRUE  none #> 5    all    Work    graded     a1      5  0.851   -Inf    Inf  TRUE  none #> 6    all    Work    graded     d1      6  2.707   -Inf    Inf  TRUE  none #> 7    all    Work    graded     d2      7  0.842   -Inf    Inf  TRUE  none #> 8    all    Work    graded     d3      8 -2.120   -Inf    Inf  TRUE  none #> 9    all  Future    graded     a1      9  0.851   -Inf    Inf  TRUE  none #> 10   all  Future    graded     d1     10  3.543   -Inf    Inf  TRUE  none #> 11   all  Future    graded     d2     11  1.522   -Inf    Inf  TRUE  none #> 12   all  Future    graded     d3     12 -1.357   -Inf    Inf  TRUE  none #> 13   all Benefit    graded     a1     13  0.851   -Inf    Inf  TRUE  none #> 14   all Benefit    graded     d1     14  3.166   -Inf    Inf  TRUE  none #> 15   all Benefit    graded     d2     15  0.982   -Inf    Inf  TRUE  none #> 16   all Benefit    graded     d3     16 -1.661   -Inf    Inf  TRUE  none #> 17   all   GROUP GroupPars MEAN_1     17  0.000   -Inf    Inf FALSE  none #> 18   all   GROUP GroupPars COV_11     18  1.000      0    Inf FALSE  none #>    nconst prior.type prior_1 prior_2 #> 1    none       none     NaN     NaN #> 2    none       none     NaN     NaN #> 3    none       none     NaN     NaN #> 4    none       none     NaN     NaN #> 5    none       none     NaN     NaN #> 6    none       none     NaN     NaN #> 7    none       none     NaN     NaN #> 8    none       none     NaN     NaN #> 9    none       none     NaN     NaN #> 10   none       none     NaN     NaN #> 11   none       none     NaN     NaN #> 12   none       none     NaN     NaN #> 13   none       none     NaN     NaN #> 14   none       none     NaN     NaN #> 15   none       none     NaN     NaN #> 16   none       none     NaN     NaN #> 17   none       none     NaN     NaN #> 18   none       none     NaN     NaN (pmod1_equalslopes <- mirt(Science, 1, constrain = list(c(1,5,9,13)))) #>  #>  #> Call: #> mirt(data = Science, model = 1, constrain = list(c(1, 5, 9, 13))) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 15 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1613.899 #> Estimated parameters: 13  #> AIC = 3253.798 #> BIC = 3305.425; SABIC = 3264.176 #> G2 (242) = 223.62, p = 0.7959 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(pmod1_equalslopes) #> $Comfort #>        a1    d1    d2     d3 #> par 1.321 5.165 2.844 -1.587 #>  #> $Work #>        a1    d1    d2     d3 #> par 1.321 2.992 0.934 -2.319 #>  #> $Future #>        a1    d1    d2     d3 #> par 1.321 4.067 1.662 -1.488 #>  #> $Benefit #>        a1   d1    d2     d3 #> par 1.321 3.55 1.057 -1.806 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   # using mirt.model syntax, constrain all item slopes to be equal model <- 'F = 1-4           CONSTRAIN = (1-4, a1)' (pmod1_equalslopes <- mirt(Science, model)) #>  #>  #> Call: #> mirt(data = Science, model = model) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 15 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1613.899 #> Estimated parameters: 13  #> AIC = 3253.798 #> BIC = 3305.425; SABIC = 3264.176 #> G2 (242) = 223.62, p = 0.7959 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(pmod1_equalslopes) #> $Comfort #>        a1    d1    d2     d3 #> par 1.321 5.165 2.844 -1.587 #>  #> $Work #>        a1    d1    d2     d3 #> par 1.321 2.992 0.934 -2.319 #>  #> $Future #>        a1    d1    d2     d3 #> par 1.321 4.067 1.662 -1.488 #>  #> $Benefit #>        a1   d1    d2     d3 #> par 1.321 3.55 1.057 -1.806 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   coef(pmod1_equalslopes) #> $Comfort #>        a1    d1    d2     d3 #> par 1.321 5.165 2.844 -1.587 #>  #> $Work #>        a1    d1    d2     d3 #> par 1.321 2.992 0.934 -2.319 #>  #> $Future #>        a1    d1    d2     d3 #> par 1.321 4.067 1.662 -1.488 #>  #> $Benefit #>        a1   d1    d2     d3 #> par 1.321 3.55 1.057 -1.806 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  anova(pmod1_equalslopes, pmod1) #significantly worse fit with almost all criteria #>                        AIC    SABIC       HQ      BIC    logLik     X2 df     p #> pmod1_equalslopes 3253.798 3264.176 3274.259 3305.425 -1613.899                 #> pmod1             3249.739 3262.512 3274.922 3313.279 -1608.870 10.059  3 0.018  pmod2 <- mirt(Science, 2) #>  summary(pmod2) #>  #> Rotation:  oblimin  #>  #> Rotated factor loadings:  #>  #>              F1      F2    h2 #> Comfort  0.6016  0.0312 0.382 #> Work    -0.0573  0.7971 0.592 #> Future   0.3302  0.5153 0.548 #> Benefit  0.7231 -0.0239 0.506 #>  #> Rotated SS loadings:  0.997 0.902  #>  #> Factor correlations:  #>  #>       F1 F2 #> F1 1.000    #> F2 0.511  1 plot(pmod2, rotate = 'oblimin')  itemplot(pmod2, 1, rotate = 'oblimin')  anova(pmod1, pmod2) #>            AIC    SABIC       HQ      BIC    logLik     X2 df     p #> pmod1 3249.739 3262.512 3274.922 3313.279 -1608.870                 #> pmod2 3241.938 3257.106 3271.843 3317.392 -1601.969 13.801  3 0.003  # unidimensional fit with a generalized partial credit and nominal model (gpcmod <- mirt(Science, 1, 'gpcm')) #>  #>  #> Call: #> mirt(data = Science, model = 1, itemtype = \"gpcm\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 50 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1612.683 #> Estimated parameters: 16  #> AIC = 3257.366 #> BIC = 3320.906; SABIC = 3270.139 #> G2 (239) = 221.19, p = 0.7896 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(gpcmod) #> $Comfort #>        a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par 0.865   0   1   2   3  0 2.831 5.324 3.998 #>  #> $Work #>        a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par 0.841   0   1   2   3  0 1.711 2.578 0.848 #>  #> $Future #>        a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par 2.204   0   1   2   3  0 4.601 6.759 4.918 #>  #> $Benefit #>        a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par 0.724   0   1   2   3  0 2.099 2.899 1.721 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   # for the nominal model the lowest and highest categories are assumed to be the #  theoretically lowest and highest categories that related to the latent trait(s) (nomod <- mirt(Science, 1, 'nominal')) #>  #>  #> Call: #> mirt(data = Science, model = 1, itemtype = \"nominal\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 71 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1608.455 #> Estimated parameters: 24  #> AIC = 3264.91 #> BIC = 3360.22; SABIC = 3284.069 #> G2 (231) = 212.73, p = 0.8002 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(nomod) #ordering of ak values suggest that the items are indeed ordinal #> $Comfort #>        a1 ak0   ak1   ak2 ak3 d0    d1    d2    d3 #> par 1.008   0 1.541 1.999   3  0 3.639 5.905 4.533 #>  #> $Work #>        a1 ak0   ak1 ak2 ak3 d0    d1    d2    d3 #> par 0.841   0 0.689 1.5   3  0 1.464 2.326 0.325 #>  #> $Future #>        a1 ak0   ak1   ak2 ak3 d0    d1    d2    d3 #> par 2.041   0 0.762 1.861   3  0 3.668 5.868 3.949 #>  #> $Benefit #>        a1 ak0   ak1   ak2 ak3 d0    d1    d2    d3 #> par 0.779   0 1.036 1.742   3  0 2.144 2.911 1.621 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  anova(gpcmod, nomod) #>             AIC    SABIC       HQ      BIC    logLik    X2 df    p #> gpcmod 3257.366 3270.139 3282.549 3320.906 -1612.683               #> nomod  3264.910 3284.069 3302.684 3360.220 -1608.455 8.456  8 0.39 itemplot(nomod, 3)   # generalized graded unfolding model (ggum <- mirt(Science, 1, 'ggum')) #>  #>  #> Call: #> mirt(data = Science, model = 1, itemtype = \"ggum\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 89 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1611.484 #> Estimated parameters: 20  #> AIC = 3262.968 #> BIC = 3342.393; SABIC = 3278.934 #> G2 (235) = 218.79, p = 0.7687 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(ggum, simplify=TRUE) #> $items #>            a1    b1    t1    t2    t3 #> Comfort 0.824 3.478 6.826 6.475 1.780 #> Work    0.818 3.217 5.280 4.274 0.969 #> Future  2.241 2.800 4.888 3.774 1.961 #> Benefit 0.696 3.584 6.556 4.725 1.744 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  plot(ggum)  plot(ggum, type = 'trace')  plot(ggum, type = 'itemscore')   # monotonic polyomial models (monopoly <- mirt(Science, 1, 'monopoly')) #>  #>  #> Call: #> mirt(data = Science, model = 1, itemtype = \"monopoly\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 55 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1601.174 #> Estimated parameters: 24  #> AIC = 3250.347 #> BIC = 3345.657; SABIC = 3269.506 #> G2 (231) = 198.17, p = 0.9424 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(monopoly, simplify=TRUE) #> $items #>          omega   xi1   xi2    xi3 alpha1   tau2 #> Comfort -1.431 2.911 2.218 -1.469 -0.934  0.728 #> Work    -0.412 1.378 0.698 -2.152 -0.499 -1.151 #> Future   0.833 4.988 2.259 -1.910  0.019 -8.472 #> Benefit -1.714 1.883 0.618 -1.389 -1.424  0.716 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  plot(monopoly)  plot(monopoly, type = 'trace')  plot(monopoly, type = 'itemscore')   # unipolar IRT model unimod <- mirt(Science, itemtype = 'ULL') #>  coef(unimod, simplify=TRUE) #> $items #>          eta1 log_lambda1 log_lambda2 log_lambda3 #> Comfort 1.175       4.776       2.299      -1.709 #> Work    1.618       2.533       0.554      -2.736 #> Future  2.801       4.030       1.525      -2.594 #> Benefit 1.319       3.020       0.681      -1.995 #>  #> $GroupPars #>     meanlog sdlog #> par       0     1 #>  plot(unimod)  plot(unimod, type = 'trace')  itemplot(unimod, 1)   # following use the correct log-normal density for latent trait itemfit(unimod) #>      item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1 Comfort  5.664       6      0.000  0.462 #> 2    Work 10.136       8      0.026  0.256 #> 3  Future 19.477       8      0.061  0.013 #> 4 Benefit 12.106      11      0.016  0.356 M2(unimod, type = 'C2') #>             M2 df            p     RMSEA    RMSEA_5  RMSEA_95     SRMSR #> stats 18.69535  2 8.716799e-05 0.1461148 0.09026025 0.2096111 0.0786373 #>             TLI       CFI #> stats 0.7376985 0.9125662 fs <- fscores(unimod) hist(fs, 20)  fscores(unimod, method = 'EAPsum', full.scores = FALSE) #>       df     X2 p.X2 SEM.alpha rxx.alpha rxx_F1 #> stats 10 33.926    0     1.305     0.658  0.531 #>  #>    Sum.Scores    F1 SE_F1 observed expected std.res #> 4           4 0.138 0.153        2    0.127   5.251 #> 5           5 0.304 0.088        1    0.766   0.267 #> 6           6 0.328 0.084        2    4.339   1.123 #> 7           7 0.352 0.126        1   13.909   3.461 #> 8           8 0.407 0.199       11   27.739   3.178 #> 9           9 0.530 0.305       32   40.624   1.353 #> 10         10 0.748 0.440       58   52.271   0.792 #> 11         11 1.053 0.604       70   63.507   0.815 #> 12         12 1.478 0.845       91   68.879   2.665 #> 13         13 2.164 1.282       56   54.418   0.214 #> 14         14 3.299 2.001       36   36.187   0.031 #> 15         15 5.109 3.236       20   20.821   0.180 #> 16         16 8.222 5.298       12    8.414   1.236  ## example applying survey weights. # weight the first half of the cases to be more representative of population survey.weights <- c(rep(2, nrow(Science)/2), rep(1, nrow(Science)/2)) survey.weights <- survey.weights/sum(survey.weights) * nrow(Science) unweighted <- mirt(Science, 1) #>  weighted <- mirt(Science, 1, survey.weights=survey.weights) #>   ########### # empirical dimensionality testing that includes 'guessing'  data(SAT12) data <- key2binary(SAT12,   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) itemstats(data) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  600           18.202          5.054 0.108 0.075 0.798     2.272 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item.1  600 2 0.283 0.451   0.380         0.300       0.793 #> Item.2  600 2 0.568 0.496   0.539         0.464       0.785 #> Item.3  600 2 0.280 0.449   0.446         0.371       0.789 #> Item.4  600 2 0.378 0.485   0.325         0.235       0.796 #> Item.5  600 2 0.620 0.486   0.424         0.340       0.791 #> Item.6  600 2 0.160 0.367   0.414         0.351       0.791 #> Item.7  600 2 0.760 0.427   0.366         0.289       0.793 #> Item.8  600 2 0.202 0.402   0.307         0.233       0.795 #> Item.9  600 2 0.885 0.319   0.189         0.127       0.798 #> Item.10 600 2 0.422 0.494   0.465         0.383       0.789 #> Item.11 600 2 0.983 0.128   0.181         0.156       0.797 #> Item.12 600 2 0.415 0.493   0.173         0.076       0.803 #> Item.13 600 2 0.662 0.474   0.438         0.358       0.790 #> Item.14 600 2 0.723 0.448   0.411         0.333       0.791 #> Item.15 600 2 0.817 0.387   0.393         0.325       0.792 #> Item.16 600 2 0.413 0.493   0.367         0.278       0.794 #> Item.17 600 2 0.963 0.188   0.238         0.202       0.796 #> Item.18 600 2 0.352 0.478   0.576         0.508       0.783 #> Item.19 600 2 0.548 0.498   0.401         0.314       0.792 #> Item.20 600 2 0.873 0.333   0.376         0.318       0.792 #> Item.21 600 2 0.915 0.279   0.190         0.136       0.798 #> Item.22 600 2 0.935 0.247   0.284         0.238       0.795 #> Item.23 600 2 0.313 0.464   0.338         0.253       0.795 #> Item.24 600 2 0.728 0.445   0.422         0.346       0.791 #> Item.25 600 2 0.375 0.485   0.383         0.297       0.793 #> Item.26 600 2 0.460 0.499   0.562         0.489       0.783 #> Item.27 600 2 0.862 0.346   0.425         0.367       0.791 #> Item.28 600 2 0.530 0.500   0.465         0.383       0.789 #> Item.29 600 2 0.340 0.474   0.407         0.324       0.791 #> Item.30 600 2 0.440 0.497   0.255         0.159       0.799 #> Item.31 600 2 0.833 0.373   0.479         0.419       0.788 #> Item.32 600 2 0.162 0.368   0.110         0.037       0.802 #>  #> $proportions #>             0     1 #> Item.1  0.717 0.283 #> Item.2  0.432 0.568 #> Item.3  0.720 0.280 #> Item.4  0.622 0.378 #> Item.5  0.380 0.620 #> Item.6  0.840 0.160 #> Item.7  0.240 0.760 #> Item.8  0.798 0.202 #> Item.9  0.115 0.885 #> Item.10 0.578 0.422 #> Item.11 0.017 0.983 #> Item.12 0.585 0.415 #> Item.13 0.338 0.662 #> Item.14 0.277 0.723 #> Item.15 0.183 0.817 #> Item.16 0.587 0.413 #> Item.17 0.037 0.963 #> Item.18 0.648 0.352 #> Item.19 0.452 0.548 #> Item.20 0.127 0.873 #> Item.21 0.085 0.915 #> Item.22 0.065 0.935 #> Item.23 0.687 0.313 #> Item.24 0.272 0.728 #> Item.25 0.625 0.375 #> Item.26 0.540 0.460 #> Item.27 0.138 0.862 #> Item.28 0.470 0.530 #> Item.29 0.660 0.340 #> Item.30 0.560 0.440 #> Item.31 0.167 0.833 #> Item.32 0.838 0.162 #>   mod1 <- mirt(data, 1) #>  extract.mirt(mod1, 'time') #time elapsed for each estimation component #> TOTAL:   Data  Estep  Mstep     SE   Post  #>  0.267  0.035  0.099  0.116  0.000  0.000   # optionally use Newton-Raphson for (generally) faster convergence in the M-step's mod1 <- mirt(data, 1, optimizer = 'NR') #>  extract.mirt(mod1, 'time') #> TOTAL:   Data  Estep  Mstep     SE   Post  #>  0.217  0.035  0.091  0.069  0.000  0.000   mod2 <- mirt(data, 2, optimizer = 'NR') #>  #> Warning: EM cycles terminated after 500 iterations. # difficulty converging with reduced quadpts, reduce TOL mod3 <- mirt(data, 3, TOL = .001, optimizer = 'NR') #>  anova(mod1,mod2) #>           AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod1 19105.91 19184.13 19215.46 19387.31 -9488.955             #> mod2 19073.92 19190.03 19236.53 19491.63 -9441.963 93.985 31 0 anova(mod2, mod3) #negative AIC, 2 factors probably best #>           AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mod2 19073.92 19190.03 19236.53 19491.63 -9441.963                 #> mod3 19080.18 19232.96 19294.13 19629.80 -9415.090 53.744 30 0.005  # same as above, but using the QMCEM method for generally better accuracy in mod3 mod3 <- mirt(data, 3, method = 'QMCEM', TOL = .001, optimizer = 'NR') #>  anova(mod2, mod3) #>           AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mod2 19073.92 19190.03 19236.53 19491.63 -9441.963                 #> mod3 19081.58 19234.36 19295.54 19631.20 -9415.792 52.342 30 0.007  # with fixed guessing parameters mod1g <- mirt(data, 1, guess = .1) #>  coef(mod1g) #> $Item.1 #>        a1      d   g u #> par 1.211 -1.737 0.1 1 #>  #> $Item.2 #>       a1     d   g u #> par 1.78 0.147 0.1 1 #>  #> $Item.3 #>       a1    d   g u #> par 1.91 -2.2 0.1 1 #>  #> $Item.4 #>        a1      d   g u #> par 0.833 -0.944 0.1 1 #>  #> $Item.5 #>        a1     d   g u #> par 1.089 0.399 0.1 1 #>  #> $Item.6 #>        a1      d   g u #> par 3.265 -5.212 0.1 1 #>  #> $Item.7 #>       a1     d   g u #> par 1.02 1.224 0.1 1 #>  #> $Item.8 #>        a1      d   g u #> par 1.639 -2.977 0.1 1 #>  #> $Item.9 #>       a1     d   g u #> par 0.49 2.007 0.1 1 #>  #> $Item.10 #>        a1      d   g u #> par 1.257 -0.756 0.1 1 #>  #> $Item.11 #>       a1    d   g u #> par 1.68 5.18 0.1 1 #>  #> $Item.12 #>        a1      d   g u #> par 0.191 -0.625 0.1 1 #>  #> $Item.13 #>        a1     d   g u #> par 1.147 0.654 0.1 1 #>  #> $Item.14 #>        a1     d   g u #> par 1.099 1.008 0.1 1 #>  #> $Item.15 #>        a1    d   g u #> par 1.337 1.79 0.1 1 #>  #> $Item.16 #>        a1      d   g u #> par 0.923 -0.744 0.1 1 #>  #> $Item.17 #>        a1     d   g u #> par 1.519 4.077 0.1 1 #>  #> $Item.18 #>        a1      d   g u #> par 2.585 -1.749 0.1 1 #>  #> $Item.19 #>       a1      d   g u #> par 0.91 -0.002 0.1 1 #>  #> $Item.20 #>        a1     d   g u #> par 1.485 2.438 0.1 1 #>  #> $Item.21 #>        a1     d   g u #> par 0.616 2.407 0.1 1 #>  #> $Item.22 #>        a1     d   g u #> par 1.429 3.291 0.1 1 #>  #> $Item.23 #>       a1      d   g u #> par 0.96 -1.393 0.1 1 #>  #> $Item.24 #>        a1     d   g u #> par 1.282 1.099 0.1 1 #>  #> $Item.25 #>        a1  d   g u #> par 1.028 -1 0.1 1 #>  #> $Item.26 #>        a1      d   g u #> par 2.059 -0.658 0.1 1 #>  #> $Item.27 #>        a1     d   g u #> par 1.839 2.564 0.1 1 #>  #> $Item.28 #>        a1      d   g u #> par 1.222 -0.095 0.1 1 #>  #> $Item.29 #>        a1      d   g u #> par 1.281 -1.357 0.1 1 #>  #> $Item.30 #>        a1      d   g u #> par 0.444 -0.521 0.1 1 #>  #> $Item.31 #>        a1     d   g u #> par 2.476 2.697 0.1 1 #>  #> $Item.32 #>        a1      d   g u #> par 0.461 -2.742 0.1 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>   ########### # graded rating scale example  # make some data set.seed(1234) a <- matrix(rep(1, 10)) d <- matrix(c(1,0.5,-.5,-1), 10, 4, byrow = TRUE) c <- seq(-1, 1, length.out=10) data <- simdata(a, d + c, 2000, itemtype = rep('graded',10)) itemstats(data) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  2000           20.196           8.33 0.203 0.027 0.719     4.419 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  2000 5 1.284 1.510   0.512         0.359       0.700 #> Item_2  2000 5 1.427 1.544   0.529         0.375       0.697 #> Item_3  2000 5 1.592 1.584   0.545         0.389       0.695 #> Item_4  2000 5 1.774 1.586   0.538         0.381       0.696 #> Item_5  2000 5 1.910 1.607   0.539         0.380       0.696 #> Item_6  2000 5 2.124 1.606   0.533         0.373       0.697 #> Item_7  2000 5 2.284 1.598   0.520         0.359       0.700 #> Item_8  2000 5 2.420 1.583   0.578         0.430       0.688 #> Item_9  2000 5 2.606 1.543   0.530         0.377       0.697 #> Item_10 2000 5 2.776 1.491   0.495         0.342       0.702 #>  #> $proportions #>             0     1     2     3     4 #> Item_1  0.500 0.096 0.182 0.065 0.158 #> Item_2  0.450 0.108 0.197 0.059 0.187 #> Item_3  0.407 0.108 0.182 0.092 0.212 #> Item_4  0.346 0.111 0.212 0.085 0.246 #> Item_5  0.319 0.102 0.211 0.086 0.281 #> Item_6  0.269 0.097 0.205 0.099 0.330 #> Item_7  0.244 0.073 0.211 0.101 0.372 #> Item_8  0.216 0.074 0.195 0.106 0.410 #> Item_9  0.175 0.072 0.196 0.083 0.473 #> Item_10 0.150 0.059 0.174 0.102 0.516 #>   mod1 <- mirt(data, 1) #>  mod2 <- mirt(data, 1, itemtype = 'grsm') #>  coef(mod2) #> $Item_1 #>        a1    b1     b2     b3     b4 c #> par 0.959 0.001 -0.507 -1.541 -2.032 0 #>  #> $Item_2 #>        a1    b1     b2     b3     b4     c #> par 0.987 0.001 -0.507 -1.541 -2.032 0.235 #>  #> $Item_3 #>        a1    b1     b2     b3     b4     c #> par 0.994 0.001 -0.507 -1.541 -2.032 0.457 #>  #> $Item_4 #>        a1    b1     b2     b3     b4     c #> par 1.027 0.001 -0.507 -1.541 -2.032 0.728 #>  #> $Item_5 #>        a1    b1     b2     b3     b4     c #> par 0.995 0.001 -0.507 -1.541 -2.032 0.895 #>  #> $Item_6 #>        a1    b1     b2     b3     b4     c #> par 0.987 0.001 -0.507 -1.541 -2.032 1.179 #>  #> $Item_7 #>        a1    b1     b2     b3     b4     c #> par 0.957 0.001 -0.507 -1.541 -2.032 1.404 #>  #> $Item_8 #>       a1    b1     b2     b3     b4     c #> par 1.04 0.001 -0.507 -1.541 -2.032 1.578 #>  #> $Item_9 #>        a1    b1     b2     b3     b4     c #> par 0.964 0.001 -0.507 -1.541 -2.032 1.878 #>  #> $Item_10 #>        a1    b1     b2     b3     b4     c #> par 0.947 0.001 -0.507 -1.541 -2.032 2.136 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #>  anova(mod2, mod1) #not sig, mod2 should be preferred #>           AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mod2 55239.72 55295.47 55287.03 55368.55 -27596.86                 #> mod1 55252.05 55373.25 55354.88 55532.10 -27576.03 41.671 27 0.035 itemplot(mod2, 1)  itemplot(mod2, 5)  itemplot(mod2, 10)   ########### # 2PL nominal response model example (Suh and Bolt, 2010) data(SAT12) SAT12[SAT12 == 8] <- NA #set 8 as a missing value head(SAT12) #>   Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8 Item.9 Item.10 #> 1      1      4      5      2      3      1      2      1      3       1 #> 2      3      4      2     NA      3      3      2     NA      3       1 #> 3      1      4      5      4      3      2      2      3      3       2 #> 4      2      4      4      2      3      3      2      4      3       2 #> 5      2      4      5      2      3      2      2      1      1       2 #> 6      1      4      3      1      3      2      2      3      3       1 #>   Item.11 Item.12 Item.13 Item.14 Item.15 Item.16 Item.17 Item.18 Item.19 #> 1       2       4       2       1       5       3       4       4       1 #> 2       2      NA       2       1       5       2       4       1       1 #> 3       2       1       3       1       5       5       4       1       3 #> 4       2       4       2       1       5       2       4       1       3 #> 5       2       4       2       1       5       4       4       5       1 #> 6       2       3       2       1       5       5       4       4       1 #>   Item.20 Item.21 Item.22 Item.23 Item.24 Item.25 Item.26 Item.27 Item.28 #> 1       4       3       3       4       1       3       5       1       3 #> 2       4       3       3      NA       1      NA       4       1       4 #> 3       4       3       3       1       1       3       4       1       3 #> 4       4       3       1       5       2       5       4       1       3 #> 5       4       3       3       3       1       1       5       1       3 #> 6       4       3       3       4       1       1       4       1       4 #>   Item.29 Item.30 Item.31 Item.32 #> 1       1       5       4       5 #> 2       5      NA       4      NA #> 3       4       4       4       1 #> 4       4       2       4       2 #> 5       1       2       4       1 #> 6       2       3       4       3  # correct answer key key <- c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5) scoredSAT12 <- key2binary(SAT12, key) mod0 <- mirt(scoredSAT12, 1) #>   # for first 5 items use 2PLNRM and nominal scoredSAT12[,1:5] <- as.matrix(SAT12[,1:5]) mod1 <- mirt(scoredSAT12, 1, c(rep('nominal',5),rep('2PL', 27))) #>  mod2 <- mirt(scoredSAT12, 1, c(rep('2PLNRM',5),rep('2PL', 27)), key=key) #>  coef(mod0)$Item.1 #>            a1         d g u #> par 0.8107167 -1.042366 0 1 coef(mod1)$Item.1 #>             a1 ak0       ak1      ak2      ak3 ak4 d0         d1         d2 #> par -0.8772035   0 0.5286601 1.116593 1.129494   4  0 -0.1909232 0.01878861 #>             d3       d4 #> par -0.1258261 -5.65218 coef(mod2)$Item.1 #>            a1        d g u ak0        ak1        ak2       ak3 d0        d1 #> par 0.8102548 -1.04233 0 1   0 -0.5653287 -0.5712706 -3.025613  0 0.2117761 #>             d2        d3 #> par 0.06919723 -5.309272 itemplot(mod0, 1)  itemplot(mod1, 1)  itemplot(mod2, 1)   # compare added information from distractors Theta <- matrix(seq(-4,4,.01)) par(mfrow = c(2,3)) for(i in 1:5){     info <- iteminfo(extract.item(mod0,i), Theta)     info2 <- iteminfo(extract.item(mod2,i), Theta)     plot(Theta, info2, type = 'l', main = paste('Information for item', i), ylab = 'Information')     lines(Theta, info, col = 'red') } par(mfrow = c(1,1))   # test information plot(Theta, testinfo(mod2, Theta), type = 'l', main = 'Test information', ylab = 'Information') lines(Theta, testinfo(mod0, Theta), col = 'red')   ########### # using the MH-RM algorithm data(LSAT7) fulldata <- expand.table(LSAT7) (mod1 <- mirt(fulldata, 1, method = 'MHRM')) #> , Max-Change = 0.0343, Max-Change = 0.0321, Max-Change = 0.0244, Max-Change = 0.0454, Max-Change = 0.0518, Max-Change = 0.0217, Max-Change = 0.0328, Max-Change = 0.0227, Max-Change = 0.0287, Max-Change = 0.0194, Max-Change = 0.0210, Max-Change = 0.0517, Max-Change = 0.0631, Max-Change = 0.0216, Max-Change = 0.0277, Max-Change = 0.0191, Max-Change = 0.0253, Max-Change = 0.0380, Max-Change = 0.0219, Max-Change = 0.0382, Max-Change = 0.0325, Max-Change = 0.0429, Max-Change = 0.0375, Max-Change = 0.0238, Max-Change = 0.0391, Max-Change = 0.0400, Max-Change = 0.0139, Max-Change = 0.0325, Max-Change = 0.0143, Max-Change = 0.0271, Max-Change = 0.0202, Max-Change = 0.0155, Max-Change = 0.0353, Max-Change = 0.0603, Max-Change = 0.0193, Max-Change = 0.0270, Max-Change = 0.0234, Max-Change = 0.0329, Max-Change = 0.0450, Max-Change = 0.0438, Max-Change = 0.0420, Max-Change = 0.0558, Max-Change = 0.0300, Max-Change = 0.0203, Max-Change = 0.0384, Max-Change = 0.0183, Max-Change = 0.0178, Max-Change = 0.0142, Max-Change = 0.0165, Max-Change = 0.0152, Max-Change = 0.0430, Max-Change = 0.0577, Max-Change = 0.0273, Max-Change = 0.0351, Max-Change = 0.0191, Max-Change = 0.0106, Max-Change = 0.0242, Max-Change = 0.0290, Max-Change = 0.0189, Max-Change = 0.0211, Max-Change = 0.0176, Max-Change = 0.0322, Max-Change = 0.0263, Max-Change = 0.0259, Max-Change = 0.0295, Max-Change = 0.0401, Max-Change = 0.0123, Max-Change = 0.0411, Max-Change = 0.0175, Max-Change = 0.0356, Max-Change = 0.0190, Max-Change = 0.0254, Max-Change = 0.0190, Max-Change = 0.0235, Max-Change = 0.0216, Max-Change = 0.0183, Max-Change = 0.0151, Max-Change = 0.0392, Max-Change = 0.0207, Max-Change = 0.0135, Max-Change = 0.0314, Max-Change = 0.0380, Max-Change = 0.0442, Max-Change = 0.0163, Max-Change = 0.0227, Max-Change = 0.0268, Max-Change = 0.0140, Max-Change = 0.0211, Max-Change = 0.0146, Max-Change = 0.0419, Max-Change = 0.0299, Max-Change = 0.0168, Max-Change = 0.0297, Max-Change = 0.0207, Max-Change = 0.0229, Max-Change = 0.0329, Max-Change = 0.0384, Max-Change = 0.0203, Max-Change = 0.0273, Max-Change = 0.0129, Max-Change = 0.0143, Max-Change = 0.0248, Max-Change = 0.0268, Max-Change = 0.0267, Max-Change = 0.0342, Max-Change = 0.0256, Max-Change = 0.0346, Max-Change = 0.0357, Max-Change = 0.0225, Max-Change = 0.0236, Max-Change = 0.0390, Max-Change = 0.0243, Max-Change = 0.0328, Max-Change = 0.0294, Max-Change = 0.0478, Max-Change = 0.0269, Max-Change = 0.0292, Max-Change = 0.0329, Max-Change = 0.0127, Max-Change = 0.0280, Max-Change = 0.0355, Max-Change = 0.0357, Max-Change = 0.0183, Max-Change = 0.0201, Max-Change = 0.0258, Max-Change = 0.0241, Max-Change = 0.0265, Max-Change = 0.0413, Max-Change = 0.0309, Max-Change = 0.0368, Max-Change = 0.0182, Max-Change = 0.0521, Max-Change = 0.0192, Max-Change = 0.0279, Max-Change = 0.0287, Max-Change = 0.0111, Max-Change = 0.0109, Max-Change = 0.0181, Max-Change = 0.0334, Max-Change = 0.0324, Max-Change = 0.0434, Max-Change = 0.0336, Max-Change = 0.0361, Max-Change = 0.0365, Max-Change = 0.0401, Max-Change = 0.0390, Max-Change = 0.0134, Max-Change = 0.0310, Max-Change = 0.0252, Max-Change = 0.0230, Max-Change = 0.0128, Max-Change = 0.0381, Max-Change = 0.0210, Max-Change = 0.0256, Max-Change = 0.0320, Max-Change = 0.0227, Max-Change = 0.0332, Max-Change = 0.0103, Max-Change = 0.0267, Max-Change = 0.0244, Max-Change = 0.0244, Max-Change = 0.0336, Max-Change = 0.0209, Max-Change = 0.0287, Max-Change = 0.0210, Max-Change = 0.0163, Max-Change = 0.0394, Max-Change = 0.0194, Max-Change = 0.0141, Max-Change = 0.0347, Max-Change = 0.0188, Max-Change = 0.0249, Max-Change = 0.0504, Max-Change = 0.0254, Max-Change = 0.0192, Max-Change = 0.0197, Max-Change = 0.0477, Max-Change = 0.0258, Max-Change = 0.0296, Max-Change = 0.0425, Max-Change = 0.0353, Max-Change = 0.0328, Max-Change = 0.0186, Max-Change = 0.0190, Max-Change = 0.0243, Max-Change = 0.0284, Max-Change = 0.0441, Max-Change = 0.0193, Max-Change = 0.0185, Max-Change = 0.0279, Max-Change = 0.0206, Max-Change = 0.0270, Max-Change = 0.0225, Max-Change = 0.0261, Max-Change = 0.0200, Max-Change = 0.0242, Max-Change = 0.0229, Max-Change = 0.0176, Max-Change = 0.0300, Max-Change = 0.0435, Max-Change = 0.0193, Max-Change = 0.0254, Max-Change = 0.0431, Max-Change = 0.0187, Max-Change = 0.0259, Max-Change = 0.0235, Max-Change = 0.0274, Max-Change = 0.0291, Max-Change = 0.0226, Max-Change = 0.0347, Max-Change = 0.0352, Max-Change = 0.0129, Max-Change = 0.0599, Max-Change = 0.0234, Max-Change = 0.0325, Max-Change = 0.0117, Max-Change = 0.0211, Max-Change = 0.0094, Max-Change = 0.0331, Max-Change = 0.0236, Max-Change = 0.0391, Max-Change = 0.0287, Max-Change = 0.0359, Max-Change = 0.0266, Max-Change = 0.0286, Max-Change = 0.0188, Max-Change = 0.0268, Max-Change = 0.0187, Max-Change = 0.0217, Max-Change = 0.0414, Max-Change = 0.0215, Max-Change = 0.0299, Max-Change = 0.0270, Max-Change = 0.0305, Max-Change = 0.0661, Max-Change = 0.0131, Max-Change = 0.0423, Max-Change = 0.0174, Max-Change = 0.0311, Max-Change = 0.0227, Max-Change = 0.0335, Max-Change = 0.0233, Max-Change = 0.0172, Max-Change = 0.0584, Max-Change = 0.0442, Max-Change = 0.0101, Max-Change = 0.0284, Max-Change = 0.0279, Max-Change = 0.0353, Max-Change = 0.0325, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0136, gam = 0.1057, Max-Change = 0.0187, gam = 0.0780, Max-Change = 0.0054, gam = 0.0629, Max-Change = 0.0068, gam = 0.0532, Max-Change = 0.0054, gam = 0.0464, Max-Change = 0.0051, gam = 0.0413, Max-Change = 0.0079, gam = 0.0374, Max-Change = 0.0091, gam = 0.0342, Max-Change = 0.0035, gam = 0.0316, Max-Change = 0.0049, gam = 0.0294, Max-Change = 0.0015, gam = 0.0276, Max-Change = 0.0042, gam = 0.0260, Max-Change = 0.0040, gam = 0.0246, Max-Change = 0.0085, gam = 0.0233, Max-Change = 0.0034, gam = 0.0222, Max-Change = 0.0031, gam = 0.0212, Max-Change = 0.0021, gam = 0.0203, Max-Change = 0.0027, gam = 0.0195, Max-Change = 0.0016, gam = 0.0188, Max-Change = 0.0026, gam = 0.0181, Max-Change = 0.0033, gam = 0.0175, Max-Change = 0.0036, gam = 0.0169, Max-Change = 0.0023, gam = 0.0164, Max-Change = 0.0019, gam = 0.0159, Max-Change = 0.0020, gam = 0.0154, Max-Change = 0.0024, gam = 0.0150, Max-Change = 0.0012, gam = 0.0146, Max-Change = 0.0021, gam = 0.0142, Max-Change = 0.0013, gam = 0.0139, Max-Change = 0.0034, gam = 0.0135, Max-Change = 0.0010, gam = 0.0132, Max-Change = 0.0017, gam = 0.0129, Max-Change = 0.0029, gam = 0.0126, Max-Change = 0.0019, gam = 0.0124, Max-Change = 0.0015, gam = 0.0121, Max-Change = 0.0030, gam = 0.0119, Max-Change = 0.0017, gam = 0.0116, Max-Change = 0.0006, gam = 0.0114, Max-Change = 0.0007, gam = 0.0112, Max-Change = 0.0013, gam = 0.0110, Max-Change = 0.0008, gam = 0.0108, Max-Change = 0.0011, gam = 0.0106, Max-Change = 0.0010, gam = 0.0104, Max-Change = 0.0014, gam = 0.0102, Max-Change = 0.0023, gam = 0.0101, Max-Change = 0.0025, gam = 0.0099, Max-Change = 0.0013, gam = 0.0098, Max-Change = 0.0014, gam = 0.0096, Max-Change = 0.0018, gam = 0.0095, Max-Change = 0.0012, gam = 0.0093, Max-Change = 0.0008, gam = 0.0092, Max-Change = 0.0009, gam = 0.0091, Max-Change = 0.0019, gam = 0.0089, Max-Change = 0.0030, gam = 0.0088, Max-Change = 0.0014, gam = 0.0087, Max-Change = 0.0004, gam = 0.0086, Max-Change = 0.0010, gam = 0.0085, Max-Change = 0.0009, gam = 0.0084, Max-Change = 0.0023, gam = 0.0082, Max-Change = 0.0013, gam = 0.0081, Max-Change = 0.0007, gam = 0.0080, Max-Change = 0.0006, gam = 0.0080, Max-Change = 0.0015, gam = 0.0079, Max-Change = 0.0006, gam = 0.0078, Max-Change = 0.0023, gam = 0.0077, Max-Change = 0.0007, gam = 0.0076, Max-Change = 0.0003, gam = 0.0075, Max-Change = 0.0014, gam = 0.0074, Max-Change = 0.0012, gam = 0.0073, Max-Change = 0.0009, gam = 0.0073, Max-Change = 0.0008, gam = 0.0072, Max-Change = 0.0006 #>  #> Calculating log-likelihood... #>  #> Call: #> mirt(data = fulldata, model = 1, method = \"MHRM\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 0.001 tolerance after 73 MHRM iterations. #> mirt version: 1.45.2  #> M-step optimizer: NR1  #> Latent density type: Gaussian  #> Average MH acceptance ratio(s): 0.4  #>  #> Log-likelihood = -2659.472, SE = 0.018 #> Estimated parameters: 10  #> AIC = 5338.944 #> BIC = 5388.022; SABIC = 5356.261 #> G2 (21) = 32.89, p = 0.0475 #> RMSEA = 0.024, CFI = NaN, TLI = NaN  # Confirmatory models  # simulate data a <- matrix(c( 1.5,NA, 0.5,NA, 1.0,NA, 1.0,0.5,  NA,1.5,  NA,0.5,  NA,1.0,  NA,1.0),ncol=2,byrow=TRUE)  d <- matrix(c( -1.0,NA,NA, -1.5,NA,NA,  1.5,NA,NA,  0.0,NA,NA, 3.0,2.0,-0.5, 2.5,1.0,-1, 2.0,0.0,NA, 1.0,NA,NA),ncol=3,byrow=TRUE)  sigma <- diag(2) sigma[1,2] <- sigma[2,1] <- .4 items <- c(rep('2PL',4), rep('graded',3), '2PL') dataset <- simdata(a,d,2000,items,sigma)  # analyses # CIFA for 2 factor crossed structure  model.1 <- '   F1 = 1-4   F2 = 4-8   COV = F1*F2'  # compute model, and use parallel computation of the log-likelihood if(interactive()) mirtCluster() mod1 <- mirt(dataset, model.1, method = 'MHRM') #> , Max-Change = 0.0371, Max-Change = 0.0261, Max-Change = 0.0288, Max-Change = 0.0212, Max-Change = 0.0317, Max-Change = 0.0243, Max-Change = 0.0199, Max-Change = 0.0231, Max-Change = 0.0308, Max-Change = 0.0268, Max-Change = 0.0221, Max-Change = 0.0232, Max-Change = 0.0165, Max-Change = 0.0163, Max-Change = 0.0249, Max-Change = 0.0210, Max-Change = 0.0220, Max-Change = 0.0258, Max-Change = 0.0255, Max-Change = 0.0246, Max-Change = 0.0263, Max-Change = 0.0252, Max-Change = 0.0180, Max-Change = 0.0112, Max-Change = 0.0216, Max-Change = 0.0182, Max-Change = 0.0228, Max-Change = 0.0240, Max-Change = 0.0207, Max-Change = 0.0176, Max-Change = 0.0182, Max-Change = 0.0102, Max-Change = 0.0198, Max-Change = 0.0150, Max-Change = 0.0185, Max-Change = 0.0136, Max-Change = 0.0131, Max-Change = 0.0189, Max-Change = 0.0273, Max-Change = 0.0159, Max-Change = 0.0248, Max-Change = 0.0142, Max-Change = 0.0183, Max-Change = 0.0195, Max-Change = 0.0200, Max-Change = 0.0216, Max-Change = 0.0284, Max-Change = 0.0097, Max-Change = 0.0198, Max-Change = 0.0152, Max-Change = 0.0137, Max-Change = 0.0351, Max-Change = 0.0252, Max-Change = 0.0266, Max-Change = 0.0119, Max-Change = 0.0135, Max-Change = 0.0107, Max-Change = 0.0143, Max-Change = 0.0193, Max-Change = 0.0129, Max-Change = 0.0165, Max-Change = 0.0216, Max-Change = 0.0155, Max-Change = 0.0243, Max-Change = 0.0345, Max-Change = 0.0290, Max-Change = 0.0154, Max-Change = 0.0242, Max-Change = 0.0175, Max-Change = 0.0130, Max-Change = 0.0147, Max-Change = 0.0137, Max-Change = 0.0186, Max-Change = 0.0173, Max-Change = 0.0213, Max-Change = 0.0194, Max-Change = 0.0180, Max-Change = 0.0139, Max-Change = 0.0144, Max-Change = 0.0150, Max-Change = 0.0093, Max-Change = 0.0127, Max-Change = 0.0086, Max-Change = 0.0212, Max-Change = 0.0170, Max-Change = 0.0150, Max-Change = 0.0295, Max-Change = 0.0141, Max-Change = 0.0191, Max-Change = 0.0193, Max-Change = 0.0152, Max-Change = 0.0189, Max-Change = 0.0077, Max-Change = 0.0243, Max-Change = 0.0274, Max-Change = 0.0250, Max-Change = 0.0188, Max-Change = 0.0154, Max-Change = 0.0163, Max-Change = 0.0206, Max-Change = 0.0113, Max-Change = 0.0223, Max-Change = 0.0164, Max-Change = 0.0141, Max-Change = 0.0208, Max-Change = 0.0169, Max-Change = 0.0186, Max-Change = 0.0192, Max-Change = 0.0135, Max-Change = 0.0178, Max-Change = 0.0133, Max-Change = 0.0270, Max-Change = 0.0103, Max-Change = 0.0152, Max-Change = 0.0281, Max-Change = 0.0203, Max-Change = 0.0255, Max-Change = 0.0260, Max-Change = 0.0213, Max-Change = 0.0167, Max-Change = 0.0312, Max-Change = 0.0228, Max-Change = 0.0188, Max-Change = 0.0128, Max-Change = 0.0273, Max-Change = 0.0123, Max-Change = 0.0122, Max-Change = 0.0205, Max-Change = 0.0235, Max-Change = 0.0125, Max-Change = 0.0171, Max-Change = 0.0146, Max-Change = 0.0100, Max-Change = 0.0244, Max-Change = 0.0191, Max-Change = 0.0189, Max-Change = 0.0183, Max-Change = 0.0268, Max-Change = 0.0159, Max-Change = 0.0246, Max-Change = 0.0225, Max-Change = 0.0136, Max-Change = 0.0178, Max-Change = 0.0301, Max-Change = 0.0195, Max-Change = 0.0195, Max-Change = 0.0158, Max-Change = 0.0269, Max-Change = 0.0155, Max-Change = 0.0155, Max-Change = 0.0221, Max-Change = 0.0391, Max-Change = 0.0221, Max-Change = 0.0347, Max-Change = 0.0227, Max-Change = 0.0230, Max-Change = 0.0234, Max-Change = 0.0178, Max-Change = 0.0101, Max-Change = 0.0255, Max-Change = 0.0262, Max-Change = 0.0201, Max-Change = 0.0151, Max-Change = 0.0120, Max-Change = 0.0180, Max-Change = 0.0161, Max-Change = 0.0169, Max-Change = 0.0139, Max-Change = 0.0208, Max-Change = 0.0150, Max-Change = 0.0191, Max-Change = 0.0211, Max-Change = 0.0104, Max-Change = 0.0145, Max-Change = 0.0194, Max-Change = 0.0231, Max-Change = 0.0218, Max-Change = 0.0155, Max-Change = 0.0163, Max-Change = 0.0205, Max-Change = 0.0279, Max-Change = 0.0133, Max-Change = 0.0233, Max-Change = 0.0230, Max-Change = 0.0358, Max-Change = 0.0223, Max-Change = 0.0202, Max-Change = 0.0193, Max-Change = 0.0243, Max-Change = 0.0209, Max-Change = 0.0223, Max-Change = 0.0190, Max-Change = 0.0190, Max-Change = 0.0170, Max-Change = 0.0361, Max-Change = 0.0267, Max-Change = 0.0144, Max-Change = 0.0164, Max-Change = 0.0092, Max-Change = 0.0233, Max-Change = 0.0190, Max-Change = 0.0178, Max-Change = 0.0197, Max-Change = 0.0129, Max-Change = 0.0242, Max-Change = 0.0252, Max-Change = 0.0236, Max-Change = 0.0162, Max-Change = 0.0222, Max-Change = 0.0112, Max-Change = 0.0187, Max-Change = 0.0183, Max-Change = 0.0251, Max-Change = 0.0177, Max-Change = 0.0159, Max-Change = 0.0122, Max-Change = 0.0150, Max-Change = 0.0194, Max-Change = 0.0212, Max-Change = 0.0140, Max-Change = 0.0156, Max-Change = 0.0136, Max-Change = 0.0135, Max-Change = 0.0289, Max-Change = 0.0293, Max-Change = 0.0120, Max-Change = 0.0203, Max-Change = 0.0247, Max-Change = 0.0242, Max-Change = 0.0126, Max-Change = 0.0184, Max-Change = 0.0193, Max-Change = 0.0225, Max-Change = 0.0201, Max-Change = 0.0205, Max-Change = 0.0210, Max-Change = 0.0181, Max-Change = 0.0256, Max-Change = 0.0091, Max-Change = 0.0222, Max-Change = 0.0197, Max-Change = 0.0165, Max-Change = 0.0140, Max-Change = 0.0159, Max-Change = 0.0268, Max-Change = 0.0139, Max-Change = 0.0231, Max-Change = 0.0231, Max-Change = 0.0189, Max-Change = 0.0222, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0221, gam = 0.1057, Max-Change = 0.0141, gam = 0.0780, Max-Change = 0.0059, gam = 0.0629, Max-Change = 0.0057, gam = 0.0532, Max-Change = 0.0042, gam = 0.0464, Max-Change = 0.0047, gam = 0.0413, Max-Change = 0.0027, gam = 0.0374, Max-Change = 0.0025, gam = 0.0342, Max-Change = 0.0032, gam = 0.0316, Max-Change = 0.0025, gam = 0.0294, Max-Change = 0.0021, gam = 0.0276, Max-Change = 0.0035, gam = 0.0260, Max-Change = 0.0020, gam = 0.0246, Max-Change = 0.0025, gam = 0.0233, Max-Change = 0.0027, gam = 0.0222, Max-Change = 0.0025, gam = 0.0212, Max-Change = 0.0041, gam = 0.0203, Max-Change = 0.0027, gam = 0.0195, Max-Change = 0.0016, gam = 0.0188, Max-Change = 0.0015, gam = 0.0181, Max-Change = 0.0019, gam = 0.0175, Max-Change = 0.0029, gam = 0.0169, Max-Change = 0.0007, gam = 0.0164, Max-Change = 0.0017, gam = 0.0159, Max-Change = 0.0016, gam = 0.0154, Max-Change = 0.0012, gam = 0.0150, Max-Change = 0.0011, gam = 0.0146, Max-Change = 0.0018, gam = 0.0142, Max-Change = 0.0017, gam = 0.0139, Max-Change = 0.0010, gam = 0.0135, Max-Change = 0.0016, gam = 0.0132, Max-Change = 0.0007, gam = 0.0129, Max-Change = 0.0013, gam = 0.0126, Max-Change = 0.0006, gam = 0.0124, Max-Change = 0.0008, gam = 0.0121, Max-Change = 0.0016, gam = 0.0119, Max-Change = 0.0014, gam = 0.0116, Max-Change = 0.0011, gam = 0.0114, Max-Change = 0.0012, gam = 0.0112, Max-Change = 0.0010, gam = 0.0110, Max-Change = 0.0010, gam = 0.0108, Max-Change = 0.0008 #>  #> Calculating log-likelihood... coef(mod1) #> $Item_1 #>        a1 a2      d g u #> par 1.418  0 -0.977 0 1 #>  #> $Item_2 #>        a1 a2     d g u #> par 0.506  0 -1.42 0 1 #>  #> $Item_3 #>      a1 a2     d g u #> par 0.9  0 1.394 0 1 #>  #> $Item_4 #>        a1    a2     d g u #> par 1.156 0.526 0.054 0 1 #>  #> $Item_5 #>     a1   a2    d1    d2     d3 #> par  0 1.36 2.942 2.044 -0.489 #>  #> $Item_6 #>     a1    a2    d1    d2     d3 #> par  0 0.583 2.464 1.053 -0.978 #>  #> $Item_7 #>     a1    a2    d1    d2 #> par  0 0.847 1.917 0.014 #>  #> $Item_8 #>     a1    a2     d g u #> par  0 0.951 0.997 0 1 #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0      0      1  0.465      1 #>  summary(mod1) #>           F1    F2     h2 #> Item_1 0.640       0.4096 #> Item_2 0.285       0.0813 #> Item_3 0.467       0.2185 #> Item_4 0.544 0.248 0.3575 #> Item_5       0.624 0.3897 #> Item_6       0.324 0.1051 #> Item_7       0.446 0.1985 #> Item_8       0.488 0.2380 #>  #> SS loadings:  1.006 0.993  #> Proportion Var:  0.126 0.124  #>  #> Factor correlations:  #>  #>       F1 F2 #> F1 1.000    #> F2 0.465  1 residuals(mod1) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.059  -0.031   0.002  -0.003   0.017   0.058  #>  #>        Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 #> Item_1         0.007 -0.002  0.008  0.058 -0.059 -0.040  0.011 #> Item_2  0.089         0.014 -0.023  0.028  0.054  0.017 -0.031 #> Item_3  0.008  0.382        -0.009  0.018 -0.031 -0.021 -0.005 #> Item_4  0.116  1.093  0.172        -0.053 -0.033  0.007  0.036 #> Item_5  6.710  1.548  0.672  5.628         0.027 -0.033 -0.046 #> Item_6  6.944  5.812  1.916  2.167  4.268         0.043 -0.026 #> Item_7  3.245  0.580  0.861  0.102  4.234  7.301         0.009 #> Item_8  0.232  1.978  0.041  2.547  4.254  1.307  0.151         ##### # bifactor model.3 <- '   G = 1-8   F1 = 1-4   F2 = 5-8'  mod3 <- mirt(dataset,model.3, method = 'MHRM') #> , Max-Change = 0.1428, Max-Change = 0.0965, Max-Change = 0.0723, Max-Change = 0.0696, Max-Change = 0.0517, Max-Change = 0.0489, Max-Change = 0.0438, Max-Change = 0.0397, Max-Change = 0.0283, Max-Change = 0.0377, Max-Change = 0.0289, Max-Change = 0.0282, Max-Change = 0.0197, Max-Change = 0.0251, Max-Change = 0.0240, Max-Change = 0.0260, Max-Change = 0.0266, Max-Change = 0.0198, Max-Change = 0.0202, Max-Change = 0.0260, Max-Change = 0.0237, Max-Change = 0.0371, Max-Change = 0.0258, Max-Change = 0.0210, Max-Change = 0.0202, Max-Change = 0.0149, Max-Change = 0.0146, Max-Change = 0.0152, Max-Change = 0.0239, Max-Change = 0.0218, Max-Change = 0.0245, Max-Change = 0.0181, Max-Change = 0.0238, Max-Change = 0.0180, Max-Change = 0.0200, Max-Change = 0.0245, Max-Change = 0.0224, Max-Change = 0.0174, Max-Change = 0.0232, Max-Change = 0.0236, Max-Change = 0.0228, Max-Change = 0.0162, Max-Change = 0.0170, Max-Change = 0.0291, Max-Change = 0.0244, Max-Change = 0.0231, Max-Change = 0.0190, Max-Change = 0.0261, Max-Change = 0.0175, Max-Change = 0.0176, Max-Change = 0.0198, Max-Change = 0.0312, Max-Change = 0.0245, Max-Change = 0.0200, Max-Change = 0.0183, Max-Change = 0.0262, Max-Change = 0.0183, Max-Change = 0.0282, Max-Change = 0.0175, Max-Change = 0.0211, Max-Change = 0.0144, Max-Change = 0.0253, Max-Change = 0.0176, Max-Change = 0.0203, Max-Change = 0.0200, Max-Change = 0.0170, Max-Change = 0.0154, Max-Change = 0.0204, Max-Change = 0.0186, Max-Change = 0.0222, Max-Change = 0.0154, Max-Change = 0.0181, Max-Change = 0.0268, Max-Change = 0.0263, Max-Change = 0.0250, Max-Change = 0.0204, Max-Change = 0.0106, Max-Change = 0.0182, Max-Change = 0.0168, Max-Change = 0.0219, Max-Change = 0.0234, Max-Change = 0.0259, Max-Change = 0.0128, Max-Change = 0.0202, Max-Change = 0.0245, Max-Change = 0.0171, Max-Change = 0.0174, Max-Change = 0.0215, Max-Change = 0.0250, Max-Change = 0.0174, Max-Change = 0.0251, Max-Change = 0.0248, Max-Change = 0.0328, Max-Change = 0.0250, Max-Change = 0.0163, Max-Change = 0.0231, Max-Change = 0.0210, Max-Change = 0.0205, Max-Change = 0.0197, Max-Change = 0.0187, Max-Change = 0.0227, Max-Change = 0.0225, Max-Change = 0.0144, Max-Change = 0.0290, Max-Change = 0.0192, Max-Change = 0.0246, Max-Change = 0.0199, Max-Change = 0.0271, Max-Change = 0.0296, Max-Change = 0.0311, Max-Change = 0.0194, Max-Change = 0.0198, Max-Change = 0.0224, Max-Change = 0.0246, Max-Change = 0.0172, Max-Change = 0.0180, Max-Change = 0.0186, Max-Change = 0.0183, Max-Change = 0.0189, Max-Change = 0.0267, Max-Change = 0.0180, Max-Change = 0.0220, Max-Change = 0.0150, Max-Change = 0.0196, Max-Change = 0.0134, Max-Change = 0.0235, Max-Change = 0.0280, Max-Change = 0.0218, Max-Change = 0.0271, Max-Change = 0.0137, Max-Change = 0.0192, Max-Change = 0.0160, Max-Change = 0.0151, Max-Change = 0.0178, Max-Change = 0.0174, Max-Change = 0.0320, Max-Change = 0.0129, Max-Change = 0.0187, Max-Change = 0.0110, Max-Change = 0.0271, Max-Change = 0.0194, Max-Change = 0.0225, Max-Change = 0.0176, Max-Change = 0.0189, Max-Change = 0.0123, Max-Change = 0.0197, Max-Change = 0.0154, Max-Change = 0.0123, Max-Change = 0.0251, Max-Change = 0.0270, Max-Change = 0.0230, Max-Change = 0.0205, Max-Change = 0.0165, Max-Change = 0.0258, Max-Change = 0.0223, Max-Change = 0.0196, Max-Change = 0.0158, Max-Change = 0.0180, Max-Change = 0.0127, Max-Change = 0.0276, Max-Change = 0.0412, Max-Change = 0.0200, Max-Change = 0.0183, Max-Change = 0.0319, Max-Change = 0.0190, Max-Change = 0.0135, Max-Change = 0.0183, Max-Change = 0.0236, Max-Change = 0.0175, Max-Change = 0.0192, Max-Change = 0.0252, Max-Change = 0.0171, Max-Change = 0.0184, Max-Change = 0.0252, Max-Change = 0.0230, Max-Change = 0.0187, Max-Change = 0.0274, Max-Change = 0.0163, Max-Change = 0.0127, Max-Change = 0.0237, Max-Change = 0.0188, Max-Change = 0.0258, Max-Change = 0.0322, Max-Change = 0.0186, Max-Change = 0.0238, Max-Change = 0.0217, Max-Change = 0.0198, Max-Change = 0.0177, Max-Change = 0.0257, Max-Change = 0.0219, Max-Change = 0.0198, Max-Change = 0.0219, Max-Change = 0.0265, Max-Change = 0.0281, Max-Change = 0.0259, Max-Change = 0.0262, Max-Change = 0.0190, Max-Change = 0.0211, Max-Change = 0.0217, Max-Change = 0.0338, Max-Change = 0.0145, Max-Change = 0.0165, Max-Change = 0.0257, Max-Change = 0.0322, Max-Change = 0.0216, Max-Change = 0.0147, Max-Change = 0.0153, Max-Change = 0.0204, Max-Change = 0.0204, Max-Change = 0.0329, Max-Change = 0.0134, Max-Change = 0.0208, Max-Change = 0.0173, Max-Change = 0.0295, Max-Change = 0.0254, Max-Change = 0.0198, Max-Change = 0.0198, Max-Change = 0.0171, Max-Change = 0.0233, Max-Change = 0.0200, Max-Change = 0.0211, Max-Change = 0.0268, Max-Change = 0.0231, Max-Change = 0.0217, Max-Change = 0.0191, Max-Change = 0.0206, Max-Change = 0.0274, Max-Change = 0.0289, Max-Change = 0.0285, Max-Change = 0.0176, Max-Change = 0.0240, Max-Change = 0.0129, Max-Change = 0.0201, Max-Change = 0.0170, Max-Change = 0.0155, Max-Change = 0.0237, Max-Change = 0.0244, Max-Change = 0.0155, Max-Change = 0.0244, Max-Change = 0.0147, Max-Change = 0.0207, Max-Change = 0.0163, Max-Change = 0.0259, Max-Change = 0.0101, Max-Change = 0.0191, Max-Change = 0.0259, Max-Change = 0.0197, Max-Change = 0.0257, Max-Change = 0.0268, Max-Change = 0.0236, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0226, gam = 0.1057, Max-Change = 0.0140, gam = 0.0780, Max-Change = 0.0052, gam = 0.0629, Max-Change = 0.0039, gam = 0.0532, Max-Change = 0.0072, gam = 0.0464, Max-Change = 0.0045, gam = 0.0413, Max-Change = 0.0037, gam = 0.0374, Max-Change = 0.0023, gam = 0.0342, Max-Change = 0.0030, gam = 0.0316, Max-Change = 0.0030, gam = 0.0294, Max-Change = 0.0025, gam = 0.0276, Max-Change = 0.0033, gam = 0.0260, Max-Change = 0.0037, gam = 0.0246, Max-Change = 0.0023, gam = 0.0233, Max-Change = 0.0025, gam = 0.0222, Max-Change = 0.0030, gam = 0.0212, Max-Change = 0.0018, gam = 0.0203, Max-Change = 0.0023, gam = 0.0195, Max-Change = 0.0019, gam = 0.0188, Max-Change = 0.0025, gam = 0.0181, Max-Change = 0.0021, gam = 0.0175, Max-Change = 0.0016, gam = 0.0169, Max-Change = 0.0010, gam = 0.0164, Max-Change = 0.0026, gam = 0.0159, Max-Change = 0.0015, gam = 0.0154, Max-Change = 0.0016, gam = 0.0150, Max-Change = 0.0016, gam = 0.0146, Max-Change = 0.0011, gam = 0.0142, Max-Change = 0.0020, gam = 0.0139, Max-Change = 0.0012, gam = 0.0135, Max-Change = 0.0014, gam = 0.0132, Max-Change = 0.0009, gam = 0.0129, Max-Change = 0.0017, gam = 0.0126, Max-Change = 0.0011, gam = 0.0124, Max-Change = 0.0007, gam = 0.0121, Max-Change = 0.0011, gam = 0.0119, Max-Change = 0.0011, gam = 0.0116, Max-Change = 0.0015, gam = 0.0114, Max-Change = 0.0010, gam = 0.0112, Max-Change = 0.0015, gam = 0.0110, Max-Change = 0.0007, gam = 0.0108, Max-Change = 0.0015, gam = 0.0106, Max-Change = 0.0009, gam = 0.0104, Max-Change = 0.0007, gam = 0.0102, Max-Change = 0.0013, gam = 0.0101, Max-Change = 0.0011, gam = 0.0099, Max-Change = 0.0007, gam = 0.0098, Max-Change = 0.0012, gam = 0.0096, Max-Change = 0.0010, gam = 0.0095, Max-Change = 0.0017, gam = 0.0093, Max-Change = 0.0008, gam = 0.0092, Max-Change = 0.0010, gam = 0.0091, Max-Change = 0.0014, gam = 0.0089, Max-Change = 0.0007, gam = 0.0088, Max-Change = 0.0012, gam = 0.0087, Max-Change = 0.0012, gam = 0.0086, Max-Change = 0.0007, gam = 0.0085, Max-Change = 0.0005, gam = 0.0084, Max-Change = 0.0007 #>  #> Calculating log-likelihood... coef(mod3) #> $Item_1 #>        a1    a2 a3      d g u #> par 0.906 1.303  0 -1.025 0 1 #>  #> $Item_2 #>        a1    a2 a3      d g u #> par 0.237 0.467  0 -1.423 0 1 #>  #> $Item_3 #>       a1   a2 a3     d g u #> par 0.55 0.61  0 1.365 0 1 #>  #> $Item_4 #>       a1    a2 a3     d g u #> par 1.54 0.691  0 0.062 0 1 #>  #> $Item_5 #>        a1 a2    a3    d1    d2    d3 #> par 0.981  0 0.896 2.925 2.034 -0.48 #>  #> $Item_6 #>        a1 a2    a3    d1    d2     d3 #> par 0.322  0 0.574 2.505 1.076 -0.992 #>  #> $Item_7 #>        a1 a2    a3    d1    d2 #> par 0.621  0 0.534 1.908 0.016 #>  #> $Item_8 #>        a1 a2    a3     d g u #> par 0.825  0 0.486 1.004 0 1 #>  #> $GroupPars #>     MEAN_1 MEAN_2 MEAN_3 COV_11 COV_21 COV_31 COV_22 COV_32 COV_33 #> par      0      0      0      1      0      0      1      0      1 #>  summary(mod3) #>            G    F1    F2     h2 #> Item_1 0.389 0.560       0.4650 #> Item_2 0.133 0.262       0.0864 #> Item_3 0.291 0.323       0.1888 #> Item_4 0.642 0.288       0.4957 #> Item_5 0.454       0.415 0.3787 #> Item_6 0.177       0.314 0.1300 #> Item_7 0.329       0.283 0.1880 #> Item_8 0.423       0.249 0.2405 #>  #> SS loadings:  1.191 0.569 0.413  #> Proportion Var:  0.149 0.071 0.052  #>  #> Factor correlations:  #>  #>    G F1 F2 #> G  1       #> F1 0  1    #> F2 0  0  1 residuals(mod3) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.054  -0.024   0.004   0.001   0.020   0.061  #>  #>        Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 #> Item_1        -0.004  0.005  0.004  0.059 -0.054 -0.038 -0.004 #> Item_2  0.036         0.018 -0.014  0.031  0.061  0.023 -0.027 #> Item_3  0.048  0.684        -0.004  0.020 -0.024  0.021 -0.014 #> Item_4  0.031  0.395  0.025        -0.053  0.016  0.008  0.010 #> Item_5  6.904  1.952  0.785  5.515         0.026 -0.031 -0.045 #> Item_6  5.909  7.454  1.179  0.535  4.010         0.043 -0.023 #> Item_7  2.958  1.096  0.887  0.122  3.761  7.274         0.013 #> Item_8  0.028  1.462  0.394  0.220  4.105  1.095  0.324        anova(mod1,mod3) #>           AIC    SABIC       HQ      BIC    logLik    X2 df    p #> mod1 24911.29 24967.04 24958.59 25040.11 -12432.65               #> mod3 24916.60 24986.89 24976.23 25079.02 -12429.30 6.697  6 0.35  ##### # polynomial/combinations data(SAT12) data <- key2binary(SAT12,                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))  model.quad <- '        F1 = 1-32   (F1*F1) = 1-32'   model.combo <- '        F1 = 1-16        F2 = 17-32   (F1*F2) = 1-8'  (mod.quad <- mirt(data, model.quad)) #>  #> Warning: EM cycles terminated after 500 iterations. #>  #> Call: #> mirt(data = data, model = model.quad) #>  #> Full-information item factor analysis with 1 factor(s). #> FAILED TO CONVERGE within 1e-04 tolerance after 500 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -9424.25 #> Estimated parameters: 96  #> AIC = 19040.5 #> BIC = 19462.61; SABIC = 19157.83 #>  summary(mod.quad) #>               F1 (F1*F1)     h2 #> Item.1   0.24781  0.3206 0.1642 #> Item.2   0.31819  0.6617 0.5390 #> Item.3   0.18997  0.4629 0.2504 #> Item.4   0.22615  0.2802 0.1297 #> Item.5   0.27007  0.4764 0.2999 #> Item.6   0.23129  0.4340 0.2418 #> Item.7  -0.23295  0.6835 0.5215 #> Item.8   0.07142  0.3230 0.1094 #> Item.9   0.07120  0.2448 0.0650 #> Item.10  0.12985  0.4483 0.2178 #> Item.11  0.00489  0.9832 0.9667 #> Item.12  0.13130  0.0666 0.0217 #> Item.13 -0.12244  0.6412 0.4261 #> Item.14  0.42256  0.5436 0.4741 #> Item.15 -0.25904  0.8074 0.7190 #> Item.16  0.15771  0.3584 0.1533 #> Item.17 -0.30637  0.8837 0.8747 #> Item.18  0.22597  0.6542 0.4790 #> Item.19  0.17275  0.4037 0.1928 #> Item.20  0.37087  0.7925 0.7656 #> Item.21 -0.36576  0.5739 0.4631 #> Item.22 -0.27360  0.9330 0.9454 #> Item.23  0.41421  0.2192 0.2196 #> Item.24 -0.13434  0.7637 0.6012 #> Item.25  0.60732  0.2554 0.4341 #> Item.26  0.35413  0.6293 0.5214 #> Item.27 -0.05234  0.9284 0.8647 #> Item.28  0.09058  0.5130 0.2714 #> Item.29  0.26616  0.3615 0.2016 #> Item.30  0.05551  0.1696 0.0319 #> Item.31  0.25711  0.9259 0.9234 #> Item.32  0.01322  0.1086 0.0120 #>  #> SS loadings:  2.116 10.985  #> Proportion Var:  0.066 0.343  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 (mod.combo <- mirt(data, model.combo)) #>  #>  #> Call: #> mirt(data = data, model = model.combo) #>  #> Full-information item factor analysis with 2 factor(s). #> Converged within 1e-04 tolerance after 22 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 31 #> Latent density type: Gaussian  #>  #> Log-likelihood = -9619.871 #> Estimated parameters: 72  #> AIC = 19383.74 #> BIC = 19700.32; SABIC = 19471.74 #>  anova(mod.combo, mod.quad) #>                AIC    SABIC       HQ      BIC    logLik      X2 df p #> mod.combo 19383.74 19471.74 19506.98 19700.32 -9619.871              #> mod.quad  19040.50 19157.83 19204.82 19462.60 -9424.250 391.241 24 0  # non-linear item and test plots plot(mod.quad)  plot(mod.combo, type = 'SE')  itemplot(mod.quad, 1, type = 'score')  itemplot(mod.combo, 2, type = 'score')  itemplot(mod.combo, 2, type = 'infocontour')   ## empirical histogram examples (normal, skew and bimodality) # make some data set.seed(1234) a <- matrix(rlnorm(50, .2, .2)) d <- matrix(rnorm(50)) ThetaNormal <- matrix(rnorm(2000)) ThetaBimodal <- scale(matrix(c(rnorm(1000, -2), rnorm(1000,2)))) #bimodal ThetaSkew <- scale(matrix(rchisq(2000, 3))) #positive skew datNormal <- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaNormal) datBimodal <- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaBimodal) datSkew <- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaSkew)  normal <- mirt(datNormal, 1, dentype = \"empiricalhist\") #>  plot(normal, type = 'empiricalhist')  histogram(ThetaNormal, breaks=30)   bimodal <- mirt(datBimodal, 1, dentype = \"empiricalhist\") #>  plot(bimodal, type = 'empiricalhist')  histogram(ThetaBimodal, breaks=30)   skew <- mirt(datSkew, 1, dentype = \"empiricalhist\") #>  plot(skew, type = 'empiricalhist')  histogram(ThetaSkew, breaks=30)   ##### # non-linear parameter constraints with Rsolnp package (nloptr supported as well): # Find Rasch model subject to the constraint that the intercepts sum to 0  dat <- expand.table(LSAT6) itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r sd.r alpha SEM.alpha #>  1000            3.819          1.035 0.077 0.03 0.295     0.869 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1 1000 2 0.924 0.265   0.362         0.113       0.275 #> Item_2 1000 2 0.709 0.454   0.567         0.153       0.238 #> Item_3 1000 2 0.553 0.497   0.618         0.173       0.217 #> Item_4 1000 2 0.763 0.425   0.534         0.144       0.246 #> Item_5 1000 2 0.870 0.336   0.435         0.122       0.266 #>  #> $proportions #>            0     1 #> Item_1 0.076 0.924 #> Item_2 0.291 0.709 #> Item_3 0.447 0.553 #> Item_4 0.237 0.763 #> Item_5 0.130 0.870 #>   # free latent mean and variance terms model <- 'Theta = 1-5           MEAN = Theta           COV = Theta*Theta'  # view how vector of parameters is organized internally sv <- mirt(dat, model, itemtype = 'Rasch', pars = 'values') sv[sv$est, ] #>    group   item     class   name parnum value lbound ubound  est const nconst #> 2    all Item_1      dich      d      2 2.815   -Inf    Inf TRUE  none   none #> 6    all Item_2      dich      d      6 1.082   -Inf    Inf TRUE  none   none #> 10   all Item_3      dich      d     10 0.262   -Inf    Inf TRUE  none   none #> 14   all Item_4      dich      d     14 1.407   -Inf    Inf TRUE  none   none #> 18   all Item_5      dich      d     18 2.214   -Inf    Inf TRUE  none   none #> 21   all  GROUP GroupPars MEAN_1     21 0.000   -Inf    Inf TRUE  none   none #> 22   all  GROUP GroupPars COV_11     22 1.000      0    Inf TRUE  none   none #>    prior.type prior_1 prior_2 #> 2        none     NaN     NaN #> 6        none     NaN     NaN #> 10       none     NaN     NaN #> 14       none     NaN     NaN #> 18       none     NaN     NaN #> 21       none     NaN     NaN #> 22       none     NaN     NaN  # constraint: create function for solnp to compute constraint, and declare value in eqB eqfun <- function(p, optim_args) sum(p[1:5]) #could use browser() here, if it helps LB <- c(rep(-15, 6), 1e-4) # more reasonable lower bound for variance term  mod <- mirt(dat, model, sv=sv, itemtype = 'Rasch', optimizer = 'solnp',    solnp_args=list(eqfun=eqfun, eqB=0, LB=LB)) #>  print(mod) #>  #> Call: #> mirt(data = dat, model = model, itemtype = \"Rasch\", optimizer = \"solnp\",  #>     solnp_args = list(eqfun = eqfun, eqB = 0, LB = LB), sv = sv) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 34 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: solnp  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2466.943 #> Estimated parameters: 7  #> AIC = 4947.887 #> BIC = 4982.241; SABIC = 4960.009 #> G2 (25) = 21.81, p = 0.6467 #> RMSEA = 0, CFI = NaN, TLI = NaN coef(mod) #> $Item_1 #>     a1     d g u #> par  1 1.253 0 1 #>  #> $Item_2 #>     a1      d g u #> par  1 -0.475 0 1 #>  #> $Item_3 #>     a1      d g u #> par  1 -1.233 0 1 #>  #> $Item_4 #>     a1      d g u #> par  1 -0.168 0 1 #>  #> $Item_5 #>     a1     d g u #> par  1 0.623 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par  1.472  0.559 #>  (ds <- sapply(coef(mod)[1:5], function(x) x[,'d'])) #>     Item_1     Item_2     Item_3     Item_4     Item_5  #>  1.2529432 -0.4754429 -1.2327196 -0.1681687  0.6233879  sum(ds) #> [1] 4.635181e-15  # same likelihood location as: mirt(dat, 1, itemtype = 'Rasch')   ####### # latent regression Rasch model  # simulate data set.seed(1234) N <- 1000  # covariates X1 <- rnorm(N); X2 <- rnorm(N) covdata <- data.frame(X1, X2, X3 = rnorm(N)) Theta <- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))  # items and response data a <- matrix(1, 20); d <- matrix(rnorm(20)) dat <- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)  # unconditional Rasch model mod0 <- mirt(dat, 1, 'Rasch', SE=TRUE) #>  #>  #> Calculating information matrix... coef(mod0, printSE=TRUE) #> $Item_1 #>     a1      d logit(g) logit(u) #> par  1 -0.998     -999      999 #> SE  NA  0.085       NA       NA #>  #> $Item_2 #>     a1      d logit(g) logit(u) #> par  1 -0.917     -999      999 #> SE  NA  0.085       NA       NA #>  #> $Item_3 #>     a1      d logit(g) logit(u) #> par  1 -0.099     -999      999 #> SE  NA  0.081       NA       NA #>  #> $Item_4 #>     a1     d logit(g) logit(u) #> par  1 1.893     -999      999 #> SE  NA 0.099       NA       NA #>  #> $Item_5 #>     a1     d logit(g) logit(u) #> par  1 0.610     -999      999 #> SE  NA 0.082       NA       NA #>  #> $Item_6 #>     a1     d logit(g) logit(u) #> par  1 1.071     -999      999 #> SE  NA 0.086       NA       NA #>  #> $Item_7 #>     a1      d logit(g) logit(u) #> par  1 -0.074     -999      999 #> SE  NA  0.081       NA       NA #>  #> $Item_8 #>     a1      d logit(g) logit(u) #> par  1 -1.405     -999      999 #> SE  NA  0.090       NA       NA #>  #> $Item_9 #>     a1     d logit(g) logit(u) #> par  1 0.707     -999      999 #> SE  NA 0.083       NA       NA #>  #> $Item_10 #>     a1      d logit(g) logit(u) #> par  1 -0.258     -999      999 #> SE  NA  0.081       NA       NA #>  #> $Item_11 #>     a1     d logit(g) logit(u) #> par  1 0.336     -999      999 #> SE  NA 0.081       NA       NA #>  #> $Item_12 #>     a1     d logit(g) logit(u) #> par  1 0.891     -999      999 #> SE  NA 0.084       NA       NA #>  #> $Item_13 #>     a1     d logit(g) logit(u) #> par  1 0.653     -999      999 #> SE  NA 0.083       NA       NA #>  #> $Item_14 #>     a1      d logit(g) logit(u) #> par  1 -1.942     -999      999 #> SE  NA  0.099       NA       NA #>  #> $Item_15 #>     a1      d logit(g) logit(u) #> par  1 -2.143     -999      999 #> SE  NA  0.104       NA       NA #>  #> $Item_16 #>     a1     d logit(g) logit(u) #> par  1 1.759     -999      999 #> SE  NA 0.096       NA       NA #>  #> $Item_17 #>     a1      d logit(g) logit(u) #> par  1 -1.015     -999      999 #> SE  NA  0.085       NA       NA #>  #> $Item_18 #>     a1      d logit(g) logit(u) #> par  1 -1.009     -999      999 #> SE  NA  0.085       NA       NA #>  #> $Item_19 #>     a1      d logit(g) logit(u) #> par  1 -1.251     -999      999 #> SE  NA  0.088       NA       NA #>  #> $Item_20 #>     a1      d logit(g) logit(u) #> par  1 -0.619     -999      999 #> SE  NA  0.082       NA       NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  1.393 #> SE      NA  0.085 #>   # conditional model using X1, X2, and X3 (bad) as predictors of Theta mod1 <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2 + X3, SE=TRUE) #>  #>  #> Calculating information matrix... coef(mod1, printSE=TRUE) #> $Item_1 #>     a1      d logit(g) logit(u) #> par  1 -0.967     -999      999 #> SE  NA  0.078       NA       NA #>  #> $Item_2 #>     a1      d logit(g) logit(u) #> par  1 -0.887     -999      999 #> SE  NA  0.077       NA       NA #>  #> $Item_3 #>     a1      d logit(g) logit(u) #> par  1 -0.068     -999      999 #> SE  NA  0.073       NA       NA #>  #> $Item_4 #>     a1     d logit(g) logit(u) #> par  1 1.920     -999      999 #> SE  NA 0.092       NA       NA #>  #> $Item_5 #>     a1     d logit(g) logit(u) #> par  1 0.640     -999      999 #> SE  NA 0.075       NA       NA #>  #> $Item_6 #>     a1     d logit(g) logit(u) #> par  1 1.100     -999      999 #> SE  NA 0.079       NA       NA #>  #> $Item_7 #>     a1      d logit(g) logit(u) #> par  1 -0.043     -999      999 #> SE  NA  0.073       NA       NA #>  #> $Item_8 #>     a1      d logit(g) logit(u) #> par  1 -1.375     -999      999 #> SE  NA  0.083       NA       NA #>  #> $Item_9 #>     a1     d logit(g) logit(u) #> par  1 0.737     -999      999 #> SE  NA 0.076       NA       NA #>  #> $Item_10 #>     a1      d logit(g) logit(u) #> par  1 -0.227     -999      999 #> SE  NA  0.073       NA       NA #>  #> $Item_11 #>     a1     d logit(g) logit(u) #> par  1 0.367     -999      999 #> SE  NA 0.074       NA       NA #>  #> $Item_12 #>     a1     d logit(g) logit(u) #> par  1 0.921     -999      999 #> SE  NA 0.077       NA       NA #>  #> $Item_13 #>     a1     d logit(g) logit(u) #> par  1 0.683     -999      999 #> SE  NA 0.075       NA       NA #>  #> $Item_14 #>     a1      d logit(g) logit(u) #> par  1 -1.913     -999      999 #> SE  NA  0.093       NA       NA #>  #> $Item_15 #>     a1      d logit(g) logit(u) #> par  1 -2.114     -999      999 #> SE  NA  0.098       NA       NA #>  #> $Item_16 #>     a1     d logit(g) logit(u) #> par  1 1.786     -999      999 #> SE  NA 0.090       NA       NA #>  #> $Item_17 #>     a1      d logit(g) logit(u) #> par  1 -0.985     -999      999 #> SE  NA  0.078       NA       NA #>  #> $Item_18 #>     a1      d logit(g) logit(u) #> par  1 -0.979     -999      999 #> SE  NA  0.078       NA       NA #>  #> $Item_19 #>     a1      d logit(g) logit(u) #> par  1 -1.221     -999      999 #> SE  NA  0.081       NA       NA #>  #> $Item_20 #>     a1      d logit(g) logit(u) #> par  1 -0.589     -999      999 #> SE  NA  0.075       NA       NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  0.210 #> SE      NA  0.011 #>  #> $lr.betas #> $lr.betas$betas #>                 F1 #> (Intercept)  0.000 #> X1           0.513 #> X2          -1.003 #> X3          -0.003 #>  #> $lr.betas$SE #>                F1 #> (Intercept)    NA #> X1          0.015 #> X2          0.015 #> X3          0.014 #>  #>  coef(mod1, simplify=TRUE) #> $items #>         a1      d g u #> Item_1   1 -0.967 0 1 #> Item_2   1 -0.887 0 1 #> Item_3   1 -0.068 0 1 #> Item_4   1  1.920 0 1 #> Item_5   1  0.640 0 1 #> Item_6   1  1.100 0 1 #> Item_7   1 -0.043 0 1 #> Item_8   1 -1.375 0 1 #> Item_9   1  0.737 0 1 #> Item_10  1 -0.227 0 1 #> Item_11  1  0.367 0 1 #> Item_12  1  0.921 0 1 #> Item_13  1  0.683 0 1 #> Item_14  1 -1.913 0 1 #> Item_15  1 -2.114 0 1 #> Item_16  1  1.786 0 1 #> Item_17  1 -0.985 0 1 #> Item_18  1 -0.979 0 1 #> Item_19  1 -1.221 0 1 #> Item_20  1 -0.589 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>      F1 #> F1 0.21 #>  #> $lr.betas #> $lr.betas$betas #>                 F1 #> (Intercept)  0.000 #> X1           0.513 #> X2          -1.003 #> X3          -0.003 #>  #> $lr.betas$CI_2.5 #>                 F1 #> (Intercept)     NA #> X1           0.485 #> X2          -1.032 #> X3          -0.031 #>  #> $lr.betas$CI_97.5 #>                 F1 #> (Intercept)     NA #> X1           0.542 #> X2          -0.974 #> X3           0.025 #>  #>  anova(mod0, mod1)  # jointly significant predictors of theta #>           AIC    SABIC       HQ      BIC    logLik       X2 df p #> mod0 21935.46 21971.83 21974.63 22038.53 -10946.73               #> mod1 20756.61 20798.17 20801.38 20874.40 -10354.31 1184.851  3 0  # large sample z-ratios and p-values (if one cares) cfs <- coef(mod1, printSE=TRUE) (z <- cfs$lr.betas[[1]] / cfs$lr.betas[[2]]) #>                      F1 #> (Intercept)          NA #> X1           35.2668946 #> X2          -67.5847949 #> X3           -0.2114561 round(pnorm(abs(z[,1]), lower.tail=FALSE)*2, 3) #> (Intercept)          X1          X2          X3  #>          NA       0.000       0.000       0.833   # drop predictor for nested comparison mod1b <- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2) #>  anova(mod1b, mod1) #>            AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod1b 20754.63 20794.46 20797.53 20867.51 -10354.32                #> mod1  20756.61 20798.17 20801.38 20874.40 -10354.31 0.018  1 0.893  # compare to mixedmirt() version of the same model mod1.mixed <- mixedmirt(dat, 1, itemtype='Rasch',                         covdata=covdata, lr.fixed = ~ X1 + X2 + X3, SE=TRUE) #> , Max-Change = 0.1317, Max-Change = 0.1109, Max-Change = 0.0928, Max-Change = 0.2000, Max-Change = 0.0832, Max-Change = 0.0494, Max-Change = 0.0447, Max-Change = 0.0467, Max-Change = 0.0290, Max-Change = 0.0373, Max-Change = 0.0231, Max-Change = 0.0177, Max-Change = 0.0250, Max-Change = 0.0135, Max-Change = 0.0126, Max-Change = 0.0102, Max-Change = 0.0078, Max-Change = 0.0107, Max-Change = 0.0102, Max-Change = 0.0073, Max-Change = 0.0075, Max-Change = 0.0059, Max-Change = 0.0071, Max-Change = 0.0106, Max-Change = 0.0133, Max-Change = 0.0034, Max-Change = 0.0015, Max-Change = 0.0054, Max-Change = 0.0074, Max-Change = 0.0034, Max-Change = 0.0037, Max-Change = 0.0062, Max-Change = 0.0042, Max-Change = 0.0055, Max-Change = 0.0040, Max-Change = 0.0024, Max-Change = 0.0034, Max-Change = 0.0049, Max-Change = 0.0043, Max-Change = 0.0024, Max-Change = 0.0024, Max-Change = 0.0032, Max-Change = 0.0032, Max-Change = 0.0040, Max-Change = 0.0022, Max-Change = 0.0031, Max-Change = 0.0010, Max-Change = 0.0035, Max-Change = 0.0025, Max-Change = 0.0016, Max-Change = 0.0031, Max-Change = 0.0033, Max-Change = 0.0033, Max-Change = 0.0024, Max-Change = 0.0025, Max-Change = 0.0029, Max-Change = 0.0014, Max-Change = 0.0025, Max-Change = 0.0028, Max-Change = 0.0024, Max-Change = 0.0023, Max-Change = 0.0028, Max-Change = 0.0025, Max-Change = 0.0033, Max-Change = 0.0055, Max-Change = 0.0030, Max-Change = 0.0016, Max-Change = 0.0034, Max-Change = 0.0030, Max-Change = 0.0026, Max-Change = 0.0033, Max-Change = 0.0006, Max-Change = 0.0026, Max-Change = 0.0041, Max-Change = 0.0029, Max-Change = 0.0015, Max-Change = 0.0026, Max-Change = 0.0024, Max-Change = 0.0050, Max-Change = 0.0037, Max-Change = 0.0017, Max-Change = 0.0027, Max-Change = 0.0042, Max-Change = 0.0027, Max-Change = 0.0037, Max-Change = 0.0048, Max-Change = 0.0020, Max-Change = 0.0024, Max-Change = 0.0039, Max-Change = 0.0027, Max-Change = 0.0018, Max-Change = 0.0015, Max-Change = 0.0019, Max-Change = 0.0022, Max-Change = 0.0019, Max-Change = 0.0022, Max-Change = 0.0024, Max-Change = 0.0024, Max-Change = 0.0018, Max-Change = 0.0029, Max-Change = 0.0042, Max-Change = 0.0017, Max-Change = 0.0013, Max-Change = 0.0029, Max-Change = 0.0016, Max-Change = 0.0027, Max-Change = 0.0021, Max-Change = 0.0027, Max-Change = 0.0026, Max-Change = 0.0019, Max-Change = 0.0008, Max-Change = 0.0019, Max-Change = 0.0043, Max-Change = 0.0016, Max-Change = 0.0032, Max-Change = 0.0024, Max-Change = 0.0043, Max-Change = 0.0022, Max-Change = 0.0026, Max-Change = 0.0037, Max-Change = 0.0034, Max-Change = 0.0029, Max-Change = 0.0016, Max-Change = 0.0033, Max-Change = 0.0014, Max-Change = 0.0035, Max-Change = 0.0023, Max-Change = 0.0027, Max-Change = 0.0010, Max-Change = 0.0018, Max-Change = 0.0015, Max-Change = 0.0009, Max-Change = 0.0017, Max-Change = 0.0026, Max-Change = 0.0035, Max-Change = 0.0030, Max-Change = 0.0052, Max-Change = 0.0011, Max-Change = 0.0025, Max-Change = 0.0043, Max-Change = 0.0016, Max-Change = 0.0028, Max-Change = 0.0021, Max-Change = 0.0028, Max-Change = 0.0026, Max-Change = 0.0032, Max-Change = 0.0020, Max-Change = 0.0021, Max-Change = 0.0051, Max-Change = 0.0025, Max-Change = 0.0024, Max-Change = 0.0018, Max-Change = 0.0014, Max-Change = 0.0029, Max-Change = 0.0029, Max-Change = 0.0009, Max-Change = 0.0022, Max-Change = 0.0029, Max-Change = 0.0015, Max-Change = 0.0018, Max-Change = 0.0032, Max-Change = 0.0027, Max-Change = 0.0011, Max-Change = 0.0019, Max-Change = 0.0027, Max-Change = 0.0039, Max-Change = 0.0032, Max-Change = 0.0031, Max-Change = 0.0026, Max-Change = 0.0036, Max-Change = 0.0021, Max-Change = 0.0019, Max-Change = 0.0011, Max-Change = 0.0029, Max-Change = 0.0017, Max-Change = 0.0012, Max-Change = 0.0014, Max-Change = 0.0040, Max-Change = 0.0017, Max-Change = 0.0028, Max-Change = 0.0019, Max-Change = 0.0015, Max-Change = 0.0026, Max-Change = 0.0026, Max-Change = 0.0025, Max-Change = 0.0032, Max-Change = 0.0019, Max-Change = 0.0019, Max-Change = 0.0025, Max-Change = 0.0020, Max-Change = 0.0027, Max-Change = 0.0019, Max-Change = 0.0011, Max-Change = 0.0034, Max-Change = 0.0035, Max-Change = 0.0029, Max-Change = 0.0015, Max-Change = 0.0034, Max-Change = 0.0019, Max-Change = 0.0015, Max-Change = 0.0013, Max-Change = 0.0031, Max-Change = 0.0028, Max-Change = 0.0017, Max-Change = 0.0023, Max-Change = 0.0033, Max-Change = 0.0031, Max-Change = 0.0019, Max-Change = 0.0034, Max-Change = 0.0025, Max-Change = 0.0028, Max-Change = 0.0020, Max-Change = 0.0027, Max-Change = 0.0023, Max-Change = 0.0053, Max-Change = 0.0036, Max-Change = 0.0026, Max-Change = 0.0024, Max-Change = 0.0024, Max-Change = 0.0029, Max-Change = 0.0021, Max-Change = 0.0011, Max-Change = 0.0020, Max-Change = 0.0018, Max-Change = 0.0020, Max-Change = 0.0016, Max-Change = 0.0012, Max-Change = 0.0025, Max-Change = 0.0040, Max-Change = 0.0030, Max-Change = 0.0019, Max-Change = 0.0039, Max-Change = 0.0017, Max-Change = 0.0022, Max-Change = 0.0013, Max-Change = 0.0013, Max-Change = 0.0034, Max-Change = 0.0010, Max-Change = 0.0014, Max-Change = 0.0015, Max-Change = 0.0014, Max-Change = 0.0011, Max-Change = 0.0036, Max-Change = 0.0013, Max-Change = 0.0020, Max-Change = 0.0024, Max-Change = 0.0018, Max-Change = 0.0029, Max-Change = 0.0051, Max-Change = 0.0023, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0033, gam = 0.1057, Max-Change = 0.0012, gam = 0.0780, Max-Change = 0.0010, gam = 0.0629, Max-Change = 0.0005, gam = 0.0532, Max-Change = 0.0008, gam = 0.0464, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... coef(mod1.mixed) #> $Item_1 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_2 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_3 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_4 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_5 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_6 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_7 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_8 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_9 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_10 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_11 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_12 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_13 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_14 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_15 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_16 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_17 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_18 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_19 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $Item_20 #>         (Intercept) a1  d  g  u #> par          -0.131  1  0  0  1 #> CI_2.5       -0.166 NA NA NA NA #> CI_97.5      -0.097 NA NA NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0  0.087 #> CI_2.5      NA  0.068 #> CI_97.5     NA  0.105 #>  #> $lr.betas #>         F1_(Intercept) F1_X1  F1_X2  F1_X3 #> par                  0 0.409 -0.795 -0.007 #> CI_2.5              NA 0.376 -0.837 -0.040 #> CI_97.5             NA 0.441 -0.753  0.027 #>  coef(mod1.mixed, printSE=TRUE) #> $Item_1 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_2 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_3 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_4 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_5 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_6 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_7 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_8 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_9 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_10 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_11 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_12 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_13 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_14 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_15 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_16 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_17 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_18 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_19 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $Item_20 #>     (Intercept) a1  d    g   u #> par      -0.131  1  0 -999 999 #> SE        0.018 NA NA   NA  NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  0.087 #> SE      NA  0.009 #>  #> $lr.betas #>     F1_(Intercept) F1_X1  F1_X2  F1_X3 #> par              0 0.409 -0.795 -0.007 #> SE              NA 0.016  0.021  0.017 #>   # draw plausible values for secondary analyses pv <- fscores(mod1, plausible.draws = 10) pvmods <- lapply(pv, function(x, covdata) lm(x ~ covdata$X1 + covdata$X2),                  covdata=covdata) # population characteristics recovered well, and can be averaged over so <- lapply(pvmods, summary) so #> [[1]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.30381 -0.28686  0.00516  0.29451  1.48126  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.02764    0.01441  -1.918   0.0553 .   #> covdata$X1   0.50310    0.01447  34.773   <2e-16 *** #> covdata$X2  -1.00385    0.01471 -68.261   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4553 on 997 degrees of freedom #> Multiple R-squared:  0.8493,\tAdjusted R-squared:  0.849  #> F-statistic:  2809 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[2]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.44620 -0.30407 -0.00998  0.32209  1.50996  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.009629   0.014344   0.671    0.502     #> covdata$X1   0.526280   0.014406  36.532   <2e-16 *** #> covdata$X2  -0.998349   0.014643 -68.179   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4534 on 997 degrees of freedom #> Multiple R-squared:  0.8516,\tAdjusted R-squared:  0.8513  #> F-statistic:  2860 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[3]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.35926 -0.33268 -0.00322  0.33980  1.46940  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.003481   0.014833  -0.235    0.815     #> covdata$X1   0.508282   0.014897  34.121   <2e-16 *** #> covdata$X2  -1.010081   0.015142 -66.708   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4688 on 997 degrees of freedom #> Multiple R-squared:  0.8435,\tAdjusted R-squared:  0.8432  #> F-statistic:  2687 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[4]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.58818 -0.31213  0.00162  0.31373  1.35583  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.005489   0.014330   0.383    0.702     #> covdata$X1   0.521293   0.014391  36.223   <2e-16 *** #> covdata$X2  -0.985449   0.014628 -67.367   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4529 on 997 degrees of freedom #> Multiple R-squared:  0.8487,\tAdjusted R-squared:  0.8484  #> F-statistic:  2796 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[5]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.38886 -0.31645 -0.01151  0.30538  1.68913  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.002674   0.014904  -0.179    0.858     #> covdata$X1   0.513344   0.014968  34.296   <2e-16 *** #> covdata$X2  -1.022914   0.015214 -67.234   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4711 on 997 degrees of freedom #> Multiple R-squared:  0.8454,\tAdjusted R-squared:  0.8451  #> F-statistic:  2726 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[6]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.61896 -0.31934  0.01145  0.32585  1.32115  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.008359   0.015008  -0.557    0.578     #> covdata$X1   0.519352   0.015073  34.457   <2e-16 *** #> covdata$X2  -1.015467   0.015321 -66.281   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4744 on 997 degrees of freedom #> Multiple R-squared:  0.8426,\tAdjusted R-squared:  0.8423  #> F-statistic:  2669 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[7]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -1.4344 -0.2932 -0.0091  0.2732  1.4719  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.008984   0.014382  -0.625    0.532     #> covdata$X1   0.510036   0.014443  35.313   <2e-16 *** #> covdata$X2  -1.002653   0.014681 -68.296   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4546 on 997 degrees of freedom #> Multiple R-squared:  0.8501,\tAdjusted R-squared:  0.8498  #> F-statistic:  2828 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[8]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.50514 -0.32231 -0.00027  0.30983  1.34894  #>  #> Coefficients: #>              Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.006793   0.014740  -0.461    0.645     #> covdata$X1   0.522459   0.014804  35.293   <2e-16 *** #> covdata$X2  -1.011639   0.015047 -67.231   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4659 on 997 degrees of freedom #> Multiple R-squared:  0.8469,\tAdjusted R-squared:  0.8466  #> F-statistic:  2757 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[9]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -1.43485 -0.29728  0.00103  0.32027  1.55251  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.00781    0.01454   0.537    0.591     #> covdata$X1   0.52295    0.01460  35.813   <2e-16 *** #> covdata$X2  -1.01561    0.01484 -68.425   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.4596 on 997 degrees of freedom #> Multiple R-squared:  0.8512,\tAdjusted R-squared:  0.8509  #> F-statistic:  2853 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>  #> [[10]] #>  #> Call: #> lm(formula = x ~ covdata$X1 + covdata$X2) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -1.4522 -0.3197 -0.0102  0.3195  1.4794  #>  #> Coefficients: #>               Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.0001743  0.0148080   0.012    0.991     #> covdata$X1   0.5194120  0.0148716  34.927   <2e-16 *** #> covdata$X2  -1.0114153  0.0151163 -66.909   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 0.468 on 997 degrees of freedom #> Multiple R-squared:  0.8453,\tAdjusted R-squared:  0.845  #> F-statistic:  2725 on 2 and 997 DF,  p-value: < 2.2e-16 #>  #>   # compute Rubin's multiple imputation average par <- lapply(so, function(x) x$coefficients[, 'Estimate']) SEpar <- lapply(so, function(x) x$coefficients[, 'Std. Error']) averageMI(par, SEpar) #>                par SEpar       t      df     p #> (Intercept) -0.003 0.018  -0.188  64.661 0.213 #> covdata$X1   0.517 0.017  30.966 178.841     0 #> covdata$X2  -1.008 0.019 -54.115  70.736     0  ############ # Example using Gauss-Hermite quadrature with custom input functions  if (FALSE) { # \\dontrun{ library(fastGHQuad) data(SAT12) data <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) GH <- gaussHermiteData(50) Theta <- matrix(GH$x)  # This prior works for uni- and multi-dimensional models prior <- function(Theta, Etable){     P <- grid <- GH$w / sqrt(pi)     if(ncol(Theta) > 1)         for(i in 2:ncol(Theta))             P <- expand.grid(P, grid)      if(!is.vector(P)) P <- apply(P, 1, prod)      P }  GHmod1 <- mirt(data, 1, optimizer = 'NR',               technical = list(customTheta = Theta, customPriorFun = prior)) coef(GHmod1, simplify=TRUE)  Theta2 <- as.matrix(expand.grid(Theta, Theta)) GHmod2 <- mirt(data, 2, optimizer = 'NR', TOL = .0002,               technical = list(customTheta = Theta2, customPriorFun = prior)) summary(GHmod2, suppress=.2) } # }  ############ # Davidian curve example  dat <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) dav <- mirt(dat, 1, dentype = 'Davidian-4') # use four smoothing parameters #>  plot(dav, type = 'Davidian') # shape of latent trait distribution  coef(dav, simplify=TRUE) #> $items #>            a1      d g u #> Item.1  0.774 -1.048 0 1 #> Item.2  1.684  0.495 0 1 #> Item.3  1.051 -1.114 0 1 #> Item.4  0.582 -0.531 0 1 #> Item.5  1.043  0.613 0 1 #> Item.6  1.037 -2.030 0 1 #> Item.7  1.096  1.397 0 1 #> Item.8  0.639 -1.513 0 1 #> Item.9  0.543  2.128 0 1 #> Item.10 0.993 -0.352 0 1 #> Item.11 2.130  5.453 0 1 #> Item.12 0.163 -0.338 0 1 #> Item.13 1.204  0.867 0 1 #> Item.14 1.171  1.211 0 1 #> Item.15 1.387  1.925 0 1 #> Item.16 0.725 -0.389 0 1 #> Item.17 1.860  4.273 0 1 #> Item.18 1.763 -0.788 0 1 #> Item.19 0.880  0.236 0 1 #> Item.20 1.866  2.743 0 1 #> Item.21 0.695  2.552 0 1 #> Item.22 1.863  3.592 0 1 #> Item.23 0.590 -0.851 0 1 #> Item.24 1.335  1.296 0 1 #> Item.25 0.733 -0.558 0 1 #> Item.26 1.649 -0.125 0 1 #> Item.27 2.356  2.968 0 1 #> Item.28 1.060  0.184 0 1 #> Item.29 0.803 -0.742 0 1 #> Item.30 0.352 -0.241 0 1 #> Item.31 2.944  3.061 0 1 #> Item.32 0.169 -1.651 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #> $Davidian_phis #> [1]  1.289  0.086 -0.443  1.245 #>   fs <- fscores(dav) # assume normal prior fs2 <- fscores(dav, use_dentype_estimate=TRUE) # use Davidian estimated prior shape head(cbind(fs, fs2)) #>               F1           F1 #> [1,]  2.66818540  3.599616034 #> [2,]  0.14648879  0.070501775 #> [3,]  0.06802365  0.004037417 #> [4,] -0.41577386 -0.426755059 #> [5,]  0.67027700  0.559830142 #> [6,]  0.45477422  0.353831282  itemfit(dav) # assume normal prior #> Error: Only X2, G2, PV_Q1, PV_Q1*, infit, X2*, and X2*_df can be computed with missing data. #>              Pass na.rm=TRUE to remove missing data row-wise itemfit(dav, use_dentype_estimate=TRUE) # use Davidian estimated prior shape #> Error: Only X2, G2, PV_Q1, PV_Q1*, infit, X2*, and X2*_df can be computed with missing data. #>              Pass na.rm=TRUE to remove missing data row-wise  ############ # Unfolding models  # polytomous hyperbolic cosine model with #  estimated latitude of acceptance (rho parameters) mod <- mirt(Science, model=1, itemtype = 'hcm') #>  coef(mod, simplify=TRUE)$items #>         a1        d log_rho1 log_rho2  log_rho3 #> Comfort  1 1.989655 1.625421 1.526102 -16.17198 #> Work     1 2.485054 1.478531 1.224489 -20.39161 #> Future   1 1.801569 1.491945 1.185052 -15.30324 #> Benefit  1 1.903674 1.471276 1.039336 -17.53716 coef(mod, simplify=TRUE, IRTpars=TRUE)$items #>         a         b     rho1     rho2         rho3 #> Comfort 1 -1.989655 5.080557 4.600212 9.475379e-08 #> Work    1 -2.485054 4.386497 3.402426 1.393270e-09 #> Future  1 -1.801569 4.445732 3.270856 2.258856e-07 #> Benefit 1 -1.903674 4.354789 2.827339 2.419408e-08  plot(mod)  plot(mod, type = 'trace')  plot(mod, type = 'itemscore')   # EAP estimates fs <- fscores(mod) head(fs) #>          F1 #> [1,] -0.668 #> [2,] -0.158 #> [3,]  0.656 #> [4,]  0.656 #> [5,] -0.206 #> [6,] -1.008  itemfit(mod) #>      item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1 Comfort  4.437       6      0.000  0.618 #> 2    Work 10.778       8      0.030  0.215 #> 3  Future 18.242      10      0.046  0.051 #> 4 Benefit 12.020      11      0.015  0.362 M2(mod, type = 'C2') #>             M2 df            p     RMSEA    RMSEA_5 RMSEA_95      TLI       CFI #> stats 18.78276  2 8.344004e-05 0.1464969 0.09063855 0.209979 0.736325 0.9121083  ########### # 5PL and restricted 5PL example dat <- expand.table(LSAT7)  mod2PL <- mirt(dat) #>  mod2PL #>  #> Call: #> mirt(data = dat) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN  # Following does not converge without including strong priors # mod5PL <- mirt(dat, itemtype = '5PL') # mod5PL  # restricted version of 5PL (asymmetric 2PL) model <- 'Theta = 1-5           FIXED = (1-5, g), (1-5, u)'  mod2PL_asym <- mirt(dat, model=model, itemtype = '5PL') #>  mod2PL_asym #>  #> Call: #> mirt(data = dat, model = model, itemtype = \"5PL\") #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 69 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2657.911 #> Estimated parameters: 15  #> AIC = 5345.822 #> BIC = 5419.438; SABIC = 5371.797 #> G2 (16) = 29.91, p = 0.0185 #> RMSEA = 0.03, CFI = NaN, TLI = NaN coef(mod2PL_asym, simplify=TRUE) #> $items #>           a1      d g u   logS #> Item.1 0.926  2.882 0 1  0.962 #> Item.2 2.141 -1.547 0 1 -1.454 #> Item.3 1.589  2.066 0 1  0.264 #> Item.4 0.613  2.223 0 1  1.518 #> Item.5 0.748  1.948 0 1  0.079 #>  #> $means #> Theta  #>     0  #>  #> $cov #>       Theta #> Theta     1 #>  coef(mod2PL_asym, simplify=TRUE, IRTpars=TRUE) #> $items #>            a      b g u     S #> Item.1 0.926 -3.113 0 1 2.618 #> Item.2 2.141  0.722 0 1 0.234 #> Item.3 1.589 -1.301 0 1 1.301 #> Item.4 0.613 -3.627 0 1 4.563 #> Item.5 0.748 -2.605 0 1 1.082 #>  #> $means #> Theta  #>     0  #>  #> $cov #>       Theta #> Theta     1 #>   # no big difference statistically or visually anova(mod2PL, mod2PL_asym) #>                  AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod2PL      5337.610 5354.927 5356.263 5386.688 -2658.805                #> mod2PL_asym 5345.822 5371.797 5373.801 5419.438 -2657.911 1.788  5 0.878 plot(mod2PL, type = 'trace')  plot(mod2PL_asym, type = 'trace')    ################### # LLTM example  a <- matrix(rep(1,30)) d <- rep(c(1,0, -1),each = 10)  # first easy, then medium, last difficult dat <- simdata(a, d, 1000, itemtype = '2PL')  # unconditional model for intercept comparisons mod <- mirt(dat, itemtype = 'Rasch') #>  coef(mod, simplify=TRUE) #> $items #>         a1      d g u #> Item_1   1  1.048 0 1 #> Item_2   1  0.969 0 1 #> Item_3   1  1.008 0 1 #> Item_4   1  0.974 0 1 #> Item_5   1  1.019 0 1 #> Item_6   1  1.008 0 1 #> Item_7   1  1.071 0 1 #> Item_8   1  0.946 0 1 #> Item_9   1  0.969 0 1 #> Item_10  1  0.946 0 1 #> Item_11  1 -0.044 0 1 #> Item_12  1 -0.102 0 1 #> Item_13  1 -0.010 0 1 #> Item_14  1  0.009 0 1 #> Item_15  1  0.024 0 1 #> Item_16  1 -0.092 0 1 #> Item_17  1  0.092 0 1 #> Item_18  1  0.014 0 1 #> Item_19  1 -0.068 0 1 #> Item_20  1 -0.024 0 1 #> Item_21  1 -1.111 0 1 #> Item_22  1 -1.065 0 1 #> Item_23  1 -1.117 0 1 #> Item_24  1 -1.129 0 1 #> Item_25  1 -1.060 0 1 #> Item_26  1 -1.088 0 1 #> Item_27  1 -1.026 0 1 #> Item_28  1 -1.026 0 1 #> Item_29  1 -1.026 0 1 #> Item_30  1 -1.054 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # Suppose that the first 10 items were suspected to be easy, followed by 10 medium difficulty items, # then finally the last 10 items are difficult, # and we wish to test this item structure hypothesis (more intercept designs are possible # by including more columns). itemdesign <- data.frame(difficulty =    factor(c(rep('easy', 10), rep('medium', 10), rep('hard', 10)))) rownames(itemdesign) <- colnames(dat) itemdesign #>         difficulty #> Item_1        easy #> Item_2        easy #> Item_3        easy #> Item_4        easy #> Item_5        easy #> Item_6        easy #> Item_7        easy #> Item_8        easy #> Item_9        easy #> Item_10       easy #> Item_11     medium #> Item_12     medium #> Item_13     medium #> Item_14     medium #> Item_15     medium #> Item_16     medium #> Item_17     medium #> Item_18     medium #> Item_19     medium #> Item_20     medium #> Item_21       hard #> Item_22       hard #> Item_23       hard #> Item_24       hard #> Item_25       hard #> Item_26       hard #> Item_27       hard #> Item_28       hard #> Item_29       hard #> Item_30       hard  # LLTM with mirt() lltm <- mirt(dat, itemtype = 'Rasch', SE=TRUE,    item.formula = ~ 0 + difficulty, itemdesign=itemdesign) #>  #>  #> Calculating information matrix... coef(lltm, simplify=TRUE) #> $items #>         difficultyeasy difficultyhard difficultymedium a1 d g u #> Item_1           0.995           0.00             0.00  1 0 0 1 #> Item_2           0.995           0.00             0.00  1 0 0 1 #> Item_3           0.995           0.00             0.00  1 0 0 1 #> Item_4           0.995           0.00             0.00  1 0 0 1 #> Item_5           0.995           0.00             0.00  1 0 0 1 #> Item_6           0.995           0.00             0.00  1 0 0 1 #> Item_7           0.995           0.00             0.00  1 0 0 1 #> Item_8           0.995           0.00             0.00  1 0 0 1 #> Item_9           0.995           0.00             0.00  1 0 0 1 #> Item_10          0.995           0.00             0.00  1 0 0 1 #> Item_11          0.000           0.00            -0.02  1 0 0 1 #> Item_12          0.000           0.00            -0.02  1 0 0 1 #> Item_13          0.000           0.00            -0.02  1 0 0 1 #> Item_14          0.000           0.00            -0.02  1 0 0 1 #> Item_15          0.000           0.00            -0.02  1 0 0 1 #> Item_16          0.000           0.00            -0.02  1 0 0 1 #> Item_17          0.000           0.00            -0.02  1 0 0 1 #> Item_18          0.000           0.00            -0.02  1 0 0 1 #> Item_19          0.000           0.00            -0.02  1 0 0 1 #> Item_20          0.000           0.00            -0.02  1 0 0 1 #> Item_21          0.000          -1.07             0.00  1 0 0 1 #> Item_22          0.000          -1.07             0.00  1 0 0 1 #> Item_23          0.000          -1.07             0.00  1 0 0 1 #> Item_24          0.000          -1.07             0.00  1 0 0 1 #> Item_25          0.000          -1.07             0.00  1 0 0 1 #> Item_26          0.000          -1.07             0.00  1 0 0 1 #> Item_27          0.000          -1.07             0.00  1 0 0 1 #> Item_28          0.000          -1.07             0.00  1 0 0 1 #> Item_29          0.000          -1.07             0.00  1 0 0 1 #> Item_30          0.000          -1.07             0.00  1 0 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 0.999 #>  coef(lltm, printSE=TRUE) #> $Item_1 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_2 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_3 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_4 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_5 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_6 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_7 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_8 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_9 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_10 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_11 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_12 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_13 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_14 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_15 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_16 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_17 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_18 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_19 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_20 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_21 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_22 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_23 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_24 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_25 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_26 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_27 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_28 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_29 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $Item_30 #>     difficultyeasy difficultyhard difficultymedium a1  d logit(g) logit(u) #> par          0.995          -1.07           -0.020  1  0     -999      999 #> SE           0.040           0.04            0.039 NA NA       NA       NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  0.999 #> SE      NA  0.057 #>  anova(lltm, mod)  # models fit effectively the same; hence, intercept variability well captured #>           AIC    SABIC       HQ      BIC    logLik     X2 df     p #> lltm 35018.84 35025.76 35026.30 35038.47 -17505.42                 #> mod  35061.09 35114.78 35118.92 35213.23 -17499.55 11.744 27 0.995  # additional information for LLTM plot(lltm)  plot(lltm, type = 'trace')  itemplot(lltm, item=1)  itemfit(lltm) #>       item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1 21.535      20      0.009  0.366 #> 2   Item_2 25.974      20      0.017  0.167 #> 3   Item_3 32.164      20      0.025  0.042 #> 4   Item_4 27.432      20      0.019  0.124 #> 5   Item_5 21.695      20      0.009  0.357 #> 6   Item_6 17.244      20      0.000  0.637 #> 7   Item_7 25.605      20      0.017  0.179 #> 8   Item_8 25.354      20      0.016  0.188 #> 9   Item_9 23.310      20      0.013  0.274 #> 10 Item_10 14.190      20      0.000  0.821 #> 11 Item_11 25.249      20      0.016  0.192 #> 12 Item_12 15.303      20      0.000  0.759 #> 13 Item_13 21.484      20      0.009  0.369 #> 14 Item_14 15.529      20      0.000  0.745 #> 15 Item_15 29.388      20      0.022  0.080 #> 16 Item_16 33.081      20      0.026  0.033 #> 17 Item_17 20.473      20      0.005  0.429 #> 18 Item_18 28.304      20      0.020  0.102 #> 19 Item_19 16.119      20      0.000  0.709 #> 20 Item_20 25.418      20      0.016  0.186 #> 21 Item_21 25.079      20      0.016  0.198 #> 22 Item_22 16.297      20      0.000  0.698 #> 23 Item_23 15.865      20      0.000  0.725 #> 24 Item_24 29.800      20      0.022  0.073 #> 25 Item_25 31.219      20      0.024  0.052 #> 26 Item_26 21.776      20      0.009  0.353 #> 27 Item_27 36.764      20      0.029  0.012 #> 28 Item_28 30.916      20      0.023  0.056 #> 29 Item_29 21.151      20      0.008  0.388 #> 30 Item_30 16.045      20      0.000  0.714 head(fscores(lltm))  #EAP estimates #>          F1 #> [1,] -1.312 #> [2,]  1.196 #> [3,]  1.364 #> [4,] -0.112 #> [5,]  0.586 #> [6,] -1.492 fscores(lltm, method='EAPsum', full.scores=FALSE) #>       df    X2  p.X2 SEM.alpha rxx.alpha rxx_F1 #> stats 29 29.11 0.459     2.373     0.848  0.845 #>  #>    Sum.Scores     F1 SE_F1 observed expected std.res #> 0           0 -2.677 0.564        4    1.165   2.626 #> 1           1 -2.382 0.525        5    3.754   0.643 #> 2           2 -2.123 0.493        9    7.558   0.524 #> 3           3 -1.893 0.468       11   12.252   0.358 #> 4           4 -1.684 0.447       17   17.523   0.125 #> 5           5 -1.492 0.431       23   23.096   0.020 #> 6           6 -1.312 0.417       30   28.741   0.235 #> 7           7 -1.143 0.406       30   34.262   0.728 #> 8           8 -0.982 0.397       34   39.489   0.873 #> 9           9 -0.828 0.390       42   44.276   0.342 #> 10         10 -0.679 0.384       40   48.497   1.220 #> 11         11 -0.533 0.379       56   52.048   0.548 #> 12         12 -0.391 0.376       57   54.843   0.291 #> 13         13 -0.251 0.373       47   56.815   1.302 #> 14         14 -0.112 0.372       66   57.920   1.062 #> 15         15  0.026 0.371       70   58.134   1.556 #> 16         16  0.165 0.372       60   57.455   0.336 #> 17         17  0.303 0.373       52   55.901   0.522 #> 18         18  0.444 0.376       51   53.513   0.344 #> 19         19  0.586 0.379       58   50.353   1.078 #> 20         20  0.731 0.384       44   46.502   0.367 #> 21         21  0.880 0.389       38   42.060   0.626 #> 22         22  1.035 0.397       38   37.146   0.140 #> 23         23  1.196 0.406       33   31.894   0.196 #> 24         24  1.364 0.416       39   26.457   2.438 #> 25         25  1.543 0.430       15   21.006   1.310 #> 26         26  1.735 0.446       15   15.729   0.184 #> 27         27  1.943 0.466        8   10.841   0.863 #> 28         28  2.172 0.491        3    6.581   1.396 #> 29         29  2.429 0.523        3    3.211   0.118 #> 30         30  2.722 0.561        2    0.976   1.036 M2(lltm) # goodness of fit #>             M2  df         p       RMSEA RMSEA_5   RMSEA_95      SRMSR #> stats 464.9869 461 0.4392511 0.002942297       0 0.01127896 0.03151651 #>             TLI       CFI #> stats 0.9996428 0.9996215 head(personfit(lltm)) #>      outfit     z.outfit     infit    z.infit         Zh #> 1 0.6826005 -0.905033821 0.8382160 -0.7019253  0.7988198 #> 2 1.3508799  1.125406415 1.0585040  0.3526859 -0.5762150 #> 3 0.6846659 -0.908427126 0.8372797 -0.7083944  0.8024032 #> 4 1.1529149  0.943961566 1.1255263  0.8694090 -0.8810454 #> 5 0.9849684 -0.008208092 1.0322031  0.2544840 -0.1077164 #> 6 0.8025989 -0.405144253 0.9365478 -0.1805723  0.3174856 residuals(lltm) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.098  -0.036  -0.014  -0.002   0.034   0.101  #>  #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1         -0.040  0.054 -0.031  0.042  0.050  0.041 -0.052  0.050   0.035 #> Item_2   1.562         0.025 -0.031  0.046  0.018 -0.034 -0.018  0.071  -0.023 #> Item_3   2.970  0.633         0.018  0.019  0.066  0.034  0.032  0.083   0.047 #> Item_4   0.968  0.938  0.317        -0.031 -0.037 -0.037 -0.032  0.010   0.026 #> Item_5   1.742  2.156  0.343  0.971         0.039  0.033  0.064 -0.037   0.024 #> Item_6   2.533  0.309  4.416  1.386  1.515         0.039  0.023  0.042   0.039 #> Item_7   1.714  1.150  1.164  1.380  1.057  1.525        -0.062  0.101   0.038 #> Item_8   2.661  0.333  1.005  1.006  4.125  0.510  3.832        -0.018   0.024 #> Item_9   2.467  5.089  6.853  0.109  1.400  1.787 10.221  0.333          0.045 #> Item_10  1.241  0.535  2.256  0.695  0.586  1.546  1.472  0.560  2.006         #> Item_11  1.155  0.178  4.727  0.184  0.325  0.665  1.139  0.838  0.114   2.269 #> Item_12  1.751  1.904  1.508  9.535  1.294  1.697  2.385  1.161  2.516   1.192 #> Item_13  0.703  1.178  0.855  0.443  0.376  4.705  2.338  3.713  0.166   0.870 #> Item_14  0.846  3.470  0.273  5.363  0.417  1.050  1.037  1.605  0.946   0.688 #> Item_15  1.569  0.774  0.428  0.704  3.088  2.541  4.876  0.867  0.997   5.312 #> Item_16  1.744  5.688  1.329  1.782  1.621  0.949  6.125  1.014  0.841   1.014 #> Item_17  3.128  5.188  2.379  2.868  4.564  3.744  3.649  5.424  2.726   4.622 #> Item_18  0.678  0.761  1.063  0.999  1.281  0.285  4.392  3.820  2.109   1.535 #> Item_19  1.605  2.861  4.167  3.518  0.595  0.556  1.626  2.295  1.248   0.531 #> Item_20  0.905  0.213  1.445  0.043  1.574  0.858  1.103  0.393  2.318   2.742 #> Item_21  0.924  0.699  1.859  1.544  0.860  0.375  1.768  1.808  2.544   0.574 #> Item_22  1.228  0.116  0.120  0.955  4.033  0.057  0.973  0.447  0.201   0.321 #> Item_23  3.849  1.388  1.011  4.546  0.581  0.393  1.463  0.530  0.437   0.530 #> Item_24  1.156  1.100  5.081  0.585  1.282  0.791  1.717  1.298  0.520   2.326 #> Item_25  1.838  0.239  0.590  0.071  0.131  0.111  0.969  1.010  1.385   1.308 #> Item_26  1.048  0.347  0.641  2.410  0.870  1.240  2.026  1.633  0.128   0.549 #> Item_27  1.273  1.022  0.441  2.950  0.714  1.017  1.944  0.720  1.244   0.776 #> Item_28  1.887  0.450  0.444  0.447  1.962  1.328  1.670  1.547  0.599   0.720 #> Item_29  0.860  2.385  0.776  0.986  1.962  0.578  1.125  1.271  0.444   1.547 #> Item_30  1.401  0.147  2.230  1.777  2.086  0.116  2.553  3.918  0.143   0.533 #>         Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> Item_1    0.034  -0.042   0.027  -0.029   0.040  -0.042   0.056  -0.026   0.040 #> Item_2   -0.013   0.044   0.034  -0.059   0.028  -0.075   0.072  -0.028  -0.053 #> Item_3    0.069  -0.039   0.029  -0.017   0.021  -0.036   0.049  -0.033   0.065 #> Item_4   -0.014  -0.098  -0.021   0.073  -0.027  -0.042  -0.054  -0.032  -0.059 #> Item_5    0.018  -0.036   0.019   0.020   0.056  -0.040   0.068   0.036  -0.024 #> Item_6    0.026  -0.041   0.069   0.032   0.050  -0.031   0.061  -0.017   0.024 #> Item_7   -0.034  -0.049  -0.048   0.032   0.070  -0.078  -0.060  -0.066  -0.040 #> Item_8   -0.029  -0.034   0.061   0.040  -0.029  -0.032   0.074  -0.062   0.048 #> Item_9    0.011   0.050   0.013  -0.031  -0.032  -0.029   0.052  -0.046   0.035 #> Item_10   0.048   0.035   0.029   0.026   0.073  -0.032   0.068  -0.039  -0.023 #> Item_11           0.032  -0.016  -0.033   0.028  -0.033   0.062  -0.020   0.020 #> Item_12   1.013          -0.034   0.038   0.049   0.043   0.069  -0.073   0.056 #> Item_13   0.253   1.159          -0.033  -0.031  -0.030   0.059  -0.047  -0.021 #> Item_14   1.083   1.428   1.105           0.041   0.035   0.055  -0.031  -0.031 #> Item_15   0.765   2.416   0.979   1.645          -0.080   0.064  -0.052  -0.047 #> Item_16   1.093   1.852   0.905   1.217   6.388          -0.063  -0.052   0.048 #> Item_17   3.855   4.725   3.460   3.018   4.054   3.984          -0.057   0.056 #> Item_18   0.383   5.391   2.210   0.960   2.688   2.672   3.271          -0.059 #> Item_19   0.407   3.179   0.434   0.937   2.167   2.297   3.116   3.424         #> Item_20   1.929   1.080   0.118   0.498   2.538   1.007   2.413   1.246   0.893 #> Item_21   0.305   2.462   0.318   1.347   1.387   1.451   3.309   1.086   0.775 #> Item_22   0.072   2.272   1.660   2.575   0.914   1.616   2.387   2.093   0.373 #> Item_23   0.517   2.043   1.670   0.626   2.537   1.290   3.466   3.294   3.736 #> Item_24   0.525   1.414   0.678   0.830   1.218   1.812   5.563   1.432   4.906 #> Item_25   0.128   1.106   0.195   0.242   0.531   9.689   7.843   0.348   3.425 #> Item_26   0.183   1.260   3.420   0.457   0.877   1.275   4.454   0.560   2.529 #> Item_27   0.623   1.990   1.343   2.169   0.648   7.342   2.953   0.627   2.145 #> Item_28   2.416   1.596   4.941   0.451   1.613   1.489   5.884   0.546   1.194 #> Item_29   1.393   1.990   0.641   0.658   0.651   2.349   2.520   0.748   0.755 #> Item_30   0.582   2.104   0.104   5.650   0.897   4.033   7.618   0.323   0.569 #>         Item_20 Item_21 Item_22 Item_23 Item_24 Item_25 Item_26 Item_27 Item_28 #> Item_1   -0.030   0.030  -0.035  -0.062   0.034   0.043  -0.032  -0.036  -0.043 #> Item_2   -0.015  -0.026  -0.011  -0.037  -0.033   0.015  -0.019   0.032   0.021 #> Item_3    0.038   0.043  -0.011  -0.032   0.071  -0.024   0.025  -0.021   0.021 #> Item_4   -0.007   0.039   0.031  -0.067  -0.024  -0.008  -0.049  -0.054   0.021 #> Item_5    0.040   0.029   0.064   0.024  -0.036   0.011   0.029  -0.027   0.044 #> Item_6    0.029   0.019  -0.008   0.020   0.028  -0.011   0.035  -0.032   0.036 #> Item_7    0.033  -0.042  -0.031  -0.038  -0.041   0.031   0.045  -0.044  -0.041 #> Item_8    0.020   0.043  -0.021  -0.023  -0.036  -0.032   0.040   0.027   0.039 #> Item_9   -0.048   0.050  -0.014   0.021  -0.023  -0.037  -0.011  -0.035  -0.024 #> Item_10   0.052   0.024  -0.018  -0.023  -0.048  -0.036   0.023   0.028   0.027 #> Item_11   0.044   0.017  -0.008   0.023   0.023   0.011   0.014  -0.025   0.049 #> Item_12   0.033  -0.050  -0.048  -0.045  -0.038   0.033   0.036  -0.045  -0.040 #> Item_13   0.011   0.018   0.041  -0.041   0.026  -0.014  -0.058  -0.037  -0.070 #> Item_14   0.022   0.037   0.051   0.025   0.029   0.016  -0.021  -0.047  -0.021 #> Item_15  -0.050   0.037   0.030   0.050  -0.035   0.023   0.030   0.025   0.040 #> Item_16   0.032   0.038  -0.040  -0.036  -0.043  -0.098   0.036  -0.086  -0.039 #> Item_17   0.049   0.058  -0.049  -0.059  -0.075   0.089  -0.067   0.054   0.077 #> Item_18   0.035  -0.033  -0.046  -0.057  -0.038   0.019  -0.024  -0.025  -0.023 #> Item_19  -0.030   0.028   0.019  -0.061  -0.070  -0.059  -0.050   0.046  -0.035 #> Item_20           0.049  -0.042  -0.033  -0.042   0.005   0.008  -0.023   0.022 #> Item_21   2.412           0.038  -0.027  -0.053   0.037  -0.042  -0.035   0.045 #> Item_22   1.736   1.428          -0.018   0.023   0.005  -0.066  -0.025  -0.020 #> Item_23   1.069   0.746   0.335          -0.037  -0.049  -0.020  -0.035   0.051 #> Item_24   1.778   2.758   0.516   1.351          -0.040  -0.027  -0.052  -0.056 #> Item_25   0.021   1.346   0.024   2.416   1.616          -0.022  -0.019   0.022 #> Item_26   0.067   1.760   4.396   0.404   0.721   0.502          -0.021  -0.040 #> Item_27   0.533   1.222   0.647   1.234   2.743   0.352   0.452           0.029 #> Item_28   0.477   2.010   0.394   2.602   3.163   0.484   1.637   0.840         #> Item_29   0.876   1.686   0.647   0.748   0.963   0.712   2.822   0.663   0.701 #> Item_30   1.150   0.443   1.886   3.572   2.497   3.486   0.833   0.478   0.386 #>         Item_29 Item_30 #> Item_1    0.029  -0.037 #> Item_2   -0.049  -0.012 #> Item_3    0.028   0.047 #> Item_4   -0.031  -0.042 #> Item_5    0.044   0.046 #> Item_6   -0.024  -0.011 #> Item_7    0.034  -0.051 #> Item_8   -0.036   0.063 #> Item_9   -0.021   0.012 #> Item_10   0.039   0.023 #> Item_11   0.037   0.024 #> Item_12  -0.045  -0.046 #> Item_13   0.025  -0.010 #> Item_14  -0.026  -0.075 #> Item_15  -0.026   0.030 #> Item_16  -0.048  -0.064 #> Item_17  -0.050  -0.087 #> Item_18  -0.027   0.018 #> Item_19  -0.027  -0.024 #> Item_20  -0.030  -0.034 #> Item_21   0.041  -0.021 #> Item_22  -0.025  -0.043 #> Item_23  -0.027  -0.060 #> Item_24  -0.031  -0.050 #> Item_25  -0.027  -0.059 #> Item_26  -0.053  -0.029 #> Item_27  -0.026  -0.022 #> Item_28   0.026  -0.020 #> Item_29           0.065 #> Item_30   4.272          # intercept across items also possible by removing ~ 0 portion, just interpreted differently lltm.int <- mirt(dat, itemtype = 'Rasch',    item.formula = ~ difficulty, itemdesign=itemdesign) #>  anova(lltm, lltm.int) # same #>               AIC    SABIC      HQ      BIC    logLik X2 df   p #> lltm     35018.84 35025.76 35026.3 35038.47 -17505.42           #> lltm.int 35018.84 35025.76 35026.3 35038.47 -17505.42  0  0 NaN coef(lltm.int, simplify=TRUE) #> $items #>         (Intercept) difficultyhard difficultymedium a1 d g u #> Item_1        0.995          0.000            0.000  1 0 0 1 #> Item_2        0.995          0.000            0.000  1 0 0 1 #> Item_3        0.995          0.000            0.000  1 0 0 1 #> Item_4        0.995          0.000            0.000  1 0 0 1 #> Item_5        0.995          0.000            0.000  1 0 0 1 #> Item_6        0.995          0.000            0.000  1 0 0 1 #> Item_7        0.995          0.000            0.000  1 0 0 1 #> Item_8        0.995          0.000            0.000  1 0 0 1 #> Item_9        0.995          0.000            0.000  1 0 0 1 #> Item_10       0.995          0.000            0.000  1 0 0 1 #> Item_11       0.995          0.000           -1.016  1 0 0 1 #> Item_12       0.995          0.000           -1.016  1 0 0 1 #> Item_13       0.995          0.000           -1.016  1 0 0 1 #> Item_14       0.995          0.000           -1.016  1 0 0 1 #> Item_15       0.995          0.000           -1.016  1 0 0 1 #> Item_16       0.995          0.000           -1.016  1 0 0 1 #> Item_17       0.995          0.000           -1.016  1 0 0 1 #> Item_18       0.995          0.000           -1.016  1 0 0 1 #> Item_19       0.995          0.000           -1.016  1 0 0 1 #> Item_20       0.995          0.000           -1.016  1 0 0 1 #> Item_21       0.995         -2.065            0.000  1 0 0 1 #> Item_22       0.995         -2.065            0.000  1 0 0 1 #> Item_23       0.995         -2.065            0.000  1 0 0 1 #> Item_24       0.995         -2.065            0.000  1 0 0 1 #> Item_25       0.995         -2.065            0.000  1 0 0 1 #> Item_26       0.995         -2.065            0.000  1 0 0 1 #> Item_27       0.995         -2.065            0.000  1 0 0 1 #> Item_28       0.995         -2.065            0.000  1 0 0 1 #> Item_29       0.995         -2.065            0.000  1 0 0 1 #> Item_30       0.995         -2.065            0.000  1 0 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 0.999 #>   # using unconditional modeling for first four items itemdesign.sub <- itemdesign[5:nrow(itemdesign), , drop=FALSE] itemdesign.sub    # note that rownames are required in this case #>         difficulty #> Item_5        easy #> Item_6        easy #> Item_7        easy #> Item_8        easy #> Item_9        easy #> Item_10       easy #> Item_11     medium #> Item_12     medium #> Item_13     medium #> Item_14     medium #> Item_15     medium #> Item_16     medium #> Item_17     medium #> Item_18     medium #> Item_19     medium #> Item_20     medium #> Item_21       hard #> Item_22       hard #> Item_23       hard #> Item_24       hard #> Item_25       hard #> Item_26       hard #> Item_27       hard #> Item_28       hard #> Item_29       hard #> Item_30       hard lltm.4 <- mirt(dat, itemtype = 'Rasch',    item.formula = ~ 0 + difficulty, itemdesign=itemdesign.sub) #>  coef(lltm.4, simplify=TRUE) # first four items are the standard Rasch #> $items #>         difficultyeasy difficultyhard difficultymedium a1     d g u #> Item_1           0.000           0.00             0.00  1 1.048 0 1 #> Item_2           0.000           0.00             0.00  1 0.968 0 1 #> Item_3           0.000           0.00             0.00  1 1.008 0 1 #> Item_4           0.000           0.00             0.00  1 0.974 0 1 #> Item_5           0.993           0.00             0.00  1 0.000 0 1 #> Item_6           0.993           0.00             0.00  1 0.000 0 1 #> Item_7           0.993           0.00             0.00  1 0.000 0 1 #> Item_8           0.993           0.00             0.00  1 0.000 0 1 #> Item_9           0.993           0.00             0.00  1 0.000 0 1 #> Item_10          0.993           0.00             0.00  1 0.000 0 1 #> Item_11          0.000           0.00            -0.02  1 0.000 0 1 #> Item_12          0.000           0.00            -0.02  1 0.000 0 1 #> Item_13          0.000           0.00            -0.02  1 0.000 0 1 #> Item_14          0.000           0.00            -0.02  1 0.000 0 1 #> Item_15          0.000           0.00            -0.02  1 0.000 0 1 #> Item_16          0.000           0.00            -0.02  1 0.000 0 1 #> Item_17          0.000           0.00            -0.02  1 0.000 0 1 #> Item_18          0.000           0.00            -0.02  1 0.000 0 1 #> Item_19          0.000           0.00            -0.02  1 0.000 0 1 #> Item_20          0.000           0.00            -0.02  1 0.000 0 1 #> Item_21          0.000          -1.07             0.00  1 0.000 0 1 #> Item_22          0.000          -1.07             0.00  1 0.000 0 1 #> Item_23          0.000          -1.07             0.00  1 0.000 0 1 #> Item_24          0.000          -1.07             0.00  1 0.000 0 1 #> Item_25          0.000          -1.07             0.00  1 0.000 0 1 #> Item_26          0.000          -1.07             0.00  1 0.000 0 1 #> Item_27          0.000          -1.07             0.00  1 0.000 0 1 #> Item_28          0.000          -1.07             0.00  1 0.000 0 1 #> Item_29          0.000          -1.07             0.00  1 0.000 0 1 #> Item_30          0.000          -1.07             0.00  1 0.000 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 0.999 #>  anova(lltm, lltm.4) # similar fit, hence more constrained model preferred #>             AIC    SABIC       HQ      BIC    logLik    X2 df     p #> lltm   35018.84 35025.76 35026.30 35038.47 -17505.42                #> lltm.4 35026.11 35039.97 35041.04 35065.37 -17505.06 0.725  4 0.948  # LLTM with mixedmirt() (more flexible in general, but slower) LLTM <- mixedmirt(dat, model=1, fixed = ~ 0 + difficulty,                   itemdesign=itemdesign, SE=FALSE) #> , Max-Change = 0.1914, Max-Change = 0.1569, Max-Change = 0.1266, Max-Change = 0.1071, Max-Change = 0.0861, Max-Change = 0.0669, Max-Change = 0.0568, Max-Change = 0.0495, Max-Change = 0.0407, Max-Change = 0.0320, Max-Change = 0.0250, Max-Change = 0.0205, Max-Change = 0.0196, Max-Change = 0.0145, Max-Change = 0.0130, Max-Change = 0.0117, Max-Change = 0.0085, Max-Change = 0.0087, Max-Change = 0.0104, Max-Change = 0.0081, Max-Change = 0.0046, Max-Change = 0.0039, Max-Change = 0.0037, Max-Change = 0.0060, Max-Change = 0.0094, Max-Change = 0.0030, Max-Change = 0.0052, Max-Change = 0.0036, Max-Change = 0.0115, Max-Change = 0.0059, Max-Change = 0.0056, Max-Change = 0.0057, Max-Change = 0.0030, Max-Change = 0.0074, Max-Change = 0.0031, Max-Change = 0.0031, Max-Change = 0.0073, Max-Change = 0.0020, Max-Change = 0.0043, Max-Change = 0.0007, Max-Change = 0.0048, Max-Change = 0.0042, Max-Change = 0.0031, Max-Change = 0.0079, Max-Change = 0.0058, Max-Change = 0.0023, Max-Change = 0.0055, Max-Change = 0.0089, Max-Change = 0.0075, Max-Change = 0.0021, Max-Change = 0.0026, Max-Change = 0.0021, Max-Change = 0.0040, Max-Change = 0.0065, Max-Change = 0.0040, Max-Change = 0.0036, Max-Change = 0.0036, Max-Change = 0.0067, Max-Change = 0.0059, Max-Change = 0.0030, Max-Change = 0.0026, Max-Change = 0.0033, Max-Change = 0.0086, Max-Change = 0.0032, Max-Change = 0.0048, Max-Change = 0.0042, Max-Change = 0.0013, Max-Change = 0.0058, Max-Change = 0.0018, Max-Change = 0.0038, Max-Change = 0.0065, Max-Change = 0.0093, Max-Change = 0.0041, Max-Change = 0.0041, Max-Change = 0.0042, Max-Change = 0.0026, Max-Change = 0.0094, Max-Change = 0.0054, Max-Change = 0.0061, Max-Change = 0.0039, Max-Change = 0.0032, Max-Change = 0.0027, Max-Change = 0.0074, Max-Change = 0.0019, Max-Change = 0.0063, Max-Change = 0.0101, Max-Change = 0.0059, Max-Change = 0.0051, Max-Change = 0.0041, Max-Change = 0.0059, Max-Change = 0.0042, Max-Change = 0.0078, Max-Change = 0.0005, Max-Change = 0.0094, Max-Change = 0.0024, Max-Change = 0.0081, Max-Change = 0.0053, Max-Change = 0.0047, Max-Change = 0.0067, Max-Change = 0.0037, Max-Change = 0.0113, Max-Change = 0.0026, Max-Change = 0.0039, Max-Change = 0.0011, Max-Change = 0.0041, Max-Change = 0.0032, Max-Change = 0.0057, Max-Change = 0.0047, Max-Change = 0.0046, Max-Change = 0.0182, Max-Change = 0.0064, Max-Change = 0.0074, Max-Change = 0.0036, Max-Change = 0.0050, Max-Change = 0.0057, Max-Change = 0.0008, Max-Change = 0.0077, Max-Change = 0.0039, Max-Change = 0.0052, Max-Change = 0.0030, Max-Change = 0.0033, Max-Change = 0.0074, Max-Change = 0.0022, Max-Change = 0.0041, Max-Change = 0.0072, Max-Change = 0.0127, Max-Change = 0.0144, Max-Change = 0.0035, Max-Change = 0.0016, Max-Change = 0.0058, Max-Change = 0.0044, Max-Change = 0.0040, Max-Change = 0.0022, Max-Change = 0.0023, Max-Change = 0.0086, Max-Change = 0.0033, Max-Change = 0.0036, Max-Change = 0.0024, Max-Change = 0.0055, Max-Change = 0.0036, Max-Change = 0.0021, Max-Change = 0.0072, Max-Change = 0.0056, Max-Change = 0.0018, Max-Change = 0.0093, Max-Change = 0.0031, Max-Change = 0.0046, Max-Change = 0.0055, Max-Change = 0.0057, Max-Change = 0.0032, Max-Change = 0.0020, Max-Change = 0.0040, Max-Change = 0.0010, Max-Change = 0.0054, Max-Change = 0.0042, Max-Change = 0.0036, Max-Change = 0.0031, Max-Change = 0.0095, Max-Change = 0.0018, Max-Change = 0.0029, Max-Change = 0.0075, Max-Change = 0.0057, Max-Change = 0.0115, Max-Change = 0.0006, Max-Change = 0.0061, Max-Change = 0.0063, Max-Change = 0.0022, Max-Change = 0.0045, Max-Change = 0.0049, Max-Change = 0.0128, Max-Change = 0.0019, Max-Change = 0.0054, Max-Change = 0.0074, Max-Change = 0.0033, Max-Change = 0.0042, Max-Change = 0.0053, Max-Change = 0.0060, Max-Change = 0.0037, Max-Change = 0.0011, Max-Change = 0.0122, Max-Change = 0.0018, Max-Change = 0.0005, Max-Change = 0.0006, Max-Change = 0.0034, Max-Change = 0.0017, Max-Change = 0.0035, Max-Change = 0.0014, Max-Change = 0.0026, Max-Change = 0.0012, Max-Change = 0.0057, Max-Change = 0.0024, Max-Change = 0.0001, Max-Change = 0.0079, Max-Change = 0.0047, Max-Change = 0.0045, Max-Change = 0.0062, Max-Change = 0.0017, Max-Change = 0.0015, Max-Change = 0.0066, Max-Change = 0.0038, Max-Change = 0.0048, Max-Change = 0.0063, Max-Change = 0.0036, Max-Change = 0.0043, Max-Change = 0.0029, Max-Change = 0.0021, Max-Change = 0.0058, Max-Change = 0.0039, Max-Change = 0.0047, Max-Change = 0.0034, Max-Change = 0.0039, Max-Change = 0.0088, Max-Change = 0.0068, Max-Change = 0.0023, Max-Change = 0.0056, Max-Change = 0.0072, Max-Change = 0.0059, Max-Change = 0.0047, Max-Change = 0.0010, Max-Change = 0.0039, Max-Change = 0.0135, Max-Change = 0.0028, Max-Change = 0.0025, Max-Change = 0.0083, Max-Change = 0.0072, Max-Change = 0.0042, Max-Change = 0.0038, Max-Change = 0.0020, Max-Change = 0.0107, Max-Change = 0.0024, Max-Change = 0.0042, Max-Change = 0.0095, Max-Change = 0.0050, Max-Change = 0.0090, Max-Change = 0.0020, Max-Change = 0.0010, Max-Change = 0.0078, Max-Change = 0.0013, Max-Change = 0.0101, Max-Change = 0.0059, Max-Change = 0.0059, Max-Change = 0.0043, Max-Change = 0.0066, Max-Change = 0.0028, Max-Change = 0.0019, Max-Change = 0.0038, Max-Change = 0.0011, Max-Change = 0.0043, Max-Change = 0.0120, Max-Change = 0.0047, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0035, gam = 0.1057, Max-Change = 0.0027, gam = 0.0780, Max-Change = 0.0004, gam = 0.0629, Max-Change = 0.0007, gam = 0.0532, Max-Change = 0.0026, gam = 0.0464, Max-Change = 0.0027, gam = 0.0413, Max-Change = 0.0011, gam = 0.0374, Max-Change = 0.0003, gam = 0.0342, Max-Change = 0.0003, gam = 0.0316, Max-Change = 0.0008 #>  #> Calculating log-likelihood... summary(LLTM) #>  #> Call: #> mixedmirt(data = dat, model = 1, fixed = ~0 + difficulty, itemdesign = itemdesign,  #>     SE = FALSE) #>  #> -------------- #> FIXED EFFECTS: #>                  Estimate Std.Error z.value #> difficultyeasy      0.996        NA      NA #> difficultyhard     -1.067        NA      NA #> difficultymedium   -0.018        NA      NA #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1 #> F1 0.99 #>  coef(LLTM) #> $Item_1 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_2 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_3 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_4 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_5 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_6 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_7 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_8 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_9 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_10 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_11 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_12 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_13 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_14 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_15 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_16 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_17 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_18 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_19 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_20 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_21 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_22 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_23 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_24 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_25 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_26 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_27 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_28 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_29 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $Item_30 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          0.996         -1.067           -0.018  1 0 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0   0.99 #>   # LLTM with random error estimate (not supported with mirt() ) LLTM.e <- mixedmirt(dat, model=1, fixed = ~ 0 + difficulty,                   random = ~ 1|items, itemdesign=itemdesign, SE=FALSE) #> , Max-Change = 0.1914, Max-Change = 0.1569, Max-Change = 0.1266, Max-Change = 0.1071, Max-Change = 0.0861, Max-Change = 0.0669, Max-Change = 0.0568, Max-Change = 0.0495, Max-Change = 0.0407, Max-Change = 0.0320, Max-Change = 0.0250, Max-Change = 0.0205, Max-Change = 0.0196, Max-Change = 0.0145, Max-Change = 0.0130, Max-Change = 0.0117, Max-Change = 0.0085, Max-Change = 0.0087, Max-Change = 0.0104, Max-Change = 0.0081, Max-Change = 0.0046, Max-Change = 0.0039, Max-Change = 0.0037, Max-Change = 0.0060, Max-Change = 0.0094, Max-Change = 0.0030, Max-Change = 0.0052, Max-Change = 0.0036, Max-Change = 0.0115, Max-Change = 0.0059, Max-Change = 0.0056, Max-Change = 0.0057, Max-Change = 0.0030, Max-Change = 0.0074, Max-Change = 0.0031, Max-Change = 0.0031, Max-Change = 0.0073, Max-Change = 0.0020, Max-Change = 0.0043, Max-Change = 0.0007, Max-Change = 0.0048, Max-Change = 0.0042, Max-Change = 0.0031, Max-Change = 0.0079, Max-Change = 0.0058, Max-Change = 0.0023, Max-Change = 0.0055, Max-Change = 0.0089, Max-Change = 0.0075, Max-Change = 0.0021, Max-Change = 0.0026, Max-Change = 0.0021, Max-Change = 0.0040, Max-Change = 0.0065, Max-Change = 0.0040, Max-Change = 0.0036, Max-Change = 0.0036, Max-Change = 0.0067, Max-Change = 0.0059, Max-Change = 0.0030, Max-Change = 0.0026, Max-Change = 0.0033, Max-Change = 0.0086, Max-Change = 0.0032, Max-Change = 0.0048, Max-Change = 0.0042, Max-Change = 0.0013, Max-Change = 0.0058, Max-Change = 0.0018, Max-Change = 0.0038, Max-Change = 0.0065, Max-Change = 0.0093, Max-Change = 0.0041, Max-Change = 0.0041, Max-Change = 0.0042, Max-Change = 0.0026, Max-Change = 0.0094, Max-Change = 0.0054, Max-Change = 0.0061, Max-Change = 0.0039, Max-Change = 0.0032, Max-Change = 0.0027, Max-Change = 0.0074, Max-Change = 0.0019, Max-Change = 0.0063, Max-Change = 0.0101, Max-Change = 0.0059, Max-Change = 0.0051, Max-Change = 0.0041, Max-Change = 0.0059, Max-Change = 0.0042, Max-Change = 0.0078, Max-Change = 0.0005, Max-Change = 0.0094, Max-Change = 0.0024, Max-Change = 0.0081, Max-Change = 0.0053, Max-Change = 0.0047, Max-Change = 0.0067, Max-Change = 0.0348, Max-Change = 0.2000, Max-Change = 0.1634, Max-Change = 0.1313, Max-Change = 0.1028, Max-Change = 0.0821, Max-Change = 0.0661, Max-Change = 0.0531, Max-Change = 0.0423, Max-Change = 0.0335, Max-Change = 0.0266, Max-Change = 0.0217, Max-Change = 0.0186, Max-Change = 0.0153, Max-Change = 0.0124, Max-Change = 0.0118, Max-Change = 0.0279, Max-Change = 0.0048, Max-Change = 0.0212, Max-Change = 0.0046, Max-Change = 0.0061, Max-Change = 0.0068, Max-Change = 0.0006, Max-Change = 0.0059, Max-Change = 0.0079, Max-Change = 0.0030, Max-Change = 0.0051, Max-Change = 0.0108, Max-Change = 0.0068, Max-Change = 0.0031, Max-Change = 0.0065, Max-Change = 0.0119, Max-Change = 0.0052, Max-Change = 0.0028, Max-Change = 0.0025, Max-Change = 0.0033, Max-Change = 0.0038, Max-Change = 0.0043, Max-Change = 0.0072, Max-Change = 0.0031, Max-Change = 0.0061, Max-Change = 0.0029, Max-Change = 0.0020, Max-Change = 0.0048, Max-Change = 0.0085, Max-Change = 0.0044, Max-Change = 0.0097, Max-Change = 0.0022, Max-Change = 0.0056, Max-Change = 0.0065, Max-Change = 0.0060, Max-Change = 0.0041, Max-Change = 0.0035, Max-Change = 0.0055, Max-Change = 0.0049, Max-Change = 0.0086, Max-Change = 0.0060, Max-Change = 0.0052, Max-Change = 0.0028, Max-Change = 0.0016, Max-Change = 0.0109, Max-Change = 0.0047, Max-Change = 0.0031, Max-Change = 0.0078, Max-Change = 0.0038, Max-Change = 0.0085, Max-Change = 0.0038, Max-Change = 0.0033, Max-Change = 0.0050, Max-Change = 0.0035, Max-Change = 0.0057, Max-Change = 0.0053, Max-Change = 0.0018, Max-Change = 0.0039, Max-Change = 0.0032, Max-Change = 0.0044, Max-Change = 0.0065, Max-Change = 0.0070, Max-Change = 0.0037, Max-Change = 0.0024, Max-Change = 0.0034, Max-Change = 0.0035, Max-Change = 0.0048, Max-Change = 0.0047, Max-Change = 0.0033, Max-Change = 0.0051, Max-Change = 0.0076, Max-Change = 0.0066, Max-Change = 0.0031, Max-Change = 0.0089, Max-Change = 0.0065, Max-Change = 0.0038, Max-Change = 0.0055, Max-Change = 0.0038, Max-Change = 0.0064, Max-Change = 0.0053, Max-Change = 0.0039, Max-Change = 0.0053, Max-Change = 0.0041, Max-Change = 0.0072, Max-Change = 0.0054, Max-Change = 0.0073, Max-Change = 0.0046, Max-Change = 0.0050, Max-Change = 0.0093, Max-Change = 0.0021, Max-Change = 0.0066, Max-Change = 0.0044, Max-Change = 0.0007, Max-Change = 0.0016, Max-Change = 0.0070, Max-Change = 0.0099, Max-Change = 0.0023, Max-Change = 0.0035, Max-Change = 0.0035, Max-Change = 0.0071, Max-Change = 0.0042, Max-Change = 0.0034, Max-Change = 0.0055, Max-Change = 0.0013, Max-Change = 0.0029, Max-Change = 0.0072, Max-Change = 0.0103, Max-Change = 0.0095, Max-Change = 0.0046, Max-Change = 0.0037, Max-Change = 0.0087, Max-Change = 0.0032, Max-Change = 0.0048, Max-Change = 0.0146, Max-Change = 0.0046, Max-Change = 0.0029, Max-Change = 0.0027, Max-Change = 0.0055, Max-Change = 0.0042, Max-Change = 0.0048, Max-Change = 0.0070, Max-Change = 0.0121, Max-Change = 0.0041, Max-Change = 0.0040, Max-Change = 0.0095, Max-Change = 0.0041, Max-Change = 0.0048, Max-Change = 0.0059, Max-Change = 0.0009, Max-Change = 0.0048, Max-Change = 0.0079, Max-Change = 0.0067, Max-Change = 0.0095, Max-Change = 0.0010, Max-Change = 0.0008, Max-Change = 0.0081, Max-Change = 0.0021, Max-Change = 0.0057, Max-Change = 0.0071, Max-Change = 0.0064, Max-Change = 0.0045, Max-Change = 0.0042, Max-Change = 0.0103, Max-Change = 0.0025, Max-Change = 0.0056, Max-Change = 0.0076, Max-Change = 0.0070, Max-Change = 0.0018, Max-Change = 0.0012, Max-Change = 0.0092, Max-Change = 0.0036, Max-Change = 0.0102, Max-Change = 0.0037, Max-Change = 0.0017, Max-Change = 0.0028, Max-Change = 0.0019, Max-Change = 0.0039, Max-Change = 0.0028, Max-Change = 0.0109, Max-Change = 0.0064, Max-Change = 0.0105, Max-Change = 0.0006, Max-Change = 0.0071, Max-Change = 0.0062, Max-Change = 0.0035, Max-Change = 0.0047, Max-Change = 0.0040, Max-Change = 0.0014, Max-Change = 0.0026, Max-Change = 0.0018, Max-Change = 0.0009, Max-Change = 0.0052, Max-Change = 0.0020, Max-Change = 0.0026, Max-Change = 0.0027, Max-Change = 0.0054, Max-Change = 0.0034, Max-Change = 0.0031, Max-Change = 0.0077, Max-Change = 0.0045, Max-Change = 0.0125, Max-Change = 0.0016, Max-Change = 0.0055, Max-Change = 0.0085, Max-Change = 0.0168, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0091, gam = 0.1057, Max-Change = 0.0014, gam = 0.0780, Max-Change = 0.0028, gam = 0.0629, Max-Change = 0.0029, gam = 0.0532, Max-Change = 0.0018, gam = 0.0464, Max-Change = 0.0003, gam = 0.0413, Max-Change = 0.0011, gam = 0.0374, Max-Change = 0.0009, gam = 0.0342, Max-Change = 0.0009, gam = 0.0316, Max-Change = 0.0005 #>  #> Calculating log-likelihood... coef(LLTM.e) #> $Item_1 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_2 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_3 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_4 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_5 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_6 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_7 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_8 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_9 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_10 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_11 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_12 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_13 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_14 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_15 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_16 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_17 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_18 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_19 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_20 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_21 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_22 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_23 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_24 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_25 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_26 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_27 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_28 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_29 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $Item_30 #>     difficultyeasy difficultyhard difficultymedium a1 d g u #> par          1.024         -1.071            0.001  1 0 0 1 #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0  1.011 #>  #> $items #>     COV_items_items #> par           0.003 #>    ################### # General MLTM example (Embretson, 1984)  set.seed(42)  as <- matrix(rep(1,60), ncol=2) as[11:18,1] <- as[1:9,2] <- 0 d1 <- rep(c(3,1),each = 6)  # first easy, then medium, last difficult for first trait d2 <- rep(c(0,1,2),times = 4)    # difficult to easy d <- rnorm(18) ds <- rbind(cbind(d1=NA, d2=d), cbind(d1, d2)) (pars <- data.frame(a=as, d=ds)) #>    a.1 a.2 d.d1        d.d2 #> 1    1   0   NA  1.37095845 #> 2    1   0   NA -0.56469817 #> 3    1   0   NA  0.36312841 #> 4    1   0   NA  0.63286260 #> 5    1   0   NA  0.40426832 #> 6    1   0   NA -0.10612452 #> 7    1   0   NA  1.51152200 #> 8    1   0   NA -0.09465904 #> 9    1   0   NA  2.01842371 #> 10   1   1   NA -0.06271410 #> 11   0   1   NA  1.30486965 #> 12   0   1   NA  2.28664539 #> 13   0   1   NA -1.38886070 #> 14   0   1   NA -0.27878877 #> 15   0   1   NA -0.13332134 #> 16   0   1   NA  0.63595040 #> 17   0   1   NA -0.28425292 #> 18   0   1   NA -2.65645542 #> 19   1   1    3  0.00000000 #> 20   1   1    3  1.00000000 #> 21   1   1    3  2.00000000 #> 22   1   1    3  0.00000000 #> 23   1   1    3  1.00000000 #> 24   1   1    3  2.00000000 #> 25   1   1    1  0.00000000 #> 26   1   1    1  1.00000000 #> 27   1   1    1  2.00000000 #> 28   1   1    1  0.00000000 #> 29   1   1    1  1.00000000 #> 30   1   1    1  2.00000000 dat <- simdata(as, ds, 2500,   itemtype = c(rep('dich', 18), rep('partcomp', 12))) itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  2500           16.494           4.83 0.088 0.059 0.747     2.428 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  2500 2 0.752 0.432   0.265         0.180       0.745 #> Item_2  2500 2 0.384 0.486   0.328         0.234       0.742 #> Item_3  2500 2 0.563 0.496   0.319         0.222       0.743 #> Item_4  2500 2 0.635 0.481   0.318         0.224       0.743 #> Item_5  2500 2 0.582 0.493   0.320         0.224       0.743 #> Item_6  2500 2 0.478 0.500   0.329         0.233       0.742 #> Item_7  2500 2 0.767 0.423   0.274         0.191       0.744 #> Item_8  2500 2 0.469 0.499   0.315         0.218       0.743 #> Item_9  2500 2 0.849 0.358   0.233         0.161       0.745 #> Item_10 2500 2 0.471 0.499   0.557         0.480       0.727 #> Item_11 2500 2 0.736 0.441   0.352         0.268       0.740 #> Item_12 2500 2 0.882 0.323   0.246         0.182       0.745 #> Item_13 2500 2 0.232 0.422   0.302         0.220       0.743 #> Item_14 2500 2 0.460 0.499   0.319         0.222       0.743 #> Item_15 2500 2 0.480 0.500   0.387         0.294       0.739 #> Item_16 2500 2 0.627 0.484   0.352         0.260       0.741 #> Item_17 2500 2 0.441 0.497   0.318         0.222       0.743 #> Item_18 2500 2 0.097 0.296   0.209         0.149       0.746 #> Item_19 2500 2 0.466 0.499   0.381         0.287       0.739 #> Item_20 2500 2 0.643 0.479   0.360         0.269       0.740 #> Item_21 2500 2 0.788 0.409   0.335         0.257       0.741 #> Item_22 2500 2 0.456 0.498   0.406         0.315       0.737 #> Item_23 2500 2 0.646 0.478   0.403         0.315       0.737 #> Item_24 2500 2 0.769 0.422   0.364         0.284       0.740 #> Item_25 2500 2 0.349 0.477   0.408         0.321       0.737 #> Item_26 2500 2 0.492 0.500   0.414         0.323       0.737 #> Item_27 2500 2 0.586 0.493   0.381         0.289       0.739 #> Item_28 2500 2 0.330 0.470   0.388         0.300       0.738 #> Item_29 2500 2 0.477 0.500   0.361         0.266       0.740 #> Item_30 2500 2 0.587 0.492   0.371         0.278       0.740 #>  #> $proportions #>             0     1 #> Item_1  0.248 0.752 #> Item_2  0.616 0.384 #> Item_3  0.437 0.563 #> Item_4  0.365 0.635 #> Item_5  0.418 0.582 #> Item_6  0.522 0.478 #> Item_7  0.233 0.767 #> Item_8  0.531 0.469 #> Item_9  0.151 0.849 #> Item_10 0.529 0.471 #> Item_11 0.264 0.736 #> Item_12 0.118 0.882 #> Item_13 0.768 0.232 #> Item_14 0.540 0.460 #> Item_15 0.520 0.480 #> Item_16 0.373 0.627 #> Item_17 0.559 0.441 #> Item_18 0.903 0.097 #> Item_19 0.534 0.466 #> Item_20 0.357 0.643 #> Item_21 0.212 0.788 #> Item_22 0.544 0.456 #> Item_23 0.354 0.646 #> Item_24 0.231 0.769 #> Item_25 0.651 0.349 #> Item_26 0.508 0.492 #> Item_27 0.414 0.586 #> Item_28 0.670 0.330 #> Item_29 0.523 0.477 #> Item_30 0.413 0.587 #>   # unconditional model syntax <- \"theta1 = 1-9, 19-30            theta2 = 10-30            COV = theta1*theta2\" itemtype <- c(rep('Rasch', 18), rep('PC1PL', 12)) mod <- mirt(dat, syntax, itemtype=itemtype) #>  coef(mod, simplify=TRUE) #> $items #>         a1 a2      d g u    d1     d2 #> Item_1   1  0  1.313 0 1    NA     NA #> Item_2   1  0 -0.563 0 1    NA     NA #> Item_3   1  0  0.303 0 1    NA     NA #> Item_4   1  0  0.660 0 1    NA     NA #> Item_5   1  0  0.393 0 1    NA     NA #> Item_6   1  0 -0.105 0 1    NA     NA #> Item_7   1  0  1.404 0 1    NA     NA #> Item_8   1  0 -0.147 0 1    NA     NA #> Item_9   1  0  2.013 0 1    NA     NA #> Item_10  0  1 -0.141 0 1    NA     NA #> Item_11  0  1  1.227 0 1    NA     NA #> Item_12  0  1  2.350 0 1    NA     NA #> Item_13  0  1 -1.429 0 1    NA     NA #> Item_14  0  1 -0.193 0 1    NA     NA #> Item_15  0  1 -0.098 0 1    NA     NA #> Item_16  0  1  0.623 0 1    NA     NA #> Item_17  0  1 -0.286 0 1    NA     NA #> Item_18  0  1 -2.592 0 1    NA     NA #> Item_19  1  1     NA 0 1 2.870  0.013 #> Item_20  1  1     NA 0 1 3.716  0.832 #> Item_21  1  1     NA 0 1 3.238  1.900 #> Item_22  1  1     NA 0 1 4.407 -0.174 #> Item_23  1  1     NA 0 1 3.538  0.866 #> Item_24  1  1     NA 0 1 2.851  1.890 #> Item_25  1  1     NA 0 1 1.197 -0.137 #> Item_26  1  1     NA 0 1 1.038  0.975 #> Item_27  1  1     NA 0 1 1.063  1.818 #> Item_28  1  1     NA 0 1 0.970 -0.138 #> Item_29  1  1     NA 0 1 0.902  1.010 #> Item_30  1  1     NA 0 1 1.015  1.914 #>  #> $means #> theta1 theta2  #>      0      0  #>  #> $cov #>        theta1 theta2 #> theta1  0.917  0.081 #> theta2  0.081  0.984 #>  data.frame(est=coef(mod, simplify=TRUE)$items, pop=data.frame(a=as, d=ds)) #>         est.a1 est.a2       est.d est.g est.u    est.d1      est.d2 pop.a.1 #> Item_1       1      0  1.31307855     0     1        NA          NA       1 #> Item_2       1      0 -0.56331423     0     1        NA          NA       1 #> Item_3       1      0  0.30311181     0     1        NA          NA       1 #> Item_4       1      0  0.66017201     0     1        NA          NA       1 #> Item_5       1      0  0.39267181     0     1        NA          NA       1 #> Item_6       1      0 -0.10529560     0     1        NA          NA       1 #> Item_7       1      0  1.40429460     0     1        NA          NA       1 #> Item_8       1      0 -0.14742905     0     1        NA          NA       1 #> Item_9       1      0  2.01310778     0     1        NA          NA       1 #> Item_10      0      1 -0.14050425     0     1        NA          NA       1 #> Item_11      0      1  1.22727159     0     1        NA          NA       0 #> Item_12      0      1  2.35002102     0     1        NA          NA       0 #> Item_13      0      1 -1.42944927     0     1        NA          NA       0 #> Item_14      0      1 -0.19283592     0     1        NA          NA       0 #> Item_15      0      1 -0.09794928     0     1        NA          NA       0 #> Item_16      0      1  0.62283206     0     1        NA          NA       0 #> Item_17      0      1 -0.28628773     0     1        NA          NA       0 #> Item_18      0      1 -2.59213954     0     1        NA          NA       0 #> Item_19      1      1          NA     0     1 2.8695796  0.01318001       1 #> Item_20      1      1          NA     0     1 3.7157820  0.83154537       1 #> Item_21      1      1          NA     0     1 3.2383233  1.90018431       1 #> Item_22      1      1          NA     0     1 4.4073154 -0.17448556       1 #> Item_23      1      1          NA     0     1 3.5382631  0.86641897       1 #> Item_24      1      1          NA     0     1 2.8505117  1.88958564       1 #> Item_25      1      1          NA     0     1 1.1972230 -0.13675332       1 #> Item_26      1      1          NA     0     1 1.0378260  0.97497271       1 #> Item_27      1      1          NA     0     1 1.0634033  1.81828381       1 #> Item_28      1      1          NA     0     1 0.9704764 -0.13769090       1 #> Item_29      1      1          NA     0     1 0.9017976  1.00959896       1 #> Item_30      1      1          NA     0     1 1.0149521  1.91386682       1 #>         pop.a.2 pop.d.d1    pop.d.d2 #> Item_1        0       NA  1.37095845 #> Item_2        0       NA -0.56469817 #> Item_3        0       NA  0.36312841 #> Item_4        0       NA  0.63286260 #> Item_5        0       NA  0.40426832 #> Item_6        0       NA -0.10612452 #> Item_7        0       NA  1.51152200 #> Item_8        0       NA -0.09465904 #> Item_9        0       NA  2.01842371 #> Item_10       1       NA -0.06271410 #> Item_11       1       NA  1.30486965 #> Item_12       1       NA  2.28664539 #> Item_13       1       NA -1.38886070 #> Item_14       1       NA -0.27878877 #> Item_15       1       NA -0.13332134 #> Item_16       1       NA  0.63595040 #> Item_17       1       NA -0.28425292 #> Item_18       1       NA -2.65645542 #> Item_19       1        3  0.00000000 #> Item_20       1        3  1.00000000 #> Item_21       1        3  2.00000000 #> Item_22       1        3  0.00000000 #> Item_23       1        3  1.00000000 #> Item_24       1        3  2.00000000 #> Item_25       1        1  0.00000000 #> Item_26       1        1  1.00000000 #> Item_27       1        1  2.00000000 #> Item_28       1        1  0.00000000 #> Item_29       1        1  1.00000000 #> Item_30       1        1  2.00000000 itemplot(mod, 1)  itemplot(mod, 30)   # MLTM design only for PC1PL items itemdesign <- data.frame(t1_difficulty= factor(d1, labels=c('medium', 'easy')),                         t2_difficulty=factor(d2, labels=c('hard', 'medium', 'easy'))) rownames(itemdesign) <- colnames(dat)[19:30] itemdesign #>         t1_difficulty t2_difficulty #> Item_19          easy          hard #> Item_20          easy        medium #> Item_21          easy          easy #> Item_22          easy          hard #> Item_23          easy        medium #> Item_24          easy          easy #> Item_25        medium          hard #> Item_26        medium        medium #> Item_27        medium          easy #> Item_28        medium          hard #> Item_29        medium        medium #> Item_30        medium          easy  # fit MLTM design, leaving first 18 items as 'Rasch' type mltm <- mirt(dat, syntax, itemtype=itemtype, itemdesign=itemdesign,              item.formula = list(theta1 ~ 0 + t1_difficulty,                                  theta2 ~ 0 + t2_difficulty), SE=TRUE) #>  #>  #> Calculating information matrix... coef(mltm, simplify=TRUE) #> $items #>         theta1.t1_difficultyeasy theta1.t1_difficultymedium #> Item_1                      0.00                      0.000 #> Item_2                      0.00                      0.000 #> Item_3                      0.00                      0.000 #> Item_4                      0.00                      0.000 #> Item_5                      0.00                      0.000 #> Item_6                      0.00                      0.000 #> Item_7                      0.00                      0.000 #> Item_8                      0.00                      0.000 #> Item_9                      0.00                      0.000 #> Item_10                     0.00                      0.000 #> Item_11                     0.00                      0.000 #> Item_12                     0.00                      0.000 #> Item_13                     0.00                      0.000 #> Item_14                     0.00                      0.000 #> Item_15                     0.00                      0.000 #> Item_16                     0.00                      0.000 #> Item_17                     0.00                      0.000 #> Item_18                     0.00                      0.000 #> Item_19                     3.19                      0.000 #> Item_20                     3.19                      0.000 #> Item_21                     3.19                      0.000 #> Item_22                     3.19                      0.000 #> Item_23                     3.19                      0.000 #> Item_24                     3.19                      0.000 #> Item_25                     0.00                      1.031 #> Item_26                     0.00                      1.031 #> Item_27                     0.00                      1.031 #> Item_28                     0.00                      1.031 #> Item_29                     0.00                      1.031 #> Item_30                     0.00                      1.031 #>         theta2.t2_difficultyeasy theta2.t2_difficultyhard #> Item_1                     0.000                    0.000 #> Item_2                     0.000                    0.000 #> Item_3                     0.000                    0.000 #> Item_4                     0.000                    0.000 #> Item_5                     0.000                    0.000 #> Item_6                     0.000                    0.000 #> Item_7                     0.000                    0.000 #> Item_8                     0.000                    0.000 #> Item_9                     0.000                    0.000 #> Item_10                    0.000                    0.000 #> Item_11                    0.000                    0.000 #> Item_12                    0.000                    0.000 #> Item_13                    0.000                    0.000 #> Item_14                    0.000                    0.000 #> Item_15                    0.000                    0.000 #> Item_16                    0.000                    0.000 #> Item_17                    0.000                    0.000 #> Item_18                    0.000                    0.000 #> Item_19                    0.000                   -0.078 #> Item_20                    0.000                    0.000 #> Item_21                    1.857                    0.000 #> Item_22                    0.000                   -0.078 #> Item_23                    0.000                    0.000 #> Item_24                    1.857                    0.000 #> Item_25                    0.000                   -0.078 #> Item_26                    0.000                    0.000 #> Item_27                    1.857                    0.000 #> Item_28                    0.000                   -0.078 #> Item_29                    0.000                    0.000 #> Item_30                    1.857                    0.000 #>         theta2.t2_difficultymedium a1 a2      d g u d1 d2 #> Item_1                       0.000  1  0  1.314 0 1 NA NA #> Item_2                       0.000  1  0 -0.563 0 1 NA NA #> Item_3                       0.000  1  0  0.303 0 1 NA NA #> Item_4                       0.000  1  0  0.661 0 1 NA NA #> Item_5                       0.000  1  0  0.393 0 1 NA NA #> Item_6                       0.000  1  0 -0.105 0 1 NA NA #> Item_7                       0.000  1  0  1.405 0 1 NA NA #> Item_8                       0.000  1  0 -0.147 0 1 NA NA #> Item_9                       0.000  1  0  2.014 0 1 NA NA #> Item_10                      0.000  0  1 -0.140 0 1 NA NA #> Item_11                      0.000  0  1  1.228 0 1 NA NA #> Item_12                      0.000  0  1  2.351 0 1 NA NA #> Item_13                      0.000  0  1 -1.430 0 1 NA NA #> Item_14                      0.000  0  1 -0.193 0 1 NA NA #> Item_15                      0.000  0  1 -0.098 0 1 NA NA #> Item_16                      0.000  0  1  0.623 0 1 NA NA #> Item_17                      0.000  0  1 -0.286 0 1 NA NA #> Item_18                      0.000  0  1 -2.594 0 1 NA NA #> Item_19                      0.000  1  1     NA 0 1  0  0 #> Item_20                      0.924  1  1     NA 0 1  0  0 #> Item_21                      0.000  1  1     NA 0 1  0  0 #> Item_22                      0.000  1  1     NA 0 1  0  0 #> Item_23                      0.924  1  1     NA 0 1  0  0 #> Item_24                      0.000  1  1     NA 0 1  0  0 #> Item_25                      0.000  1  1     NA 0 1  0  0 #> Item_26                      0.924  1  1     NA 0 1  0  0 #> Item_27                      0.000  1  1     NA 0 1  0  0 #> Item_28                      0.000  1  1     NA 0 1  0  0 #> Item_29                      0.924  1  1     NA 0 1  0  0 #> Item_30                      0.000  1  1     NA 0 1  0  0 #>  #> $means #> theta1 theta2  #>      0      0  #>  #> $cov #>        theta1 theta2 #> theta1  0.919  0.074 #> theta2  0.074  0.988 #>  coef(mltm, printSE=TRUE) #> $Item_1 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  1  0 1.314     -999      999 #> SE                          NA NA NA 0.054       NA       NA #>  #> $Item_2 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  1  0 -0.563     -999      999 #> SE                          NA NA NA  0.049       NA       NA #>  #> $Item_3 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  1  0 0.303     -999      999 #> SE                          NA NA NA 0.048       NA       NA #>  #> $Item_4 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  1  0 0.661     -999      999 #> SE                          NA NA NA 0.049       NA       NA #>  #> $Item_5 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  1  0 0.393     -999      999 #> SE                          NA NA NA 0.048       NA       NA #>  #> $Item_6 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  1  0 -0.105     -999      999 #> SE                          NA NA NA  0.048       NA       NA #>  #> $Item_7 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  1  0 1.405     -999      999 #> SE                          NA NA NA 0.055       NA       NA #>  #> $Item_8 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  1  0 -0.147     -999      999 #> SE                          NA NA NA  0.048       NA       NA #>  #> $Item_9 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  1  0 2.014     -999      999 #> SE                          NA NA NA 0.063       NA       NA #>  #> $Item_10 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  0  1 -0.140     -999      999 #> SE                          NA NA NA  0.048       NA       NA #>  #> $Item_11 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  0  1 1.228     -999      999 #> SE                          NA NA NA 0.053       NA       NA #>  #> $Item_12 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  0  1 2.351     -999      999 #> SE                          NA NA NA 0.069       NA       NA #>  #> $Item_13 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  0  1 -1.430     -999      999 #> SE                          NA NA NA  0.055       NA       NA #>  #> $Item_14 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  0  1 -0.193     -999      999 #> SE                          NA NA NA  0.048       NA       NA #>  #> $Item_15 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  0  1 -0.098     -999      999 #> SE                          NA NA NA  0.048       NA       NA #>  #> $Item_16 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2     d logit(g) logit(u) #> par                          0  0  1 0.623     -999      999 #> SE                          NA NA NA 0.050       NA       NA #>  #> $Item_17 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  0  1 -0.286     -999      999 #> SE                          NA NA NA  0.049       NA       NA #>  #> $Item_18 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                        0                          0 #> SE                        NA                         NA #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                        0                        0 #> SE                        NA                       NA #>     theta2.t2_difficultymedium a1 a2      d logit(g) logit(u) #> par                          0  0  1 -2.594     -999      999 #> SE                          NA NA NA  0.074       NA       NA #>  #> $Item_19 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_20 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_21 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_22 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_23 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_24 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_25 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_26 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_27 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_28 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_29 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $Item_30 #>     theta1.t1_difficultyeasy theta1.t1_difficultymedium #> par                    3.190                      1.031 #> SE                     0.145                      0.048 #>     theta2.t2_difficultyeasy theta2.t2_difficultyhard #> par                    1.857                   -0.078 #> SE                     0.065                    0.037 #>     theta2.t2_difficultymedium a1 a2 d1 d2 logit(g) logit(u) #> par                      0.924  1  1  0  0     -999      999 #> SE                       0.046 NA NA NA NA       NA       NA #>  #> $GroupPars #>     MEAN_1 MEAN_2 COV_11 COV_21 COV_22 #> par      0      0  0.919  0.074  0.988 #> SE      NA     NA  0.047  0.029  0.045 #>  anova(mltm, mod) # similar fit; hence more constrained version preferred #>           AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mltm 87789.31 87858.12 87844.28 87940.73 -43868.65                 #> mod  87810.34 87929.44 87905.48 88072.42 -43860.17 16.972 19 0.592 M2(mltm) # goodness of fit #>             M2  df            p      RMSEA    RMSEA_5   RMSEA_95      SRMSR #> stats 724.3175 439 2.220446e-16 0.01612682 0.01400712 0.01819185 0.03054497 #>             TLI       CFI #> stats 0.9760504 0.9758302 head(personfit(mltm)) #>      outfit   z.outfit     infit    z.infit         Zh #> 1 0.4099102 -2.3020948 0.5059336 -2.9261983  2.2862274 #> 2 1.9123368  2.2520109 1.2180485  1.0684326 -1.5047067 #> 3 0.6286135 -0.8426793 0.7783421 -0.9888073  1.0049591 #> 4 0.7758581 -0.9554199 0.8563428 -0.8899493  0.9411033 #> 5 0.7022093 -0.8066740 0.8190887 -0.9254922  0.9442138 #> 6 0.4515079 -1.3679137 0.5692678 -1.6827425  1.4501646 residuals(mltm) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.064  -0.024  -0.007   0.000   0.019   0.174  #>  #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1         -0.010 -0.027 -0.040 -0.031  0.029  0.000  0.003 -0.012   0.098 #> Item_2   0.229         0.008  0.013  0.041  0.049  0.015  0.003 -0.004   0.142 #> Item_3   1.788  0.156        -0.025 -0.007 -0.012  0.012 -0.014 -0.015   0.174 #> Item_4   3.964  0.437  1.577        -0.006  0.014 -0.014  0.008  0.018   0.134 #> Item_5   2.393  4.302  0.134  0.085         0.021  0.010 -0.015 -0.005   0.154 #> Item_6   2.036  5.900  0.344  0.505  1.137         0.005 -0.012 -0.003   0.127 #> Item_7   0.000  0.581  0.363  0.498  0.261  0.064         0.005  0.006   0.134 #> Item_8   0.029  0.019  0.490  0.155  0.560  0.341  0.075        -0.011   0.166 #> Item_9   0.389  0.035  0.534  0.827  0.072  0.029  0.097  0.280          0.093 #> Item_10 23.809 50.189 75.667 44.656 59.644 40.070 45.056 68.776 21.841         #> Item_11  0.009  0.716  0.194  0.626  0.034  0.175  0.028  0.385  0.126   1.843 #> Item_12  0.753  0.236  3.918  0.095  1.109  0.582  0.818  1.181  5.494   0.011 #> Item_13  1.267  4.570  0.152  0.017  0.396  2.507  3.411  0.105  2.038   3.111 #> Item_14  7.361  0.214  0.172  0.934  1.965  4.761  4.570  0.319  3.784   1.714 #> Item_15  0.081  0.605  1.939  0.315  0.397  0.037  0.590  0.408  0.605   0.871 #> Item_16  1.749  0.256  2.779  0.965  1.745  0.134  2.493  0.001  3.477   0.281 #> Item_17  3.492  0.001  0.804  0.708  0.094  2.145  3.168  6.440  0.076   6.330 #> Item_18  1.296  0.205  0.068  0.911  0.003  0.029  0.301  0.309  0.158   0.447 #> Item_19  1.950  1.095  0.940  1.227  3.901  2.358  0.879  2.427  1.078   0.912 #> Item_20  0.821  1.556  0.836  0.291  0.071  0.862  1.370  0.069  6.617   0.072 #> Item_21  3.887  1.725  3.272  1.120  1.616  0.749  1.266  0.857  0.744   4.508 #> Item_22  2.670  0.247  0.016  4.552  0.345  0.736  0.650  0.010  0.030   1.904 #> Item_23  1.723  2.043  0.011  0.415  0.958  0.032  0.670  0.042  0.005   3.678 #> Item_24  6.039  2.418  3.100  6.560  2.357  5.733  2.198  2.200  4.635   7.501 #> Item_25  0.562  0.795  0.373  4.838  1.043  3.118  0.468  1.310  0.631  11.477 #> Item_26  4.256  1.169  0.889  0.700  1.184  0.633  3.494  1.488  3.177  20.873 #> Item_27  0.025  0.170  0.067  0.374  2.965  0.050  0.179  0.187  2.212  30.192 #> Item_28  2.586  7.102  3.183  2.042  2.136  2.200  2.730  3.809  2.120  13.578 #> Item_29  1.392  0.557  1.223  0.458  0.710  1.588  2.200  0.723  3.080  11.310 #> Item_30  0.831  1.556  1.214  0.302  0.109  0.449  0.573  0.340  0.424  20.892 #>         Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> Item_1    0.002  -0.017  -0.023  -0.054  -0.006  -0.026  -0.037  -0.023  -0.028 #> Item_2   -0.017  -0.010  -0.043  -0.009  -0.016  -0.010   0.000  -0.009   0.021 #> Item_3    0.009  -0.040   0.008  -0.008   0.028  -0.033  -0.018  -0.005  -0.019 #> Item_4   -0.016  -0.006  -0.003  -0.019  -0.011  -0.020  -0.017   0.019   0.022 #> Item_5   -0.004  -0.021  -0.013  -0.028  -0.013  -0.026   0.006  -0.001   0.040 #> Item_6    0.008  -0.015  -0.032  -0.044   0.004   0.007  -0.029  -0.003   0.031 #> Item_7    0.003   0.018  -0.037  -0.043  -0.015  -0.032  -0.036   0.011   0.019 #> Item_8    0.012  -0.022   0.006  -0.011   0.013   0.001  -0.051  -0.011   0.031 #> Item_9    0.007  -0.047  -0.029  -0.039  -0.016  -0.037   0.006   0.008   0.021 #> Item_10   0.027   0.002   0.035  -0.026   0.019   0.011  -0.050   0.013  -0.019 #> Item_11          -0.022   0.022  -0.006   0.009  -0.009  -0.027   0.006  -0.019 #> Item_12   1.214          -0.008  -0.027   0.011  -0.003  -0.014  -0.028  -0.020 #> Item_13   1.222   0.141          -0.013   0.035   0.017  -0.008  -0.027  -0.023 #> Item_14   0.096   1.802   0.404          -0.014   0.018  -0.013  -0.038  -0.042 #> Item_15   0.208   0.293   3.129   0.460           0.021  -0.011  -0.026   0.029 #> Item_16   0.208   0.018   0.759   0.815   1.060          -0.007  -0.003  -0.019 #> Item_17   1.773   0.461   0.180   0.392   0.290   0.140           0.005  -0.023 #> Item_18   0.100   1.944   1.860   3.653   1.691   0.020   0.064          -0.033 #> Item_19   0.913   1.015   1.284   4.468   2.033   0.859   1.304   2.695         #> Item_20   1.446   0.039   0.045   2.772   4.411   0.072   0.042   3.259   0.949 #> Item_21   0.747   0.875   1.773   1.730   0.759   1.420   0.979   1.137   5.069 #> Item_22   0.717   0.201   0.020   0.388   5.866   0.030   0.071   1.091   1.009 #> Item_23   8.564   1.754   4.656   0.443   1.035   0.005   0.173   1.152   0.997 #> Item_24   3.006   2.617   2.265   2.175   2.826   2.329   2.261   4.236   6.280 #> Item_25   0.480   0.827   0.946   0.373   0.576   1.593   2.431   1.596   1.146 #> Item_26   1.356   0.825   1.879   2.200   0.954   1.012   5.500   4.288   1.332 #> Item_27   0.144   1.132   0.112   0.783   0.837   1.936   4.920   3.868   1.314 #> Item_28   2.097   4.981   2.166   2.329   2.583   3.338   2.228   2.049   3.566 #> Item_29   0.736   0.533   1.869   2.544   2.516   1.394  10.093   0.484   5.562 #> Item_30   0.221   0.086   5.871   2.007   0.460   0.201   5.445   2.127   0.862 #>         Item_20 Item_21 Item_22 Item_23 Item_24 Item_25 Item_26 Item_27 Item_28 #> Item_1   -0.018   0.039  -0.033  -0.026   0.049   0.015   0.041   0.003  -0.032 #> Item_2   -0.025  -0.026   0.010   0.029   0.031   0.018   0.022  -0.008   0.053 #> Item_3   -0.018  -0.036   0.003   0.002   0.035   0.012   0.019   0.005  -0.036 #> Item_4   -0.011   0.021   0.043   0.013   0.051  -0.044   0.017   0.012  -0.029 #> Item_5   -0.005  -0.025   0.012  -0.020   0.031  -0.020   0.022  -0.034   0.029 #> Item_6    0.019  -0.017  -0.017   0.004   0.048   0.035  -0.016  -0.004   0.030 #> Item_7   -0.023   0.023  -0.016  -0.016   0.030   0.014  -0.037  -0.008   0.033 #> Item_8    0.005  -0.019   0.002   0.004   0.030  -0.023  -0.024   0.009  -0.039 #> Item_9   -0.051  -0.017  -0.003  -0.001   0.043  -0.016  -0.036   0.030   0.029 #> Item_10  -0.005   0.042   0.028   0.038   0.055   0.068   0.091   0.110   0.074 #> Item_11   0.024  -0.017  -0.017   0.059   0.035  -0.014   0.023   0.008   0.029 #> Item_12  -0.004  -0.019   0.009   0.026  -0.032   0.018   0.018   0.021  -0.045 #> Item_13  -0.004  -0.027  -0.003   0.043  -0.030  -0.019  -0.027   0.007  -0.029 #> Item_14  -0.033  -0.026  -0.012  -0.013   0.029  -0.012  -0.030  -0.018  -0.031 #> Item_15   0.042  -0.017   0.048   0.020  -0.034   0.015  -0.020   0.018  -0.032 #> Item_16   0.005  -0.024   0.003   0.001   0.031   0.025   0.020  -0.028  -0.037 #> Item_17  -0.004   0.020   0.005  -0.008  -0.030  -0.031  -0.047  -0.044  -0.030 #> Item_18  -0.036   0.021   0.021  -0.021   0.041  -0.025  -0.041  -0.039  -0.029 #> Item_19   0.019  -0.045   0.020   0.020  -0.050   0.021  -0.023  -0.023  -0.038 #> Item_20           0.021   0.029   0.011  -0.045  -0.015  -0.019  -0.026  -0.036 #> Item_21   1.097          -0.018   0.022   0.041   0.031  -0.023   0.027   0.041 #> Item_22   2.114   0.778           0.023   0.046   0.035   0.016   0.005  -0.033 #> Item_23   0.304   1.176   1.318           0.036  -0.019   0.022  -0.003   0.037 #> Item_24   5.068   4.269   5.374   3.166           0.034   0.050  -0.030  -0.047 #> Item_25   0.569   2.467   3.060   0.871   2.822           0.019   0.020  -0.039 #> Item_26   0.944   1.268   0.663   1.248   6.316   0.862           0.032   0.036 #> Item_27   1.693   1.795   0.068   0.021   2.264   0.969   2.522          -0.033 #> Item_28   3.193   4.110   2.716   3.385   5.434   3.775   3.228   2.749         #> Item_29   0.841   1.320   2.280   2.795   4.367   1.522   2.260   5.717   4.057 #> Item_30   6.126   0.904   0.633   3.421   3.815   0.664   1.371   0.140   3.142 #>         Item_29 Item_30 #> Item_1   -0.024  -0.018 #> Item_2   -0.015   0.025 #> Item_3    0.022   0.022 #> Item_4    0.014  -0.011 #> Item_5    0.017   0.007 #> Item_6   -0.025  -0.013 #> Item_7   -0.030  -0.015 #> Item_8   -0.017  -0.012 #> Item_9   -0.035  -0.013 #> Item_10   0.067   0.091 #> Item_11  -0.017  -0.009 #> Item_12  -0.015  -0.006 #> Item_13  -0.027  -0.048 #> Item_14  -0.032  -0.028 #> Item_15  -0.032   0.014 #> Item_16  -0.024  -0.009 #> Item_17  -0.064  -0.047 #> Item_18  -0.014  -0.029 #> Item_19  -0.047  -0.019 #> Item_20  -0.018  -0.050 #> Item_21  -0.023  -0.019 #> Item_22  -0.030   0.016 #> Item_23  -0.033   0.037 #> Item_24  -0.042  -0.039 #> Item_25  -0.025   0.016 #> Item_26  -0.030   0.023 #> Item_27  -0.048   0.007 #> Item_28  -0.040  -0.035 #> Item_29          -0.029 #> Item_30   2.120          # EAP estimates fscores(mltm) |> head() #>      theta1 theta2 #> [1,] -2.002 -0.481 #> [2,]  1.138  0.370 #> [3,]  0.149  1.793 #> [4,] -1.302 -0.235 #> [5,] -0.091  1.455 #> [6,]  1.472  1.122  # }"},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify model information — mirt.model","title":"Specify model information — mirt.model","text":"mirt.model function scans/reads user input specify confirmatory model. Item locations must used specifications itemnames argument supplied. called implicitly estimation functions string passed model argument.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify model information — mirt.model","text":"","code":"mirt.model(   input = NULL,   itemnames = NULL,   file = \"\",   COV = NULL,   quiet = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify model information — mirt.model","text":"input input writing model syntax. Can either string declaration class character -called Q-matrix class matrix specifies model either integer logical values. Q-matrix method chosen covariances terms can specified COV input itemnames character vector factor indicating item names. data.frame matrix object supplied names extracted using colnames(itemnames). Supplying input allows syntax specified raw item names rather item locations file input specifying external file declares input. COV symmetric, logical matrix used declare covariance terms estimated quiet logical argument passed scan() suppress console read message ... additional arguments scan()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify model information — mirt.model","text":"Returns model specification object used   mirt, bfactor, multipleGroup,   mixedmirt","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify model information — mirt.model","text":"Factors first named specify numerical items affect (.e., slope equal 0), separated either commas - indicate range items. Products factors may specified enclosing left hand term within brackets. finish declaration model simply enter blank line carriage return (.e., 'enter' 'return' key), instead read input version model syntax. associated slopes throughout package label coefficients a1, a2, ..., ak, associated number assigned according respective order defined factors. example, syntax \"G = 1-10        F = 1-5        = 6-10\" G factor assigned slopes a1 item, F assigned slopes a2, assigned slopes a3. principle applies bfactor function whereby slopes automatically included specific factors general factor structure assigned. optional keyword specifying correlation relationships factors called COV, non-linear factor products can included enclosing product combination left hand side declaration (e.g., (F1*F1) create quadratic factor F1). keywords CONSTRAIN, CONSTRAINB, PRIOR, FIXED, FREE, START, UBOUND, LBOUND can applied specific sub-groups multiple-group models included square brackets = sign, groups separated commas. example, apply within-group equality constraints group called \"male\", specifying: CONSTRAIN [male] = (1-5, a1) appropriate, specifying constraints sub-groups \"male\" \"female\" appear CONSTRAIN [male, female] = (1-5, a1) groups multi-group model, within-group equality constraints appear. Therefore, bracketed group specifications useful modifying priors, starting values, /within group equality constraints, specifications sub-group may differ. Additionally, use negations can used omit specific groups constraint specifications prefixing string - operator, following applies -group  constraints groups except \"Group2\" \"Group3\": CONSTRAINB [-Group2, -Group3] = (1-5, a1) Finally, keyword GROUP can used specify group-level hyper-parameter terms, means variance default Gaussian distribution. example, set starting value variance parameter (COV_11) 1.5: START = (GROUP, COV_11, 1.5) COV Specify relationship latent factors.   Estimating correlation factors declared joining two   factors asterisk (e.g., F1*F2), asterisk three factors   estimate possible correlations (e.g., F1*F2*F3). Specifications factor   (e.g., F1*F1) free variance said factor instead MEAN comma separated list specifying latent factor means freely estimate.   E.g., MEAN = F1, F2 free latent means factors F1 F2 CONSTRAIN bracketed, comma separated list specifying equality constrains items.   input format   CONSTRAIN = (items, ..., parameterName(s)),   (items, ..., parameterName). example, single group 10-item dichotomous tests, using default 2PL model,   first last 5 item slopes (a1) can constrained equal using   CONSTRAIN = (1-5, a1), (6-10, a1), combination   CONSTRAIN = (1-3,4,5,a1), (6,7,8-10,a1). constraining parameters equal across items different parameter names,   balanced bracketed vector must supplied. E.g., setting first slope item 1 equal   second slope item 3 CONSTRAIN = (1, 3, a1, a2) CONSTRAINB bracketed, comma separate list specifying equality constrains groups.   input format CONSTRAINB = (items, ..., parameterName),   (items, ..., parameterName). example, two group 10-item dichotomous tests, using default 2PL model, first   5 item slopes (a1) can constrained equal across groups using   CONSTRAINB = (1-5, a1), combination CONSTRAINB = (1-3,4,5,a1) PRIOR bracketed, comma separate list specifying prior parameter distributions.   input format   PRIOR = (items, ..., parameterName, priorType, val1, val2),   (items, ..., parameterName, priorType, val1, val2).   example, single group 10-item dichotomous tests, using default 2PL model,   defining normal prior N(0,2) first 5 item intercepts (d) can defined   PRIOR = (1-5, d, norm, 0, 2) Currently supported priors form: (items, norm, mean, sd)   normal/Gaussian, (items, lnorm, log_mean, log_sd) log-normal,   (items, beta, alpha, beta) beta, (items, expbeta, alpha, beta)   beta distribution applying   function plogis input value (note, specifically applying beta   prior lower-bound parameters 3/4PL models) LBOUND bracketed, comma separate list specifying lower bounds estimated   parameters (used optimizers L-BFGS-B nlminb).   input format LBOUND = (items, ..., parameterName, value),   (items, ..., parameterName, value). example, single group 10-item dichotomous tests, using 3PL model   setting lower bounds 'g' parameters first 5 items 0.2 accomplished   LBOUND = (1-5, g, 0.2) UBOUND LBOUND, specifying upper bounds estimated parameters START bracketed, comma separate list specifying starting values individual parameters.   input form (items, ..., parameterName, value). instance, setting 10th   12th 15th item slope parameters (a1) 1.0 specified START = (10, 12-15, a1, 1.0) hands control starting values pass argument pars = 'values'   whatever estimation function used FIXED bracketed, comma separate list specifying parameters fixed   starting values (.e., freely estimated).   input form (items, ..., parameterName). instance, fixing 10th   12th 15th item slope parameters (a1) accomplished FIXED = (10, 12-15, a1) hands control estimated values pass argument pars = 'values'   whatever estimation function used FREE Equivalent FIXED input, except parameters freely estimated instead   fixed starting value NEXPLORE Number exploratory factors extract. Usually required   passing numeric value model argument estimation function   generate exploratory factor analysis model, however different start values,   priors, lower upper bounds, etc, desired input can used","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Specify model information — mirt.model","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Specify model information — mirt.model","text":"Phil Chalmers rphilip.chalmers@gmail.com Alexander Robitzsch","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirt.model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify model information — mirt.model","text":"","code":"# \\donttest{  # interactively through the console (not run) #model <- mirt.model() #  F1 = 1,2,3,4-10 #  F2 = 10-20 #  (F1*F2) = 1,2,3,4-10 #  COV = F1*F2   # Or alternatively with a string input s <- 'F1 = 1,2,3,4-10       F2 = 10-20       (F1*F2) = 1,2,3,4-10       COV = F1*F2' model <- mirt.model(s)  # strings can also be passed to the estimation functions directly, #   which silently calls mirt.model(). E.g., using the string above: # mod <- mirt(data, s)   # Q-matrix specification Q <- matrix(c(1,1,1,0,0,0,0,0,0,1,1,1), ncol=2, dimnames = list(NULL, c('Factor1', 'Factor2'))) COV <- matrix(c(FALSE, TRUE, TRUE, FALSE), 2) model <- mirt.model(Q, COV=COV)  ## constrain various items slopes and all intercepts in single group model to be equal, #   and use a log-normal prior for all the slopes s <- 'F = 1-10       CONSTRAIN = (1-3, 5, 6, a1), (1-10, d)       PRIOR = (1-10, a1, lnorm, .2, .2)' model <- mirt.model(s)   ## constrain various items slopes and intercepts across groups for use in multipleGroup(), #  and constrain first two slopes within 'group1' to be equal s <- 'F = 1-10       CONSTRAIN = (1-2, a1)       CONSTRAINB = (1-3, 5, 6, a1), (1-10, d)' model <- mirt.model(s)   ## specify model using raw item names data(data.read, package = 'sirt') dat <- data.read  # syntax with variable names mirtsyn2 <- \"        F1 = A1,B2,B3,C4        F2 = A1-A4,C2,C4        MEAN = F1        COV = F1*F1, F1*F2        CONSTRAIN=(A2-A4,a2),(A3,C2,d)        PRIOR = (C3,A2-A4,a2,lnorm, .2, .2),(B3,d,norm,0,.0001)\" # create a mirt model mirtmodel <- mirt.model(mirtsyn2, itemnames=dat) # or equivalently: # mirtmodel <- mirt.model(mirtsyn2, itemnames=colnames(dat))  # mod <- mirt(dat , mirtmodel)  # using sprintf() to functionally fill in information (useful for long tests # or more complex specifications) nitems <- 100 s <- sprintf('F = 1-%i       CONSTRAIN = (%s, a1)       CONSTRAINB = (%s, a1), (1-%i, d)',       nitems, \"1,2,4,50,100\",       paste0(1:45, collapse=','),       nitems) cat(s) #> F = 1-100 #>       CONSTRAIN = (1,2,4,50,100, a1) #>       CONSTRAINB = (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45, a1), (1-100, d) model <- mirt.model(s)      # }"},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a parallel cluster object to be used in internal functions — mirtCluster","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"function defines object placed relevant internal environment defined mirt. Internal functions calcLogLik, fscores, etc, utilize object automatically capitalize parallel processing architecture. object defined call parallel::makeCluster(). Note defining parallel objects (simulation designs, example) recommended define mirtCluster.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"","code":"mirtCluster(spec, omp_threads, remove = FALSE, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"spec input passed parallel::makeCluster(). input given maximum number available local cores minus 1 used. Setting NULL skip new definition (allows omp_threads used independently) omp_threads number OpenMP threads use (currently applies E-step computations ). used argument input missing remove logical; remove previously defined mirtCluster()? ... additional arguments pass parallel::makeCluster","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mirtCluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a parallel cluster object to be used in internal functions — mirtCluster","text":"","code":"if (FALSE) { # \\dontrun{ if(interactive()){   # use all available cores   mirtCluster()   mirtCluster(remove = TRUE)    # make 4 cores available for parallel computing   mirtCluster(4)   mirtCluster(remove = TRUE)    # create 3 core architecture in R, and 4 thread architecture with OpenMP   mirtCluster(spec = 3, omp_threads = 4)    # leave previous multicore objects, but change omp_threads   mirtCluster(spec = NULL, omp_threads = 2) }  } # }"},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed effects modeling for MIRT models — mixedmirt","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"mixedmirt fits MIRT models using FIML estimation dichotomous polytomous IRT models conditional fixed random effect person item level covariates. can also understood 'explanatory IRT' fixed effects modeled, multilevel/mixed IRT random fixed effects included. method uses MH-RM algorithm exclusively. Additionally, computation log-likelihood can sped using parallel estimation via mirtCluster.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"","code":"mixedmirt(   data,   covdata = NULL,   model = 1,   fixed = ~1,   random = NULL,   itemtype = \"Rasch\",   lr.fixed = ~1,   lr.random = NULL,   itemdesign = NULL,   constrain = NULL,   pars = NULL,   return.design = FALSE,   SE = TRUE,   internal_constraints = TRUE,   technical = list(SEtol = 1e-04),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA covdata data.frame consists nrow(data) K 'person level' fixed random predictors. missing data present object observations covdata data removed row-wise via rowSums(.na(covdata)) > 0 model object returned , string passed , mirt.model() declare IRT model estimated. See mirt.model mirt detail fixed right sided R formula specifying fixed effect (aka 'explanatory') predictors covdata itemdesign. estimate intercepts item keyword items reserved automatically added itemdesign input. polytomous items model items argument valid since intercept parameters freely estimated identified parameterizations found mirt, first column fixed design matrix (commonly intercept reference group) omitted random right sided formula list formulas containing crossed random effects form v1 + ... v_n | G, G grouping variable v_n random numeric predictors within group. intercept value specified default correlations v's G estimated, can suppressed including ~ -1 + ... 0 constant. G may contain interaction terms, group:items include cross person-level interactions effects itemtype itemtype mirt, except fixed random inputs used support following item types: c('PC2PL', 'PC3PL', '2PLNRM', '3PLNRM', '3PLuNRM', '4PLNRM') lr.fixed R formula (list formulas) specify regression effects latent variables variables covdata. used construct models -called 'latent regression model' explain person-level ability/trait differences. named list formulas supplied (names correspond latent trait names model) specific regression effects can estimated factor. Supplying single formula estimate regression parameters latent traits default. lr.random list random effect terms modeling variability latent trait scores, syntax uses style random argument. Useful building -called 'multilevel IRT' models non-Rasch (multilevel Rasch models technically require can built using fixed random inputs alone) itemdesign data.frame object used create design matrix items, nrow(itemdesign) == nitems number columns equal number fixed effect predictors (.e., item intercepts). default items variable reserved modeling item intercept parameters constrain list indicating parameter equality constrains. See mirt detail pars used parameter starting values. See mirt detail return.design logical; return design matrices (potentially) reassigned? SE logical; compute standard errors approximating information matrix using MHRM algorithm? Default TRUE internal_constraints logical; use internally defined constraints constraining effects across persons items? Default TRUE. Setting FALSE runs risk -identification technical technical list passed MH-RM estimation engine, SEtol default increased .0001. Additionally, argument RANDSTART available indicate iteration (burn-stage) additional random effect variables begin approximated (.e., elements lr.random random). default RANDSTART start iteration 100, random effects included default number burn-iterations increased 150 200. See mirt details ... additional arguments passed MH-RM estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"function returns object class MixedClass   (MixedClass-class).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"dichotomous response models, mixedmirt follows general form $$P(x = 1|\\theta, \\psi) = g + \\frac{(u - g)}{1 + exp(-1 * [\\theta +  X \\beta + Z \\delta])}$$ X design matrix associated \\(\\beta\\) fixed effect intercept coefficients,  Z design matrix associated \\(\\delta\\) random effects intercepts.  simplicity easier interpretation, unique item intercept values typically found  \\(X \\beta\\)  extracted reassigned within mirt's 'intercept' parameters (e.g., 'd').  observe design matrices structured prior reassignment estimation pass  argument return.design = TRUE. Polytomous IRT models follow similar format except item intercepts automatically  estimated internally, rendering items argument fixed formula redundant  therefore must omitted specification. mixture dichotomous  polytomous items intercepts dichotomous models also estimated consistency. decomposition \\(\\theta\\) parameters also possible form  latent regression multilevel IRT models using lr.fixed lr.random  inputs. effects decompose \\(\\theta\\) $$\\theta = V \\Gamma + W \\zeta + \\epsilon$$ V W fixed random effects design matrices associated coefficients. simulate expected posteriori predictions random effect terms  use randef function.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mixedmirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixed effects modeling for MIRT models — mixedmirt","text":"","code":"# \\donttest{  # make some data set.seed(1234) N <- 750 a <- matrix(rlnorm(10,.3,1),10,1) d <- matrix(rnorm(10), 10) Theta <- matrix(sort(rnorm(N))) pseudoIQ <- Theta * 5 + 100  + rnorm(N, 0 , 5) pseudoIQ <- (pseudoIQ - mean(pseudoIQ))/10  #rescale variable for numerical stability group <- factor(rep(c('G1','G2','G3'), each = N/3)) data <- simdata(a,d,N, itemtype = rep('2PL',10), Theta=Theta) covdata <- data.frame(group, pseudoIQ)  itemstats(data) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  750            4.655          2.346 0.166 0.133 0.671     1.345 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  750 2 0.363 0.481   0.368         0.172       0.678 #> Item_2  750 2 0.335 0.472   0.631         0.485       0.617 #> Item_3  750 2 0.428 0.495   0.711         0.580       0.594 #> Item_4  750 2 0.512 0.500   0.234         0.021       0.708 #> Item_5  750 2 0.628 0.484   0.638         0.490       0.615 #> Item_6  750 2 0.472 0.500   0.669         0.523       0.607 #> Item_7  750 2 0.385 0.487   0.471         0.286       0.657 #> Item_8  750 2 0.301 0.459   0.483         0.312       0.651 #> Item_9  750 2 0.319 0.466   0.481         0.307       0.652 #> Item_10 750 2 0.912 0.283   0.295         0.180       0.670 #>  #> $proportions #>             0     1 #> Item_1  0.637 0.363 #> Item_2  0.665 0.335 #> Item_3  0.572 0.428 #> Item_4  0.488 0.512 #> Item_5  0.372 0.628 #> Item_6  0.528 0.472 #> Item_7  0.615 0.385 #> Item_8  0.699 0.301 #> Item_9  0.681 0.319 #> Item_10 0.088 0.912 #>   # use parallel computing if(interactive()) mirtCluster()  # specify IRT model model <- 'Theta = 1-10'  # model with no person predictors mod0 <- mirt(data, model, itemtype = 'Rasch') #>   # group as a fixed effect predictor (aka, uniform dif) mod1 <- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1804, Max-Change = 0.1582, Max-Change = 0.1359, Max-Change = 0.1172, Max-Change = 0.1000, Max-Change = 0.0848, Max-Change = 0.0698, Max-Change = 0.0570, Max-Change = 0.0459, Max-Change = 0.0370, Max-Change = 0.0293, Max-Change = 0.0246, Max-Change = 0.0201, Max-Change = 0.0183, Max-Change = 0.0156, Max-Change = 0.0103, Max-Change = 0.0106, Max-Change = 0.0098, Max-Change = 0.0093, Max-Change = 0.0055, Max-Change = 0.0062, Max-Change = 0.0108, Max-Change = 0.0065, Max-Change = 0.0076, Max-Change = 0.0137, Max-Change = 0.0067, Max-Change = 0.0036, Max-Change = 0.0023, Max-Change = 0.0095, Max-Change = 0.0108, Max-Change = 0.0141, Max-Change = 0.0083, Max-Change = 0.0064, Max-Change = 0.0056, Max-Change = 0.0151, Max-Change = 0.0066, Max-Change = 0.0049, Max-Change = 0.0097, Max-Change = 0.0052, Max-Change = 0.0064, Max-Change = 0.0080, Max-Change = 0.0028, Max-Change = 0.0076, Max-Change = 0.0055, Max-Change = 0.0063, Max-Change = 0.0047, Max-Change = 0.0077, Max-Change = 0.0048, Max-Change = 0.0053, Max-Change = 0.0095, Max-Change = 0.0085, Max-Change = 0.0055, Max-Change = 0.0095, Max-Change = 0.0115, Max-Change = 0.0062, Max-Change = 0.0076, Max-Change = 0.0043, Max-Change = 0.0053, Max-Change = 0.0035, Max-Change = 0.0064, Max-Change = 0.0078, Max-Change = 0.0051, Max-Change = 0.0046, Max-Change = 0.0057, Max-Change = 0.0020, Max-Change = 0.0050, Max-Change = 0.0058, Max-Change = 0.0027, Max-Change = 0.0093, Max-Change = 0.0032, Max-Change = 0.0042, Max-Change = 0.0052, Max-Change = 0.0036, Max-Change = 0.0018, Max-Change = 0.0045, Max-Change = 0.0024, Max-Change = 0.0042, Max-Change = 0.0082, Max-Change = 0.0086, Max-Change = 0.0041, Max-Change = 0.0053, Max-Change = 0.0045, Max-Change = 0.0170, Max-Change = 0.0099, Max-Change = 0.0101, Max-Change = 0.0036, Max-Change = 0.0036, Max-Change = 0.0038, Max-Change = 0.0076, Max-Change = 0.0062, Max-Change = 0.0065, Max-Change = 0.0065, Max-Change = 0.0056, Max-Change = 0.0076, Max-Change = 0.0084, Max-Change = 0.0055, Max-Change = 0.0083, Max-Change = 0.0023, Max-Change = 0.0065, Max-Change = 0.0067, Max-Change = 0.0066, Max-Change = 0.0082, Max-Change = 0.0057, Max-Change = 0.0032, Max-Change = 0.0022, Max-Change = 0.0035, Max-Change = 0.0064, Max-Change = 0.0047, Max-Change = 0.0093, Max-Change = 0.0073, Max-Change = 0.0025, Max-Change = 0.0040, Max-Change = 0.0090, Max-Change = 0.0089, Max-Change = 0.0055, Max-Change = 0.0073, Max-Change = 0.0068, Max-Change = 0.0070, Max-Change = 0.0012, Max-Change = 0.0116, Max-Change = 0.0067, Max-Change = 0.0072, Max-Change = 0.0057, Max-Change = 0.0018, Max-Change = 0.0095, Max-Change = 0.0058, Max-Change = 0.0035, Max-Change = 0.0024, Max-Change = 0.0059, Max-Change = 0.0059, Max-Change = 0.0058, Max-Change = 0.0080, Max-Change = 0.0033, Max-Change = 0.0074, Max-Change = 0.0073, Max-Change = 0.0078, Max-Change = 0.0066, Max-Change = 0.0064, Max-Change = 0.0035, Max-Change = 0.0048, Max-Change = 0.0064, Max-Change = 0.0050, Max-Change = 0.0039, Max-Change = 0.0038, Max-Change = 0.0065, Max-Change = 0.0068, Max-Change = 0.0092, Max-Change = 0.0043, Max-Change = 0.0068, Max-Change = 0.0037, Max-Change = 0.0050, Max-Change = 0.0054, Max-Change = 0.0032, Max-Change = 0.0052, Max-Change = 0.0028, Max-Change = 0.0067, Max-Change = 0.0052, Max-Change = 0.0035, Max-Change = 0.0057, Max-Change = 0.0049, Max-Change = 0.0056, Max-Change = 0.0030, Max-Change = 0.0007, Max-Change = 0.0016, Max-Change = 0.0075, Max-Change = 0.0040, Max-Change = 0.0058, Max-Change = 0.0023, Max-Change = 0.0035, Max-Change = 0.0011, Max-Change = 0.0046, Max-Change = 0.0061, Max-Change = 0.0018, Max-Change = 0.0095, Max-Change = 0.0076, Max-Change = 0.0073, Max-Change = 0.0022, Max-Change = 0.0035, Max-Change = 0.0048, Max-Change = 0.0053, Max-Change = 0.0102, Max-Change = 0.0054, Max-Change = 0.0048, Max-Change = 0.0028, Max-Change = 0.0055, Max-Change = 0.0081, Max-Change = 0.0010, Max-Change = 0.0050, Max-Change = 0.0072, Max-Change = 0.0047, Max-Change = 0.0100, Max-Change = 0.0074, Max-Change = 0.0054, Max-Change = 0.0040, Max-Change = 0.0051, Max-Change = 0.0031, Max-Change = 0.0062, Max-Change = 0.0077, Max-Change = 0.0071, Max-Change = 0.0033, Max-Change = 0.0062, Max-Change = 0.0026, Max-Change = 0.0040, Max-Change = 0.0086, Max-Change = 0.0046, Max-Change = 0.0067, Max-Change = 0.0048, Max-Change = 0.0070, Max-Change = 0.0062, Max-Change = 0.0078, Max-Change = 0.0077, Max-Change = 0.0041, Max-Change = 0.0018, Max-Change = 0.0074, Max-Change = 0.0023, Max-Change = 0.0036, Max-Change = 0.0037, Max-Change = 0.0045, Max-Change = 0.0059, Max-Change = 0.0057, Max-Change = 0.0042, Max-Change = 0.0059, Max-Change = 0.0054, Max-Change = 0.0096, Max-Change = 0.0061, Max-Change = 0.0041, Max-Change = 0.0048, Max-Change = 0.0029, Max-Change = 0.0087, Max-Change = 0.0017, Max-Change = 0.0022, Max-Change = 0.0036, Max-Change = 0.0031, Max-Change = 0.0031, Max-Change = 0.0025, Max-Change = 0.0085, Max-Change = 0.0045, Max-Change = 0.0064, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0048, gam = 0.1057, Max-Change = 0.0032, gam = 0.0780, Max-Change = 0.0010, gam = 0.0629, Max-Change = 0.0022, gam = 0.0532, Max-Change = 0.0012, gam = 0.0464, Max-Change = 0.0022, gam = 0.0413, Max-Change = 0.0008, gam = 0.0374, Max-Change = 0.0012, gam = 0.0342, Max-Change = 0.0016, gam = 0.0316, Max-Change = 0.0006, gam = 0.0294, Max-Change = 0.0006, gam = 0.0276, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... anova(mod0, mod1) #>           AIC    SABIC       HQ      BIC    logLik      X2 df p #> mod0 8799.543 8815.435 8819.126 8850.364 -4388.772              #> mod1 8111.326 8130.107 8134.469 8171.387 -4042.663 692.217  2 0 summary(mod1) #>  #> Call: #> mixedmirt(data = data, covdata = covdata, model = model, fixed = ~0 +  #>     group + items) #>  #> -------------- #> FIXED EFFECTS: #>         Estimate Std.Error z.value #> groupG1   -1.858     0.100 -18.495 #> groupG2   -0.748     0.094  -7.979 #> groupG3    0.515     0.094   5.493 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       Theta #> Theta 0.118 #>  coef(mod1) #> $Item_1 #>         groupG1 groupG2 groupG3 a1  d  g  u #> par      -1.858  -0.748   0.515  1  0  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA NA NA NA #> CI_97.5  -1.661  -0.564   0.699 NA NA NA NA #>  #> $Item_2 #>         groupG1 groupG2 groupG3 a1      d  g  u #> par      -1.858  -0.748   0.515  1 -0.152  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA -0.388 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA  0.084 NA NA #>  #> $Item_3 #>         groupG1 groupG2 groupG3 a1     d  g  u #> par      -1.858  -0.748   0.515  1 0.340  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA 0.109 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA 0.572 NA NA #>  #> $Item_4 #>         groupG1 groupG2 groupG3 a1     d  g  u #> par      -1.858  -0.748   0.515  1 0.763  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA 0.532 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA 0.994 NA NA #>  #> $Item_5 #>         groupG1 groupG2 groupG3 a1     d  g  u #> par      -1.858  -0.748   0.515  1 1.353  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA 1.119 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA 1.588 NA NA #>  #> $Item_6 #>         groupG1 groupG2 groupG3 a1     d  g  u #> par      -1.858  -0.748   0.515  1 0.563  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA 0.332 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA 0.793 NA NA #>  #> $Item_7 #>         groupG1 groupG2 groupG3 a1      d  g  u #> par      -1.858  -0.748   0.515  1  0.120  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA -0.113 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA  0.353 NA NA #>  #> $Item_8 #>         groupG1 groupG2 groupG3 a1      d  g  u #> par      -1.858  -0.748   0.515  1 -0.339  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA -0.578 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA -0.101 NA NA #>  #> $Item_9 #>         groupG1 groupG2 groupG3 a1      d  g  u #> par      -1.858  -0.748   0.515  1 -0.241  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA -0.478 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA -0.004 NA NA #>  #> $Item_10 #>         groupG1 groupG2 groupG3 a1     d  g  u #> par      -1.858  -0.748   0.515  1 3.432  0  1 #> CI_2.5   -2.055  -0.931   0.331 NA 3.117 NA NA #> CI_97.5  -1.661  -0.564   0.699 NA 3.747 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0  0.118 #> CI_2.5      NA  0.072 #> CI_97.5     NA  0.164 #>   if (FALSE) { # \\dontrun{ # same model as above in lme4 wide <- data.frame(id=1:nrow(data),data,covdata) long <- reshape2::melt(wide, id.vars = c('id', 'group', 'pseudoIQ')) library(lme4) lmod0 <- glmer(value ~ 0 + variable + (1|id), long, family = binomial) lmod1 <- glmer(value ~ 0 + group + variable + (1|id), long, family = binomial) anova(lmod0, lmod1) } # }  # model using 2PL items instead of Rasch mod1b <- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items, itemtype = '2PL') #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1860, Max-Change = 0.1696, Max-Change = 0.1434, Max-Change = 0.1281, Max-Change = 0.1024, Max-Change = 0.0980, Max-Change = 0.0816, Max-Change = 0.0806, Max-Change = 0.0636, Max-Change = 0.0644, Max-Change = 0.0457, Max-Change = 0.0484, Max-Change = 0.0573, Max-Change = 0.0544, Max-Change = 0.0444, Max-Change = 0.0289, Max-Change = 0.0242, Max-Change = 0.0313, Max-Change = 0.0332, Max-Change = 0.0317, Max-Change = 0.0343, Max-Change = 0.0348, Max-Change = 0.0514, Max-Change = 0.0715, Max-Change = 0.0273, Max-Change = 0.0443, Max-Change = 0.0254, Max-Change = 0.0261, Max-Change = 0.0364, Max-Change = 0.0200, Max-Change = 0.0392, Max-Change = 0.0491, Max-Change = 0.0365, Max-Change = 0.0491, Max-Change = 0.0339, Max-Change = 0.0376, Max-Change = 0.0239, Max-Change = 0.0464, Max-Change = 0.0513, Max-Change = 0.0378, Max-Change = 0.0793, Max-Change = 0.0370, Max-Change = 0.0447, Max-Change = 0.0359, Max-Change = 0.0696, Max-Change = 0.0790, Max-Change = 0.0264, Max-Change = 0.0346, Max-Change = 0.0233, Max-Change = 0.0334, Max-Change = 0.0345, Max-Change = 0.0441, Max-Change = 0.0441, Max-Change = 0.0380, Max-Change = 0.0255, Max-Change = 0.0391, Max-Change = 0.0394, Max-Change = 0.0293, Max-Change = 0.0720, Max-Change = 0.0462, Max-Change = 0.0417, Max-Change = 0.0285, Max-Change = 0.0245, Max-Change = 0.0603, Max-Change = 0.0343, Max-Change = 0.0166, Max-Change = 0.0561, Max-Change = 0.0314, Max-Change = 0.0257, Max-Change = 0.0314, Max-Change = 0.0342, Max-Change = 0.0598, Max-Change = 0.0402, Max-Change = 0.0349, Max-Change = 0.0471, Max-Change = 0.0189, Max-Change = 0.0324, Max-Change = 0.0257, Max-Change = 0.0750, Max-Change = 0.0510, Max-Change = 0.0721, Max-Change = 0.0339, Max-Change = 0.0547, Max-Change = 0.0469, Max-Change = 0.0607, Max-Change = 0.0375, Max-Change = 0.0417, Max-Change = 0.0378, Max-Change = 0.0610, Max-Change = 0.0517, Max-Change = 0.0244, Max-Change = 0.0349, Max-Change = 0.0239, Max-Change = 0.0503, Max-Change = 0.0232, Max-Change = 0.0854, Max-Change = 0.0282, Max-Change = 0.0397, Max-Change = 0.0406, Max-Change = 0.0820, Max-Change = 0.0267, Max-Change = 0.0839, Max-Change = 0.0307, Max-Change = 0.0237, Max-Change = 0.0285, Max-Change = 0.1084, Max-Change = 0.1160, Max-Change = 0.0390, Max-Change = 0.0355, Max-Change = 0.0703, Max-Change = 0.0391, Max-Change = 0.0954, Max-Change = 0.0553, Max-Change = 0.0308, Max-Change = 0.0652, Max-Change = 0.0169, Max-Change = 0.0664, Max-Change = 0.1173, Max-Change = 0.0311, Max-Change = 0.0509, Max-Change = 0.1200, Max-Change = 0.0904, Max-Change = 0.1736, Max-Change = 0.0696, Max-Change = 0.0348, Max-Change = 0.0707, Max-Change = 0.0487, Max-Change = 0.0574, Max-Change = 0.0342, Max-Change = 0.0850, Max-Change = 0.0477, Max-Change = 0.0656, Max-Change = 0.0731, Max-Change = 0.0842, Max-Change = 0.1089, Max-Change = 0.0266, Max-Change = 0.1092, Max-Change = 0.0731, Max-Change = 0.0200, Max-Change = 0.0487, Max-Change = 0.0573, Max-Change = 0.1227, Max-Change = 0.0633, Max-Change = 0.0499, Max-Change = 0.0307, Max-Change = 0.1556, Max-Change = 0.0620, Max-Change = 0.0445, Max-Change = 0.1713, Max-Change = 0.0844, Max-Change = 0.0719, Max-Change = 0.0258, Max-Change = 0.0742, Max-Change = 0.0565, Max-Change = 0.0339, Max-Change = 0.0182, Max-Change = 0.0373, Max-Change = 0.1227, Max-Change = 0.0404, Max-Change = 0.0894, Max-Change = 0.0172, Max-Change = 0.1133, Max-Change = 0.0502, Max-Change = 0.0338, Max-Change = 0.0758, Max-Change = 0.0635, Max-Change = 0.0280, Max-Change = 0.0781, Max-Change = 0.0398, Max-Change = 0.0805, Max-Change = 0.1266, Max-Change = 0.1815, Max-Change = 0.0498, Max-Change = 0.0387, Max-Change = 0.0311, Max-Change = 0.0463, Max-Change = 0.1127, Max-Change = 0.0519, Max-Change = 0.1120, Max-Change = 0.2000, Max-Change = 0.0178, Max-Change = 0.0509, Max-Change = 0.1411, Max-Change = 0.1258, Max-Change = 0.0486, Max-Change = 0.0713, Max-Change = 0.0751, Max-Change = 0.1150, Max-Change = 0.0370, Max-Change = 0.1355, Max-Change = 0.2000, Max-Change = 0.1107, Max-Change = 0.0404, Max-Change = 0.1141, Max-Change = 0.1374, Max-Change = 0.1567, Max-Change = 0.0502, Max-Change = 0.0305, Max-Change = 0.0899, Max-Change = 0.0245, Max-Change = 0.0828, Max-Change = 0.1181, Max-Change = 0.0241, Max-Change = 0.0989, Max-Change = 0.1326, Max-Change = 0.0390, Max-Change = 0.1871, Max-Change = 0.0252, Max-Change = 0.0234, Max-Change = 0.0791, Max-Change = 0.1058, Max-Change = 0.0712, Max-Change = 0.1591, Max-Change = 0.0433, Max-Change = 0.0432, Max-Change = 0.0488, Max-Change = 0.1257, Max-Change = 0.2000, Max-Change = 0.1857, Max-Change = 0.0790, Max-Change = 0.0391, Max-Change = 0.0559, Max-Change = 0.2000, Max-Change = 0.1776, Max-Change = 0.0181, Max-Change = 0.0494, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1295, Max-Change = 0.1152, Max-Change = 0.2000, Max-Change = 0.1530, Max-Change = 0.0186, Max-Change = 0.1586, Max-Change = 0.0536, Max-Change = 0.0350, Max-Change = 0.0466, Max-Change = 0.0195, Max-Change = 0.0606, Max-Change = 0.1190, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.1087, gam = 0.1057, Max-Change = 0.0780, gam = 0.0780, Max-Change = 0.0283, gam = 0.0629, Max-Change = 0.0549, gam = 0.0532, Max-Change = 0.0181, gam = 0.0464, Max-Change = 0.0171, gam = 0.0413, Max-Change = 0.0038, gam = 0.0374, Max-Change = 0.0220, gam = 0.0342, Max-Change = 0.0112, gam = 0.0316, Max-Change = 0.0208, gam = 0.0294, Max-Change = 0.0122, gam = 0.0276, Max-Change = 0.0115, gam = 0.0260, Max-Change = 0.0075, gam = 0.0246, Max-Change = 0.0027, gam = 0.0233, Max-Change = 0.0056, gam = 0.0222, Max-Change = 0.0078, gam = 0.0212, Max-Change = 0.0072, gam = 0.0203, Max-Change = 0.0164, gam = 0.0195, Max-Change = 0.0044, gam = 0.0188, Max-Change = 0.0097, gam = 0.0181, Max-Change = 0.0156, gam = 0.0175, Max-Change = 0.0020, gam = 0.0169, Max-Change = 0.0043, gam = 0.0164, Max-Change = 0.0047, gam = 0.0159, Max-Change = 0.0035, gam = 0.0154, Max-Change = 0.0101, gam = 0.0150, Max-Change = 0.0149, gam = 0.0146, Max-Change = 0.0065, gam = 0.0142, Max-Change = 0.0078, gam = 0.0139, Max-Change = 0.0128, gam = 0.0135, Max-Change = 0.0101, gam = 0.0132, Max-Change = 0.0038, gam = 0.0129, Max-Change = 0.0029, gam = 0.0126, Max-Change = 0.0119, gam = 0.0124, Max-Change = 0.0033, gam = 0.0121, Max-Change = 0.0080, gam = 0.0119, Max-Change = 0.0169, gam = 0.0116, Max-Change = 0.0034, gam = 0.0114, Max-Change = 0.0056, gam = 0.0112, Max-Change = 0.0060, gam = 0.0110, Max-Change = 0.0023, gam = 0.0108, Max-Change = 0.0043, gam = 0.0106, Max-Change = 0.0020, gam = 0.0104, Max-Change = 0.0057, gam = 0.0102, Max-Change = 0.0074, gam = 0.0101, Max-Change = 0.0063, gam = 0.0099, Max-Change = 0.0016, gam = 0.0098, Max-Change = 0.0024, gam = 0.0096, Max-Change = 0.0020, gam = 0.0095, Max-Change = 0.0067, gam = 0.0093, Max-Change = 0.0017, gam = 0.0092, Max-Change = 0.0083, gam = 0.0091, Max-Change = 0.0015, gam = 0.0089, Max-Change = 0.0056, gam = 0.0088, Max-Change = 0.0027, gam = 0.0087, Max-Change = 0.0033, gam = 0.0086, Max-Change = 0.0011, gam = 0.0085, Max-Change = 0.0055, gam = 0.0084, Max-Change = 0.0023, gam = 0.0082, Max-Change = 0.0023, gam = 0.0081, Max-Change = 0.0026, gam = 0.0080, Max-Change = 0.0037, gam = 0.0080, Max-Change = 0.0017, gam = 0.0079, Max-Change = 0.0048, gam = 0.0078, Max-Change = 0.0043, gam = 0.0077, Max-Change = 0.0037, gam = 0.0076, Max-Change = 0.0094, gam = 0.0075, Max-Change = 0.0067, gam = 0.0074, Max-Change = 0.0068, gam = 0.0073, Max-Change = 0.0047, gam = 0.0073, Max-Change = 0.0012, gam = 0.0072, Max-Change = 0.0018, gam = 0.0071, Max-Change = 0.0062, gam = 0.0070, Max-Change = 0.0020, gam = 0.0070, Max-Change = 0.0033, gam = 0.0069, Max-Change = 0.0012, gam = 0.0068, Max-Change = 0.0033, gam = 0.0068, Max-Change = 0.0062, gam = 0.0067, Max-Change = 0.0011, gam = 0.0066, Max-Change = 0.0029, gam = 0.0066, Max-Change = 0.0041, gam = 0.0065, Max-Change = 0.0012, gam = 0.0065, Max-Change = 0.0057, gam = 0.0064, Max-Change = 0.0021, gam = 0.0064, Max-Change = 0.0071, gam = 0.0063, Max-Change = 0.0066, gam = 0.0062, Max-Change = 0.0013, gam = 0.0062, Max-Change = 0.0006, gam = 0.0061, Max-Change = 0.0019, gam = 0.0061, Max-Change = 0.0009, gam = 0.0060, Max-Change = 0.0007, gam = 0.0060, Max-Change = 0.0083, gam = 0.0059, Max-Change = 0.0034, gam = 0.0059, Max-Change = 0.0028, gam = 0.0058, Max-Change = 0.0063, gam = 0.0058, Max-Change = 0.0073, gam = 0.0058, Max-Change = 0.0037, gam = 0.0057, Max-Change = 0.0018, gam = 0.0057, Max-Change = 0.0017, gam = 0.0056, Max-Change = 0.0037, gam = 0.0056, Max-Change = 0.0027, gam = 0.0055, Max-Change = 0.0012, gam = 0.0055, Max-Change = 0.0006, gam = 0.0055, Max-Change = 0.0031, gam = 0.0054, Max-Change = 0.0048, gam = 0.0054, Max-Change = 0.0019, gam = 0.0053, Max-Change = 0.0032, gam = 0.0053, Max-Change = 0.0005, gam = 0.0053, Max-Change = 0.0049, gam = 0.0052, Max-Change = 0.0029, gam = 0.0052, Max-Change = 0.0023, gam = 0.0052, Max-Change = 0.0056, gam = 0.0051, Max-Change = 0.0060, gam = 0.0051, Max-Change = 0.0031, gam = 0.0051, Max-Change = 0.0050, gam = 0.0050, Max-Change = 0.0049, gam = 0.0050, Max-Change = 0.0009, gam = 0.0050, Max-Change = 0.0036, gam = 0.0049, Max-Change = 0.0055, gam = 0.0049, Max-Change = 0.0032, gam = 0.0049, Max-Change = 0.0043, gam = 0.0048, Max-Change = 0.0007, gam = 0.0048, Max-Change = 0.0024, gam = 0.0048, Max-Change = 0.0019, gam = 0.0048, Max-Change = 0.0025, gam = 0.0047, Max-Change = 0.0025, gam = 0.0047, Max-Change = 0.0007, gam = 0.0047, Max-Change = 0.0005, gam = 0.0046, Max-Change = 0.0008 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... anova(mod1, mod1b) #better with 2PL models using all criteria (as expected, given simdata pars) #>            AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod1  8111.326 8130.107 8134.469 8171.387 -4042.663             #> mod1b 7975.487 8007.270 8014.651 8077.128 -3965.743 153.84  9 0  # continuous predictor with group mod2 <- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items + pseudoIQ) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1807, Max-Change = 0.1593, Max-Change = 0.1350, Max-Change = 0.1155, Max-Change = 0.1001, Max-Change = 0.0861, Max-Change = 0.0702, Max-Change = 0.0585, Max-Change = 0.0465, Max-Change = 0.0362, Max-Change = 0.0292, Max-Change = 0.0245, Max-Change = 0.0166, Max-Change = 0.0178, Max-Change = 0.0144, Max-Change = 0.0085, Max-Change = 0.0130, Max-Change = 0.0096, Max-Change = 0.0103, Max-Change = 0.0061, Max-Change = 0.0049, Max-Change = 0.0084, Max-Change = 0.0113, Max-Change = 0.0152, Max-Change = 0.0156, Max-Change = 0.0068, Max-Change = 0.0083, Max-Change = 0.0068, Max-Change = 0.0079, Max-Change = 0.0075, Max-Change = 0.0149, Max-Change = 0.0082, Max-Change = 0.0035, Max-Change = 0.0157, Max-Change = 0.0115, Max-Change = 0.0088, Max-Change = 0.0055, Max-Change = 0.0128, Max-Change = 0.0083, Max-Change = 0.0046, Max-Change = 0.0066, Max-Change = 0.0040, Max-Change = 0.0086, Max-Change = 0.0020, Max-Change = 0.0069, Max-Change = 0.0051, Max-Change = 0.0081, Max-Change = 0.0034, Max-Change = 0.0156, Max-Change = 0.0074, Max-Change = 0.0066, Max-Change = 0.0084, Max-Change = 0.0088, Max-Change = 0.0151, Max-Change = 0.0069, Max-Change = 0.0178, Max-Change = 0.0042, Max-Change = 0.0129, Max-Change = 0.0094, Max-Change = 0.0068, Max-Change = 0.0076, Max-Change = 0.0032, Max-Change = 0.0093, Max-Change = 0.0067, Max-Change = 0.0026, Max-Change = 0.0060, Max-Change = 0.0056, Max-Change = 0.0064, Max-Change = 0.0079, Max-Change = 0.0038, Max-Change = 0.0052, Max-Change = 0.0105, Max-Change = 0.0046, Max-Change = 0.0047, Max-Change = 0.0059, Max-Change = 0.0055, Max-Change = 0.0067, Max-Change = 0.0072, Max-Change = 0.0068, Max-Change = 0.0074, Max-Change = 0.0033, Max-Change = 0.0105, Max-Change = 0.0133, Max-Change = 0.0075, Max-Change = 0.0087, Max-Change = 0.0052, Max-Change = 0.0040, Max-Change = 0.0056, Max-Change = 0.0094, Max-Change = 0.0095, Max-Change = 0.0116, Max-Change = 0.0043, Max-Change = 0.0044, Max-Change = 0.0038, Max-Change = 0.0096, Max-Change = 0.0055, Max-Change = 0.0047, Max-Change = 0.0035, Max-Change = 0.0089, Max-Change = 0.0055, Max-Change = 0.0059, Max-Change = 0.0088, Max-Change = 0.0103, Max-Change = 0.0040, Max-Change = 0.0033, Max-Change = 0.0102, Max-Change = 0.0063, Max-Change = 0.0033, Max-Change = 0.0072, Max-Change = 0.0095, Max-Change = 0.0037, Max-Change = 0.0092, Max-Change = 0.0103, Max-Change = 0.0058, Max-Change = 0.0068, Max-Change = 0.0071, Max-Change = 0.0047, Max-Change = 0.0138, Max-Change = 0.0077, Max-Change = 0.0070, Max-Change = 0.0086, Max-Change = 0.0091, Max-Change = 0.0099, Max-Change = 0.0031, Max-Change = 0.0124, Max-Change = 0.0060, Max-Change = 0.0074, Max-Change = 0.0038, Max-Change = 0.0101, Max-Change = 0.0044, Max-Change = 0.0073, Max-Change = 0.0048, Max-Change = 0.0057, Max-Change = 0.0058, Max-Change = 0.0079, Max-Change = 0.0054, Max-Change = 0.0106, Max-Change = 0.0074, Max-Change = 0.0023, Max-Change = 0.0120, Max-Change = 0.0061, Max-Change = 0.0063, Max-Change = 0.0069, Max-Change = 0.0075, Max-Change = 0.0097, Max-Change = 0.0032, Max-Change = 0.0077, Max-Change = 0.0058, Max-Change = 0.0041, Max-Change = 0.0022, Max-Change = 0.0034, Max-Change = 0.0067, Max-Change = 0.0071, Max-Change = 0.0055, Max-Change = 0.0043, Max-Change = 0.0030, Max-Change = 0.0056, Max-Change = 0.0043, Max-Change = 0.0119, Max-Change = 0.0053, Max-Change = 0.0059, Max-Change = 0.0087, Max-Change = 0.0026, Max-Change = 0.0041, Max-Change = 0.0052, Max-Change = 0.0077, Max-Change = 0.0074, Max-Change = 0.0031, Max-Change = 0.0066, Max-Change = 0.0108, Max-Change = 0.0058, Max-Change = 0.0067, Max-Change = 0.0018, Max-Change = 0.0069, Max-Change = 0.0096, Max-Change = 0.0059, Max-Change = 0.0066, Max-Change = 0.0018, Max-Change = 0.0049, Max-Change = 0.0040, Max-Change = 0.0106, Max-Change = 0.0046, Max-Change = 0.0021, Max-Change = 0.0047, Max-Change = 0.0034, Max-Change = 0.0067, Max-Change = 0.0070, Max-Change = 0.0061, Max-Change = 0.0059, Max-Change = 0.0024, Max-Change = 0.0069, Max-Change = 0.0041, Max-Change = 0.0036, Max-Change = 0.0061, Max-Change = 0.0058, Max-Change = 0.0057, Max-Change = 0.0072, Max-Change = 0.0068, Max-Change = 0.0071, Max-Change = 0.0056, Max-Change = 0.0109, Max-Change = 0.0047, Max-Change = 0.0063, Max-Change = 0.0082, Max-Change = 0.0020, Max-Change = 0.0107, Max-Change = 0.0032, Max-Change = 0.0050, Max-Change = 0.0109, Max-Change = 0.0056, Max-Change = 0.0076, Max-Change = 0.0024, Max-Change = 0.0072, Max-Change = 0.0038, Max-Change = 0.0062, Max-Change = 0.0041, Max-Change = 0.0049, Max-Change = 0.0037, Max-Change = 0.0042, Max-Change = 0.0044, Max-Change = 0.0017, Max-Change = 0.0054, Max-Change = 0.0066, Max-Change = 0.0098, Max-Change = 0.0067, Max-Change = 0.0066, Max-Change = 0.0087, Max-Change = 0.0095, Max-Change = 0.0073, Max-Change = 0.0092, Max-Change = 0.0051, Max-Change = 0.0043, Max-Change = 0.0059, Max-Change = 0.0057, Max-Change = 0.0041, Max-Change = 0.0052, Max-Change = 0.0076, Max-Change = 0.0058, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0043, gam = 0.1057, Max-Change = 0.0022, gam = 0.0780, Max-Change = 0.0015, gam = 0.0629, Max-Change = 0.0023, gam = 0.0532, Max-Change = 0.0019, gam = 0.0464, Max-Change = 0.0010, gam = 0.0413, Max-Change = 0.0004, gam = 0.0374, Max-Change = 0.0012, gam = 0.0342, Max-Change = 0.0014, gam = 0.0316, Max-Change = 0.0007, gam = 0.0294, Max-Change = 0.0007, gam = 0.0276, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod2) #>  #> Call: #> mixedmirt(data = data, covdata = covdata, model = model, fixed = ~0 +  #>     group + items + pseudoIQ) #>  #> -------------- #> FIXED EFFECTS: #>          Estimate Std.Error z.value #> groupG1    -1.711     0.105 -16.317 #> groupG2    -0.750     0.093  -8.029 #> groupG3     0.366     0.099   3.714 #> pseudoIQ    0.268     0.058   4.594 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       Theta #> Theta 0.105 #>  anova(mod1b, mod2) #>            AIC    SABIC       HQ      BIC    logLik       X2 df   p #> mod1b 7975.487 8007.270 8014.651 8077.128 -3965.743                 #> mod2  8090.269 8110.494 8115.192 8154.950 -4031.134 -130.782 -8 NaN  # view fixed design matrix with and without unique item level intercepts withint <- mixedmirt(data, covdata, model, fixed = ~ 0 + items + group, return.design = TRUE) withoutint <- mixedmirt(data, covdata, model, fixed = ~ 0 + group, return.design = TRUE)  # notice that in result above, the intercepts 'items1 to items 10' were reassigned to 'd' head(withint$X) #>     items1 items2 items3 items4 items5 items6 items7 items8 items9 items10 #> 1.1      1      0      0      0      0      0      0      0      0       0 #> 2.1      1      0      0      0      0      0      0      0      0       0 #> 3.1      1      0      0      0      0      0      0      0      0       0 #> 4.1      1      0      0      0      0      0      0      0      0       0 #> 5.1      1      0      0      0      0      0      0      0      0       0 #> 6.1      1      0      0      0      0      0      0      0      0       0 #>     groupG2 groupG3 #> 1.1       0       0 #> 2.1       0       0 #> 3.1       0       0 #> 4.1       0       0 #> 5.1       0       0 #> 6.1       0       0 tail(withint$X) #>        items1 items2 items3 items4 items5 items6 items7 items8 items9 items10 #> 745.10      0      0      0      0      0      0      0      0      0       1 #> 746.10      0      0      0      0      0      0      0      0      0       1 #> 747.10      0      0      0      0      0      0      0      0      0       1 #> 748.10      0      0      0      0      0      0      0      0      0       1 #> 749.10      0      0      0      0      0      0      0      0      0       1 #> 750.10      0      0      0      0      0      0      0      0      0       1 #>        groupG2 groupG3 #> 745.10       0       1 #> 746.10       0       1 #> 747.10       0       1 #> 748.10       0       1 #> 749.10       0       1 #> 750.10       0       1 head(withoutint$X) # no intercepts design here to be reassigned into item intercepts #>     groupG1 groupG2 groupG3 #> 1.1       1       0       0 #> 2.1       1       0       0 #> 3.1       1       0       0 #> 4.1       1       0       0 #> 5.1       1       0       0 #> 6.1       1       0       0 tail(withoutint$X) #>        groupG1 groupG2 groupG3 #> 745.10       0       0       1 #> 746.10       0       0       1 #> 747.10       0       0       1 #> 748.10       0       0       1 #> 749.10       0       0       1 #> 750.10       0       0       1  ################################################### ### random effects # make the number of groups much larger covdata$group <- factor(rep(paste0('G',1:50), each = N/50))  # random groups rmod1 <- mixedmirt(data, covdata, 1, fixed = ~ 0 + items, random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1864, Max-Change = 0.1623, Max-Change = 0.1436, Max-Change = 0.1243, Max-Change = 0.1035, Max-Change = 0.0953, Max-Change = 0.0862, Max-Change = 0.0730, Max-Change = 0.0612, Max-Change = 0.0490, Max-Change = 0.0426, Max-Change = 0.0342, Max-Change = 0.0359, Max-Change = 0.0255, Max-Change = 0.0251, Max-Change = 0.0175, Max-Change = 0.0105, Max-Change = 0.0121, Max-Change = 0.0184, Max-Change = 0.0194, Max-Change = 0.0092, Max-Change = 0.0064, Max-Change = 0.0083, Max-Change = 0.0065, Max-Change = 0.0026, Max-Change = 0.0066, Max-Change = 0.0110, Max-Change = 0.0004, Max-Change = 0.0044, Max-Change = 0.0104, Max-Change = 0.0118, Max-Change = 0.0071, Max-Change = 0.0056, Max-Change = 0.0073, Max-Change = 0.0134, Max-Change = 0.0043, Max-Change = 0.0143, Max-Change = 0.0042, Max-Change = 0.0109, Max-Change = 0.0061, Max-Change = 0.0096, Max-Change = 0.0130, Max-Change = 0.0158, Max-Change = 0.0124, Max-Change = 0.0075, Max-Change = 0.0080, Max-Change = 0.0056, Max-Change = 0.0025, Max-Change = 0.0109, Max-Change = 0.0030, Max-Change = 0.0135, Max-Change = 0.0156, Max-Change = 0.0136, Max-Change = 0.0085, Max-Change = 0.0083, Max-Change = 0.0118, Max-Change = 0.0017, Max-Change = 0.0074, Max-Change = 0.0278, Max-Change = 0.0030, Max-Change = 0.0086, Max-Change = 0.0053, Max-Change = 0.0006, Max-Change = 0.0139, Max-Change = 0.0106, Max-Change = 0.0060, Max-Change = 0.0048, Max-Change = 0.0084, Max-Change = 0.0076, Max-Change = 0.0094, Max-Change = 0.0090, Max-Change = 0.0120, Max-Change = 0.0036, Max-Change = 0.0029, Max-Change = 0.0089, Max-Change = 0.0036, Max-Change = 0.0030, Max-Change = 0.0074, Max-Change = 0.0044, Max-Change = 0.0153, Max-Change = 0.0043, Max-Change = 0.0295, Max-Change = 0.0054, Max-Change = 0.0105, Max-Change = 0.0154, Max-Change = 0.0094, Max-Change = 0.0021, Max-Change = 0.0077, Max-Change = 0.0113, Max-Change = 0.0035, Max-Change = 0.0045, Max-Change = 0.0065, Max-Change = 0.2000, Max-Change = 0.1344, Max-Change = 0.0744, Max-Change = 0.0786, Max-Change = 0.0581, Max-Change = 0.0426, Max-Change = 0.0315, Max-Change = 0.0381, Max-Change = 0.0227, Max-Change = 0.0228, Max-Change = 0.0159, Max-Change = 0.0193, Max-Change = 0.0112, Max-Change = 0.0092, Max-Change = 0.0150, Max-Change = 0.0126, Max-Change = 0.0093, Max-Change = 0.0185, Max-Change = 0.0088, Max-Change = 0.0108, Max-Change = 0.0167, Max-Change = 0.0128, Max-Change = 0.0118, Max-Change = 0.0094, Max-Change = 0.0056, Max-Change = 0.0258, Max-Change = 0.0316, Max-Change = 0.0118, Max-Change = 0.0106, Max-Change = 0.0198, Max-Change = 0.0252, Max-Change = 0.0309, Max-Change = 0.0159, Max-Change = 0.0162, Max-Change = 0.0087, Max-Change = 0.0045, Max-Change = 0.0110, Max-Change = 0.0057, Max-Change = 0.0069, Max-Change = 0.0039, Max-Change = 0.0225, Max-Change = 0.0115, Max-Change = 0.0144, Max-Change = 0.0102, Max-Change = 0.0078, Max-Change = 0.0102, Max-Change = 0.0065, Max-Change = 0.0275, Max-Change = 0.0248, Max-Change = 0.0045, Max-Change = 0.0114, Max-Change = 0.0065, Max-Change = 0.0160, Max-Change = 0.0145, Max-Change = 0.0068, Max-Change = 0.0129, Max-Change = 0.0116, Max-Change = 0.0161, Max-Change = 0.0138, Max-Change = 0.0076, Max-Change = 0.0139, Max-Change = 0.0116, Max-Change = 0.0067, Max-Change = 0.0162, Max-Change = 0.0228, Max-Change = 0.0090, Max-Change = 0.0079, Max-Change = 0.0054, Max-Change = 0.0223, Max-Change = 0.0171, Max-Change = 0.0075, Max-Change = 0.0105, Max-Change = 0.0246, Max-Change = 0.0028, Max-Change = 0.0061, Max-Change = 0.0095, Max-Change = 0.0026, Max-Change = 0.0123, Max-Change = 0.0207, Max-Change = 0.0063, Max-Change = 0.0044, Max-Change = 0.0084, Max-Change = 0.0051, Max-Change = 0.0050, Max-Change = 0.0085, Max-Change = 0.0051, Max-Change = 0.0207, Max-Change = 0.0080, Max-Change = 0.0121, Max-Change = 0.0258, Max-Change = 0.0036, Max-Change = 0.0144, Max-Change = 0.0108, Max-Change = 0.0057, Max-Change = 0.0055, Max-Change = 0.0196, Max-Change = 0.0071, Max-Change = 0.0062, Max-Change = 0.0077, Max-Change = 0.0068, Max-Change = 0.0187, Max-Change = 0.0174, Max-Change = 0.0161, Max-Change = 0.0129, Max-Change = 0.0047, Max-Change = 0.0088, Max-Change = 0.0096, Max-Change = 0.0171, Max-Change = 0.0073, Max-Change = 0.0098, Max-Change = 0.0079, Max-Change = 0.0198, Max-Change = 0.0111, Max-Change = 0.0425, Max-Change = 0.0146, Max-Change = 0.0073, Max-Change = 0.0110, Max-Change = 0.0258, Max-Change = 0.0168, Max-Change = 0.0345, Max-Change = 0.0010, Max-Change = 0.0187, Max-Change = 0.0113, Max-Change = 0.0134, Max-Change = 0.0198, Max-Change = 0.0027, Max-Change = 0.0127, Max-Change = 0.0065, Max-Change = 0.0132, Max-Change = 0.0139, Max-Change = 0.0045, Max-Change = 0.0400, Max-Change = 0.0098, Max-Change = 0.0053, Max-Change = 0.0015, Max-Change = 0.0103, Max-Change = 0.0102, Max-Change = 0.0054, Max-Change = 0.0199, Max-Change = 0.0100, Max-Change = 0.0041, Max-Change = 0.0184, Max-Change = 0.0145, Max-Change = 0.0103, Max-Change = 0.0038, Max-Change = 0.0143, Max-Change = 0.0152, Max-Change = 0.0110, Max-Change = 0.0068, Max-Change = 0.0118, Max-Change = 0.0066, Max-Change = 0.0130, Max-Change = 0.0208, Max-Change = 0.0037, Max-Change = 0.0121, Max-Change = 0.0141, Max-Change = 0.0072, Max-Change = 0.0143, Max-Change = 0.0123, Max-Change = 0.0070, Max-Change = 0.0035, Max-Change = 0.0055, Max-Change = 0.0196, Max-Change = 0.0027, Max-Change = 0.0068, Max-Change = 0.0078, Max-Change = 0.0070, Max-Change = 0.0023, Max-Change = 0.0069, Max-Change = 0.0069, Max-Change = 0.0115, Max-Change = 0.0052, Max-Change = 0.0048, Max-Change = 0.0232, Max-Change = 0.0055, Max-Change = 0.0128, Max-Change = 0.0051, Max-Change = 0.0093, Max-Change = 0.0252, Max-Change = 0.0142, Max-Change = 0.0101, Max-Change = 0.0092, Max-Change = 0.0333, Max-Change = 0.0122, Max-Change = 0.0084, Max-Change = 0.0098, Max-Change = 0.0081, Max-Change = 0.0300, Max-Change = 0.0306, Max-Change = 0.0112, Max-Change = 0.0048, Max-Change = 0.0091, Max-Change = 0.0088, Max-Change = 0.0263, Max-Change = 0.0100, Max-Change = 0.0118, Max-Change = 0.0103, Max-Change = 0.0021, Max-Change = 0.0084, Max-Change = 0.0130, Max-Change = 0.0080, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0151, gam = 0.1057, Max-Change = 0.0072, gam = 0.0780, Max-Change = 0.0048, gam = 0.0629, Max-Change = 0.0014, gam = 0.0532, Max-Change = 0.0047, gam = 0.0464, Max-Change = 0.0016, gam = 0.0413, Max-Change = 0.0021, gam = 0.0374, Max-Change = 0.0007, gam = 0.0342, Max-Change = 0.0026, gam = 0.0316, Max-Change = 0.0035, gam = 0.0294, Max-Change = 0.0018, gam = 0.0276, Max-Change = 0.0009, gam = 0.0260, Max-Change = 0.0013, gam = 0.0246, Max-Change = 0.0007, gam = 0.0233, Max-Change = 0.0016, gam = 0.0222, Max-Change = 0.0012, gam = 0.0212, Max-Change = 0.0011, gam = 0.0203, Max-Change = 0.0024, gam = 0.0195, Max-Change = 0.0020, gam = 0.0188, Max-Change = 0.0010, gam = 0.0181, Max-Change = 0.0013, gam = 0.0175, Max-Change = 0.0003, gam = 0.0169, Max-Change = 0.0011, gam = 0.0164, Max-Change = 0.0008, gam = 0.0159, Max-Change = 0.0007, gam = 0.0154, Max-Change = 0.0008 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(rmod1) #>  #> Call: #> mixedmirt(data = data, covdata = covdata, model = 1, fixed = ~0 +  #>     items, random = ~1 | group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       F1 #> F1 0.062 #>  #> $group #>           COV_group #> COV_group      1.11 #>  coef(rmod1) #> $Item_1 #>         a1      d  g  u #> par      1 -0.713  0  1 #> CI_2.5  NA -0.927 NA NA #> CI_97.5 NA -0.500 NA NA #>  #> $Item_2 #>         a1      d  g  u #> par      1 -0.867  0  1 #> CI_2.5  NA -1.081 NA NA #> CI_97.5 NA -0.653 NA NA #>  #> $Item_3 #>         a1      d  g  u #> par      1 -0.370  0  1 #> CI_2.5  NA -0.583 NA NA #> CI_97.5 NA -0.156 NA NA #>  #> $Item_4 #>         a1      d  g  u #> par      1  0.057  0  1 #> CI_2.5  NA -0.161 NA NA #> CI_97.5 NA  0.276 NA NA #>  #> $Item_5 #>         a1     d  g  u #> par      1 0.654  0  1 #> CI_2.5  NA 0.422 NA NA #> CI_97.5 NA 0.886 NA NA #>  #> $Item_6 #>         a1      d  g  u #> par      1 -0.145  0  1 #> CI_2.5  NA -0.361 NA NA #> CI_97.5 NA  0.071 NA NA #>  #> $Item_7 #>         a1      d  g  u #> par      1 -0.592  0  1 #> CI_2.5  NA -0.805 NA NA #> CI_97.5 NA -0.379 NA NA #>  #> $Item_8 #>         a1      d  g  u #> par      1 -1.057  0  1 #> CI_2.5  NA -1.273 NA NA #> CI_97.5 NA -0.842 NA NA #>  #> $Item_9 #>         a1      d  g  u #> par      1 -0.957  0  1 #> CI_2.5  NA -1.172 NA NA #> CI_97.5 NA -0.743 NA NA #>  #> $Item_10 #>         a1     d  g  u #> par      1 2.769  0  1 #> CI_2.5  NA 2.425 NA NA #> CI_97.5 NA 3.113 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0  0.062 #> CI_2.5      NA  0.004 #> CI_97.5     NA  0.120 #>  #> $group #>         COV_group_group #> par               1.112 #> CI_2.5            0.631 #> CI_97.5           1.592 #>   # random groups and random items rmod2 <- mixedmirt(data, covdata, 1, random = list(~ 1|group, ~ 1|items)) #> , Max-Change = 0.0274, Max-Change = 0.0217, Max-Change = 0.0087, Max-Change = 0.0228, Max-Change = 0.0182, Max-Change = 0.0177, Max-Change = 0.0220, Max-Change = 0.0255, Max-Change = 0.0132, Max-Change = 0.0106, Max-Change = 0.0070, Max-Change = 0.0106, Max-Change = 0.0120, Max-Change = 0.0060, Max-Change = 0.0116, Max-Change = 0.0019, Max-Change = 0.0029, Max-Change = 0.0069, Max-Change = 0.0130, Max-Change = 0.0098, Max-Change = 0.0232, Max-Change = 0.0104, Max-Change = 0.0034, Max-Change = 0.0054, Max-Change = 0.0075, Max-Change = 0.0051, Max-Change = 0.0113, Max-Change = 0.0033, Max-Change = 0.0032, Max-Change = 0.0056, Max-Change = 0.0037, Max-Change = 0.0047, Max-Change = 0.0051, Max-Change = 0.0028, Max-Change = 0.0024, Max-Change = 0.0006, Max-Change = 0.0045, Max-Change = 0.0037, Max-Change = 0.0007, Max-Change = 0.0013, Max-Change = 0.0057, Max-Change = 0.0169, Max-Change = 0.0131, Max-Change = 0.0095, Max-Change = 0.0038, Max-Change = 0.0032, Max-Change = 0.0049, Max-Change = 0.0047, Max-Change = 0.0137, Max-Change = 0.0022, Max-Change = 0.0077, Max-Change = 0.0074, Max-Change = 0.0048, Max-Change = 0.0044, Max-Change = 0.0044, Max-Change = 0.0059, Max-Change = 0.0017, Max-Change = 0.0037, Max-Change = 0.0062, Max-Change = 0.0062, Max-Change = 0.0026, Max-Change = 0.0063, Max-Change = 0.0057, Max-Change = 0.0151, Max-Change = 0.0044, Max-Change = 0.0059, Max-Change = 0.0086, Max-Change = 0.0036, Max-Change = 0.0044, Max-Change = 0.0054, Max-Change = 0.0030, Max-Change = 0.0035, Max-Change = 0.0056, Max-Change = 0.0004, Max-Change = 0.0009, Max-Change = 0.0027, Max-Change = 0.0004, Max-Change = 0.0020, Max-Change = 0.0066, Max-Change = 0.0013, Max-Change = 0.0023, Max-Change = 0.0045, Max-Change = 0.0076, Max-Change = 0.0024, Max-Change = 0.0015, Max-Change = 0.0012, Max-Change = 0.0033, Max-Change = 0.0040, Max-Change = 0.0105, Max-Change = 0.0004, Max-Change = 0.0064, Max-Change = 0.0121, Max-Change = 0.0016, Max-Change = 0.0090, Max-Change = 0.0018, Max-Change = 0.0069, Max-Change = 0.0070, Max-Change = 0.0055, Max-Change = 0.0037, Max-Change = 0.0504, Max-Change = 0.1569, Max-Change = 0.0713, Max-Change = 0.0281, Max-Change = 0.0327, Max-Change = 0.0567, Max-Change = 0.0160, Max-Change = 0.0127, Max-Change = 0.0138, Max-Change = 0.0226, Max-Change = 0.0120, Max-Change = 0.0178, Max-Change = 0.0122, Max-Change = 0.0057, Max-Change = 0.0087, Max-Change = 0.0137, Max-Change = 0.0088, Max-Change = 0.0196, Max-Change = 0.0088, Max-Change = 0.0167, Max-Change = 0.0123, Max-Change = 0.0119, Max-Change = 0.0139, Max-Change = 0.0092, Max-Change = 0.0199, Max-Change = 0.0132, Max-Change = 0.0030, Max-Change = 0.0045, Max-Change = 0.0065, Max-Change = 0.0194, Max-Change = 0.0114, Max-Change = 0.0146, Max-Change = 0.0089, Max-Change = 0.0129, Max-Change = 0.0156, Max-Change = 0.0131, Max-Change = 0.0130, Max-Change = 0.0087, Max-Change = 0.0086, Max-Change = 0.0054, Max-Change = 0.0052, Max-Change = 0.0106, Max-Change = 0.0146, Max-Change = 0.0035, Max-Change = 0.0120, Max-Change = 0.0061, Max-Change = 0.0061, Max-Change = 0.0023, Max-Change = 0.0062, Max-Change = 0.0086, Max-Change = 0.0083, Max-Change = 0.0035, Max-Change = 0.0077, Max-Change = 0.0064, Max-Change = 0.0033, Max-Change = 0.0061, Max-Change = 0.0065, Max-Change = 0.0129, Max-Change = 0.0230, Max-Change = 0.0068, Max-Change = 0.0033, Max-Change = 0.0121, Max-Change = 0.0015, Max-Change = 0.0018, Max-Change = 0.0051, Max-Change = 0.0016, Max-Change = 0.0140, Max-Change = 0.0063, Max-Change = 0.0193, Max-Change = 0.0179, Max-Change = 0.0064, Max-Change = 0.0051, Max-Change = 0.0061, Max-Change = 0.0067, Max-Change = 0.0110, Max-Change = 0.0131, Max-Change = 0.0151, Max-Change = 0.0057, Max-Change = 0.0098, Max-Change = 0.0081, Max-Change = 0.0068, Max-Change = 0.0101, Max-Change = 0.0025, Max-Change = 0.0068, Max-Change = 0.0015, Max-Change = 0.0160, Max-Change = 0.0077, Max-Change = 0.0060, Max-Change = 0.0057, Max-Change = 0.0068, Max-Change = 0.0053, Max-Change = 0.0143, Max-Change = 0.0049, Max-Change = 0.0012, Max-Change = 0.0075, Max-Change = 0.0059, Max-Change = 0.0126, Max-Change = 0.0084, Max-Change = 0.0163, Max-Change = 0.0068, Max-Change = 0.0511, Max-Change = 0.0088, Max-Change = 0.0075, Max-Change = 0.0063, Max-Change = 0.0070, Max-Change = 0.0058, Max-Change = 0.0064, Max-Change = 0.0086, Max-Change = 0.0082, Max-Change = 0.0145, Max-Change = 0.0049, Max-Change = 0.0087, Max-Change = 0.0072, Max-Change = 0.0055, Max-Change = 0.0123, Max-Change = 0.0124, Max-Change = 0.0067, Max-Change = 0.0308, Max-Change = 0.0055, Max-Change = 0.0237, Max-Change = 0.0222, Max-Change = 0.0140, Max-Change = 0.0075, Max-Change = 0.0180, Max-Change = 0.0111, Max-Change = 0.0081, Max-Change = 0.0086, Max-Change = 0.0068, Max-Change = 0.0053, Max-Change = 0.0135, Max-Change = 0.0094, Max-Change = 0.0109, Max-Change = 0.0093, Max-Change = 0.0060, Max-Change = 0.0103, Max-Change = 0.0121, Max-Change = 0.0125, Max-Change = 0.0084, Max-Change = 0.0025, Max-Change = 0.0033, Max-Change = 0.0045, Max-Change = 0.0197, Max-Change = 0.0107, Max-Change = 0.0052, Max-Change = 0.0106, Max-Change = 0.0027, Max-Change = 0.0060, Max-Change = 0.0156, Max-Change = 0.0083, Max-Change = 0.0089, Max-Change = 0.0035, Max-Change = 0.0071, Max-Change = 0.0058, Max-Change = 0.0088, Max-Change = 0.0106, Max-Change = 0.0061, Max-Change = 0.0024, Max-Change = 0.0024, Max-Change = 0.0082, Max-Change = 0.0089, Max-Change = 0.0078, Max-Change = 0.0087, Max-Change = 0.0008, Max-Change = 0.0146, Max-Change = 0.0082, Max-Change = 0.0179, Max-Change = 0.0087, Max-Change = 0.0155, Max-Change = 0.0085, Max-Change = 0.0156, Max-Change = 0.0047, Max-Change = 0.0068, Max-Change = 0.0045, Max-Change = 0.0033, Max-Change = 0.0102, Max-Change = 0.0098, Max-Change = 0.0087, Max-Change = 0.0054, Max-Change = 0.0097, Max-Change = 0.0142, Max-Change = 0.0110, Max-Change = 0.0107, Max-Change = 0.0042, Max-Change = 0.0030, Max-Change = 0.0054, Max-Change = 0.0063, Max-Change = 0.0173, Max-Change = 0.0087, Max-Change = 0.0167, Max-Change = 0.0098, Max-Change = 0.0046, Max-Change = 0.0170, Max-Change = 0.0173, Max-Change = 0.0085, Max-Change = 0.0076, Max-Change = 0.0287, Max-Change = 0.0082, Max-Change = 0.0072, Max-Change = 0.0086, Max-Change = 0.0074, Max-Change = 0.0086, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0048, gam = 0.1057, Max-Change = 0.0035, gam = 0.0780, Max-Change = 0.0012, gam = 0.0629, Max-Change = 0.0029, gam = 0.0532, Max-Change = 0.0044, gam = 0.0464, Max-Change = 0.0044, gam = 0.0413, Max-Change = 0.0006, gam = 0.0374, Max-Change = 0.0018, gam = 0.0342, Max-Change = 0.0023, gam = 0.0316, Max-Change = 0.0016, gam = 0.0294, Max-Change = 0.0028, gam = 0.0276, Max-Change = 0.0004, gam = 0.0260, Max-Change = 0.0009, gam = 0.0246, Max-Change = 0.0004 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(rmod2) #>  #> Call: #> mixedmirt(data = data, covdata = covdata, model = 1, random = list(~1 |  #>     group, ~1 | items)) #>  #> -------------- #> FIXED EFFECTS: #>             Estimate Std.Error z.value #> (Intercept)   -0.605     0.013 -47.455 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>        F1 #> F1 0.0593 #>  #> $group #>           COV_group #> COV_group     0.969 #>  #> $items #>           COV_items #> COV_items     0.694 #>  eff <- randef(rmod2) #estimate random effects  # random slopes with fixed intercepts (suppressed correlation) rmod3 <- mixedmirt(data, covdata, 1, fixed = ~ 0 + items, random = ~ -1 + pseudoIQ|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1864, Max-Change = 0.1623, Max-Change = 0.1436, Max-Change = 0.1243, Max-Change = 0.1035, Max-Change = 0.0953, Max-Change = 0.0862, Max-Change = 0.0730, Max-Change = 0.0612, Max-Change = 0.0490, Max-Change = 0.0426, Max-Change = 0.0342, Max-Change = 0.0359, Max-Change = 0.0255, Max-Change = 0.0251, Max-Change = 0.0175, Max-Change = 0.0105, Max-Change = 0.0121, Max-Change = 0.0184, Max-Change = 0.0194, Max-Change = 0.0092, Max-Change = 0.0064, Max-Change = 0.0083, Max-Change = 0.0065, Max-Change = 0.0026, Max-Change = 0.0066, Max-Change = 0.0110, Max-Change = 0.0004, Max-Change = 0.0044, Max-Change = 0.0104, Max-Change = 0.0118, Max-Change = 0.0071, Max-Change = 0.0056, Max-Change = 0.0073, Max-Change = 0.0134, Max-Change = 0.0043, Max-Change = 0.0143, Max-Change = 0.0042, Max-Change = 0.0109, Max-Change = 0.0061, Max-Change = 0.0096, Max-Change = 0.0130, Max-Change = 0.0158, Max-Change = 0.0124, Max-Change = 0.0075, Max-Change = 0.0080, Max-Change = 0.0056, Max-Change = 0.0025, Max-Change = 0.0109, Max-Change = 0.0030, Max-Change = 0.0135, Max-Change = 0.0156, Max-Change = 0.0136, Max-Change = 0.0085, Max-Change = 0.0083, Max-Change = 0.0118, Max-Change = 0.0017, Max-Change = 0.0074, Max-Change = 0.0278, Max-Change = 0.0030, Max-Change = 0.0086, Max-Change = 0.0053, Max-Change = 0.0006, Max-Change = 0.0139, Max-Change = 0.0106, Max-Change = 0.0060, Max-Change = 0.0048, Max-Change = 0.0084, Max-Change = 0.0076, Max-Change = 0.0094, Max-Change = 0.0090, Max-Change = 0.0120, Max-Change = 0.0036, Max-Change = 0.0029, Max-Change = 0.0089, Max-Change = 0.0036, Max-Change = 0.0030, Max-Change = 0.0074, Max-Change = 0.0044, Max-Change = 0.0153, Max-Change = 0.0043, Max-Change = 0.0295, Max-Change = 0.0054, Max-Change = 0.0105, Max-Change = 0.0154, Max-Change = 0.0094, Max-Change = 0.0021, Max-Change = 0.0077, Max-Change = 0.0113, Max-Change = 0.0035, Max-Change = 0.0045, Max-Change = 0.0065, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.0620, Max-Change = 0.0394, Max-Change = 0.0281, Max-Change = 0.0205, Max-Change = 0.0199, Max-Change = 0.0517, Max-Change = 0.0185, Max-Change = 0.0067, Max-Change = 0.0141, Max-Change = 0.0170, Max-Change = 0.0190, Max-Change = 0.0213, Max-Change = 0.0206, Max-Change = 0.0102, Max-Change = 0.0144, Max-Change = 0.0149, Max-Change = 0.0186, Max-Change = 0.0133, Max-Change = 0.0153, Max-Change = 0.0083, Max-Change = 0.0201, Max-Change = 0.0119, Max-Change = 0.0101, Max-Change = 0.0102, Max-Change = 0.0116, Max-Change = 0.0103, Max-Change = 0.0138, Max-Change = 0.0114, Max-Change = 0.0096, Max-Change = 0.0143, Max-Change = 0.0112, Max-Change = 0.0052, Max-Change = 0.0129, Max-Change = 0.0050, Max-Change = 0.0069, Max-Change = 0.0115, Max-Change = 0.0161, Max-Change = 0.0211, Max-Change = 0.0159, Max-Change = 0.0214, Max-Change = 0.0115, Max-Change = 0.0161, Max-Change = 0.0133, Max-Change = 0.0057, Max-Change = 0.0090, Max-Change = 0.0073, Max-Change = 0.0074, Max-Change = 0.0091, Max-Change = 0.0059, Max-Change = 0.0164, Max-Change = 0.0378, Max-Change = 0.0162, Max-Change = 0.0071, Max-Change = 0.0116, Max-Change = 0.0195, Max-Change = 0.0175, Max-Change = 0.0311, Max-Change = 0.0127, Max-Change = 0.0213, Max-Change = 0.0165, Max-Change = 0.0228, Max-Change = 0.0124, Max-Change = 0.0231, Max-Change = 0.0031, Max-Change = 0.0051, Max-Change = 0.0071, Max-Change = 0.0128, Max-Change = 0.0067, Max-Change = 0.0103, Max-Change = 0.0062, Max-Change = 0.0078, Max-Change = 0.0059, Max-Change = 0.0112, Max-Change = 0.0211, Max-Change = 0.0079, Max-Change = 0.0113, Max-Change = 0.0155, Max-Change = 0.0214, Max-Change = 0.0076, Max-Change = 0.0141, Max-Change = 0.0077, Max-Change = 0.0132, Max-Change = 0.0065, Max-Change = 0.0096, Max-Change = 0.0197, Max-Change = 0.0292, Max-Change = 0.0085, Max-Change = 0.0121, Max-Change = 0.0045, Max-Change = 0.0164, Max-Change = 0.0094, Max-Change = 0.0174, Max-Change = 0.0066, Max-Change = 0.0051, Max-Change = 0.0148, Max-Change = 0.0141, Max-Change = 0.0092, Max-Change = 0.0097, Max-Change = 0.0092, Max-Change = 0.0047, Max-Change = 0.0197, Max-Change = 0.0115, Max-Change = 0.0174, Max-Change = 0.0189, Max-Change = 0.0048, Max-Change = 0.0090, Max-Change = 0.0168, Max-Change = 0.0043, Max-Change = 0.0088, Max-Change = 0.0175, Max-Change = 0.0223, Max-Change = 0.0080, Max-Change = 0.0114, Max-Change = 0.0086, Max-Change = 0.0130, Max-Change = 0.0102, Max-Change = 0.0142, Max-Change = 0.0136, Max-Change = 0.0089, Max-Change = 0.0116, Max-Change = 0.0048, Max-Change = 0.0155, Max-Change = 0.0401, Max-Change = 0.0167, Max-Change = 0.0126, Max-Change = 0.0013, Max-Change = 0.0050, Max-Change = 0.0060, Max-Change = 0.0117, Max-Change = 0.0052, Max-Change = 0.0086, Max-Change = 0.0101, Max-Change = 0.0164, Max-Change = 0.0097, Max-Change = 0.0056, Max-Change = 0.0179, Max-Change = 0.0056, Max-Change = 0.0072, Max-Change = 0.0118, Max-Change = 0.0031, Max-Change = 0.0076, Max-Change = 0.0171, Max-Change = 0.0125, Max-Change = 0.0159, Max-Change = 0.0089, Max-Change = 0.0146, Max-Change = 0.0109, Max-Change = 0.0075, Max-Change = 0.0102, Max-Change = 0.0110, Max-Change = 0.0174, Max-Change = 0.0163, Max-Change = 0.0087, Max-Change = 0.0054, Max-Change = 0.0102, Max-Change = 0.0127, Max-Change = 0.0176, Max-Change = 0.0243, Max-Change = 0.0061, Max-Change = 0.0035, Max-Change = 0.0121, Max-Change = 0.0134, Max-Change = 0.0163, Max-Change = 0.0043, Max-Change = 0.0094, Max-Change = 0.0096, Max-Change = 0.0183, Max-Change = 0.0114, Max-Change = 0.0099, Max-Change = 0.0313, Max-Change = 0.0248, Max-Change = 0.0163, Max-Change = 0.0125, Max-Change = 0.0056, Max-Change = 0.0097, Max-Change = 0.0210, Max-Change = 0.0163, Max-Change = 0.0101, Max-Change = 0.0173, Max-Change = 0.0129, Max-Change = 0.0087, Max-Change = 0.0150, Max-Change = 0.0198, Max-Change = 0.0080, Max-Change = 0.0213, Max-Change = 0.0164, Max-Change = 0.0118, Max-Change = 0.0174, Max-Change = 0.0076, Max-Change = 0.0076, Max-Change = 0.0159, Max-Change = 0.0115, Max-Change = 0.0215, Max-Change = 0.0067, Max-Change = 0.0148, Max-Change = 0.0073, Max-Change = 0.0075, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0050, gam = 0.1057, Max-Change = 0.0160, gam = 0.0780, Max-Change = 0.0089, gam = 0.0629, Max-Change = 0.0076, gam = 0.0532, Max-Change = 0.0028, gam = 0.0464, Max-Change = 0.0033, gam = 0.0413, Max-Change = 0.0039, gam = 0.0374, Max-Change = 0.0038, gam = 0.0342, Max-Change = 0.0013, gam = 0.0316, Max-Change = 0.0024, gam = 0.0294, Max-Change = 0.0012, gam = 0.0276, Max-Change = 0.0031, gam = 0.0260, Max-Change = 0.0046, gam = 0.0246, Max-Change = 0.0009, gam = 0.0233, Max-Change = 0.0039, gam = 0.0222, Max-Change = 0.0026, gam = 0.0212, Max-Change = 0.0005, gam = 0.0203, Max-Change = 0.0010, gam = 0.0195, Max-Change = 0.0004 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(rmod3) #>  #> Call: #> mixedmirt(data = data, covdata = covdata, model = 1, fixed = ~0 +  #>     items, random = ~-1 + pseudoIQ | group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       F1 #> F1 0.073 #>  #> $group #>              COV_group COV_pseudoIQ #> COV_group        0.903         0.00 #> COV_pseudoIQ     0.000         0.16 #>  eff <- randef(rmod3) str(eff) #> List of 2 #>  $ Theta: num [1:750, 1] -0.02771 0.06944 0.0653 0.03018 -0.00748 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr \"F1\" #>  $ group: num [1:50, 1:2] -1.59 -1.17 -1.4 -1.54 -1.49 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:50] \"G1\" \"G2\" \"G3\" \"G4\" ... #>   .. ..$ : chr [1:2] \"group\" \"pseudoIQ\"  ################################################### ## LLTM, and 2PL version of LLTM data(SAT12) data <- key2binary(SAT12,                    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)) model <- 'Theta = 1-32'  # for unconditional intercept comparison mod <- mirt(data, model, itemtype='Rasch') #>  coef(mod, simplify=TRUE) #> $items #>         a1      d g u #> Item.1   1 -1.077 0 1 #> Item.2   1  0.331 0 1 #> Item.3   1 -1.096 0 1 #> Item.4   1 -0.574 0 1 #> Item.5   1  0.581 0 1 #> Item.6   1 -1.912 0 1 #> Item.7   1  1.342 0 1 #> Item.8   1 -1.593 0 1 #> Item.9   1  2.324 0 1 #> Item.10  1 -0.362 0 1 #> Item.11  1  4.449 0 1 #> Item.12  1 -0.394 0 1 #> Item.13  1  0.791 0 1 #> Item.14  1  1.124 0 1 #> Item.15  1  1.724 0 1 #> Item.16  1 -0.402 0 1 #> Item.17  1  3.620 0 1 #> Item.18  1 -0.709 0 1 #> Item.19  1  0.237 0 1 #> Item.20  1  2.204 0 1 #> Item.21  1  2.684 0 1 #> Item.22  1  2.991 0 1 #> Item.23  1 -0.910 0 1 #> Item.24  1  1.153 0 1 #> Item.25  1 -0.590 0 1 #> Item.26  1 -0.179 0 1 #> Item.27  1  2.094 0 1 #> Item.28  1  0.150 0 1 #> Item.29  1 -0.769 0 1 #> Item.30  1 -0.274 0 1 #> Item.31  1  1.852 0 1 #> Item.32  1 -1.899 0 1 #>  #> $means #> Theta  #>     0  #>  #> $cov #>       Theta #> Theta  0.82 #>   # Suppose that the first 16 items were suspected to be easier than the last 16 items, #   and we wish to test this item structure hypothesis (more intercept designs are possible #   by including more columns). itemdesign <- data.frame(itemorder = factor(c(rep('easier', 16), rep('harder', 16)))) rownames(itemdesign) <- colnames(data) itemdesign #>         itemorder #> Item.1     easier #> Item.2     easier #> Item.3     easier #> Item.4     easier #> Item.5     easier #> Item.6     easier #> Item.7     easier #> Item.8     easier #> Item.9     easier #> Item.10    easier #> Item.11    easier #> Item.12    easier #> Item.13    easier #> Item.14    easier #> Item.15    easier #> Item.16    easier #> Item.17    harder #> Item.18    harder #> Item.19    harder #> Item.20    harder #> Item.21    harder #> Item.22    harder #> Item.23    harder #> Item.24    harder #> Item.25    harder #> Item.26    harder #> Item.27    harder #> Item.28    harder #> Item.29    harder #> Item.30    harder #> Item.31    harder #> Item.32    harder  # notice that the 'fixed = ~ ... + items' argument is omitted LLTM <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemdesign = itemdesign,    SE = TRUE) # SE argument ensures that the information matrix is computed accurately #> , Max-Change = 0.2000, Max-Change = 0.1211, Max-Change = 0.0434, Max-Change = 0.0359, Max-Change = 0.0327, Max-Change = 0.0388, Max-Change = 0.0141, Max-Change = 0.0267, Max-Change = 0.0141, Max-Change = 0.0104, Max-Change = 0.0137, Max-Change = 0.0148, Max-Change = 0.0114, Max-Change = 0.0116, Max-Change = 0.0112, Max-Change = 0.0118, Max-Change = 0.0093, Max-Change = 0.0096, Max-Change = 0.0059, Max-Change = 0.0056, Max-Change = 0.0114, Max-Change = 0.0124, Max-Change = 0.0062, Max-Change = 0.0059, Max-Change = 0.0072, Max-Change = 0.0089, Max-Change = 0.0046, Max-Change = 0.0061, Max-Change = 0.0051, Max-Change = 0.0022, Max-Change = 0.0050, Max-Change = 0.0068, Max-Change = 0.0016, Max-Change = 0.0028, Max-Change = 0.0049, Max-Change = 0.0067, Max-Change = 0.0019, Max-Change = 0.0038, Max-Change = 0.0054, Max-Change = 0.0082, Max-Change = 0.0038, Max-Change = 0.0019, Max-Change = 0.0055, Max-Change = 0.0044, Max-Change = 0.0065, Max-Change = 0.0020, Max-Change = 0.0034, Max-Change = 0.0029, Max-Change = 0.0062, Max-Change = 0.0021, Max-Change = 0.0029, Max-Change = 0.0023, Max-Change = 0.0030, Max-Change = 0.0008, Max-Change = 0.0130, Max-Change = 0.0023, Max-Change = 0.0062, Max-Change = 0.0028, Max-Change = 0.0057, Max-Change = 0.0035, Max-Change = 0.0029, Max-Change = 0.0017, Max-Change = 0.0020, Max-Change = 0.0012, Max-Change = 0.0021, Max-Change = 0.0028, Max-Change = 0.0012, Max-Change = 0.0020, Max-Change = 0.0019, Max-Change = 0.0036, Max-Change = 0.0029, Max-Change = 0.0029, Max-Change = 0.0051, Max-Change = 0.0044, Max-Change = 0.0053, Max-Change = 0.0021, Max-Change = 0.0016, Max-Change = 0.0037, Max-Change = 0.0021, Max-Change = 0.0044, Max-Change = 0.0073, Max-Change = 0.0023, Max-Change = 0.0070, Max-Change = 0.0025, Max-Change = 0.0043, Max-Change = 0.0035, Max-Change = 0.0026, Max-Change = 0.0011, Max-Change = 0.0024, Max-Change = 0.0019, Max-Change = 0.0024, Max-Change = 0.0031, Max-Change = 0.0037, Max-Change = 0.0065, Max-Change = 0.0016, Max-Change = 0.0041, Max-Change = 0.0015, Max-Change = 0.0028, Max-Change = 0.0038, Max-Change = 0.0031, Max-Change = 0.0016, Max-Change = 0.0069, Max-Change = 0.0031, Max-Change = 0.0026, Max-Change = 0.0034, Max-Change = 0.0028, Max-Change = 0.0035, Max-Change = 0.0050, Max-Change = 0.0047, Max-Change = 0.0036, Max-Change = 0.0028, Max-Change = 0.0040, Max-Change = 0.0049, Max-Change = 0.0024, Max-Change = 0.0062, Max-Change = 0.0044, Max-Change = 0.0023, Max-Change = 0.0040, Max-Change = 0.0037, Max-Change = 0.0031, Max-Change = 0.0024, Max-Change = 0.0037, Max-Change = 0.0040, Max-Change = 0.0030, Max-Change = 0.0023, Max-Change = 0.0020, Max-Change = 0.0022, Max-Change = 0.0064, Max-Change = 0.0008, Max-Change = 0.0028, Max-Change = 0.0063, Max-Change = 0.0073, Max-Change = 0.0020, Max-Change = 0.0055, Max-Change = 0.0041, Max-Change = 0.0032, Max-Change = 0.0033, Max-Change = 0.0030, Max-Change = 0.0027, Max-Change = 0.0036, Max-Change = 0.0049, Max-Change = 0.0020, Max-Change = 0.0024, Max-Change = 0.0041, Max-Change = 0.0026, Max-Change = 0.0031, Max-Change = 0.0018, Max-Change = 0.0002, Max-Change = 0.0031, Max-Change = 0.0031, Max-Change = 0.0054, Max-Change = 0.0037, Max-Change = 0.0008, Max-Change = 0.0040, Max-Change = 0.0019, Max-Change = 0.0045, Max-Change = 0.0029, Max-Change = 0.0032, Max-Change = 0.0029, Max-Change = 0.0013, Max-Change = 0.0032, Max-Change = 0.0034, Max-Change = 0.0036, Max-Change = 0.0046, Max-Change = 0.0044, Max-Change = 0.0075, Max-Change = 0.0045, Max-Change = 0.0043, Max-Change = 0.0046, Max-Change = 0.0012, Max-Change = 0.0027, Max-Change = 0.0060, Max-Change = 0.0018, Max-Change = 0.0031, Max-Change = 0.0019, Max-Change = 0.0085, Max-Change = 0.0035, Max-Change = 0.0013, Max-Change = 0.0054, Max-Change = 0.0023, Max-Change = 0.0016, Max-Change = 0.0031, Max-Change = 0.0021, Max-Change = 0.0027, Max-Change = 0.0059, Max-Change = 0.0024, Max-Change = 0.0027, Max-Change = 0.0041, Max-Change = 0.0032, Max-Change = 0.0014, Max-Change = 0.0021, Max-Change = 0.0075, Max-Change = 0.0044, Max-Change = 0.0061, Max-Change = 0.0026, Max-Change = 0.0014, Max-Change = 0.0076, Max-Change = 0.0022, Max-Change = 0.0014, Max-Change = 0.0052, Max-Change = 0.0035, Max-Change = 0.0014, Max-Change = 0.0029, Max-Change = 0.0028, Max-Change = 0.0006, Max-Change = 0.0050, Max-Change = 0.0027, Max-Change = 0.0054, Max-Change = 0.0038, Max-Change = 0.0051, Max-Change = 0.0040, Max-Change = 0.0028, Max-Change = 0.0055, Max-Change = 0.0050, Max-Change = 0.0020, Max-Change = 0.0037, Max-Change = 0.0067, Max-Change = 0.0031, Max-Change = 0.0011, Max-Change = 0.0024, Max-Change = 0.0075, Max-Change = 0.0025, Max-Change = 0.0044, Max-Change = 0.0043, Max-Change = 0.0024, Max-Change = 0.0034, Max-Change = 0.0008, Max-Change = 0.0025, Max-Change = 0.0021, Max-Change = 0.0031, Max-Change = 0.0038, Max-Change = 0.0012, Max-Change = 0.0064, Max-Change = 0.0045, Max-Change = 0.0014, Max-Change = 0.0030, Max-Change = 0.0028, Max-Change = 0.0024, Max-Change = 0.0055, Max-Change = 0.0039, Max-Change = 0.0063, Max-Change = 0.0022, Max-Change = 0.0013, Max-Change = 0.0015, Max-Change = 0.0027, Max-Change = 0.0006, Max-Change = 0.0032, Max-Change = 0.0020, Max-Change = 0.0071, Max-Change = 0.0010, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0050, gam = 0.1057, Max-Change = 0.0015, gam = 0.0780, Max-Change = 0.0014, gam = 0.0629, Max-Change = 0.0005, gam = 0.0532, Max-Change = 0.0005, gam = 0.0464, Max-Change = 0.0008 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(LLTM) #>  #> Call: #> mixedmirt(data = data, model = model, fixed = ~0 + itemorder,  #>     itemdesign = itemdesign, SE = TRUE) #>  #> -------------- #> FIXED EFFECTS: #>                 Estimate Std.Error z.value #> itemordereasier    0.165     0.029   5.746 #> itemorderharder    0.456     0.029  15.757 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       Theta #> Theta 0.359 #>  coef(LLTM) #> $Item.1 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.2 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.3 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.4 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.5 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.6 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.7 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.8 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.9 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.10 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.11 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.12 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.13 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.14 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.15 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.16 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.17 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.18 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.19 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.20 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.21 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.22 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.23 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.24 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.25 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.26 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.27 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.28 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.29 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.30 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.31 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $Item.32 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.165           0.456  1  0  0  1 #> CI_2.5            0.109           0.400 NA NA NA NA #> CI_97.5           0.221           0.513 NA NA NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0  0.359 #> CI_2.5      NA  0.300 #> CI_97.5     NA  0.417 #>  wald(LLTM) #> itemordereasier.1.7.13.19.25.31.37.43.49.55.61.67.73.79.85.91.97.103.109.115.121.127.133.139.145.151.157.163.169.175.181.187  #>                                                                                                                        0.165  #> itemorderharder.2.8.14.20.26.32.38.44.50.56.62.68.74.80.86.92.98.104.110.116.122.128.134.140.146.152.158.164.170.176.182.188  #>                                                                                                                        0.456  #>                                                                                                                   COV_11.194  #>                                                                                                                        0.359  L <- matrix(c(-1, 1, 0), 1) wald(LLTM, L) #first half different from second #>          W df p #> 1 92.08467  1 0  # compare to items with estimated slopes (2PL) twoPL <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemtype = '2PL',                    itemdesign = itemdesign) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1442, Max-Change = 0.1334, Max-Change = 0.1011, Max-Change = 0.1513, Max-Change = 0.1542, Max-Change = 0.1931, Max-Change = 0.1260, Max-Change = 0.1033, Max-Change = 0.0642, Max-Change = 0.0382, Max-Change = 0.0362, Max-Change = 0.0938, Max-Change = 0.1657, Max-Change = 0.0519, Max-Change = 0.0473, Max-Change = 0.0912, Max-Change = 0.1021, Max-Change = 0.0542, Max-Change = 0.0314, Max-Change = 0.0865, Max-Change = 0.1497, Max-Change = 0.0749, Max-Change = 0.0938, Max-Change = 0.0806, Max-Change = 0.0620, Max-Change = 0.1095, Max-Change = 0.0995, Max-Change = 0.0615, Max-Change = 0.0376, Max-Change = 0.0565, Max-Change = 0.1273, Max-Change = 0.0580, Max-Change = 0.0892, Max-Change = 0.1018, Max-Change = 0.1197, Max-Change = 0.0277, Max-Change = 0.0370, Max-Change = 0.0888, Max-Change = 0.1287, Max-Change = 0.0706, Max-Change = 0.0717, Max-Change = 0.1049, Max-Change = 0.0358, Max-Change = 0.0426, Max-Change = 0.0958, Max-Change = 0.0737, Max-Change = 0.0686, Max-Change = 0.0378, Max-Change = 0.0280, Max-Change = 0.0456, Max-Change = 0.0404, Max-Change = 0.0484, Max-Change = 0.0489, Max-Change = 0.0659, Max-Change = 0.0907, Max-Change = 0.0830, Max-Change = 0.0461, Max-Change = 0.0758, Max-Change = 0.0964, Max-Change = 0.0503, Max-Change = 0.1839, Max-Change = 0.0628, Max-Change = 0.0445, Max-Change = 0.0308, Max-Change = 0.1108, Max-Change = 0.0750, Max-Change = 0.0491, Max-Change = 0.1908, Max-Change = 0.0673, Max-Change = 0.1160, Max-Change = 0.0179, Max-Change = 0.0481, Max-Change = 0.1369, Max-Change = 0.0348, Max-Change = 0.0430, Max-Change = 0.0454, Max-Change = 0.0662, Max-Change = 0.1296, Max-Change = 0.0452, Max-Change = 0.0481, Max-Change = 0.1019, Max-Change = 0.0639, Max-Change = 0.0883, Max-Change = 0.0408, Max-Change = 0.1144, Max-Change = 0.0848, Max-Change = 0.0220, Max-Change = 0.0204, Max-Change = 0.1042, Max-Change = 0.0727, Max-Change = 0.0235, Max-Change = 0.1152, Max-Change = 0.1283, Max-Change = 0.2000, Max-Change = 0.1024, Max-Change = 0.0790, Max-Change = 0.0530, Max-Change = 0.1599, Max-Change = 0.0882, Max-Change = 0.0701, Max-Change = 0.0432, Max-Change = 0.0908, Max-Change = 0.0740, Max-Change = 0.0306, Max-Change = 0.1226, Max-Change = 0.0799, Max-Change = 0.0216, Max-Change = 0.0709, Max-Change = 0.0772, Max-Change = 0.0427, Max-Change = 0.0283, Max-Change = 0.1534, Max-Change = 0.0620, Max-Change = 0.1452, Max-Change = 0.0580, Max-Change = 0.1788, Max-Change = 0.0190, Max-Change = 0.0533, Max-Change = 0.0625, Max-Change = 0.0330, Max-Change = 0.0542, Max-Change = 0.1262, Max-Change = 0.0511, Max-Change = 0.0660, Max-Change = 0.0970, Max-Change = 0.0928, Max-Change = 0.0803, Max-Change = 0.0857, Max-Change = 0.0280, Max-Change = 0.1594, Max-Change = 0.0863, Max-Change = 0.0378, Max-Change = 0.0311, Max-Change = 0.0886, Max-Change = 0.0715, Max-Change = 0.1207, Max-Change = 0.0359, Max-Change = 0.0906, Max-Change = 0.1337, Max-Change = 0.0909, Max-Change = 0.0324, Max-Change = 0.1398, Max-Change = 0.1323, Max-Change = 0.0913, Max-Change = 0.0333, Max-Change = 0.0595, Max-Change = 0.0449, Max-Change = 0.1344, Max-Change = 0.2000, Max-Change = 0.0278, Max-Change = 0.0459, Max-Change = 0.1154, Max-Change = 0.0319, Max-Change = 0.0714, Max-Change = 0.1099, Max-Change = 0.0942, Max-Change = 0.0636, Max-Change = 0.0819, Max-Change = 0.0860, Max-Change = 0.0412, Max-Change = 0.2000, Max-Change = 0.0422, Max-Change = 0.1284, Max-Change = 0.0594, Max-Change = 0.0843, Max-Change = 0.0775, Max-Change = 0.0348, Max-Change = 0.1056, Max-Change = 0.0353, Max-Change = 0.0363, Max-Change = 0.1896, Max-Change = 0.0535, Max-Change = 0.0978, Max-Change = 0.0959, Max-Change = 0.0827, Max-Change = 0.0291, Max-Change = 0.1093, Max-Change = 0.0862, Max-Change = 0.1114, Max-Change = 0.0440, Max-Change = 0.0922, Max-Change = 0.0546, Max-Change = 0.0655, Max-Change = 0.1098, Max-Change = 0.0620, Max-Change = 0.0964, Max-Change = 0.1176, Max-Change = 0.0687, Max-Change = 0.0395, Max-Change = 0.1172, Max-Change = 0.1350, Max-Change = 0.1815, Max-Change = 0.0760, Max-Change = 0.0625, Max-Change = 0.0623, Max-Change = 0.1998, Max-Change = 0.0979, Max-Change = 0.1779, Max-Change = 0.0804, Max-Change = 0.1349, Max-Change = 0.0441, Max-Change = 0.0772, Max-Change = 0.1331, Max-Change = 0.1961, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0468, gam = 0.1057, Max-Change = 0.0182, gam = 0.0780, Max-Change = 0.0097, gam = 0.0629, Max-Change = 0.0159, gam = 0.0532, Max-Change = 0.0087, gam = 0.0464, Max-Change = 0.0160, gam = 0.0413, Max-Change = 0.0233, gam = 0.0374, Max-Change = 0.0305, gam = 0.0342, Max-Change = 0.0305, gam = 0.0316, Max-Change = 0.0061, gam = 0.0294, Max-Change = 0.0088, gam = 0.0276, Max-Change = 0.0146, gam = 0.0260, Max-Change = 0.0119, gam = 0.0246, Max-Change = 0.0078, gam = 0.0233, Max-Change = 0.0162, gam = 0.0222, Max-Change = 0.0076, gam = 0.0212, Max-Change = 0.0183, gam = 0.0203, Max-Change = 0.0075, gam = 0.0195, Max-Change = 0.0028, gam = 0.0188, Max-Change = 0.0026, gam = 0.0181, Max-Change = 0.0044, gam = 0.0175, Max-Change = 0.0026, gam = 0.0169, Max-Change = 0.0029, gam = 0.0164, Max-Change = 0.0043, gam = 0.0159, Max-Change = 0.0071, gam = 0.0154, Max-Change = 0.0045, gam = 0.0150, Max-Change = 0.0026, gam = 0.0146, Max-Change = 0.0028, gam = 0.0142, Max-Change = 0.0063, gam = 0.0139, Max-Change = 0.0102, gam = 0.0135, Max-Change = 0.0182, gam = 0.0132, Max-Change = 0.0051, gam = 0.0129, Max-Change = 0.0043, gam = 0.0126, Max-Change = 0.0050, gam = 0.0124, Max-Change = 0.0074, gam = 0.0121, Max-Change = 0.0018, gam = 0.0119, Max-Change = 0.0029, gam = 0.0116, Max-Change = 0.0115, gam = 0.0114, Max-Change = 0.0030, gam = 0.0112, Max-Change = 0.0032, gam = 0.0110, Max-Change = 0.0031, gam = 0.0108, Max-Change = 0.0034, gam = 0.0106, Max-Change = 0.0090, gam = 0.0104, Max-Change = 0.0032, gam = 0.0102, Max-Change = 0.0048, gam = 0.0101, Max-Change = 0.0014, gam = 0.0099, Max-Change = 0.0040, gam = 0.0098, Max-Change = 0.0042, gam = 0.0096, Max-Change = 0.0083, gam = 0.0095, Max-Change = 0.0041, gam = 0.0093, Max-Change = 0.0031, gam = 0.0092, Max-Change = 0.0018, gam = 0.0091, Max-Change = 0.0060, gam = 0.0089, Max-Change = 0.0014, gam = 0.0088, Max-Change = 0.0051, gam = 0.0087, Max-Change = 0.0093, gam = 0.0086, Max-Change = 0.0104, gam = 0.0085, Max-Change = 0.0017, gam = 0.0084, Max-Change = 0.0053, gam = 0.0082, Max-Change = 0.0017, gam = 0.0081, Max-Change = 0.0012, gam = 0.0080, Max-Change = 0.0032, gam = 0.0080, Max-Change = 0.0047, gam = 0.0079, Max-Change = 0.0016, gam = 0.0078, Max-Change = 0.0063, gam = 0.0077, Max-Change = 0.0021, gam = 0.0076, Max-Change = 0.0013, gam = 0.0075, Max-Change = 0.0016, gam = 0.0074, Max-Change = 0.0012, gam = 0.0073, Max-Change = 0.0017, gam = 0.0073, Max-Change = 0.0027, gam = 0.0072, Max-Change = 0.0019, gam = 0.0071, Max-Change = 0.0018, gam = 0.0070, Max-Change = 0.0038, gam = 0.0070, Max-Change = 0.0019, gam = 0.0069, Max-Change = 0.0021, gam = 0.0068, Max-Change = 0.0023, gam = 0.0068, Max-Change = 0.0064, gam = 0.0067, Max-Change = 0.0011, gam = 0.0066, Max-Change = 0.0022, gam = 0.0066, Max-Change = 0.0022, gam = 0.0065, Max-Change = 0.0008, gam = 0.0065, Max-Change = 0.0018, gam = 0.0064, Max-Change = 0.0019, gam = 0.0064, Max-Change = 0.0021, gam = 0.0063, Max-Change = 0.0035, gam = 0.0062, Max-Change = 0.0023, gam = 0.0062, Max-Change = 0.0014, gam = 0.0061, Max-Change = 0.0013, gam = 0.0061, Max-Change = 0.0028, gam = 0.0060, Max-Change = 0.0055, gam = 0.0060, Max-Change = 0.0030, gam = 0.0059, Max-Change = 0.0029, gam = 0.0059, Max-Change = 0.0025, gam = 0.0058, Max-Change = 0.0026, gam = 0.0058, Max-Change = 0.0021, gam = 0.0058, Max-Change = 0.0017, gam = 0.0057, Max-Change = 0.0016, gam = 0.0057, Max-Change = 0.0056, gam = 0.0056, Max-Change = 0.0021, gam = 0.0056, Max-Change = 0.0011, gam = 0.0055, Max-Change = 0.0018, gam = 0.0055, Max-Change = 0.0034, gam = 0.0055, Max-Change = 0.0019, gam = 0.0054, Max-Change = 0.0007, gam = 0.0054, Max-Change = 0.0020, gam = 0.0053, Max-Change = 0.0019, gam = 0.0053, Max-Change = 0.0032, gam = 0.0053, Max-Change = 0.0030, gam = 0.0052, Max-Change = 0.0024, gam = 0.0052, Max-Change = 0.0029, gam = 0.0052, Max-Change = 0.0014, gam = 0.0051, Max-Change = 0.0017, gam = 0.0051, Max-Change = 0.0045, gam = 0.0051, Max-Change = 0.0023, gam = 0.0050, Max-Change = 0.0024, gam = 0.0050, Max-Change = 0.0018, gam = 0.0050, Max-Change = 0.0020, gam = 0.0049, Max-Change = 0.0011, gam = 0.0049, Max-Change = 0.0010, gam = 0.0049, Max-Change = 0.0007, gam = 0.0048, Max-Change = 0.0018, gam = 0.0048, Max-Change = 0.0034, gam = 0.0048, Max-Change = 0.0037, gam = 0.0048, Max-Change = 0.0018, gam = 0.0047, Max-Change = 0.0018, gam = 0.0047, Max-Change = 0.0005, gam = 0.0047, Max-Change = 0.0036, gam = 0.0046, Max-Change = 0.0017, gam = 0.0046, Max-Change = 0.0010, gam = 0.0046, Max-Change = 0.0020, gam = 0.0046, Max-Change = 0.0016, gam = 0.0045, Max-Change = 0.0022, gam = 0.0045, Max-Change = 0.0008, gam = 0.0045, Max-Change = 0.0031, gam = 0.0045, Max-Change = 0.0011, gam = 0.0044, Max-Change = 0.0013, gam = 0.0044, Max-Change = 0.0016, gam = 0.0044, Max-Change = 0.0031, gam = 0.0044, Max-Change = 0.0027, gam = 0.0043, Max-Change = 0.0013, gam = 0.0043, Max-Change = 0.0033, gam = 0.0043, Max-Change = 0.0022, gam = 0.0043, Max-Change = 0.0024, gam = 0.0043, Max-Change = 0.0007, gam = 0.0042, Max-Change = 0.0015, gam = 0.0042, Max-Change = 0.0030, gam = 0.0042, Max-Change = 0.0014, gam = 0.0042, Max-Change = 0.0015, gam = 0.0041, Max-Change = 0.0012, gam = 0.0041, Max-Change = 0.0013, gam = 0.0041, Max-Change = 0.0032, gam = 0.0041, Max-Change = 0.0025, gam = 0.0041, Max-Change = 0.0008, gam = 0.0040, Max-Change = 0.0015, gam = 0.0040, Max-Change = 0.0012, gam = 0.0040, Max-Change = 0.0010, gam = 0.0040, Max-Change = 0.0017, gam = 0.0040, Max-Change = 0.0020, gam = 0.0040, Max-Change = 0.0017, gam = 0.0039, Max-Change = 0.0031, gam = 0.0039, Max-Change = 0.0007, gam = 0.0039, Max-Change = 0.0017, gam = 0.0039, Max-Change = 0.0013, gam = 0.0039, Max-Change = 0.0014, gam = 0.0038, Max-Change = 0.0016, gam = 0.0038, Max-Change = 0.0010, gam = 0.0038, Max-Change = 0.0015, gam = 0.0038, Max-Change = 0.0006, gam = 0.0038, Max-Change = 0.0020, gam = 0.0038, Max-Change = 0.0009, gam = 0.0037, Max-Change = 0.0018, gam = 0.0037, Max-Change = 0.0020, gam = 0.0037, Max-Change = 0.0009, gam = 0.0037, Max-Change = 0.0017, gam = 0.0037, Max-Change = 0.0011, gam = 0.0037, Max-Change = 0.0004, gam = 0.0036, Max-Change = 0.0011, gam = 0.0036, Max-Change = 0.0011, gam = 0.0036, Max-Change = 0.0013, gam = 0.0036, Max-Change = 0.0039, gam = 0.0036, Max-Change = 0.0023, gam = 0.0036, Max-Change = 0.0013, gam = 0.0036, Max-Change = 0.0013, gam = 0.0035, Max-Change = 0.0012, gam = 0.0035, Max-Change = 0.0028, gam = 0.0035, Max-Change = 0.0011, gam = 0.0035, Max-Change = 0.0021, gam = 0.0035, Max-Change = 0.0020, gam = 0.0035, Max-Change = 0.0018, gam = 0.0035, Max-Change = 0.0012, gam = 0.0034, Max-Change = 0.0007, gam = 0.0034, Max-Change = 0.0011, gam = 0.0034, Max-Change = 0.0011, gam = 0.0034, Max-Change = 0.0007, gam = 0.0034, Max-Change = 0.0034, gam = 0.0034, Max-Change = 0.0012, gam = 0.0034, Max-Change = 0.0008, gam = 0.0034, Max-Change = 0.0009, gam = 0.0033, Max-Change = 0.0007 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... # twoPL not mixing too well (AR should be between .2 and .5), decrease MHcand twoPL <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemtype = '2PL',                   itemdesign = itemdesign, technical = list(MHcand = 0.8)) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1580, Max-Change = 0.1493, Max-Change = 0.1590, Max-Change = 0.1453, Max-Change = 0.1497, Max-Change = 0.2000, Max-Change = 0.1382, Max-Change = 0.1473, Max-Change = 0.0963, Max-Change = 0.0840, Max-Change = 0.0516, Max-Change = 0.0416, Max-Change = 0.0567, Max-Change = 0.0582, Max-Change = 0.0715, Max-Change = 0.0502, Max-Change = 0.0950, Max-Change = 0.0412, Max-Change = 0.0287, Max-Change = 0.0941, Max-Change = 0.1107, Max-Change = 0.1413, Max-Change = 0.1043, Max-Change = 0.0567, Max-Change = 0.0544, Max-Change = 0.0555, Max-Change = 0.0547, Max-Change = 0.0563, Max-Change = 0.0415, Max-Change = 0.0593, Max-Change = 0.0620, Max-Change = 0.0563, Max-Change = 0.1559, Max-Change = 0.1268, Max-Change = 0.0883, Max-Change = 0.1939, Max-Change = 0.0395, Max-Change = 0.0775, Max-Change = 0.1430, Max-Change = 0.2000, Max-Change = 0.0591, Max-Change = 0.0400, Max-Change = 0.0300, Max-Change = 0.0472, Max-Change = 0.0765, Max-Change = 0.0602, Max-Change = 0.0876, Max-Change = 0.0224, Max-Change = 0.0339, Max-Change = 0.0400, Max-Change = 0.0394, Max-Change = 0.0533, Max-Change = 0.0396, Max-Change = 0.0462, Max-Change = 0.0959, Max-Change = 0.0746, Max-Change = 0.1065, Max-Change = 0.1064, Max-Change = 0.1416, Max-Change = 0.1050, Max-Change = 0.0815, Max-Change = 0.0823, Max-Change = 0.2000, Max-Change = 0.0448, Max-Change = 0.0489, Max-Change = 0.0875, Max-Change = 0.0658, Max-Change = 0.1561, Max-Change = 0.1379, Max-Change = 0.1195, Max-Change = 0.1394, Max-Change = 0.1107, Max-Change = 0.0919, Max-Change = 0.0363, Max-Change = 0.0454, Max-Change = 0.0601, Max-Change = 0.0507, Max-Change = 0.0918, Max-Change = 0.0841, Max-Change = 0.0292, Max-Change = 0.0758, Max-Change = 0.0761, Max-Change = 0.1493, Max-Change = 0.0472, Max-Change = 0.1030, Max-Change = 0.0278, Max-Change = 0.0412, Max-Change = 0.0247, Max-Change = 0.0416, Max-Change = 0.1399, Max-Change = 0.1462, Max-Change = 0.2000, Max-Change = 0.0908, Max-Change = 0.2000, Max-Change = 0.1294, Max-Change = 0.0560, Max-Change = 0.0362, Max-Change = 0.1113, Max-Change = 0.0892, Max-Change = 0.0927, Max-Change = 0.0413, Max-Change = 0.0558, Max-Change = 0.0763, Max-Change = 0.1423, Max-Change = 0.0551, Max-Change = 0.0409, Max-Change = 0.0732, Max-Change = 0.1227, Max-Change = 0.0615, Max-Change = 0.1213, Max-Change = 0.1253, Max-Change = 0.0463, Max-Change = 0.0600, Max-Change = 0.1780, Max-Change = 0.1414, Max-Change = 0.0771, Max-Change = 0.1539, Max-Change = 0.0594, Max-Change = 0.0397, Max-Change = 0.0837, Max-Change = 0.0690, Max-Change = 0.0433, Max-Change = 0.0624, Max-Change = 0.0244, Max-Change = 0.0493, Max-Change = 0.1388, Max-Change = 0.0777, Max-Change = 0.0834, Max-Change = 0.0300, Max-Change = 0.0289, Max-Change = 0.0614, Max-Change = 0.1249, Max-Change = 0.0689, Max-Change = 0.0364, Max-Change = 0.0754, Max-Change = 0.1376, Max-Change = 0.0851, Max-Change = 0.0522, Max-Change = 0.0723, Max-Change = 0.0945, Max-Change = 0.1353, Max-Change = 0.0725, Max-Change = 0.0754, Max-Change = 0.1172, Max-Change = 0.0907, Max-Change = 0.2000, Max-Change = 0.0900, Max-Change = 0.0957, Max-Change = 0.1489, Max-Change = 0.0403, Max-Change = 0.0805, Max-Change = 0.1271, Max-Change = 0.0559, Max-Change = 0.0699, Max-Change = 0.0948, Max-Change = 0.0515, Max-Change = 0.0648, Max-Change = 0.1273, Max-Change = 0.0964, Max-Change = 0.0342, Max-Change = 0.1370, Max-Change = 0.0237, Max-Change = 0.0425, Max-Change = 0.0494, Max-Change = 0.0508, Max-Change = 0.0394, Max-Change = 0.1035, Max-Change = 0.0739, Max-Change = 0.0707, Max-Change = 0.0908, Max-Change = 0.0850, Max-Change = 0.0558, Max-Change = 0.1103, Max-Change = 0.1808, Max-Change = 0.1738, Max-Change = 0.1432, Max-Change = 0.0501, Max-Change = 0.2000, Max-Change = 0.0585, Max-Change = 0.1046, Max-Change = 0.1443, Max-Change = 0.1918, Max-Change = 0.0686, Max-Change = 0.0578, Max-Change = 0.0658, Max-Change = 0.0790, Max-Change = 0.1219, Max-Change = 0.1074, Max-Change = 0.1143, Max-Change = 0.1944, Max-Change = 0.2000, Max-Change = 0.0279, Max-Change = 0.1737, Max-Change = 0.0589, Max-Change = 0.1507, Max-Change = 0.1349, Max-Change = 0.0647, Max-Change = 0.1399, Max-Change = 0.0462, Max-Change = 0.1044, Max-Change = 0.0908, Max-Change = 0.0564, Max-Change = 0.0726, Max-Change = 0.1225, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0746, gam = 0.1057, Max-Change = 0.0272, gam = 0.0780, Max-Change = 0.0412, gam = 0.0629, Max-Change = 0.0188, gam = 0.0532, Max-Change = 0.0088, gam = 0.0464, Max-Change = 0.0202, gam = 0.0413, Max-Change = 0.0106, gam = 0.0374, Max-Change = 0.0108, gam = 0.0342, Max-Change = 0.0181, gam = 0.0316, Max-Change = 0.0109, gam = 0.0294, Max-Change = 0.0220, gam = 0.0276, Max-Change = 0.0024, gam = 0.0260, Max-Change = 0.0170, gam = 0.0246, Max-Change = 0.0048, gam = 0.0233, Max-Change = 0.0220, gam = 0.0222, Max-Change = 0.0166, gam = 0.0212, Max-Change = 0.0132, gam = 0.0203, Max-Change = 0.0060, gam = 0.0195, Max-Change = 0.0056, gam = 0.0188, Max-Change = 0.0016, gam = 0.0181, Max-Change = 0.0061, gam = 0.0175, Max-Change = 0.0037, gam = 0.0169, Max-Change = 0.0085, gam = 0.0164, Max-Change = 0.0039, gam = 0.0159, Max-Change = 0.0031, gam = 0.0154, Max-Change = 0.0112, gam = 0.0150, Max-Change = 0.0045, gam = 0.0146, Max-Change = 0.0044, gam = 0.0142, Max-Change = 0.0059, gam = 0.0139, Max-Change = 0.0052, gam = 0.0135, Max-Change = 0.0117, gam = 0.0132, Max-Change = 0.0068, gam = 0.0129, Max-Change = 0.0021, gam = 0.0126, Max-Change = 0.0019, gam = 0.0124, Max-Change = 0.0023, gam = 0.0121, Max-Change = 0.0069, gam = 0.0119, Max-Change = 0.0021, gam = 0.0116, Max-Change = 0.0033, gam = 0.0114, Max-Change = 0.0018, gam = 0.0112, Max-Change = 0.0051, gam = 0.0110, Max-Change = 0.0019, gam = 0.0108, Max-Change = 0.0025, gam = 0.0106, Max-Change = 0.0068, gam = 0.0104, Max-Change = 0.0052, gam = 0.0102, Max-Change = 0.0087, gam = 0.0101, Max-Change = 0.0064, gam = 0.0099, Max-Change = 0.0088, gam = 0.0098, Max-Change = 0.0082, gam = 0.0096, Max-Change = 0.0075, gam = 0.0095, Max-Change = 0.0048, gam = 0.0093, Max-Change = 0.0023, gam = 0.0092, Max-Change = 0.0030, gam = 0.0091, Max-Change = 0.0031, gam = 0.0089, Max-Change = 0.0021, gam = 0.0088, Max-Change = 0.0045, gam = 0.0087, Max-Change = 0.0025, gam = 0.0086, Max-Change = 0.0039, gam = 0.0085, Max-Change = 0.0046, gam = 0.0084, Max-Change = 0.0100, gam = 0.0082, Max-Change = 0.0049, gam = 0.0081, Max-Change = 0.0032, gam = 0.0080, Max-Change = 0.0046, gam = 0.0080, Max-Change = 0.0049, gam = 0.0079, Max-Change = 0.0015, gam = 0.0078, Max-Change = 0.0015, gam = 0.0077, Max-Change = 0.0033, gam = 0.0076, Max-Change = 0.0011, gam = 0.0075, Max-Change = 0.0021, gam = 0.0074, Max-Change = 0.0011, gam = 0.0073, Max-Change = 0.0030, gam = 0.0073, Max-Change = 0.0022, gam = 0.0072, Max-Change = 0.0013, gam = 0.0071, Max-Change = 0.0025, gam = 0.0070, Max-Change = 0.0018, gam = 0.0070, Max-Change = 0.0041, gam = 0.0069, Max-Change = 0.0017, gam = 0.0068, Max-Change = 0.0009, gam = 0.0068, Max-Change = 0.0009, gam = 0.0067, Max-Change = 0.0033, gam = 0.0066, Max-Change = 0.0023, gam = 0.0066, Max-Change = 0.0013, gam = 0.0065, Max-Change = 0.0049, gam = 0.0065, Max-Change = 0.0013, gam = 0.0064, Max-Change = 0.0012, gam = 0.0064, Max-Change = 0.0048, gam = 0.0063, Max-Change = 0.0051, gam = 0.0062, Max-Change = 0.0041, gam = 0.0062, Max-Change = 0.0081, gam = 0.0061, Max-Change = 0.0026, gam = 0.0061, Max-Change = 0.0031, gam = 0.0060, Max-Change = 0.0029, gam = 0.0060, Max-Change = 0.0040, gam = 0.0059, Max-Change = 0.0034, gam = 0.0059, Max-Change = 0.0018, gam = 0.0058, Max-Change = 0.0015, gam = 0.0058, Max-Change = 0.0046, gam = 0.0058, Max-Change = 0.0012, gam = 0.0057, Max-Change = 0.0017, gam = 0.0057, Max-Change = 0.0007, gam = 0.0056, Max-Change = 0.0009, gam = 0.0056, Max-Change = 0.0025, gam = 0.0055, Max-Change = 0.0017, gam = 0.0055, Max-Change = 0.0020, gam = 0.0055, Max-Change = 0.0016, gam = 0.0054, Max-Change = 0.0013, gam = 0.0054, Max-Change = 0.0015, gam = 0.0053, Max-Change = 0.0018, gam = 0.0053, Max-Change = 0.0012, gam = 0.0053, Max-Change = 0.0023, gam = 0.0052, Max-Change = 0.0026, gam = 0.0052, Max-Change = 0.0011, gam = 0.0052, Max-Change = 0.0024, gam = 0.0051, Max-Change = 0.0017, gam = 0.0051, Max-Change = 0.0011, gam = 0.0051, Max-Change = 0.0007, gam = 0.0050, Max-Change = 0.0030, gam = 0.0050, Max-Change = 0.0017, gam = 0.0050, Max-Change = 0.0009, gam = 0.0049, Max-Change = 0.0018, gam = 0.0049, Max-Change = 0.0022, gam = 0.0049, Max-Change = 0.0015, gam = 0.0048, Max-Change = 0.0026, gam = 0.0048, Max-Change = 0.0009, gam = 0.0048, Max-Change = 0.0028, gam = 0.0048, Max-Change = 0.0064, gam = 0.0047, Max-Change = 0.0041, gam = 0.0047, Max-Change = 0.0020, gam = 0.0047, Max-Change = 0.0019, gam = 0.0046, Max-Change = 0.0017, gam = 0.0046, Max-Change = 0.0010, gam = 0.0046, Max-Change = 0.0030, gam = 0.0046, Max-Change = 0.0026, gam = 0.0045, Max-Change = 0.0017, gam = 0.0045, Max-Change = 0.0027, gam = 0.0045, Max-Change = 0.0016, gam = 0.0045, Max-Change = 0.0031, gam = 0.0044, Max-Change = 0.0011, gam = 0.0044, Max-Change = 0.0027, gam = 0.0044, Max-Change = 0.0007, gam = 0.0044, Max-Change = 0.0012, gam = 0.0043, Max-Change = 0.0018, gam = 0.0043, Max-Change = 0.0026, gam = 0.0043, Max-Change = 0.0032, gam = 0.0043, Max-Change = 0.0051, gam = 0.0043, Max-Change = 0.0007, gam = 0.0042, Max-Change = 0.0020, gam = 0.0042, Max-Change = 0.0013, gam = 0.0042, Max-Change = 0.0013, gam = 0.0042, Max-Change = 0.0018, gam = 0.0041, Max-Change = 0.0016, gam = 0.0041, Max-Change = 0.0010, gam = 0.0041, Max-Change = 0.0010, gam = 0.0041, Max-Change = 0.0012, gam = 0.0041, Max-Change = 0.0021, gam = 0.0040, Max-Change = 0.0011, gam = 0.0040, Max-Change = 0.0021, gam = 0.0040, Max-Change = 0.0007, gam = 0.0040, Max-Change = 0.0016, gam = 0.0040, Max-Change = 0.0016, gam = 0.0040, Max-Change = 0.0009, gam = 0.0039, Max-Change = 0.0005, gam = 0.0039, Max-Change = 0.0017, gam = 0.0039, Max-Change = 0.0007, gam = 0.0039, Max-Change = 0.0017, gam = 0.0039, Max-Change = 0.0009, gam = 0.0038, Max-Change = 0.0022, gam = 0.0038, Max-Change = 0.0009, gam = 0.0038, Max-Change = 0.0010, gam = 0.0038, Max-Change = 0.0026, gam = 0.0038, Max-Change = 0.0039, gam = 0.0038, Max-Change = 0.0021, gam = 0.0037, Max-Change = 0.0011, gam = 0.0037, Max-Change = 0.0017, gam = 0.0037, Max-Change = 0.0013, gam = 0.0037, Max-Change = 0.0016, gam = 0.0037, Max-Change = 0.0011, gam = 0.0037, Max-Change = 0.0024, gam = 0.0036, Max-Change = 0.0034, gam = 0.0036, Max-Change = 0.0008, gam = 0.0036, Max-Change = 0.0013, gam = 0.0036, Max-Change = 0.0030, gam = 0.0036, Max-Change = 0.0009, gam = 0.0036, Max-Change = 0.0008, gam = 0.0036, Max-Change = 0.0018, gam = 0.0035, Max-Change = 0.0021, gam = 0.0035, Max-Change = 0.0004, gam = 0.0035, Max-Change = 0.0009, gam = 0.0035, Max-Change = 0.0005 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... anova(twoPL, LLTM) #much better fit #>            AIC    SABIC       HQ      BIC    logLik        X2  df   p #> twoPL 20484.33 20525.88 20542.52 20633.82 -10208.16                   #> LLTM  25464.27 25467.94 25469.41 25477.47 -12729.14 -5041.948 -31 NaN summary(twoPL) #>  #> Call: #> mixedmirt(data = data, model = model, fixed = ~0 + itemorder,  #>     itemtype = \"2PL\", itemdesign = itemdesign, technical = list(MHcand = 0.8)) #>  #> -------------- #> FIXED EFFECTS: #>                 Estimate Std.Error z.value #> itemordereasier   -1.669     0.087 -19.127 #> itemorderharder   -1.644     0.095 -17.316 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       Theta #> Theta     1 #>  coef(twoPL) #> $Item.1 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 0.930  0  0  1 #> CI_2.5           -1.840          -1.831 0.696 NA NA NA #> CI_97.5          -1.498          -1.458 1.165 NA NA NA #>  #> $Item.2 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 2.526  0  0  1 #> CI_2.5           -1.840          -1.831 2.201 NA NA NA #> CI_97.5          -1.498          -1.458 2.851 NA NA NA #>  #> $Item.3 #>         itemordereasier itemorderharder   a1  d  g  u #> par              -1.669          -1.644 1.00  0  0  1 #> CI_2.5           -1.840          -1.831 0.77 NA NA NA #> CI_97.5          -1.498          -1.458 1.23 NA NA NA #>  #> $Item.4 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.288  0  0  1 #> CI_2.5           -1.840          -1.831 1.035 NA NA NA #> CI_97.5          -1.498          -1.458 1.540 NA NA NA #>  #> $Item.5 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 2.704  0  0  1 #> CI_2.5           -1.840          -1.831 2.359 NA NA NA #> CI_97.5          -1.498          -1.458 3.049 NA NA NA #>  #> $Item.6 #>         itemordereasier itemorderharder   a1  d  g  u #> par              -1.669          -1.644 0.42  0  0  1 #> CI_2.5           -1.840          -1.831 0.19 NA NA NA #> CI_97.5          -1.498          -1.458 0.65 NA NA NA #>  #> $Item.7 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 3.913  0  0  1 #> CI_2.5           -1.840          -1.831 3.461 NA NA NA #> CI_97.5          -1.498          -1.458 4.365 NA NA NA #>  #> $Item.8 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 0.513  0  0  1 #> CI_2.5           -1.840          -1.831 0.282 NA NA NA #> CI_97.5          -1.498          -1.458 0.744 NA NA NA #>  #> $Item.9 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 5.455  0  0  1 #> CI_2.5           -1.840          -1.831 4.840 NA NA NA #> CI_97.5          -1.498          -1.458 6.071 NA NA NA #>  #> $Item.10 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.628  0  0  1 #> CI_2.5           -1.840          -1.831 1.352 NA NA NA #> CI_97.5          -1.498          -1.458 1.905 NA NA NA #>  #> $Item.11 #>         itemordereasier itemorderharder     a1  d  g  u #> par              -1.669          -1.644 13.512  0  0  1 #> CI_2.5           -1.840          -1.831 10.680 NA NA NA #> CI_97.5          -1.498          -1.458 16.344 NA NA NA #>  #> $Item.12 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.245  0  0  1 #> CI_2.5           -1.840          -1.831 0.974 NA NA NA #> CI_97.5          -1.498          -1.458 1.515 NA NA NA #>  #> $Item.13 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 3.042  0  0  1 #> CI_2.5           -1.840          -1.831 2.668 NA NA NA #> CI_97.5          -1.498          -1.458 3.416 NA NA NA #>  #> $Item.14 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 3.488  0  0  1 #> CI_2.5           -1.840          -1.831 3.076 NA NA NA #> CI_97.5          -1.498          -1.458 3.899 NA NA NA #>  #> $Item.15 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 4.749  0  0  1 #> CI_2.5           -1.840          -1.831 4.225 NA NA NA #> CI_97.5          -1.498          -1.458 5.272 NA NA NA #>  #> $Item.16 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.469  0  0  1 #> CI_2.5           -1.840          -1.831 1.205 NA NA NA #> CI_97.5          -1.498          -1.458 1.733 NA NA NA #>  #> $Item.17 #>         itemordereasier itemorderharder     a1  d  g  u #> par              -1.669          -1.644  9.952  0  0  1 #> CI_2.5           -1.840          -1.831  8.451 NA NA NA #> CI_97.5          -1.498          -1.458 11.454 NA NA NA #>  #> $Item.18 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.408  0  0  1 #> CI_2.5           -1.840          -1.831 1.145 NA NA NA #> CI_97.5          -1.498          -1.458 1.670 NA NA NA #>  #> $Item.19 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 2.155  0  0  1 #> CI_2.5           -1.840          -1.831 1.825 NA NA NA #> CI_97.5          -1.498          -1.458 2.486 NA NA NA #>  #> $Item.20 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 5.787  0  0  1 #> CI_2.5           -1.840          -1.831 5.118 NA NA NA #> CI_97.5          -1.498          -1.458 6.456 NA NA NA #>  #> $Item.21 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 6.345  0  0  1 #> CI_2.5           -1.840          -1.831 5.595 NA NA NA #> CI_97.5          -1.498          -1.458 7.094 NA NA NA #>  #> $Item.22 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 7.826  0  0  1 #> CI_2.5           -1.840          -1.831 6.827 NA NA NA #> CI_97.5          -1.498          -1.458 8.824 NA NA NA #>  #> $Item.23 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 0.982  0  0  1 #> CI_2.5           -1.840          -1.831 0.732 NA NA NA #> CI_97.5          -1.498          -1.458 1.231 NA NA NA #>  #> $Item.24 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 3.622  0  0  1 #> CI_2.5           -1.840          -1.831 3.186 NA NA NA #> CI_97.5          -1.498          -1.458 4.057 NA NA NA #>  #> $Item.25 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.293  0  0  1 #> CI_2.5           -1.840          -1.831 1.021 NA NA NA #> CI_97.5          -1.498          -1.458 1.565 NA NA NA #>  #> $Item.26 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.907  0  0  1 #> CI_2.5           -1.840          -1.831 1.608 NA NA NA #> CI_97.5          -1.498          -1.458 2.205 NA NA NA #>  #> $Item.27 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 5.656  0  0  1 #> CI_2.5           -1.840          -1.831 5.018 NA NA NA #> CI_97.5          -1.498          -1.458 6.293 NA NA NA #>  #> $Item.28 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 2.120  0  0  1 #> CI_2.5           -1.840          -1.831 1.807 NA NA NA #> CI_97.5          -1.498          -1.458 2.433 NA NA NA #>  #> $Item.29 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.165  0  0  1 #> CI_2.5           -1.840          -1.831 0.910 NA NA NA #> CI_97.5          -1.498          -1.458 1.420 NA NA NA #>  #> $Item.30 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 1.442  0  0  1 #> CI_2.5           -1.840          -1.831 1.156 NA NA NA #> CI_97.5          -1.498          -1.458 1.727 NA NA NA #>  #> $Item.31 #>         itemordereasier itemorderharder    a1  d  g  u #> par              -1.669          -1.644 5.235  0  0  1 #> CI_2.5           -1.840          -1.831 4.637 NA NA NA #> CI_97.5          -1.498          -1.458 5.832 NA NA NA #>  #> $Item.32 #>         itemordereasier itemorderharder     a1  d  g  u #> par              -1.669          -1.644  0.097  0  0  1 #> CI_2.5           -1.840          -1.831 -0.163 NA NA NA #> CI_97.5          -1.498          -1.458  0.357 NA NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0      1 #> CI_2.5      NA     NA #> CI_97.5     NA     NA #>   wald(twoPL) #> itemordereasier.1.7.13.19.25.31.37.43.49.55.61.67.73.79.85.91.97.103.109.115.121.127.133.139.145.151.157.163.169.175.181.187  #>                                                                                                                       -1.669  #> itemorderharder.2.8.14.20.26.32.38.44.50.56.62.68.74.80.86.92.98.104.110.116.122.128.134.140.146.152.158.164.170.176.182.188  #>                                                                                                                       -1.644  #>                                                                                                                         a1.3  #>                                                                                                                        0.930  #>                                                                                                                         a1.9  #>                                                                                                                        2.526  #>                                                                                                                        a1.15  #>                                                                                                                        1.000  #>                                                                                                                        a1.21  #>                                                                                                                        1.288  #>                                                                                                                        a1.27  #>                                                                                                                        2.704  #>                                                                                                                        a1.33  #>                                                                                                                        0.420  #>                                                                                                                        a1.39  #>                                                                                                                        3.913  #>                                                                                                                        a1.45  #>                                                                                                                        0.513  #>                                                                                                                        a1.51  #>                                                                                                                        5.455  #>                                                                                                                        a1.57  #>                                                                                                                        1.628  #>                                                                                                                        a1.63  #>                                                                                                                       13.512  #>                                                                                                                        a1.69  #>                                                                                                                        1.245  #>                                                                                                                        a1.75  #>                                                                                                                        3.042  #>                                                                                                                        a1.81  #>                                                                                                                        3.488  #>                                                                                                                        a1.87  #>                                                                                                                        4.749  #>                                                                                                                        a1.93  #>                                                                                                                        1.469  #>                                                                                                                        a1.99  #>                                                                                                                        9.952  #>                                                                                                                       a1.105  #>                                                                                                                        1.408  #>                                                                                                                       a1.111  #>                                                                                                                        2.155  #>                                                                                                                       a1.117  #>                                                                                                                        5.787  #>                                                                                                                       a1.123  #>                                                                                                                        6.345  #>                                                                                                                       a1.129  #>                                                                                                                        7.826  #>                                                                                                                       a1.135  #>                                                                                                                        0.982  #>                                                                                                                       a1.141  #>                                                                                                                        3.622  #>                                                                                                                       a1.147  #>                                                                                                                        1.293  #>                                                                                                                       a1.153  #>                                                                                                                        1.907  #>                                                                                                                       a1.159  #>                                                                                                                        5.656  #>                                                                                                                       a1.165  #>                                                                                                                        2.120  #>                                                                                                                       a1.171  #>                                                                                                                        1.165  #>                                                                                                                       a1.177  #>                                                                                                                        1.442  #>                                                                                                                       a1.183  #>                                                                                                                        5.235  #>                                                                                                                       a1.189  #>                                                                                                                        0.097  L <- matrix(0, 1, 34) L[1, 1] <- 1 L[1, 2] <- -1 wald(twoPL, L) # n.s., which is the correct conclusion. Rasch approach gave wrong inference #>            W df         p #> 1 0.07451603  1 0.7848715  ## LLTM with item error term LLTMwithError <- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, random = ~ 1|items,     itemdesign = itemdesign) #> , Max-Change = 0.2000, Max-Change = 0.1211, Max-Change = 0.0434, Max-Change = 0.0359, Max-Change = 0.0327, Max-Change = 0.0388, Max-Change = 0.0141, Max-Change = 0.0267, Max-Change = 0.0141, Max-Change = 0.0104, Max-Change = 0.0137, Max-Change = 0.0148, Max-Change = 0.0114, Max-Change = 0.0116, Max-Change = 0.0112, Max-Change = 0.0118, Max-Change = 0.0093, Max-Change = 0.0096, Max-Change = 0.0059, Max-Change = 0.0056, Max-Change = 0.0114, Max-Change = 0.0124, Max-Change = 0.0062, Max-Change = 0.0059, Max-Change = 0.0072, Max-Change = 0.0089, Max-Change = 0.0046, Max-Change = 0.0061, Max-Change = 0.0051, Max-Change = 0.0022, Max-Change = 0.0050, Max-Change = 0.0068, Max-Change = 0.0016, Max-Change = 0.0028, Max-Change = 0.0049, Max-Change = 0.0067, Max-Change = 0.0019, Max-Change = 0.0038, Max-Change = 0.0054, Max-Change = 0.0082, Max-Change = 0.0038, Max-Change = 0.0019, Max-Change = 0.0055, Max-Change = 0.0044, Max-Change = 0.0065, Max-Change = 0.0020, Max-Change = 0.0034, Max-Change = 0.0029, Max-Change = 0.0062, Max-Change = 0.0021, Max-Change = 0.0029, Max-Change = 0.0023, Max-Change = 0.0030, Max-Change = 0.0008, Max-Change = 0.0130, Max-Change = 0.0023, Max-Change = 0.0062, Max-Change = 0.0028, Max-Change = 0.0057, Max-Change = 0.0035, Max-Change = 0.0029, Max-Change = 0.0017, Max-Change = 0.0020, Max-Change = 0.0012, Max-Change = 0.0021, Max-Change = 0.0028, Max-Change = 0.0012, Max-Change = 0.0020, Max-Change = 0.0019, Max-Change = 0.0036, Max-Change = 0.0029, Max-Change = 0.0029, Max-Change = 0.0051, Max-Change = 0.0044, Max-Change = 0.0053, Max-Change = 0.0021, Max-Change = 0.0016, Max-Change = 0.0037, Max-Change = 0.0021, Max-Change = 0.0044, Max-Change = 0.0073, Max-Change = 0.0023, Max-Change = 0.0070, Max-Change = 0.0025, Max-Change = 0.0043, Max-Change = 0.0035, Max-Change = 0.0026, Max-Change = 0.0011, Max-Change = 0.0024, Max-Change = 0.0019, Max-Change = 0.0024, Max-Change = 0.0031, Max-Change = 0.0037, Max-Change = 0.0065, Max-Change = 0.0016, Max-Change = 0.0041, Max-Change = 0.0015, Max-Change = 0.0028, Max-Change = 0.0038, Max-Change = 0.0162, Max-Change = 0.0703, Max-Change = 0.0721, Max-Change = 0.0756, Max-Change = 0.0767, Max-Change = 0.0753, Max-Change = 0.0733, Max-Change = 0.0733, Max-Change = 0.0746, Max-Change = 0.0813, Max-Change = 0.0766, Max-Change = 0.0805, Max-Change = 0.0598, Max-Change = 0.0810, Max-Change = 0.0682, Max-Change = 0.0495, Max-Change = 0.0376, Max-Change = 0.0505, Max-Change = 0.0389, Max-Change = 0.0431, Max-Change = 0.0425, Max-Change = 0.0365, Max-Change = 0.0017, Max-Change = 0.0223, Max-Change = 0.0212, Max-Change = 0.0175, Max-Change = 0.0118, Max-Change = 0.0094, Max-Change = 0.0110, Max-Change = 0.0050, Max-Change = 0.0071, Max-Change = 0.0469, Max-Change = 0.0090, Max-Change = 0.0240, Max-Change = 0.0292, Max-Change = 0.0250, Max-Change = 0.0413, Max-Change = 0.0280, Max-Change = 0.0109, Max-Change = 0.0112, Max-Change = 0.0110, Max-Change = 0.0070, Max-Change = 0.0045, Max-Change = 0.0100, Max-Change = 0.0423, Max-Change = 0.0076, Max-Change = 0.0067, Max-Change = 0.0157, Max-Change = 0.0166, Max-Change = 0.0028, Max-Change = 0.0170, Max-Change = 0.0066, Max-Change = 0.0326, Max-Change = 0.0109, Max-Change = 0.0608, Max-Change = 0.0353, Max-Change = 0.0181, Max-Change = 0.0166, Max-Change = 0.0089, Max-Change = 0.0236, Max-Change = 0.0192, Max-Change = 0.0196, Max-Change = 0.0130, Max-Change = 0.0084, Max-Change = 0.0269, Max-Change = 0.0053, Max-Change = 0.0115, Max-Change = 0.0035, Max-Change = 0.0131, Max-Change = 0.0098, Max-Change = 0.0172, Max-Change = 0.0192, Max-Change = 0.0064, Max-Change = 0.0090, Max-Change = 0.0053, Max-Change = 0.0098, Max-Change = 0.0136, Max-Change = 0.0036, Max-Change = 0.0086, Max-Change = 0.0073, Max-Change = 0.0156, Max-Change = 0.0275, Max-Change = 0.0075, Max-Change = 0.0196, Max-Change = 0.0265, Max-Change = 0.0065, Max-Change = 0.0024, Max-Change = 0.0069, Max-Change = 0.0211, Max-Change = 0.0112, Max-Change = 0.0036, Max-Change = 0.0203, Max-Change = 0.0169, Max-Change = 0.0201, Max-Change = 0.0116, Max-Change = 0.0366, Max-Change = 0.0321, Max-Change = 0.0214, Max-Change = 0.0076, Max-Change = 0.0036, Max-Change = 0.0295, Max-Change = 0.0102, Max-Change = 0.0080, Max-Change = 0.0075, Max-Change = 0.0052, Max-Change = 0.0053, Max-Change = 0.0056, Max-Change = 0.0135, Max-Change = 0.0038, Max-Change = 0.0131, Max-Change = 0.0118, Max-Change = 0.0025, Max-Change = 0.0028, Max-Change = 0.0016, Max-Change = 0.0049, Max-Change = 0.0037, Max-Change = 0.0056, Max-Change = 0.0049, Max-Change = 0.0053, Max-Change = 0.0093, Max-Change = 0.0041, Max-Change = 0.0051, Max-Change = 0.0041, Max-Change = 0.0045, Max-Change = 0.0218, Max-Change = 0.0083, Max-Change = 0.0033, Max-Change = 0.0025, Max-Change = 0.0034, Max-Change = 0.0044, Max-Change = 0.0031, Max-Change = 0.0012, Max-Change = 0.0034, Max-Change = 0.0059, Max-Change = 0.0066, Max-Change = 0.0054, Max-Change = 0.0035, Max-Change = 0.0013, Max-Change = 0.0056, Max-Change = 0.0026, Max-Change = 0.0028, Max-Change = 0.0015, Max-Change = 0.0034, Max-Change = 0.0090, Max-Change = 0.0061, Max-Change = 0.0072, Max-Change = 0.0051, Max-Change = 0.0036, Max-Change = 0.0027, Max-Change = 0.0047, Max-Change = 0.0005, Max-Change = 0.0095, Max-Change = 0.0015, Max-Change = 0.0021, Max-Change = 0.0031, Max-Change = 0.0042, Max-Change = 0.0020, Max-Change = 0.0016, Max-Change = 0.0061, Max-Change = 0.0032, Max-Change = 0.0063, Max-Change = 0.0035, Max-Change = 0.0016, Max-Change = 0.0042, Max-Change = 0.0032, Max-Change = 0.0039, Max-Change = 0.0085, Max-Change = 0.0131, Max-Change = 0.0041, Max-Change = 0.0046, Max-Change = 0.0041, Max-Change = 0.0125, Max-Change = 0.0036, Max-Change = 0.0048, Max-Change = 0.0058, Max-Change = 0.0059, Max-Change = 0.0079, Max-Change = 0.0025, Max-Change = 0.0065, Max-Change = 0.0044, Max-Change = 0.0013, Max-Change = 0.0040, Max-Change = 0.0020, Max-Change = 0.0077, Max-Change = 0.0023, Max-Change = 0.0028, Max-Change = 0.0068, Max-Change = 0.0068, Max-Change = 0.0090, Max-Change = 0.0024, Max-Change = 0.0017, Max-Change = 0.0051, Max-Change = 0.0049, Max-Change = 0.0061, Max-Change = 0.0052, Max-Change = 0.0062, Max-Change = 0.0030, Max-Change = 0.0112, Max-Change = 0.0029, Max-Change = 0.0061, Max-Change = 0.0036, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0037, gam = 0.1057, Max-Change = 0.0038, gam = 0.0780, Max-Change = 0.0033, gam = 0.0629, Max-Change = 0.0032, gam = 0.0532, Max-Change = 0.0016, gam = 0.0464, Max-Change = 0.0012, gam = 0.0413, Max-Change = 0.0016, gam = 0.0374, Max-Change = 0.0008, gam = 0.0342, Max-Change = 0.0003, gam = 0.0316, Max-Change = 0.0010 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(LLTMwithError) #>  #> Call: #> mixedmirt(data = data, model = model, fixed = ~0 + itemorder,  #>     random = ~1 | items, itemdesign = itemdesign) #>  #> -------------- #> FIXED EFFECTS: #>                 Estimate Std.Error z.value #> itemordereasier    0.147     0.153   0.961 #> itemorderharder    0.567     0.138   4.107 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       Theta #> Theta  0.77 #>  #> $items #>           COV_items #> COV_items      2.36 #>  # large item level variance after itemorder is regressed; not a great predictor of item difficulty coef(LLTMwithError) #> $Item.1 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.2 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.3 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.4 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.5 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.6 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.7 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.8 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.9 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.10 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.11 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.12 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.13 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.14 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.15 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.16 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.17 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.18 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.19 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.20 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.21 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.22 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.23 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.24 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.25 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.26 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.27 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.28 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.29 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.30 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.31 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $Item.32 #>         itemordereasier itemorderharder a1  d  g  u #> par               0.147           0.567  1  0  0  1 #> CI_2.5           -0.153           0.296 NA NA NA NA #> CI_97.5           0.446           0.838 NA NA NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0  0.770 #> CI_2.5      NA  0.656 #> CI_97.5     NA  0.884 #>  #> $items #>         COV_items_items #> par               2.363 #> CI_2.5            1.229 #> CI_97.5           3.497 #>   ################################################### ### Polytomous example  # make an arbitrary group difference covdat <- data.frame(group = rep(c('m', 'f'), nrow(Science)/2))  # partial credit model mod <- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1962, Max-Change = 0.1682, Max-Change = 0.1133, Max-Change = 0.0674, Max-Change = 0.0992, Max-Change = 0.0598, Max-Change = 0.0391, Max-Change = 0.0767, Max-Change = 0.0756, Max-Change = 0.0498, Max-Change = 0.0341, Max-Change = 0.0267, Max-Change = 0.0180, Max-Change = 0.0456, Max-Change = 0.0402, Max-Change = 0.0274, Max-Change = 0.0393, Max-Change = 0.0554, Max-Change = 0.0284, Max-Change = 0.0071, Max-Change = 0.0122, Max-Change = 0.0220, Max-Change = 0.0069, Max-Change = 0.0146, Max-Change = 0.0283, Max-Change = 0.0373, Max-Change = 0.0308, Max-Change = 0.0094, Max-Change = 0.0156, Max-Change = 0.0788, Max-Change = 0.0158, Max-Change = 0.0216, Max-Change = 0.0166, Max-Change = 0.0117, Max-Change = 0.0380, Max-Change = 0.0473, Max-Change = 0.0301, Max-Change = 0.0510, Max-Change = 0.0303, Max-Change = 0.0534, Max-Change = 0.0369, Max-Change = 0.0366, Max-Change = 0.0164, Max-Change = 0.0112, Max-Change = 0.0184, Max-Change = 0.0241, Max-Change = 0.0132, Max-Change = 0.0130, Max-Change = 0.0322, Max-Change = 0.0117, Max-Change = 0.0257, Max-Change = 0.0167, Max-Change = 0.0103, Max-Change = 0.0230, Max-Change = 0.0250, Max-Change = 0.0330, Max-Change = 0.0080, Max-Change = 0.0185, Max-Change = 0.0132, Max-Change = 0.0584, Max-Change = 0.0139, Max-Change = 0.0264, Max-Change = 0.0230, Max-Change = 0.0302, Max-Change = 0.0573, Max-Change = 0.0190, Max-Change = 0.0394, Max-Change = 0.0492, Max-Change = 0.1002, Max-Change = 0.0201, Max-Change = 0.0600, Max-Change = 0.0258, Max-Change = 0.0563, Max-Change = 0.0101, Max-Change = 0.0197, Max-Change = 0.0245, Max-Change = 0.0342, Max-Change = 0.0495, Max-Change = 0.0175, Max-Change = 0.0301, Max-Change = 0.0319, Max-Change = 0.0743, Max-Change = 0.0160, Max-Change = 0.0126, Max-Change = 0.0248, Max-Change = 0.0238, Max-Change = 0.0409, Max-Change = 0.0393, Max-Change = 0.0248, Max-Change = 0.0402, Max-Change = 0.0136, Max-Change = 0.0208, Max-Change = 0.0514, Max-Change = 0.0607, Max-Change = 0.0259, Max-Change = 0.0346, Max-Change = 0.0313, Max-Change = 0.0295, Max-Change = 0.0630, Max-Change = 0.0644, Max-Change = 0.0463, Max-Change = 0.0292, Max-Change = 0.0367, Max-Change = 0.0403, Max-Change = 0.0443, Max-Change = 0.0677, Max-Change = 0.0219, Max-Change = 0.0139, Max-Change = 0.0540, Max-Change = 0.0469, Max-Change = 0.0200, Max-Change = 0.0142, Max-Change = 0.0141, Max-Change = 0.0355, Max-Change = 0.0165, Max-Change = 0.0266, Max-Change = 0.0173, Max-Change = 0.0206, Max-Change = 0.0325, Max-Change = 0.0488, Max-Change = 0.0090, Max-Change = 0.0374, Max-Change = 0.0068, Max-Change = 0.0110, Max-Change = 0.0160, Max-Change = 0.0323, Max-Change = 0.0151, Max-Change = 0.0225, Max-Change = 0.0657, Max-Change = 0.0597, Max-Change = 0.0197, Max-Change = 0.0156, Max-Change = 0.0257, Max-Change = 0.0453, Max-Change = 0.0137, Max-Change = 0.0347, Max-Change = 0.0347, Max-Change = 0.0123, Max-Change = 0.0305, Max-Change = 0.0093, Max-Change = 0.0487, Max-Change = 0.0134, Max-Change = 0.0418, Max-Change = 0.0272, Max-Change = 0.0292, Max-Change = 0.0300, Max-Change = 0.0573, Max-Change = 0.0277, Max-Change = 0.0086, Max-Change = 0.0474, Max-Change = 0.0222, Max-Change = 0.0189, Max-Change = 0.0280, Max-Change = 0.0296, Max-Change = 0.0060, Max-Change = 0.0725, Max-Change = 0.0465, Max-Change = 0.0170, Max-Change = 0.0170, Max-Change = 0.0480, Max-Change = 0.0664, Max-Change = 0.0191, Max-Change = 0.0223, Max-Change = 0.0139, Max-Change = 0.0465, Max-Change = 0.0288, Max-Change = 0.0670, Max-Change = 0.0177, Max-Change = 0.0684, Max-Change = 0.0415, Max-Change = 0.0246, Max-Change = 0.0121, Max-Change = 0.0224, Max-Change = 0.0199, Max-Change = 0.0073, Max-Change = 0.0258, Max-Change = 0.0154, Max-Change = 0.0388, Max-Change = 0.0320, Max-Change = 0.0259, Max-Change = 0.0501, Max-Change = 0.1062, Max-Change = 0.0204, Max-Change = 0.0840, Max-Change = 0.0111, Max-Change = 0.0397, Max-Change = 0.0191, Max-Change = 0.0168, Max-Change = 0.0256, Max-Change = 0.0382, Max-Change = 0.0726, Max-Change = 0.0670, Max-Change = 0.0159, Max-Change = 0.0099, Max-Change = 0.0558, Max-Change = 0.0305, Max-Change = 0.0040, Max-Change = 0.0227, Max-Change = 0.0270, Max-Change = 0.0105, Max-Change = 0.0755, Max-Change = 0.0284, Max-Change = 0.0125, Max-Change = 0.0220, Max-Change = 0.0491, Max-Change = 0.0176, Max-Change = 0.0107, Max-Change = 0.0212, Max-Change = 0.0090, Max-Change = 0.0251, Max-Change = 0.0252, Max-Change = 0.0374, Max-Change = 0.0572, Max-Change = 0.0189, Max-Change = 0.0261, Max-Change = 0.0190, Max-Change = 0.0336, Max-Change = 0.0352, Max-Change = 0.0230, Max-Change = 0.0160, Max-Change = 0.0347, Max-Change = 0.0476, Max-Change = 0.0099, Max-Change = 0.0521, Max-Change = 0.0576, Max-Change = 0.0144, Max-Change = 0.0152, Max-Change = 0.0292, Max-Change = 0.0164, Max-Change = 0.0307, Max-Change = 0.0539, Max-Change = 0.0581, Max-Change = 0.0183, Max-Change = 0.0614, Max-Change = 0.0283, Max-Change = 0.0063, Max-Change = 0.0422, Max-Change = 0.0528, Max-Change = 0.0289, Max-Change = 0.0444, Max-Change = 0.0230, Max-Change = 0.0127, Max-Change = 0.0158, Max-Change = 0.0254, Max-Change = 0.0421, Max-Change = 0.0088, Max-Change = 0.0437, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0321, gam = 0.1057, Max-Change = 0.0075, gam = 0.0780, Max-Change = 0.0111, gam = 0.0629, Max-Change = 0.0052, gam = 0.0532, Max-Change = 0.0125, gam = 0.0464, Max-Change = 0.0073, gam = 0.0413, Max-Change = 0.0042, gam = 0.0374, Max-Change = 0.0100, gam = 0.0342, Max-Change = 0.0023, gam = 0.0316, Max-Change = 0.0089, gam = 0.0294, Max-Change = 0.0029, gam = 0.0276, Max-Change = 0.0057, gam = 0.0260, Max-Change = 0.0063, gam = 0.0246, Max-Change = 0.0033, gam = 0.0233, Max-Change = 0.0053, gam = 0.0222, Max-Change = 0.0039, gam = 0.0212, Max-Change = 0.0055, gam = 0.0203, Max-Change = 0.0013, gam = 0.0195, Max-Change = 0.0041, gam = 0.0188, Max-Change = 0.0022, gam = 0.0181, Max-Change = 0.0027, gam = 0.0175, Max-Change = 0.0050, gam = 0.0169, Max-Change = 0.0055, gam = 0.0164, Max-Change = 0.0043, gam = 0.0159, Max-Change = 0.0011, gam = 0.0154, Max-Change = 0.0016, gam = 0.0150, Max-Change = 0.0014, gam = 0.0146, Max-Change = 0.0014, gam = 0.0142, Max-Change = 0.0016, gam = 0.0139, Max-Change = 0.0026, gam = 0.0135, Max-Change = 0.0041, gam = 0.0132, Max-Change = 0.0024, gam = 0.0129, Max-Change = 0.0024, gam = 0.0126, Max-Change = 0.0012, gam = 0.0124, Max-Change = 0.0010, gam = 0.0121, Max-Change = 0.0047, gam = 0.0119, Max-Change = 0.0034, gam = 0.0116, Max-Change = 0.0035, gam = 0.0114, Max-Change = 0.0021, gam = 0.0112, Max-Change = 0.0016, gam = 0.0110, Max-Change = 0.0016, gam = 0.0108, Max-Change = 0.0022, gam = 0.0106, Max-Change = 0.0027, gam = 0.0104, Max-Change = 0.0019, gam = 0.0102, Max-Change = 0.0012, gam = 0.0101, Max-Change = 0.0024, gam = 0.0099, Max-Change = 0.0007, gam = 0.0098, Max-Change = 0.0020, gam = 0.0096, Max-Change = 0.0020, gam = 0.0095, Max-Change = 0.0023, gam = 0.0093, Max-Change = 0.0021, gam = 0.0092, Max-Change = 0.0010, gam = 0.0091, Max-Change = 0.0006, gam = 0.0089, Max-Change = 0.0012, gam = 0.0088, Max-Change = 0.0012, gam = 0.0087, Max-Change = 0.0010, gam = 0.0086, Max-Change = 0.0014, gam = 0.0085, Max-Change = 0.0008, gam = 0.0084, Max-Change = 0.0007, gam = 0.0082, Max-Change = 0.0017, gam = 0.0081, Max-Change = 0.0018, gam = 0.0080, Max-Change = 0.0010, gam = 0.0080, Max-Change = 0.0007, gam = 0.0079, Max-Change = 0.0024, gam = 0.0078, Max-Change = 0.0003, gam = 0.0077, Max-Change = 0.0009, gam = 0.0076, Max-Change = 0.0014, gam = 0.0075, Max-Change = 0.0013, gam = 0.0074, Max-Change = 0.0022, gam = 0.0073, Max-Change = 0.0009, gam = 0.0073, Max-Change = 0.0011, gam = 0.0072, Max-Change = 0.0027, gam = 0.0071, Max-Change = 0.0010, gam = 0.0070, Max-Change = 0.0007, gam = 0.0070, Max-Change = 0.0008, gam = 0.0069, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... coef(mod) #> $Comfort #>         groupm a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par     -0.084  1   0   1   2   3  0 3.098 5.718 4.364 #> CI_2.5  -0.336 NA  NA  NA  NA  NA NA 2.086 4.677 3.257 #> CI_97.5  0.167 NA  NA  NA  NA  NA NA 4.110 6.759 5.472 #>  #> $Work #>         groupm a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par     -0.084  1   0   1   2   3  0 1.919 2.859 1.038 #> CI_2.5  -0.336 NA  NA  NA  NA  NA NA 1.455 2.311 0.352 #> CI_97.5  0.167 NA  NA  NA  NA  NA NA 2.382 3.406 1.723 #>  #> $Future #>         groupm a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par     -0.084  1   0   1   2   3  0 2.665 4.114 3.013 #> CI_2.5  -0.336 NA  NA  NA  NA  NA NA 2.026 3.406 2.214 #> CI_97.5  0.167 NA  NA  NA  NA  NA NA 3.304 4.822 3.813 #>  #> $Benefit #>         groupm a1 ak0 ak1 ak2 ak3 d0    d1    d2    d3 #> par     -0.084  1   0   1   2   3  0 2.469 3.398 2.076 #> CI_2.5  -0.336 NA  NA  NA  NA  NA NA 1.932 2.779 1.349 #> CI_97.5  0.167 NA  NA  NA  NA  NA NA 3.006 4.016 2.803 #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0  0.985 #> CI_2.5      NA  0.707 #> CI_97.5     NA  1.264 #>   # gpcm to estimate slopes mod2 <- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group,                  itemtype = 'gpcm') #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1776, Max-Change = 0.1068, Max-Change = 0.1180, Max-Change = 0.1121, Max-Change = 0.0996, Max-Change = 0.1305, Max-Change = 0.0338, Max-Change = 0.1041, Max-Change = 0.0588, Max-Change = 0.0460, Max-Change = 0.0885, Max-Change = 0.0954, Max-Change = 0.0450, Max-Change = 0.1303, Max-Change = 0.0976, Max-Change = 0.1155, Max-Change = 0.0919, Max-Change = 0.1057, Max-Change = 0.0780, Max-Change = 0.0979, Max-Change = 0.0675, Max-Change = 0.1021, Max-Change = 0.0427, Max-Change = 0.0814, Max-Change = 0.0625, Max-Change = 0.0662, Max-Change = 0.0919, Max-Change = 0.1059, Max-Change = 0.1302, Max-Change = 0.0629, Max-Change = 0.0813, Max-Change = 0.0782, Max-Change = 0.1577, Max-Change = 0.0302, Max-Change = 0.0778, Max-Change = 0.1032, Max-Change = 0.0458, Max-Change = 0.0519, Max-Change = 0.0532, Max-Change = 0.1538, Max-Change = 0.1558, Max-Change = 0.1330, Max-Change = 0.0485, Max-Change = 0.0976, Max-Change = 0.0576, Max-Change = 0.0236, Max-Change = 0.1744, Max-Change = 0.0174, Max-Change = 0.0716, Max-Change = 0.1091, Max-Change = 0.0652, Max-Change = 0.0722, Max-Change = 0.1248, Max-Change = 0.0696, Max-Change = 0.0928, Max-Change = 0.0199, Max-Change = 0.1060, Max-Change = 0.0868, Max-Change = 0.0901, Max-Change = 0.1216, Max-Change = 0.0595, Max-Change = 0.0360, Max-Change = 0.0834, Max-Change = 0.1512, Max-Change = 0.0561, Max-Change = 0.1249, Max-Change = 0.0744, Max-Change = 0.1373, Max-Change = 0.1111, Max-Change = 0.0304, Max-Change = 0.1097, Max-Change = 0.0966, Max-Change = 0.0830, Max-Change = 0.0232, Max-Change = 0.0628, Max-Change = 0.0403, Max-Change = 0.1226, Max-Change = 0.0310, Max-Change = 0.0457, Max-Change = 0.1221, Max-Change = 0.1108, Max-Change = 0.1636, Max-Change = 0.1611, Max-Change = 0.1112, Max-Change = 0.0778, Max-Change = 0.1025, Max-Change = 0.0633, Max-Change = 0.0344, Max-Change = 0.0296, Max-Change = 0.0352, Max-Change = 0.0954, Max-Change = 0.1280, Max-Change = 0.0501, Max-Change = 0.1303, Max-Change = 0.0549, Max-Change = 0.1357, Max-Change = 0.1346, Max-Change = 0.0546, Max-Change = 0.0694, Max-Change = 0.0904, Max-Change = 0.1042, Max-Change = 0.0233, Max-Change = 0.0545, Max-Change = 0.1438, Max-Change = 0.0567, Max-Change = 0.0701, Max-Change = 0.0924, Max-Change = 0.0772, Max-Change = 0.1517, Max-Change = 0.0887, Max-Change = 0.0719, Max-Change = 0.0368, Max-Change = 0.1098, Max-Change = 0.1057, Max-Change = 0.0267, Max-Change = 0.2000, Max-Change = 0.0747, Max-Change = 0.0943, Max-Change = 0.0283, Max-Change = 0.0432, Max-Change = 0.0995, Max-Change = 0.0564, Max-Change = 0.0250, Max-Change = 0.1342, Max-Change = 0.0971, Max-Change = 0.0706, Max-Change = 0.1048, Max-Change = 0.0733, Max-Change = 0.0640, Max-Change = 0.1025, Max-Change = 0.0336, Max-Change = 0.0938, Max-Change = 0.0412, Max-Change = 0.0341, Max-Change = 0.0649, Max-Change = 0.1457, Max-Change = 0.0507, Max-Change = 0.0572, Max-Change = 0.1275, Max-Change = 0.0559, Max-Change = 0.0260, Max-Change = 0.1585, Max-Change = 0.0572, Max-Change = 0.1437, Max-Change = 0.0925, Max-Change = 0.0352, Max-Change = 0.0378, Max-Change = 0.1587, Max-Change = 0.0881, Max-Change = 0.1472, Max-Change = 0.0677, Max-Change = 0.0775, Max-Change = 0.1794, Max-Change = 0.0888, Max-Change = 0.1212, Max-Change = 0.0466, Max-Change = 0.0483, Max-Change = 0.0559, Max-Change = 0.0440, Max-Change = 0.1637, Max-Change = 0.0334, Max-Change = 0.0264, Max-Change = 0.0531, Max-Change = 0.0262, Max-Change = 0.1146, Max-Change = 0.0283, Max-Change = 0.0489, Max-Change = 0.1149, Max-Change = 0.1332, Max-Change = 0.1170, Max-Change = 0.0390, Max-Change = 0.0484, Max-Change = 0.0567, Max-Change = 0.0678, Max-Change = 0.0505, Max-Change = 0.0526, Max-Change = 0.2000, Max-Change = 0.0915, Max-Change = 0.0471, Max-Change = 0.1616, Max-Change = 0.0679, Max-Change = 0.1139, Max-Change = 0.0587, Max-Change = 0.0723, Max-Change = 0.1630, Max-Change = 0.1455, Max-Change = 0.0390, Max-Change = 0.1358, Max-Change = 0.1216, Max-Change = 0.1024, Max-Change = 0.0847, Max-Change = 0.1856, Max-Change = 0.1123, Max-Change = 0.0340, Max-Change = 0.1251, Max-Change = 0.0451, Max-Change = 0.0858, Max-Change = 0.1119, Max-Change = 0.0819, Max-Change = 0.1402, Max-Change = 0.0619, Max-Change = 0.0700, Max-Change = 0.0546, Max-Change = 0.0847, Max-Change = 0.0283, Max-Change = 0.0607, Max-Change = 0.1731, Max-Change = 0.0976, Max-Change = 0.0916, Max-Change = 0.1646, Max-Change = 0.0688, Max-Change = 0.0275, Max-Change = 0.2000, Max-Change = 0.0603, Max-Change = 0.0934, Max-Change = 0.0944, Max-Change = 0.1044, Max-Change = 0.1739, Max-Change = 0.0828, Max-Change = 0.0794, Max-Change = 0.0359, Max-Change = 0.0265, Max-Change = 0.1483, Max-Change = 0.0836, Max-Change = 0.2000, Max-Change = 0.0339, Max-Change = 0.0317, Max-Change = 0.0652, Max-Change = 0.0273, Max-Change = 0.1724, Max-Change = 0.0454, Max-Change = 0.0369, Max-Change = 0.0521, Max-Change = 0.0760, Max-Change = 0.0256, Max-Change = 0.1141, Max-Change = 0.0382, Max-Change = 0.0813, Max-Change = 0.1710, Max-Change = 0.0684, Max-Change = 0.0900, Max-Change = 0.2000, Max-Change = 0.0473, Max-Change = 0.0458, Max-Change = 0.1378, Max-Change = 0.0302, Max-Change = 0.0392, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0665, gam = 0.1057, Max-Change = 0.0327, gam = 0.0780, Max-Change = 0.0223, gam = 0.0629, Max-Change = 0.0178, gam = 0.0532, Max-Change = 0.0253, gam = 0.0464, Max-Change = 0.0294, gam = 0.0413, Max-Change = 0.0359, gam = 0.0374, Max-Change = 0.0188, gam = 0.0342, Max-Change = 0.0164, gam = 0.0316, Max-Change = 0.0080, gam = 0.0294, Max-Change = 0.0069, gam = 0.0276, Max-Change = 0.0225, gam = 0.0260, Max-Change = 0.0079, gam = 0.0246, Max-Change = 0.0040, gam = 0.0233, Max-Change = 0.0105, gam = 0.0222, Max-Change = 0.0049, gam = 0.0212, Max-Change = 0.0051, gam = 0.0203, Max-Change = 0.0124, gam = 0.0195, Max-Change = 0.0096, gam = 0.0188, Max-Change = 0.0145, gam = 0.0181, Max-Change = 0.0066, gam = 0.0175, Max-Change = 0.0234, gam = 0.0169, Max-Change = 0.0129, gam = 0.0164, Max-Change = 0.0096, gam = 0.0159, Max-Change = 0.0039, gam = 0.0154, Max-Change = 0.0066, gam = 0.0150, Max-Change = 0.0084, gam = 0.0146, Max-Change = 0.0173, gam = 0.0142, Max-Change = 0.0095, gam = 0.0139, Max-Change = 0.0080, gam = 0.0135, Max-Change = 0.0065, gam = 0.0132, Max-Change = 0.0055, gam = 0.0129, Max-Change = 0.0156, gam = 0.0126, Max-Change = 0.0010, gam = 0.0124, Max-Change = 0.0063, gam = 0.0121, Max-Change = 0.0083, gam = 0.0119, Max-Change = 0.0064, gam = 0.0116, Max-Change = 0.0040, gam = 0.0114, Max-Change = 0.0010, gam = 0.0112, Max-Change = 0.0047, gam = 0.0110, Max-Change = 0.0012, gam = 0.0108, Max-Change = 0.0062, gam = 0.0106, Max-Change = 0.0039, gam = 0.0104, Max-Change = 0.0026, gam = 0.0102, Max-Change = 0.0022, gam = 0.0101, Max-Change = 0.0069, gam = 0.0099, Max-Change = 0.0022, gam = 0.0098, Max-Change = 0.0016, gam = 0.0096, Max-Change = 0.0025, gam = 0.0095, Max-Change = 0.0068, gam = 0.0093, Max-Change = 0.0016, gam = 0.0092, Max-Change = 0.0033, gam = 0.0091, Max-Change = 0.0024, gam = 0.0089, Max-Change = 0.0008, gam = 0.0088, Max-Change = 0.0018, gam = 0.0087, Max-Change = 0.0037, gam = 0.0086, Max-Change = 0.0033, gam = 0.0085, Max-Change = 0.0043, gam = 0.0084, Max-Change = 0.0015, gam = 0.0082, Max-Change = 0.0033, gam = 0.0081, Max-Change = 0.0017, gam = 0.0080, Max-Change = 0.0015, gam = 0.0080, Max-Change = 0.0023, gam = 0.0079, Max-Change = 0.0045, gam = 0.0078, Max-Change = 0.0084, gam = 0.0077, Max-Change = 0.0039, gam = 0.0076, Max-Change = 0.0057, gam = 0.0075, Max-Change = 0.0074, gam = 0.0074, Max-Change = 0.0028, gam = 0.0073, Max-Change = 0.0050, gam = 0.0073, Max-Change = 0.0041, gam = 0.0072, Max-Change = 0.0015, gam = 0.0071, Max-Change = 0.0017, gam = 0.0070, Max-Change = 0.0032, gam = 0.0070, Max-Change = 0.0028, gam = 0.0069, Max-Change = 0.0059, gam = 0.0068, Max-Change = 0.0013, gam = 0.0068, Max-Change = 0.0025, gam = 0.0067, Max-Change = 0.0022, gam = 0.0066, Max-Change = 0.0029, gam = 0.0066, Max-Change = 0.0010, gam = 0.0065, Max-Change = 0.0021, gam = 0.0065, Max-Change = 0.0022, gam = 0.0064, Max-Change = 0.0038, gam = 0.0064, Max-Change = 0.0062, gam = 0.0063, Max-Change = 0.0027, gam = 0.0062, Max-Change = 0.0034, gam = 0.0062, Max-Change = 0.0016, gam = 0.0061, Max-Change = 0.0009, gam = 0.0061, Max-Change = 0.0035, gam = 0.0060, Max-Change = 0.0053, gam = 0.0060, Max-Change = 0.0045, gam = 0.0059, Max-Change = 0.0027, gam = 0.0059, Max-Change = 0.0033, gam = 0.0058, Max-Change = 0.0043, gam = 0.0058, Max-Change = 0.0009, gam = 0.0058, Max-Change = 0.0033, gam = 0.0057, Max-Change = 0.0026, gam = 0.0057, Max-Change = 0.0025, gam = 0.0056, Max-Change = 0.0036, gam = 0.0056, Max-Change = 0.0012, gam = 0.0055, Max-Change = 0.0011, gam = 0.0055, Max-Change = 0.0044, gam = 0.0055, Max-Change = 0.0023, gam = 0.0054, Max-Change = 0.0014, gam = 0.0054, Max-Change = 0.0018, gam = 0.0053, Max-Change = 0.0028, gam = 0.0053, Max-Change = 0.0013, gam = 0.0053, Max-Change = 0.0060, gam = 0.0052, Max-Change = 0.0042, gam = 0.0052, Max-Change = 0.0029, gam = 0.0052, Max-Change = 0.0013, gam = 0.0051, Max-Change = 0.0012, gam = 0.0051, Max-Change = 0.0016, gam = 0.0051, Max-Change = 0.0022, gam = 0.0050, Max-Change = 0.0018, gam = 0.0050, Max-Change = 0.0008, gam = 0.0050, Max-Change = 0.0027, gam = 0.0049, Max-Change = 0.0021, gam = 0.0049, Max-Change = 0.0042, gam = 0.0049, Max-Change = 0.0008, gam = 0.0048, Max-Change = 0.0034, gam = 0.0048, Max-Change = 0.0020, gam = 0.0048, Max-Change = 0.0019, gam = 0.0048, Max-Change = 0.0020, gam = 0.0047, Max-Change = 0.0009, gam = 0.0047, Max-Change = 0.0027, gam = 0.0047, Max-Change = 0.0064, gam = 0.0046, Max-Change = 0.0032, gam = 0.0046, Max-Change = 0.0016, gam = 0.0046, Max-Change = 0.0038, gam = 0.0046, Max-Change = 0.0044, gam = 0.0045, Max-Change = 0.0015, gam = 0.0045, Max-Change = 0.0018, gam = 0.0045, Max-Change = 0.0019, gam = 0.0045, Max-Change = 0.0023, gam = 0.0044, Max-Change = 0.0010, gam = 0.0044, Max-Change = 0.0006, gam = 0.0044, Max-Change = 0.0012, gam = 0.0044, Max-Change = 0.0014, gam = 0.0043, Max-Change = 0.0025, gam = 0.0043, Max-Change = 0.0044, gam = 0.0043, Max-Change = 0.0040, gam = 0.0043, Max-Change = 0.0023, gam = 0.0043, Max-Change = 0.0011, gam = 0.0042, Max-Change = 0.0013, gam = 0.0042, Max-Change = 0.0020, gam = 0.0042, Max-Change = 0.0012, gam = 0.0042, Max-Change = 0.0027, gam = 0.0041, Max-Change = 0.0016, gam = 0.0041, Max-Change = 0.0035, gam = 0.0041, Max-Change = 0.0036, gam = 0.0041, Max-Change = 0.0044, gam = 0.0041, Max-Change = 0.0009, gam = 0.0040, Max-Change = 0.0007, gam = 0.0040, Max-Change = 0.0028, gam = 0.0040, Max-Change = 0.0029, gam = 0.0040, Max-Change = 0.0011, gam = 0.0040, Max-Change = 0.0026, gam = 0.0040, Max-Change = 0.0008, gam = 0.0039, Max-Change = 0.0011, gam = 0.0039, Max-Change = 0.0011, gam = 0.0039, Max-Change = 0.0017, gam = 0.0039, Max-Change = 0.0028, gam = 0.0039, Max-Change = 0.0012, gam = 0.0038, Max-Change = 0.0014, gam = 0.0038, Max-Change = 0.0020, gam = 0.0038, Max-Change = 0.0017, gam = 0.0038, Max-Change = 0.0020, gam = 0.0038, Max-Change = 0.0010, gam = 0.0038, Max-Change = 0.0028, gam = 0.0037, Max-Change = 0.0010, gam = 0.0037, Max-Change = 0.0015, gam = 0.0037, Max-Change = 0.0007, gam = 0.0037, Max-Change = 0.0008, gam = 0.0037, Max-Change = 0.0021, gam = 0.0037, Max-Change = 0.0017, gam = 0.0036, Max-Change = 0.0007, gam = 0.0036, Max-Change = 0.0020, gam = 0.0036, Max-Change = 0.0024, gam = 0.0036, Max-Change = 0.0015, gam = 0.0036, Max-Change = 0.0030, gam = 0.0036, Max-Change = 0.0018, gam = 0.0036, Max-Change = 0.0007, gam = 0.0035, Max-Change = 0.0012, gam = 0.0035, Max-Change = 0.0009, gam = 0.0035, Max-Change = 0.0007, gam = 0.0035, Max-Change = 0.0021, gam = 0.0035, Max-Change = 0.0040, gam = 0.0035, Max-Change = 0.0013, gam = 0.0035, Max-Change = 0.0032, gam = 0.0034, Max-Change = 0.0028, gam = 0.0034, Max-Change = 0.0010, gam = 0.0034, Max-Change = 0.0015, gam = 0.0034, Max-Change = 0.0009, gam = 0.0034, Max-Change = 0.0017, gam = 0.0034, Max-Change = 0.0024, gam = 0.0034, Max-Change = 0.0009, gam = 0.0034, Max-Change = 0.0003, gam = 0.0033, Max-Change = 0.0013, gam = 0.0033, Max-Change = 0.0014, gam = 0.0033, Max-Change = 0.0006, gam = 0.0033, Max-Change = 0.0013, gam = 0.0033, Max-Change = 0.0013, gam = 0.0033, Max-Change = 0.0011, gam = 0.0033, Max-Change = 0.0005, gam = 0.0033, Max-Change = 0.0046, gam = 0.0032, Max-Change = 0.0016, gam = 0.0032, Max-Change = 0.0018, gam = 0.0032, Max-Change = 0.0004, gam = 0.0032, Max-Change = 0.0020, gam = 0.0032, Max-Change = 0.0020, gam = 0.0032, Max-Change = 0.0007, gam = 0.0032, Max-Change = 0.0012, gam = 0.0032, Max-Change = 0.0015, gam = 0.0032, Max-Change = 0.0020, gam = 0.0031, Max-Change = 0.0005, gam = 0.0031, Max-Change = 0.0015, gam = 0.0031, Max-Change = 0.0017, gam = 0.0031, Max-Change = 0.0010, gam = 0.0031, Max-Change = 0.0008, gam = 0.0031, Max-Change = 0.0018, gam = 0.0031, Max-Change = 0.0024, gam = 0.0031, Max-Change = 0.0031, gam = 0.0031, Max-Change = 0.0023, gam = 0.0031, Max-Change = 0.0031, gam = 0.0030, Max-Change = 0.0004, gam = 0.0030, Max-Change = 0.0004, gam = 0.0030, Max-Change = 0.0009 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod2) #>  #> Call: #> mixedmirt(data = Science, covdata = covdat, model = 1, fixed = ~0 +  #>     group, itemtype = \"gpcm\") #>  #> -------------- #> FIXED EFFECTS: #>        Estimate Std.Error z.value #> groupm   -0.176     0.118  -1.494 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>    F1 #> F1  1 #>  anova(mod, mod2) #>           AIC    SABIC       HQ      BIC    logLik   X2 df     p #> mod  3264.979 3276.155 3287.014 3320.577 -1618.489               #> mod2 3258.379 3271.950 3285.136 3325.891 -1612.190 12.6  3 0.006  # graded model mod3 <- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group,                  itemtype = 'graded') #> , Max-Change = 0.0936, Max-Change = 0.0628, Max-Change = 0.0682, Max-Change = 0.0779, Max-Change = 0.0530, Max-Change = 0.0384, Max-Change = 0.0643, Max-Change = 0.0358, Max-Change = 0.1088, Max-Change = 0.0556, Max-Change = 0.0754, Max-Change = 0.0696, Max-Change = 0.0500, Max-Change = 0.0316, Max-Change = 0.0371, Max-Change = 0.0448, Max-Change = 0.0569, Max-Change = 0.0753, Max-Change = 0.0459, Max-Change = 0.0565, Max-Change = 0.0385, Max-Change = 0.0177, Max-Change = 0.0258, Max-Change = 0.0425, Max-Change = 0.0579, Max-Change = 0.0233, Max-Change = 0.0269, Max-Change = 0.0206, Max-Change = 0.0494, Max-Change = 0.0379, Max-Change = 0.0439, Max-Change = 0.0775, Max-Change = 0.0386, Max-Change = 0.0435, Max-Change = 0.0212, Max-Change = 0.0944, Max-Change = 0.0190, Max-Change = 0.0412, Max-Change = 0.0670, Max-Change = 0.0318, Max-Change = 0.0405, Max-Change = 0.0383, Max-Change = 0.0675, Max-Change = 0.0429, Max-Change = 0.0710, Max-Change = 0.0385, Max-Change = 0.0516, Max-Change = 0.0490, Max-Change = 0.0381, Max-Change = 0.0909, Max-Change = 0.0201, Max-Change = 0.0393, Max-Change = 0.0424, Max-Change = 0.0310, Max-Change = 0.0379, Max-Change = 0.0371, Max-Change = 0.1221, Max-Change = 0.0474, Max-Change = 0.0486, Max-Change = 0.0651, Max-Change = 0.0363, Max-Change = 0.0310, Max-Change = 0.0917, Max-Change = 0.0539, Max-Change = 0.0282, Max-Change = 0.0437, Max-Change = 0.0413, Max-Change = 0.0446, Max-Change = 0.0343, Max-Change = 0.0360, Max-Change = 0.0701, Max-Change = 0.0552, Max-Change = 0.0295, Max-Change = 0.0505, Max-Change = 0.0599, Max-Change = 0.0442, Max-Change = 0.0321, Max-Change = 0.0408, Max-Change = 0.0260, Max-Change = 0.0358, Max-Change = 0.0379, Max-Change = 0.0366, Max-Change = 0.0425, Max-Change = 0.0911, Max-Change = 0.0482, Max-Change = 0.0729, Max-Change = 0.0495, Max-Change = 0.0480, Max-Change = 0.0313, Max-Change = 0.0560, Max-Change = 0.0323, Max-Change = 0.0339, Max-Change = 0.0423, Max-Change = 0.0947, Max-Change = 0.0268, Max-Change = 0.0233, Max-Change = 0.0482, Max-Change = 0.0317, Max-Change = 0.0484, Max-Change = 0.0427, Max-Change = 0.0749, Max-Change = 0.0558, Max-Change = 0.0468, Max-Change = 0.0896, Max-Change = 0.0333, Max-Change = 0.0351, Max-Change = 0.0371, Max-Change = 0.0444, Max-Change = 0.0392, Max-Change = 0.0493, Max-Change = 0.0454, Max-Change = 0.0264, Max-Change = 0.0272, Max-Change = 0.0301, Max-Change = 0.0299, Max-Change = 0.0344, Max-Change = 0.0460, Max-Change = 0.0483, Max-Change = 0.0884, Max-Change = 0.0503, Max-Change = 0.0337, Max-Change = 0.0218, Max-Change = 0.0212, Max-Change = 0.0804, Max-Change = 0.0338, Max-Change = 0.0272, Max-Change = 0.0332, Max-Change = 0.0395, Max-Change = 0.0609, Max-Change = 0.0310, Max-Change = 0.0271, Max-Change = 0.0554, Max-Change = 0.0289, Max-Change = 0.0460, Max-Change = 0.0677, Max-Change = 0.0711, Max-Change = 0.0312, Max-Change = 0.0287, Max-Change = 0.0526, Max-Change = 0.0342, Max-Change = 0.0345, Max-Change = 0.0297, Max-Change = 0.0384, Max-Change = 0.0285, Max-Change = 0.0479, Max-Change = 0.0354, Max-Change = 0.1089, Max-Change = 0.0675, Max-Change = 0.0314, Max-Change = 0.0452, Max-Change = 0.1232, Max-Change = 0.0390, Max-Change = 0.0892, Max-Change = 0.0303, Max-Change = 0.0327, Max-Change = 0.1439, Max-Change = 0.0321, Max-Change = 0.0940, Max-Change = 0.0379, Max-Change = 0.0813, Max-Change = 0.0346, Max-Change = 0.0404, Max-Change = 0.0554, Max-Change = 0.0336, Max-Change = 0.0281, Max-Change = 0.0589, Max-Change = 0.0316, Max-Change = 0.0912, Max-Change = 0.0500, Max-Change = 0.0364, Max-Change = 0.1087, Max-Change = 0.0267, Max-Change = 0.0234, Max-Change = 0.0413, Max-Change = 0.0177, Max-Change = 0.0276, Max-Change = 0.0715, Max-Change = 0.0415, Max-Change = 0.0250, Max-Change = 0.1006, Max-Change = 0.0210, Max-Change = 0.0568, Max-Change = 0.1370, Max-Change = 0.0315, Max-Change = 0.0599, Max-Change = 0.0186, Max-Change = 0.0953, Max-Change = 0.0973, Max-Change = 0.0536, Max-Change = 0.0967, Max-Change = 0.0323, Max-Change = 0.0438, Max-Change = 0.0825, Max-Change = 0.0453, Max-Change = 0.0471, Max-Change = 0.0624, Max-Change = 0.0290, Max-Change = 0.0384, Max-Change = 0.0372, Max-Change = 0.0810, Max-Change = 0.0457, Max-Change = 0.0415, Max-Change = 0.0329, Max-Change = 0.0675, Max-Change = 0.0283, Max-Change = 0.0571, Max-Change = 0.0277, Max-Change = 0.0567, Max-Change = 0.0597, Max-Change = 0.1081, Max-Change = 0.0365, Max-Change = 0.0409, Max-Change = 0.0624, Max-Change = 0.0567, Max-Change = 0.0347, Max-Change = 0.1347, Max-Change = 0.0570, Max-Change = 0.0683, Max-Change = 0.0604, Max-Change = 0.0916, Max-Change = 0.0895, Max-Change = 0.0384, Max-Change = 0.0310, Max-Change = 0.0302, Max-Change = 0.0528, Max-Change = 0.0244, Max-Change = 0.0991, Max-Change = 0.0630, Max-Change = 0.0419, Max-Change = 0.0702, Max-Change = 0.0346, Max-Change = 0.0397, Max-Change = 0.0542, Max-Change = 0.0295, Max-Change = 0.0251, Max-Change = 0.0376, Max-Change = 0.0436, Max-Change = 0.0139, Max-Change = 0.0323, Max-Change = 0.0293, Max-Change = 0.0452, Max-Change = 0.1383, Max-Change = 0.0361, Max-Change = 0.0899, Max-Change = 0.0155, Max-Change = 0.0330, Max-Change = 0.0329, Max-Change = 0.0665, Max-Change = 0.0744, Max-Change = 0.0201, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0371, gam = 0.1057, Max-Change = 0.0347, gam = 0.0780, Max-Change = 0.0089, gam = 0.0629, Max-Change = 0.0091, gam = 0.0532, Max-Change = 0.0179, gam = 0.0464, Max-Change = 0.0041, gam = 0.0413, Max-Change = 0.0156, gam = 0.0374, Max-Change = 0.0204, gam = 0.0342, Max-Change = 0.0039, gam = 0.0316, Max-Change = 0.0069, gam = 0.0294, Max-Change = 0.0038, gam = 0.0276, Max-Change = 0.0136, gam = 0.0260, Max-Change = 0.0049, gam = 0.0246, Max-Change = 0.0066, gam = 0.0233, Max-Change = 0.0074, gam = 0.0222, Max-Change = 0.0075, gam = 0.0212, Max-Change = 0.0039, gam = 0.0203, Max-Change = 0.0053, gam = 0.0195, Max-Change = 0.0072, gam = 0.0188, Max-Change = 0.0108, gam = 0.0181, Max-Change = 0.0049, gam = 0.0175, Max-Change = 0.0108, gam = 0.0169, Max-Change = 0.0109, gam = 0.0164, Max-Change = 0.0079, gam = 0.0159, Max-Change = 0.0041, gam = 0.0154, Max-Change = 0.0025, gam = 0.0150, Max-Change = 0.0063, gam = 0.0146, Max-Change = 0.0015, gam = 0.0142, Max-Change = 0.0017, gam = 0.0139, Max-Change = 0.0084, gam = 0.0135, Max-Change = 0.0026, gam = 0.0132, Max-Change = 0.0021, gam = 0.0129, Max-Change = 0.0017, gam = 0.0126, Max-Change = 0.0022, gam = 0.0124, Max-Change = 0.0036, gam = 0.0121, Max-Change = 0.0035, gam = 0.0119, Max-Change = 0.0030, gam = 0.0116, Max-Change = 0.0023, gam = 0.0114, Max-Change = 0.0019, gam = 0.0112, Max-Change = 0.0028, gam = 0.0110, Max-Change = 0.0014, gam = 0.0108, Max-Change = 0.0045, gam = 0.0106, Max-Change = 0.0017, gam = 0.0104, Max-Change = 0.0016, gam = 0.0102, Max-Change = 0.0021, gam = 0.0101, Max-Change = 0.0019, gam = 0.0099, Max-Change = 0.0030, gam = 0.0098, Max-Change = 0.0021, gam = 0.0096, Max-Change = 0.0016, gam = 0.0095, Max-Change = 0.0009, gam = 0.0093, Max-Change = 0.0015, gam = 0.0092, Max-Change = 0.0024, gam = 0.0091, Max-Change = 0.0024, gam = 0.0089, Max-Change = 0.0015, gam = 0.0088, Max-Change = 0.0032, gam = 0.0087, Max-Change = 0.0023, gam = 0.0086, Max-Change = 0.0046, gam = 0.0085, Max-Change = 0.0013, gam = 0.0084, Max-Change = 0.0015, gam = 0.0082, Max-Change = 0.0019, gam = 0.0081, Max-Change = 0.0014, gam = 0.0080, Max-Change = 0.0016, gam = 0.0080, Max-Change = 0.0030, gam = 0.0079, Max-Change = 0.0009, gam = 0.0078, Max-Change = 0.0022, gam = 0.0077, Max-Change = 0.0009, gam = 0.0076, Max-Change = 0.0027, gam = 0.0075, Max-Change = 0.0026, gam = 0.0074, Max-Change = 0.0018, gam = 0.0073, Max-Change = 0.0044, gam = 0.0073, Max-Change = 0.0013, gam = 0.0072, Max-Change = 0.0018, gam = 0.0071, Max-Change = 0.0013, gam = 0.0070, Max-Change = 0.0015, gam = 0.0070, Max-Change = 0.0030, gam = 0.0069, Max-Change = 0.0032, gam = 0.0068, Max-Change = 0.0006, gam = 0.0068, Max-Change = 0.0016, gam = 0.0067, Max-Change = 0.0018, gam = 0.0066, Max-Change = 0.0017, gam = 0.0066, Max-Change = 0.0020, gam = 0.0065, Max-Change = 0.0007, gam = 0.0065, Max-Change = 0.0008, gam = 0.0064, Max-Change = 0.0013, gam = 0.0064, Max-Change = 0.0023, gam = 0.0063, Max-Change = 0.0024, gam = 0.0062, Max-Change = 0.0020, gam = 0.0062, Max-Change = 0.0009, gam = 0.0061, Max-Change = 0.0008, gam = 0.0061, Max-Change = 0.0016, gam = 0.0060, Max-Change = 0.0011, gam = 0.0060, Max-Change = 0.0005, gam = 0.0059, Max-Change = 0.0013, gam = 0.0059, Max-Change = 0.0007, gam = 0.0058, Max-Change = 0.0009, gam = 0.0058, Max-Change = 0.0007 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... coef(mod3) #> $Comfort #>         groupm    a1    d1    d2     d3 #> par     -0.248 1.000 4.951 2.735 -1.327 #> CI_2.5  -0.578 0.636 3.989 2.289 -1.682 #> CI_97.5  0.082 1.363 5.913 3.181 -0.971 #>  #> $Work #>         groupm    a1    d1    d2     d3 #> par     -0.248 1.212 3.034 1.020 -2.133 #> CI_2.5  -0.578 0.873 2.545 0.697 -2.554 #> CI_97.5  0.082 1.551 3.522 1.342 -1.712 #>  #> $Future #>         groupm    a1    d1    d2     d3 #> par     -0.248 2.581 5.761 2.524 -1.995 #> CI_2.5  -0.578 1.251 3.733 1.497 -2.807 #> CI_97.5  0.082 3.911 7.789 3.551 -1.182 #>  #> $Benefit #>         groupm    a1    d1    d2     d3 #> par     -0.248 1.075 3.456 1.110 -1.554 #> CI_2.5  -0.578 0.728 2.905 0.796 -1.925 #> CI_97.5  0.082 1.423 4.007 1.423 -1.183 #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0      1 #> CI_2.5      NA     NA #> CI_97.5     NA     NA #>    ################################################### # latent regression with Rasch and 2PL models  set.seed(1) n <- 300 a <- matrix(1, 10) d <- matrix(rnorm(10)) Theta <- matrix(c(rnorm(n, 0), rnorm(n, 1), rnorm(n, 2))) covdata <- data.frame(group=rep(c('g1','g2','g3'), each=n)) dat <- simdata(a, d, N=n*3, Theta=Theta, itemtype = '2PL') itemstats(dat) #> $overall #>    N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  900            6.932          2.347 0.197 0.035 0.709     1.266 #>  #> $itemstats #>           N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  900 2 0.570 0.495   0.604         0.443       0.673 #> Item_2  900 2 0.689 0.463   0.518         0.351       0.690 #> Item_3  900 2 0.526 0.500   0.531         0.352       0.691 #> Item_4  900 2 0.892 0.310   0.422         0.305       0.698 #> Item_5  900 2 0.748 0.435   0.522         0.367       0.687 #> Item_6  900 2 0.543 0.498   0.569         0.398       0.682 #> Item_7  900 2 0.759 0.428   0.530         0.379       0.685 #> Item_8  900 2 0.803 0.398   0.516         0.375       0.686 #> Item_9  900 2 0.777 0.417   0.489         0.337       0.692 #> Item_10 900 2 0.626 0.484   0.548         0.378       0.685 #>  #> $proportions #>             0     1 #> Item_1  0.430 0.570 #> Item_2  0.311 0.689 #> Item_3  0.474 0.526 #> Item_4  0.108 0.892 #> Item_5  0.252 0.748 #> Item_6  0.457 0.543 #> Item_7  0.241 0.759 #> Item_8  0.197 0.803 #> Item_9  0.223 0.777 #> Item_10 0.374 0.626 #>   # had we known the latent abilities, we could have computed the regression coefs summary(lm(Theta ~ covdata$group)) #>  #> Call: #> lm(formula = Theta ~ covdata$group) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -2.9871 -0.6851 -0.0427  0.7170  3.8313  #>  #> Coefficients: #>                 Estimate Std. Error t value Pr(>|t|)     #> (Intercept)      0.04434    0.05970   0.743    0.458     #> covdata$groupg2  0.93468    0.08443  11.071   <2e-16 *** #> covdata$groupg3  1.88134    0.08443  22.284   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 1.034 on 897 degrees of freedom #> Multiple R-squared:  0.3563,\tAdjusted R-squared:  0.3549  #> F-statistic: 248.3 on 2 and 897 DF,  p-value: < 2.2e-16 #>   # but all we have is observed test data. Latent regression helps to recover these coefs # Rasch model approach (and mirt equivalent) rmod0 <- mirt(dat, 1, 'Rasch') # unconditional #>   # these two models are equivalent rmod1a <- mirt(dat, 1, 'Rasch', covdata = covdata, formula = ~ group) #>  rmod1b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1660, Max-Change = 0.1608, Max-Change = 0.1153, Max-Change = 0.1284, Max-Change = 0.1084, Max-Change = 0.0957, Max-Change = 0.0911, Max-Change = 0.0686, Max-Change = 0.0641, Max-Change = 0.0574, Max-Change = 0.0470, Max-Change = 0.0606, Max-Change = 0.0515, Max-Change = 0.0547, Max-Change = 0.0557, Max-Change = 0.0498, Max-Change = 0.0395, Max-Change = 0.0418, Max-Change = 0.0242, Max-Change = 0.0275, Max-Change = 0.0258, Max-Change = 0.0452, Max-Change = 0.0276, Max-Change = 0.0125, Max-Change = 0.0253, Max-Change = 0.0108, Max-Change = 0.0333, Max-Change = 0.0210, Max-Change = 0.0134, Max-Change = 0.0152, Max-Change = 0.0231, Max-Change = 0.0217, Max-Change = 0.0079, Max-Change = 0.0055, Max-Change = 0.0177, Max-Change = 0.0161, Max-Change = 0.0112, Max-Change = 0.0215, Max-Change = 0.0093, Max-Change = 0.0148, Max-Change = 0.0046, Max-Change = 0.0062, Max-Change = 0.0209, Max-Change = 0.0151, Max-Change = 0.0218, Max-Change = 0.0196, Max-Change = 0.0184, Max-Change = 0.0086, Max-Change = 0.0131, Max-Change = 0.0063, Max-Change = 0.0094, Max-Change = 0.0153, Max-Change = 0.0218, Max-Change = 0.0101, Max-Change = 0.0083, Max-Change = 0.0093, Max-Change = 0.0063, Max-Change = 0.0164, Max-Change = 0.0056, Max-Change = 0.0080, Max-Change = 0.0213, Max-Change = 0.0182, Max-Change = 0.0181, Max-Change = 0.0143, Max-Change = 0.0046, Max-Change = 0.0158, Max-Change = 0.0097, Max-Change = 0.0053, Max-Change = 0.0100, Max-Change = 0.0160, Max-Change = 0.0180, Max-Change = 0.0125, Max-Change = 0.0130, Max-Change = 0.0052, Max-Change = 0.0130, Max-Change = 0.0063, Max-Change = 0.0151, Max-Change = 0.0077, Max-Change = 0.0175, Max-Change = 0.0040, Max-Change = 0.0118, Max-Change = 0.0074, Max-Change = 0.0119, Max-Change = 0.0034, Max-Change = 0.0066, Max-Change = 0.0120, Max-Change = 0.0091, Max-Change = 0.0088, Max-Change = 0.0247, Max-Change = 0.0402, Max-Change = 0.0111, Max-Change = 0.0130, Max-Change = 0.0303, Max-Change = 0.0130, Max-Change = 0.0019, Max-Change = 0.0164, Max-Change = 0.0046, Max-Change = 0.0144, Max-Change = 0.0129, Max-Change = 0.0112, Max-Change = 0.0158, Max-Change = 0.0095, Max-Change = 0.0094, Max-Change = 0.0093, Max-Change = 0.0221, Max-Change = 0.0065, Max-Change = 0.0094, Max-Change = 0.0084, Max-Change = 0.0103, Max-Change = 0.0149, Max-Change = 0.0050, Max-Change = 0.0116, Max-Change = 0.0152, Max-Change = 0.0187, Max-Change = 0.0131, Max-Change = 0.0103, Max-Change = 0.0097, Max-Change = 0.0067, Max-Change = 0.0101, Max-Change = 0.0154, Max-Change = 0.0066, Max-Change = 0.0054, Max-Change = 0.0095, Max-Change = 0.0134, Max-Change = 0.0274, Max-Change = 0.0198, Max-Change = 0.0215, Max-Change = 0.0062, Max-Change = 0.0192, Max-Change = 0.0136, Max-Change = 0.0070, Max-Change = 0.0231, Max-Change = 0.0084, Max-Change = 0.0036, Max-Change = 0.0111, Max-Change = 0.0212, Max-Change = 0.0077, Max-Change = 0.0103, Max-Change = 0.0066, Max-Change = 0.0145, Max-Change = 0.0148, Max-Change = 0.0220, Max-Change = 0.0106, Max-Change = 0.0029, Max-Change = 0.0118, Max-Change = 0.0063, Max-Change = 0.0111, Max-Change = 0.0124, Max-Change = 0.0123, Max-Change = 0.0334, Max-Change = 0.0058, Max-Change = 0.0069, Max-Change = 0.0107, Max-Change = 0.0096, Max-Change = 0.0085, Max-Change = 0.0131, Max-Change = 0.0087, Max-Change = 0.0044, Max-Change = 0.0128, Max-Change = 0.0061, Max-Change = 0.0071, Max-Change = 0.0255, Max-Change = 0.0085, Max-Change = 0.0039, Max-Change = 0.0073, Max-Change = 0.0116, Max-Change = 0.0178, Max-Change = 0.0079, Max-Change = 0.0110, Max-Change = 0.0258, Max-Change = 0.0104, Max-Change = 0.0107, Max-Change = 0.0188, Max-Change = 0.0064, Max-Change = 0.0130, Max-Change = 0.0245, Max-Change = 0.0130, Max-Change = 0.0056, Max-Change = 0.0093, Max-Change = 0.0055, Max-Change = 0.0215, Max-Change = 0.0085, Max-Change = 0.0101, Max-Change = 0.0114, Max-Change = 0.0121, Max-Change = 0.0113, Max-Change = 0.0278, Max-Change = 0.0092, Max-Change = 0.0157, Max-Change = 0.0057, Max-Change = 0.0107, Max-Change = 0.0197, Max-Change = 0.0160, Max-Change = 0.0130, Max-Change = 0.0111, Max-Change = 0.0104, Max-Change = 0.0099, Max-Change = 0.0070, Max-Change = 0.0122, Max-Change = 0.0056, Max-Change = 0.0191, Max-Change = 0.0057, Max-Change = 0.0093, Max-Change = 0.0135, Max-Change = 0.0127, Max-Change = 0.0101, Max-Change = 0.0207, Max-Change = 0.0223, Max-Change = 0.0166, Max-Change = 0.0193, Max-Change = 0.0147, Max-Change = 0.0132, Max-Change = 0.0091, Max-Change = 0.0186, Max-Change = 0.0149, Max-Change = 0.0111, Max-Change = 0.0074, Max-Change = 0.0106, Max-Change = 0.0046, Max-Change = 0.0145, Max-Change = 0.0145, Max-Change = 0.0062, Max-Change = 0.0128, Max-Change = 0.0127, Max-Change = 0.0167, Max-Change = 0.0117, Max-Change = 0.0079, Max-Change = 0.0170, Max-Change = 0.0163, Max-Change = 0.0093, Max-Change = 0.0094, Max-Change = 0.0147, Max-Change = 0.0057, Max-Change = 0.0175, Max-Change = 0.0084, Max-Change = 0.0149, Max-Change = 0.0051, Max-Change = 0.0126, Max-Change = 0.0149, Max-Change = 0.0224, Max-Change = 0.0094, Max-Change = 0.0108, Max-Change = 0.0175, Max-Change = 0.0080, Max-Change = 0.0122, Max-Change = 0.0100, Max-Change = 0.0113, Max-Change = 0.0164, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0118, gam = 0.1057, Max-Change = 0.0087, gam = 0.0780, Max-Change = 0.0021, gam = 0.0629, Max-Change = 0.0056, gam = 0.0532, Max-Change = 0.0039, gam = 0.0464, Max-Change = 0.0022, gam = 0.0413, Max-Change = 0.0034, gam = 0.0374, Max-Change = 0.0035, gam = 0.0342, Max-Change = 0.0008, gam = 0.0316, Max-Change = 0.0007, gam = 0.0294, Max-Change = 0.0039, gam = 0.0276, Max-Change = 0.0024, gam = 0.0260, Max-Change = 0.0019, gam = 0.0246, Max-Change = 0.0009, gam = 0.0233, Max-Change = 0.0017, gam = 0.0222, Max-Change = 0.0011, gam = 0.0212, Max-Change = 0.0014, gam = 0.0203, Max-Change = 0.0008, gam = 0.0195, Max-Change = 0.0002, gam = 0.0188, Max-Change = 0.0021, gam = 0.0181, Max-Change = 0.0009, gam = 0.0175, Max-Change = 0.0015, gam = 0.0169, Max-Change = 0.0011, gam = 0.0164, Max-Change = 0.0010, gam = 0.0159, Max-Change = 0.0004, gam = 0.0154, Max-Change = 0.0009, gam = 0.0150, Max-Change = 0.0003 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... anova(rmod0, rmod1b) #>             AIC    SABIC       HQ      BIC    logLik      X2 df p #> rmod0  9698.483 9716.375 9718.663 9751.310 -4838.242              #> rmod1b 9472.610 9493.755 9496.459 9535.041 -4723.305 229.873  2 0 coef(rmod1a, simplify=TRUE) #> $items #>         a1      d g u #> Item_1   1 -0.466 0 1 #> Item_2   1  0.193 0 1 #> Item_3   1 -0.699 0 1 #> Item_4   1  1.795 0 1 #> Item_5   1  0.561 0 1 #> Item_6   1 -0.607 0 1 #> Item_7   1  0.636 0 1 #> Item_8   1  0.957 0 1 #> Item_9   1  0.759 0 1 #> Item_10  1 -0.167 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 1.005 #>  #> $lr.betas #>                F1 #> (Intercept) 0.000 #> groupg2     0.797 #> groupg3     1.707 #>  summary(rmod1b) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items + group) #>  #> -------------- #> FIXED EFFECTS: #>         Estimate Std.Error z.value #> groupg2    0.821     0.118   6.972 #> groupg3    1.683     0.111  15.140 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>    F1 #> F1  1 #>   # 2PL, requires different input to allow Theta variance to remain fixed mod0 <- mirt(dat, 1) # unconditional #>  mod1a <- mirt(dat, 1, covdata = covdata, formula = ~ group, itemtype = '2PL') #>  mod1b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.fixed = ~group, itemtype = '2PL') #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1937, Max-Change = 0.1590, Max-Change = 0.1455, Max-Change = 0.1217, Max-Change = 0.1043, Max-Change = 0.0948, Max-Change = 0.0799, Max-Change = 0.0691, Max-Change = 0.0633, Max-Change = 0.0481, Max-Change = 0.0417, Max-Change = 0.0393, Max-Change = 0.0264, Max-Change = 0.0549, Max-Change = 0.0198, Max-Change = 0.0260, Max-Change = 0.0205, Max-Change = 0.0201, Max-Change = 0.0274, Max-Change = 0.0250, Max-Change = 0.0381, Max-Change = 0.0146, Max-Change = 0.0227, Max-Change = 0.0456, Max-Change = 0.0278, Max-Change = 0.0151, Max-Change = 0.0267, Max-Change = 0.0274, Max-Change = 0.0234, Max-Change = 0.0229, Max-Change = 0.0192, Max-Change = 0.0254, Max-Change = 0.0336, Max-Change = 0.0151, Max-Change = 0.0182, Max-Change = 0.0177, Max-Change = 0.0190, Max-Change = 0.0151, Max-Change = 0.0118, Max-Change = 0.0229, Max-Change = 0.0186, Max-Change = 0.0140, Max-Change = 0.0197, Max-Change = 0.0176, Max-Change = 0.0128, Max-Change = 0.0154, Max-Change = 0.0254, Max-Change = 0.0187, Max-Change = 0.0143, Max-Change = 0.0170, Max-Change = 0.0234, Max-Change = 0.0362, Max-Change = 0.0341, Max-Change = 0.0320, Max-Change = 0.0249, Max-Change = 0.0158, Max-Change = 0.0274, Max-Change = 0.0170, Max-Change = 0.0274, Max-Change = 0.0203, Max-Change = 0.0240, Max-Change = 0.0293, Max-Change = 0.0185, Max-Change = 0.0166, Max-Change = 0.0328, Max-Change = 0.0220, Max-Change = 0.0272, Max-Change = 0.0278, Max-Change = 0.0197, Max-Change = 0.0209, Max-Change = 0.0114, Max-Change = 0.0254, Max-Change = 0.0274, Max-Change = 0.0209, Max-Change = 0.0179, Max-Change = 0.0176, Max-Change = 0.0122, Max-Change = 0.0209, Max-Change = 0.0207, Max-Change = 0.0190, Max-Change = 0.0240, Max-Change = 0.0207, Max-Change = 0.0182, Max-Change = 0.0190, Max-Change = 0.0265, Max-Change = 0.0289, Max-Change = 0.0183, Max-Change = 0.0164, Max-Change = 0.0246, Max-Change = 0.0345, Max-Change = 0.0196, Max-Change = 0.0266, Max-Change = 0.0163, Max-Change = 0.0237, Max-Change = 0.0174, Max-Change = 0.0131, Max-Change = 0.0152, Max-Change = 0.0165, Max-Change = 0.0232, Max-Change = 0.0191, Max-Change = 0.0154, Max-Change = 0.0209, Max-Change = 0.0144, Max-Change = 0.0282, Max-Change = 0.0247, Max-Change = 0.0117, Max-Change = 0.0103, Max-Change = 0.0224, Max-Change = 0.0156, Max-Change = 0.0179, Max-Change = 0.0159, Max-Change = 0.0229, Max-Change = 0.0217, Max-Change = 0.0193, Max-Change = 0.0191, Max-Change = 0.0189, Max-Change = 0.0414, Max-Change = 0.0325, Max-Change = 0.0230, Max-Change = 0.0280, Max-Change = 0.0241, Max-Change = 0.0183, Max-Change = 0.0318, Max-Change = 0.0178, Max-Change = 0.0209, Max-Change = 0.0166, Max-Change = 0.0181, Max-Change = 0.0169, Max-Change = 0.0252, Max-Change = 0.0146, Max-Change = 0.0267, Max-Change = 0.0209, Max-Change = 0.0270, Max-Change = 0.0175, Max-Change = 0.0263, Max-Change = 0.0149, Max-Change = 0.0140, Max-Change = 0.0228, Max-Change = 0.0180, Max-Change = 0.0383, Max-Change = 0.0207, Max-Change = 0.0251, Max-Change = 0.0118, Max-Change = 0.0148, Max-Change = 0.0181, Max-Change = 0.0310, Max-Change = 0.0256, Max-Change = 0.0140, Max-Change = 0.0130, Max-Change = 0.0195, Max-Change = 0.0199, Max-Change = 0.0365, Max-Change = 0.0221, Max-Change = 0.0294, Max-Change = 0.0219, Max-Change = 0.0207, Max-Change = 0.0159, Max-Change = 0.0211, Max-Change = 0.0287, Max-Change = 0.0139, Max-Change = 0.0225, Max-Change = 0.0134, Max-Change = 0.0103, Max-Change = 0.0168, Max-Change = 0.0301, Max-Change = 0.0250, Max-Change = 0.0232, Max-Change = 0.0402, Max-Change = 0.0227, Max-Change = 0.0194, Max-Change = 0.0263, Max-Change = 0.0164, Max-Change = 0.0164, Max-Change = 0.0213, Max-Change = 0.0324, Max-Change = 0.0187, Max-Change = 0.0201, Max-Change = 0.0249, Max-Change = 0.0327, Max-Change = 0.0269, Max-Change = 0.0392, Max-Change = 0.0311, Max-Change = 0.0137, Max-Change = 0.0276, Max-Change = 0.0189, Max-Change = 0.0218, Max-Change = 0.0157, Max-Change = 0.0336, Max-Change = 0.0302, Max-Change = 0.0216, Max-Change = 0.0214, Max-Change = 0.0190, Max-Change = 0.0213, Max-Change = 0.0266, Max-Change = 0.0149, Max-Change = 0.0213, Max-Change = 0.0228, Max-Change = 0.0215, Max-Change = 0.0333, Max-Change = 0.0090, Max-Change = 0.0261, Max-Change = 0.0156, Max-Change = 0.0148, Max-Change = 0.0208, Max-Change = 0.0142, Max-Change = 0.0172, Max-Change = 0.0320, Max-Change = 0.0210, Max-Change = 0.0249, Max-Change = 0.0289, Max-Change = 0.0183, Max-Change = 0.0131, Max-Change = 0.0257, Max-Change = 0.0169, Max-Change = 0.0257, Max-Change = 0.0114, Max-Change = 0.0163, Max-Change = 0.0158, Max-Change = 0.0116, Max-Change = 0.0185, Max-Change = 0.0238, Max-Change = 0.0268, Max-Change = 0.0185, Max-Change = 0.0219, Max-Change = 0.0204, Max-Change = 0.0216, Max-Change = 0.0216, Max-Change = 0.0324, Max-Change = 0.0184, Max-Change = 0.0172, Max-Change = 0.0248, Max-Change = 0.0177, Max-Change = 0.0218, Max-Change = 0.0126, Max-Change = 0.0175, Max-Change = 0.0239, Max-Change = 0.0197, Max-Change = 0.0267, Max-Change = 0.0247, Max-Change = 0.0338, Max-Change = 0.0156, Max-Change = 0.0186, Max-Change = 0.0153, Max-Change = 0.0425, Max-Change = 0.0265, Max-Change = 0.0145, Max-Change = 0.0254, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0225, gam = 0.1057, Max-Change = 0.0134, gam = 0.0780, Max-Change = 0.0108, gam = 0.0629, Max-Change = 0.0051, gam = 0.0532, Max-Change = 0.0074, gam = 0.0464, Max-Change = 0.0045, gam = 0.0413, Max-Change = 0.0046, gam = 0.0374, Max-Change = 0.0044, gam = 0.0342, Max-Change = 0.0056, gam = 0.0316, Max-Change = 0.0034, gam = 0.0294, Max-Change = 0.0035, gam = 0.0276, Max-Change = 0.0032, gam = 0.0260, Max-Change = 0.0024, gam = 0.0246, Max-Change = 0.0036, gam = 0.0233, Max-Change = 0.0029, gam = 0.0222, Max-Change = 0.0030, gam = 0.0212, Max-Change = 0.0034, gam = 0.0203, Max-Change = 0.0021, gam = 0.0195, Max-Change = 0.0019, gam = 0.0188, Max-Change = 0.0016, gam = 0.0181, Max-Change = 0.0019, gam = 0.0175, Max-Change = 0.0018, gam = 0.0169, Max-Change = 0.0011, gam = 0.0164, Max-Change = 0.0027, gam = 0.0159, Max-Change = 0.0013, gam = 0.0154, Max-Change = 0.0008, gam = 0.0150, Max-Change = 0.0019, gam = 0.0146, Max-Change = 0.0022, gam = 0.0142, Max-Change = 0.0011, gam = 0.0139, Max-Change = 0.0012, gam = 0.0135, Max-Change = 0.0015, gam = 0.0132, Max-Change = 0.0016, gam = 0.0129, Max-Change = 0.0012, gam = 0.0126, Max-Change = 0.0018, gam = 0.0124, Max-Change = 0.0013, gam = 0.0121, Max-Change = 0.0013, gam = 0.0119, Max-Change = 0.0008, gam = 0.0116, Max-Change = 0.0008, gam = 0.0114, Max-Change = 0.0011, gam = 0.0112, Max-Change = 0.0009, gam = 0.0110, Max-Change = 0.0022, gam = 0.0108, Max-Change = 0.0014, gam = 0.0106, Max-Change = 0.0014, gam = 0.0104, Max-Change = 0.0016, gam = 0.0102, Max-Change = 0.0011, gam = 0.0101, Max-Change = 0.0005, gam = 0.0099, Max-Change = 0.0009, gam = 0.0098, Max-Change = 0.0010 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... anova(mod0, mod1b) #>            AIC    SABIC       HQ      BIC    logLik      X2 df p #> mod0  9706.089 9738.620 9742.780 9802.136 -4833.044              #> mod1b 9481.042 9516.826 9521.402 9586.694 -4718.521 229.047  2 0 coef(mod1a)$lr.betas #>                    F1 #> (Intercept) 0.0000000 #> groupg2     0.7910307 #> groupg3     1.7064184 summary(mod1b) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items, itemtype = \"2PL\", lr.fixed = ~group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>    F1 #> F1  1 #>  #> -------------- #> LATENT REGRESSION FIXED EFFECTS: #>  #>                F1 #> (Intercept) 0.000 #> groupg2     0.767 #> groupg3     1.711 #>  #>             Std.Error_F1 z_F1 #> (Intercept)           NA   NA #> groupg2              NaN  NaN #> groupg3              NaN  NaN  # specifying specific regression effects is accomplished by passing a list of formula model <- 'F1 = 1-5          F2 = 6-10' covdata$contvar <- rnorm(nrow(covdata)) mod2 <- mirt(dat, model, itemtype = 'Rasch', covdata=covdata,         formula = list(F1 = ~ group + contvar, F2 = ~ group)) #>  coef(mod2)[11:12] #> $GroupPars #>     MEAN_1 MEAN_2   COV_11 COV_21   COV_22 #> par      0      0 1.040428      0 1.103825 #>  #> $lr.betas #>                     F1        F2 #> (Intercept)  0.0000000 0.0000000 #> groupg2      0.7264127 0.9029206 #> groupg3      1.7455764 1.6960398 #> contvar     -0.0380975 0.0000000 #>  mod2b <- mixedmirt(dat, covdata, model, fixed = ~ 0 + items,         lr.fixed = list(F1 = ~ group + contvar, F2 = ~ group)) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1870, Max-Change = 0.1643, Max-Change = 0.1441, Max-Change = 0.1206, Max-Change = 0.0960, Max-Change = 0.0825, Max-Change = 0.0688, Max-Change = 0.0556, Max-Change = 0.0465, Max-Change = 0.0470, Max-Change = 0.0404, Max-Change = 0.0349, Max-Change = 0.0299, Max-Change = 0.0200, Max-Change = 0.0244, Max-Change = 0.0186, Max-Change = 0.0336, Max-Change = 0.0194, Max-Change = 0.0123, Max-Change = 0.0079, Max-Change = 0.0149, Max-Change = 0.0316, Max-Change = 0.0211, Max-Change = 0.0189, Max-Change = 0.0213, Max-Change = 0.0123, Max-Change = 0.0185, Max-Change = 0.0129, Max-Change = 0.0120, Max-Change = 0.0277, Max-Change = 0.0220, Max-Change = 0.0219, Max-Change = 0.0158, Max-Change = 0.0190, Max-Change = 0.0150, Max-Change = 0.0171, Max-Change = 0.0150, Max-Change = 0.0126, Max-Change = 0.0120, Max-Change = 0.0148, Max-Change = 0.0118, Max-Change = 0.0091, Max-Change = 0.0222, Max-Change = 0.0154, Max-Change = 0.0111, Max-Change = 0.0187, Max-Change = 0.0116, Max-Change = 0.0144, Max-Change = 0.0115, Max-Change = 0.0121, Max-Change = 0.0170, Max-Change = 0.0126, Max-Change = 0.0115, Max-Change = 0.0267, Max-Change = 0.0170, Max-Change = 0.0239, Max-Change = 0.0173, Max-Change = 0.0117, Max-Change = 0.0120, Max-Change = 0.0197, Max-Change = 0.0083, Max-Change = 0.0148, Max-Change = 0.0239, Max-Change = 0.0280, Max-Change = 0.0134, Max-Change = 0.0152, Max-Change = 0.0227, Max-Change = 0.0183, Max-Change = 0.0162, Max-Change = 0.0183, Max-Change = 0.0157, Max-Change = 0.0134, Max-Change = 0.0145, Max-Change = 0.0173, Max-Change = 0.0164, Max-Change = 0.0205, Max-Change = 0.0132, Max-Change = 0.0200, Max-Change = 0.0157, Max-Change = 0.0104, Max-Change = 0.0073, Max-Change = 0.0140, Max-Change = 0.0115, Max-Change = 0.0112, Max-Change = 0.0181, Max-Change = 0.0272, Max-Change = 0.0088, Max-Change = 0.0091, Max-Change = 0.0181, Max-Change = 0.0146, Max-Change = 0.0154, Max-Change = 0.0151, Max-Change = 0.0189, Max-Change = 0.0111, Max-Change = 0.0077, Max-Change = 0.0137, Max-Change = 0.0089, Max-Change = 0.0141, Max-Change = 0.0101, Max-Change = 0.0100, Max-Change = 0.0077, Max-Change = 0.0138, Max-Change = 0.0153, Max-Change = 0.0133, Max-Change = 0.0129, Max-Change = 0.0203, Max-Change = 0.0149, Max-Change = 0.0115, Max-Change = 0.0099, Max-Change = 0.0123, Max-Change = 0.0223, Max-Change = 0.0155, Max-Change = 0.0220, Max-Change = 0.0178, Max-Change = 0.0191, Max-Change = 0.0082, Max-Change = 0.0082, Max-Change = 0.0228, Max-Change = 0.0169, Max-Change = 0.0143, Max-Change = 0.0170, Max-Change = 0.0150, Max-Change = 0.0130, Max-Change = 0.0165, Max-Change = 0.0084, Max-Change = 0.0122, Max-Change = 0.0093, Max-Change = 0.0154, Max-Change = 0.0169, Max-Change = 0.0138, Max-Change = 0.0184, Max-Change = 0.0114, Max-Change = 0.0161, Max-Change = 0.0187, Max-Change = 0.0157, Max-Change = 0.0227, Max-Change = 0.0131, Max-Change = 0.0070, Max-Change = 0.0099, Max-Change = 0.0096, Max-Change = 0.0173, Max-Change = 0.0165, Max-Change = 0.0128, Max-Change = 0.0133, Max-Change = 0.0133, Max-Change = 0.0101, Max-Change = 0.0118, Max-Change = 0.0220, Max-Change = 0.0140, Max-Change = 0.0123, Max-Change = 0.0118, Max-Change = 0.0239, Max-Change = 0.0105, Max-Change = 0.0229, Max-Change = 0.0106, Max-Change = 0.0241, Max-Change = 0.0161, Max-Change = 0.0140, Max-Change = 0.0080, Max-Change = 0.0267, Max-Change = 0.0218, Max-Change = 0.0165, Max-Change = 0.0223, Max-Change = 0.0153, Max-Change = 0.0265, Max-Change = 0.0159, Max-Change = 0.0260, Max-Change = 0.0143, Max-Change = 0.0193, Max-Change = 0.0152, Max-Change = 0.0188, Max-Change = 0.0217, Max-Change = 0.0131, Max-Change = 0.0106, Max-Change = 0.0099, Max-Change = 0.0188, Max-Change = 0.0157, Max-Change = 0.0148, Max-Change = 0.0165, Max-Change = 0.0146, Max-Change = 0.0108, Max-Change = 0.0221, Max-Change = 0.0167, Max-Change = 0.0236, Max-Change = 0.0113, Max-Change = 0.0224, Max-Change = 0.0208, Max-Change = 0.0160, Max-Change = 0.0266, Max-Change = 0.0153, Max-Change = 0.0121, Max-Change = 0.0154, Max-Change = 0.0163, Max-Change = 0.0115, Max-Change = 0.0281, Max-Change = 0.0147, Max-Change = 0.0165, Max-Change = 0.0157, Max-Change = 0.0120, Max-Change = 0.0091, Max-Change = 0.0081, Max-Change = 0.0169, Max-Change = 0.0150, Max-Change = 0.0109, Max-Change = 0.0079, Max-Change = 0.0108, Max-Change = 0.0089, Max-Change = 0.0095, Max-Change = 0.0153, Max-Change = 0.0146, Max-Change = 0.0134, Max-Change = 0.0091, Max-Change = 0.0128, Max-Change = 0.0085, Max-Change = 0.0087, Max-Change = 0.0283, Max-Change = 0.0194, Max-Change = 0.0183, Max-Change = 0.0113, Max-Change = 0.0159, Max-Change = 0.0106, Max-Change = 0.0087, Max-Change = 0.0213, Max-Change = 0.0136, Max-Change = 0.0080, Max-Change = 0.0117, Max-Change = 0.0165, Max-Change = 0.0105, Max-Change = 0.0182, Max-Change = 0.0224, Max-Change = 0.0127, Max-Change = 0.0142, Max-Change = 0.0165, Max-Change = 0.0151, Max-Change = 0.0220, Max-Change = 0.0180, Max-Change = 0.0140, Max-Change = 0.0168, Max-Change = 0.0086, Max-Change = 0.0135, Max-Change = 0.0197, Max-Change = 0.0058, Max-Change = 0.0169, Max-Change = 0.0244, Max-Change = 0.0141, Max-Change = 0.0097, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0217, gam = 0.1057, Max-Change = 0.0053, gam = 0.0780, Max-Change = 0.0051, gam = 0.0629, Max-Change = 0.0050, gam = 0.0532, Max-Change = 0.0045, gam = 0.0464, Max-Change = 0.0041, gam = 0.0413, Max-Change = 0.0035, gam = 0.0374, Max-Change = 0.0036, gam = 0.0342, Max-Change = 0.0049, gam = 0.0316, Max-Change = 0.0020, gam = 0.0294, Max-Change = 0.0018, gam = 0.0276, Max-Change = 0.0021, gam = 0.0260, Max-Change = 0.0024, gam = 0.0246, Max-Change = 0.0018, gam = 0.0233, Max-Change = 0.0017, gam = 0.0222, Max-Change = 0.0022, gam = 0.0212, Max-Change = 0.0018, gam = 0.0203, Max-Change = 0.0017, gam = 0.0195, Max-Change = 0.0015, gam = 0.0188, Max-Change = 0.0015, gam = 0.0181, Max-Change = 0.0018, gam = 0.0175, Max-Change = 0.0011, gam = 0.0169, Max-Change = 0.0013, gam = 0.0164, Max-Change = 0.0016, gam = 0.0159, Max-Change = 0.0012, gam = 0.0154, Max-Change = 0.0009, gam = 0.0150, Max-Change = 0.0009, gam = 0.0146, Max-Change = 0.0010, gam = 0.0142, Max-Change = 0.0018, gam = 0.0139, Max-Change = 0.0009, gam = 0.0135, Max-Change = 0.0008, gam = 0.0132, Max-Change = 0.0011, gam = 0.0129, Max-Change = 0.0015, gam = 0.0126, Max-Change = 0.0015, gam = 0.0124, Max-Change = 0.0007, gam = 0.0121, Max-Change = 0.0007, gam = 0.0119, Max-Change = 0.0007 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod2b) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = model, fixed = ~0 +  #>     items, lr.fixed = list(F1 = ~group + contvar, F2 = ~group)) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1  F2 #> F1 1.02 0.0 #> F2 0.00 1.1 #>  #> -------------- #> LATENT REGRESSION FIXED EFFECTS: #>  #>                 F1    F2 #> (Intercept)  0.000 0.000 #> groupg2      0.687 0.818 #> groupg3      1.718 1.623 #> contvar     -0.040 0.000 #>  #>             Std.Error_F1 Std.Error_F2   z_F1  z_F2 #> (Intercept)           NA           NA     NA    NA #> groupg2            0.144        0.141  4.755 5.802 #> groupg3            0.140        0.175 12.290 9.296 #> contvar            0.056           NA -0.717    NA  #################################################### ## Simulated Multilevel Rasch Model  set.seed(1) N <- 2000 a <- matrix(rep(1,10),10,1) d <- matrix(rnorm(10)) cluster = 100 random_intercept = rnorm(cluster,0,1) Theta = numeric() for (i in 1:cluster)     Theta <- c(Theta, rnorm(N/cluster,0,1) + random_intercept[i])  group = factor(rep(paste0('G',1:cluster), each = N/cluster)) covdata <- data.frame(group) dat <- simdata(a,d,N, itemtype = rep('2PL',10), Theta=matrix(Theta)) itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  2000            5.414          2.749  0.25 0.019 0.769     1.321 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  2000 2 0.424 0.494   0.573         0.433       0.750 #> Item_2  2000 2 0.560 0.497   0.602         0.467       0.745 #> Item_3  2000 2 0.373 0.484   0.547         0.405       0.754 #> Item_4  2000 2 0.781 0.414   0.524         0.402       0.754 #> Item_5  2000 2 0.577 0.494   0.585         0.447       0.748 #> Item_6  2000 2 0.378 0.485   0.571         0.434       0.750 #> Item_7  2000 2 0.598 0.491   0.568         0.428       0.751 #> Item_8  2000 2 0.652 0.476   0.568         0.432       0.750 #> Item_9  2000 2 0.620 0.486   0.577         0.440       0.749 #> Item_10 2000 2 0.453 0.498   0.584         0.445       0.748 #>  #> $proportions #>             0     1 #> Item_1  0.577 0.424 #> Item_2  0.440 0.560 #> Item_3  0.627 0.373 #> Item_4  0.219 0.781 #> Item_5  0.424 0.577 #> Item_6  0.622 0.378 #> Item_7  0.402 0.598 #> Item_8  0.348 0.652 #> Item_9  0.380 0.620 #> Item_10 0.547 0.453 #>   # null model mod1 <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1825, Max-Change = 0.1571, Max-Change = 0.1285, Max-Change = 0.1118, Max-Change = 0.0969, Max-Change = 0.0772, Max-Change = 0.0708, Max-Change = 0.0561, Max-Change = 0.0421, Max-Change = 0.0388, Max-Change = 0.0371, Max-Change = 0.0292, Max-Change = 0.0279, Max-Change = 0.0280, Max-Change = 0.0298, Max-Change = 0.0281, Max-Change = 0.0155, Max-Change = 0.0170, Max-Change = 0.0196, Max-Change = 0.0178, Max-Change = 0.0237, Max-Change = 0.0187, Max-Change = 0.0213, Max-Change = 0.0099, Max-Change = 0.0244, Max-Change = 0.0166, Max-Change = 0.0162, Max-Change = 0.0050, Max-Change = 0.0021, Max-Change = 0.0102, Max-Change = 0.0067, Max-Change = 0.0116, Max-Change = 0.0072, Max-Change = 0.0132, Max-Change = 0.0120, Max-Change = 0.0046, Max-Change = 0.0212, Max-Change = 0.0191, Max-Change = 0.0018, Max-Change = 0.0017, Max-Change = 0.0211, Max-Change = 0.0152, Max-Change = 0.0106, Max-Change = 0.0155, Max-Change = 0.0061, Max-Change = 0.0041, Max-Change = 0.0070, Max-Change = 0.0047, Max-Change = 0.0054, Max-Change = 0.0031, Max-Change = 0.0151, Max-Change = 0.0071, Max-Change = 0.0130, Max-Change = 0.0058, Max-Change = 0.0035, Max-Change = 0.0044, Max-Change = 0.0068, Max-Change = 0.0106, Max-Change = 0.0058, Max-Change = 0.0065, Max-Change = 0.0030, Max-Change = 0.0078, Max-Change = 0.0160, Max-Change = 0.0089, Max-Change = 0.0077, Max-Change = 0.0106, Max-Change = 0.0092, Max-Change = 0.0155, Max-Change = 0.0181, Max-Change = 0.0104, Max-Change = 0.0151, Max-Change = 0.0145, Max-Change = 0.0030, Max-Change = 0.0058, Max-Change = 0.0041, Max-Change = 0.0064, Max-Change = 0.0187, Max-Change = 0.0024, Max-Change = 0.0019, Max-Change = 0.0066, Max-Change = 0.0035, Max-Change = 0.0057, Max-Change = 0.0059, Max-Change = 0.0063, Max-Change = 0.0050, Max-Change = 0.0150, Max-Change = 0.0118, Max-Change = 0.0072, Max-Change = 0.0049, Max-Change = 0.0037, Max-Change = 0.0012, Max-Change = 0.0023, Max-Change = 0.0076, Max-Change = 0.0033, Max-Change = 0.0071, Max-Change = 0.0045, Max-Change = 0.0169, Max-Change = 0.1604, Max-Change = 0.0823, Max-Change = 0.0655, Max-Change = 0.0506, Max-Change = 0.0506, Max-Change = 0.0465, Max-Change = 0.0366, Max-Change = 0.0268, Max-Change = 0.0292, Max-Change = 0.0274, Max-Change = 0.0089, Max-Change = 0.0328, Max-Change = 0.0200, Max-Change = 0.0162, Max-Change = 0.0139, Max-Change = 0.0238, Max-Change = 0.0122, Max-Change = 0.0054, Max-Change = 0.0121, Max-Change = 0.0102, Max-Change = 0.0059, Max-Change = 0.0210, Max-Change = 0.0241, Max-Change = 0.0091, Max-Change = 0.0027, Max-Change = 0.0034, Max-Change = 0.0108, Max-Change = 0.0070, Max-Change = 0.0126, Max-Change = 0.0176, Max-Change = 0.0136, Max-Change = 0.0162, Max-Change = 0.0077, Max-Change = 0.0107, Max-Change = 0.0056, Max-Change = 0.0137, Max-Change = 0.0097, Max-Change = 0.0057, Max-Change = 0.0045, Max-Change = 0.0058, Max-Change = 0.0074, Max-Change = 0.0012, Max-Change = 0.0096, Max-Change = 0.0073, Max-Change = 0.0058, Max-Change = 0.0048, Max-Change = 0.0091, Max-Change = 0.0057, Max-Change = 0.0058, Max-Change = 0.0106, Max-Change = 0.0070, Max-Change = 0.0027, Max-Change = 0.0044, Max-Change = 0.0036, Max-Change = 0.0032, Max-Change = 0.0063, Max-Change = 0.0053, Max-Change = 0.0049, Max-Change = 0.0114, Max-Change = 0.0080, Max-Change = 0.0054, Max-Change = 0.0143, Max-Change = 0.0183, Max-Change = 0.0110, Max-Change = 0.0025, Max-Change = 0.0047, Max-Change = 0.0071, Max-Change = 0.0039, Max-Change = 0.0101, Max-Change = 0.0093, Max-Change = 0.0067, Max-Change = 0.0014, Max-Change = 0.0041, Max-Change = 0.0047, Max-Change = 0.0073, Max-Change = 0.0108, Max-Change = 0.0033, Max-Change = 0.0120, Max-Change = 0.0109, Max-Change = 0.0149, Max-Change = 0.0138, Max-Change = 0.0082, Max-Change = 0.0119, Max-Change = 0.0063, Max-Change = 0.0074, Max-Change = 0.0123, Max-Change = 0.0063, Max-Change = 0.0044, Max-Change = 0.0047, Max-Change = 0.0098, Max-Change = 0.0102, Max-Change = 0.0207, Max-Change = 0.0144, Max-Change = 0.0101, Max-Change = 0.0039, Max-Change = 0.0079, Max-Change = 0.0092, Max-Change = 0.0020, Max-Change = 0.0040, Max-Change = 0.0080, Max-Change = 0.0104, Max-Change = 0.0072, Max-Change = 0.0118, Max-Change = 0.0109, Max-Change = 0.0041, Max-Change = 0.0042, Max-Change = 0.0096, Max-Change = 0.0043, Max-Change = 0.0046, Max-Change = 0.0031, Max-Change = 0.0090, Max-Change = 0.0019, Max-Change = 0.0042, Max-Change = 0.0068, Max-Change = 0.0022, Max-Change = 0.0023, Max-Change = 0.0132, Max-Change = 0.0032, Max-Change = 0.0025, Max-Change = 0.0070, Max-Change = 0.0065, Max-Change = 0.0040, Max-Change = 0.0055, Max-Change = 0.0056, Max-Change = 0.0031, Max-Change = 0.0085, Max-Change = 0.0067, Max-Change = 0.0029, Max-Change = 0.0080, Max-Change = 0.0046, Max-Change = 0.0137, Max-Change = 0.0070, Max-Change = 0.0052, Max-Change = 0.0119, Max-Change = 0.0087, Max-Change = 0.0039, Max-Change = 0.0069, Max-Change = 0.0050, Max-Change = 0.0104, Max-Change = 0.0009, Max-Change = 0.0057, Max-Change = 0.0095, Max-Change = 0.0100, Max-Change = 0.0024, Max-Change = 0.0044, Max-Change = 0.0044, Max-Change = 0.0057, Max-Change = 0.0026, Max-Change = 0.0058, Max-Change = 0.0074, Max-Change = 0.0071, Max-Change = 0.0028, Max-Change = 0.0094, Max-Change = 0.0088, Max-Change = 0.0034, Max-Change = 0.0017, Max-Change = 0.0107, Max-Change = 0.0048, Max-Change = 0.0058, Max-Change = 0.0038, Max-Change = 0.0046, Max-Change = 0.0038, Max-Change = 0.0072, Max-Change = 0.0089, Max-Change = 0.0011, Max-Change = 0.0016, Max-Change = 0.0039, Max-Change = 0.0060, Max-Change = 0.0053, Max-Change = 0.0025, Max-Change = 0.0028, Max-Change = 0.0076, Max-Change = 0.0029, Max-Change = 0.0118, Max-Change = 0.0030, Max-Change = 0.0035, Max-Change = 0.0043, Max-Change = 0.0055, Max-Change = 0.0024, Max-Change = 0.0072, Max-Change = 0.0038, Max-Change = 0.0030, Max-Change = 0.0019, Max-Change = 0.0023, Max-Change = 0.0024, Max-Change = 0.0070, Max-Change = 0.0108, Max-Change = 0.0044, Max-Change = 0.0071, Max-Change = 0.0100, Max-Change = 0.0029, Max-Change = 0.0073, Max-Change = 0.0056, Max-Change = 0.0049, Max-Change = 0.0081, Max-Change = 0.0053, Max-Change = 0.0076, Max-Change = 0.0016, Max-Change = 0.0056, Max-Change = 0.0062, Max-Change = 0.0020, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0020, gam = 0.1057, Max-Change = 0.0083, gam = 0.0780, Max-Change = 0.0013, gam = 0.0629, Max-Change = 0.0017, gam = 0.0532, Max-Change = 0.0011, gam = 0.0464, Max-Change = 0.0002, gam = 0.0413, Max-Change = 0.0012, gam = 0.0374, Max-Change = 0.0004, gam = 0.0342, Max-Change = 0.0012, gam = 0.0316, Max-Change = 0.0003, gam = 0.0294, Max-Change = 0.0004, gam = 0.0276, Max-Change = 0.0010, gam = 0.0260, Max-Change = 0.0006, gam = 0.0246, Max-Change = 0.0004, gam = 0.0233, Max-Change = 0.0003 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod1) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items, random = ~1 | group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1 #> F1 1.02 #>  #> $group #>           COV_group #> COV_group     0.853 #>   # include level 2 predictor for 'group' variance covdata$group_pred <- rep(random_intercept, each = N/cluster) mod2 <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group_pred, random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1797, Max-Change = 0.1540, Max-Change = 0.1292, Max-Change = 0.1114, Max-Change = 0.0981, Max-Change = 0.0797, Max-Change = 0.0726, Max-Change = 0.0565, Max-Change = 0.0436, Max-Change = 0.0397, Max-Change = 0.0353, Max-Change = 0.0313, Max-Change = 0.0278, Max-Change = 0.0326, Max-Change = 0.0265, Max-Change = 0.0204, Max-Change = 0.0212, Max-Change = 0.0173, Max-Change = 0.0144, Max-Change = 0.0184, Max-Change = 0.0145, Max-Change = 0.0115, Max-Change = 0.0066, Max-Change = 0.0137, Max-Change = 0.0068, Max-Change = 0.0131, Max-Change = 0.0088, Max-Change = 0.0131, Max-Change = 0.0121, Max-Change = 0.0098, Max-Change = 0.0085, Max-Change = 0.0064, Max-Change = 0.0127, Max-Change = 0.0081, Max-Change = 0.0079, Max-Change = 0.0073, Max-Change = 0.0062, Max-Change = 0.0087, Max-Change = 0.0085, Max-Change = 0.0046, Max-Change = 0.0091, Max-Change = 0.0039, Max-Change = 0.0077, Max-Change = 0.0035, Max-Change = 0.0032, Max-Change = 0.0047, Max-Change = 0.0046, Max-Change = 0.0074, Max-Change = 0.0039, Max-Change = 0.0037, Max-Change = 0.0104, Max-Change = 0.0064, Max-Change = 0.0067, Max-Change = 0.0035, Max-Change = 0.0043, Max-Change = 0.0088, Max-Change = 0.0028, Max-Change = 0.0047, Max-Change = 0.0040, Max-Change = 0.0024, Max-Change = 0.0078, Max-Change = 0.0162, Max-Change = 0.0064, Max-Change = 0.0054, Max-Change = 0.0070, Max-Change = 0.0016, Max-Change = 0.0066, Max-Change = 0.0069, Max-Change = 0.0076, Max-Change = 0.0078, Max-Change = 0.0057, Max-Change = 0.0103, Max-Change = 0.0023, Max-Change = 0.0051, Max-Change = 0.0057, Max-Change = 0.0055, Max-Change = 0.0184, Max-Change = 0.0044, Max-Change = 0.0037, Max-Change = 0.0050, Max-Change = 0.0042, Max-Change = 0.0070, Max-Change = 0.0010, Max-Change = 0.0078, Max-Change = 0.0022, Max-Change = 0.0104, Max-Change = 0.0058, Max-Change = 0.0075, Max-Change = 0.0049, Max-Change = 0.0010, Max-Change = 0.0014, Max-Change = 0.0033, Max-Change = 0.0029, Max-Change = 0.0033, Max-Change = 0.0053, Max-Change = 0.0015, Max-Change = 0.0026, Max-Change = 0.0172, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1757, Max-Change = 0.1798, Max-Change = 0.1665, Max-Change = 0.0043, Max-Change = 0.0036, Max-Change = 0.0047, Max-Change = 0.0044, Max-Change = 0.0095, Max-Change = 0.0068, Max-Change = 0.0034, Max-Change = 0.0076, Max-Change = 0.0038, Max-Change = 0.0058, Max-Change = 0.0064, Max-Change = 0.0070, Max-Change = 0.0053, Max-Change = 0.0115, Max-Change = 0.0084, Max-Change = 0.0088, Max-Change = 0.0042, Max-Change = 0.0051, Max-Change = 0.0060, Max-Change = 0.0075, Max-Change = 0.0062, Max-Change = 0.0056, Max-Change = 0.0088, Max-Change = 0.0070, Max-Change = 0.0040, Max-Change = 0.0161, Max-Change = 0.0061, Max-Change = 0.0044, Max-Change = 0.0038, Max-Change = 0.0070, Max-Change = 0.0018, Max-Change = 0.0071, Max-Change = 0.0095, Max-Change = 0.0081, Max-Change = 0.0092, Max-Change = 0.0070, Max-Change = 0.0144, Max-Change = 0.0061, Max-Change = 0.0084, Max-Change = 0.0076, Max-Change = 0.0065, Max-Change = 0.0046, Max-Change = 0.0049, Max-Change = 0.0092, Max-Change = 0.0063, Max-Change = 0.0027, Max-Change = 0.0061, Max-Change = 0.0085, Max-Change = 0.0043, Max-Change = 0.0063, Max-Change = 0.0052, Max-Change = 0.0028, Max-Change = 0.0054, Max-Change = 0.0076, Max-Change = 0.0027, Max-Change = 0.0039, Max-Change = 0.0033, Max-Change = 0.0041, Max-Change = 0.0082, Max-Change = 0.0050, Max-Change = 0.0104, Max-Change = 0.0078, Max-Change = 0.0037, Max-Change = 0.0060, Max-Change = 0.0080, Max-Change = 0.0045, Max-Change = 0.0068, Max-Change = 0.0039, Max-Change = 0.0078, Max-Change = 0.0041, Max-Change = 0.0038, Max-Change = 0.0019, Max-Change = 0.0061, Max-Change = 0.0112, Max-Change = 0.0074, Max-Change = 0.0025, Max-Change = 0.0039, Max-Change = 0.0087, Max-Change = 0.0016, Max-Change = 0.0032, Max-Change = 0.0020, Max-Change = 0.0066, Max-Change = 0.0022, Max-Change = 0.0048, Max-Change = 0.0050, Max-Change = 0.0066, Max-Change = 0.0036, Max-Change = 0.0040, Max-Change = 0.0049, Max-Change = 0.0049, Max-Change = 0.0078, Max-Change = 0.0041, Max-Change = 0.0093, Max-Change = 0.0046, Max-Change = 0.0109, Max-Change = 0.0053, Max-Change = 0.0105, Max-Change = 0.0050, Max-Change = 0.0022, Max-Change = 0.0057, Max-Change = 0.0064, Max-Change = 0.0040, Max-Change = 0.0044, Max-Change = 0.0053, Max-Change = 0.0095, Max-Change = 0.0033, Max-Change = 0.0030, Max-Change = 0.0066, Max-Change = 0.0019, Max-Change = 0.0035, Max-Change = 0.0124, Max-Change = 0.0072, Max-Change = 0.0072, Max-Change = 0.0075, Max-Change = 0.0074, Max-Change = 0.0034, Max-Change = 0.0055, Max-Change = 0.0036, Max-Change = 0.0020, Max-Change = 0.0090, Max-Change = 0.0070, Max-Change = 0.0048, Max-Change = 0.0064, Max-Change = 0.0046, Max-Change = 0.0049, Max-Change = 0.0049, Max-Change = 0.0042, Max-Change = 0.0090, Max-Change = 0.0049, Max-Change = 0.0034, Max-Change = 0.0071, Max-Change = 0.0040, Max-Change = 0.0124, Max-Change = 0.0072, Max-Change = 0.0065, Max-Change = 0.0072, Max-Change = 0.0140, Max-Change = 0.0046, Max-Change = 0.0095, Max-Change = 0.0052, Max-Change = 0.0078, Max-Change = 0.0026, Max-Change = 0.0081, Max-Change = 0.0097, Max-Change = 0.0031, Max-Change = 0.0037, Max-Change = 0.0112, Max-Change = 0.0082, Max-Change = 0.0051, Max-Change = 0.0026, Max-Change = 0.0031, Max-Change = 0.0055, Max-Change = 0.0118, Max-Change = 0.0060, Max-Change = 0.0030, Max-Change = 0.0054, Max-Change = 0.0032, Max-Change = 0.0106, Max-Change = 0.0020, Max-Change = 0.0077, Max-Change = 0.0047, Max-Change = 0.0053, Max-Change = 0.0060, Max-Change = 0.0062, Max-Change = 0.0019, Max-Change = 0.0039, Max-Change = 0.0009, Max-Change = 0.0143, Max-Change = 0.0031, Max-Change = 0.0069, Max-Change = 0.0050, Max-Change = 0.0027, Max-Change = 0.0020, Max-Change = 0.0085, Max-Change = 0.0023, Max-Change = 0.0040, Max-Change = 0.0049, Max-Change = 0.0040, Max-Change = 0.0048, Max-Change = 0.0056, Max-Change = 0.0050, Max-Change = 0.0046, Max-Change = 0.0065, Max-Change = 0.0133, Max-Change = 0.0035, Max-Change = 0.0059, Max-Change = 0.0067, Max-Change = 0.0044, Max-Change = 0.0060, Max-Change = 0.0030, Max-Change = 0.0072, Max-Change = 0.0066, Max-Change = 0.0067, Max-Change = 0.0045, Max-Change = 0.0033, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0026, gam = 0.1057, Max-Change = 0.0077, gam = 0.0780, Max-Change = 0.0018, gam = 0.0629, Max-Change = 0.0029, gam = 0.0532, Max-Change = 0.0016, gam = 0.0464, Max-Change = 0.0007, gam = 0.0413, Max-Change = 0.0006, gam = 0.0374, Max-Change = 0.0004 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood...  # including group means predicts nearly all variability in 'group' summary(mod2) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items + group_pred, random = ~1 | group) #>  #> -------------- #> FIXED EFFECTS: #>            Estimate Std.Error z.value #> group_pred    1.017      0.05  20.282 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1 #> F1 1.04 #>  #> $group #>           COV_group #> COV_group    0.0335 #>  anova(mod1, mod2) #>           AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod1 23548.80 23577.89 23573.48 23616.01 -11762.40             #> mod2 22744.85 22776.36 22771.59 22817.66 -11359.43 805.95  1 0  # can also be fit for Rasch/non-Rasch models with the lr.random input mod1b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1825, Max-Change = 0.1571, Max-Change = 0.1285, Max-Change = 0.1118, Max-Change = 0.0969, Max-Change = 0.0772, Max-Change = 0.0708, Max-Change = 0.0561, Max-Change = 0.0421, Max-Change = 0.0388, Max-Change = 0.0371, Max-Change = 0.0292, Max-Change = 0.0279, Max-Change = 0.0280, Max-Change = 0.0298, Max-Change = 0.0281, Max-Change = 0.0155, Max-Change = 0.0170, Max-Change = 0.0196, Max-Change = 0.0178, Max-Change = 0.0237, Max-Change = 0.0187, Max-Change = 0.0213, Max-Change = 0.0099, Max-Change = 0.0244, Max-Change = 0.0166, Max-Change = 0.0162, Max-Change = 0.0050, Max-Change = 0.0021, Max-Change = 0.0102, Max-Change = 0.0067, Max-Change = 0.0116, Max-Change = 0.0072, Max-Change = 0.0132, Max-Change = 0.0120, Max-Change = 0.0046, Max-Change = 0.0212, Max-Change = 0.0191, Max-Change = 0.0018, Max-Change = 0.0017, Max-Change = 0.0211, Max-Change = 0.0152, Max-Change = 0.0106, Max-Change = 0.0155, Max-Change = 0.0061, Max-Change = 0.0041, Max-Change = 0.0070, Max-Change = 0.0047, Max-Change = 0.0054, Max-Change = 0.0031, Max-Change = 0.0151, Max-Change = 0.0071, Max-Change = 0.0130, Max-Change = 0.0058, Max-Change = 0.0035, Max-Change = 0.0044, Max-Change = 0.0068, Max-Change = 0.0106, Max-Change = 0.0058, Max-Change = 0.0065, Max-Change = 0.0030, Max-Change = 0.0078, Max-Change = 0.0160, Max-Change = 0.0089, Max-Change = 0.0077, Max-Change = 0.0106, Max-Change = 0.0092, Max-Change = 0.0155, Max-Change = 0.0181, Max-Change = 0.0104, Max-Change = 0.0151, Max-Change = 0.0145, Max-Change = 0.0030, Max-Change = 0.0058, Max-Change = 0.0041, Max-Change = 0.0064, Max-Change = 0.0187, Max-Change = 0.0024, Max-Change = 0.0019, Max-Change = 0.0066, Max-Change = 0.0035, Max-Change = 0.0057, Max-Change = 0.0059, Max-Change = 0.0063, Max-Change = 0.0050, Max-Change = 0.0150, Max-Change = 0.0118, Max-Change = 0.0072, Max-Change = 0.0049, Max-Change = 0.0037, Max-Change = 0.0012, Max-Change = 0.0023, Max-Change = 0.0076, Max-Change = 0.0033, Max-Change = 0.0071, Max-Change = 0.0045, Max-Change = 0.0169, Max-Change = 0.0704, Max-Change = 0.0689, Max-Change = 0.0489, Max-Change = 0.0433, Max-Change = 0.0410, Max-Change = 0.0380, Max-Change = 0.0347, Max-Change = 0.0321, Max-Change = 0.0280, Max-Change = 0.0249, Max-Change = 0.0214, Max-Change = 0.0182, Max-Change = 0.0159, Max-Change = 0.0134, Max-Change = 0.0112, Max-Change = 0.0144, Max-Change = 0.0072, Max-Change = 0.0063, Max-Change = 0.0066, Max-Change = 0.0080, Max-Change = 0.0093, Max-Change = 0.0062, Max-Change = 0.0128, Max-Change = 0.0042, Max-Change = 0.0035, Max-Change = 0.0051, Max-Change = 0.0045, Max-Change = 0.0125, Max-Change = 0.0124, Max-Change = 0.0186, Max-Change = 0.0070, Max-Change = 0.0146, Max-Change = 0.0084, Max-Change = 0.0090, Max-Change = 0.0087, Max-Change = 0.0026, Max-Change = 0.0069, Max-Change = 0.0104, Max-Change = 0.0086, Max-Change = 0.0023, Max-Change = 0.0116, Max-Change = 0.0048, Max-Change = 0.0024, Max-Change = 0.0099, Max-Change = 0.0040, Max-Change = 0.0122, Max-Change = 0.0177, Max-Change = 0.0101, Max-Change = 0.0027, Max-Change = 0.0057, Max-Change = 0.0282, Max-Change = 0.0083, Max-Change = 0.0079, Max-Change = 0.0087, Max-Change = 0.0150, Max-Change = 0.0057, Max-Change = 0.0038, Max-Change = 0.0046, Max-Change = 0.0086, Max-Change = 0.0077, Max-Change = 0.0059, Max-Change = 0.0037, Max-Change = 0.0041, Max-Change = 0.0053, Max-Change = 0.0033, Max-Change = 0.0042, Max-Change = 0.0113, Max-Change = 0.0037, Max-Change = 0.0240, Max-Change = 0.0113, Max-Change = 0.0101, Max-Change = 0.0107, Max-Change = 0.0018, Max-Change = 0.0060, Max-Change = 0.0068, Max-Change = 0.0036, Max-Change = 0.0208, Max-Change = 0.0056, Max-Change = 0.0050, Max-Change = 0.0046, Max-Change = 0.0040, Max-Change = 0.0077, Max-Change = 0.0057, Max-Change = 0.0027, Max-Change = 0.0062, Max-Change = 0.0106, Max-Change = 0.0084, Max-Change = 0.0156, Max-Change = 0.0045, Max-Change = 0.0033, Max-Change = 0.0047, Max-Change = 0.0060, Max-Change = 0.0102, Max-Change = 0.0108, Max-Change = 0.0071, Max-Change = 0.0064, Max-Change = 0.0054, Max-Change = 0.0063, Max-Change = 0.0056, Max-Change = 0.0072, Max-Change = 0.0031, Max-Change = 0.0037, Max-Change = 0.0040, Max-Change = 0.0152, Max-Change = 0.0039, Max-Change = 0.0064, Max-Change = 0.0041, Max-Change = 0.0056, Max-Change = 0.0082, Max-Change = 0.0027, Max-Change = 0.0019, Max-Change = 0.0034, Max-Change = 0.0036, Max-Change = 0.0074, Max-Change = 0.0074, Max-Change = 0.0067, Max-Change = 0.0098, Max-Change = 0.0066, Max-Change = 0.0039, Max-Change = 0.0180, Max-Change = 0.0060, Max-Change = 0.0005, Max-Change = 0.0055, Max-Change = 0.0100, Max-Change = 0.0078, Max-Change = 0.0070, Max-Change = 0.0094, Max-Change = 0.0027, Max-Change = 0.0117, Max-Change = 0.0056, Max-Change = 0.0116, Max-Change = 0.0065, Max-Change = 0.0048, Max-Change = 0.0084, Max-Change = 0.0158, Max-Change = 0.0072, Max-Change = 0.0078, Max-Change = 0.0027, Max-Change = 0.0103, Max-Change = 0.0035, Max-Change = 0.0060, Max-Change = 0.0029, Max-Change = 0.0074, Max-Change = 0.0067, Max-Change = 0.0049, Max-Change = 0.0053, Max-Change = 0.0152, Max-Change = 0.0037, Max-Change = 0.0036, Max-Change = 0.0120, Max-Change = 0.0011, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0146, gam = 0.1057, Max-Change = 0.0034, gam = 0.0780, Max-Change = 0.0012, gam = 0.0629, Max-Change = 0.0018, gam = 0.0532, Max-Change = 0.0005, gam = 0.0464, Max-Change = 0.0018, gam = 0.0413, Max-Change = 0.0019, gam = 0.0374, Max-Change = 0.0007, gam = 0.0342, Max-Change = 0.0006, gam = 0.0316, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod1b) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items, lr.random = ~1 | group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1 #> F1 1.54 #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $group #>           COV_group #> COV_group      1.45 #>   mod2b <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group_pred, lr.random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1797, Max-Change = 0.1540, Max-Change = 0.1292, Max-Change = 0.1114, Max-Change = 0.0981, Max-Change = 0.0797, Max-Change = 0.0726, Max-Change = 0.0565, Max-Change = 0.0436, Max-Change = 0.0397, Max-Change = 0.0353, Max-Change = 0.0313, Max-Change = 0.0278, Max-Change = 0.0326, Max-Change = 0.0265, Max-Change = 0.0204, Max-Change = 0.0212, Max-Change = 0.0173, Max-Change = 0.0144, Max-Change = 0.0184, Max-Change = 0.0145, Max-Change = 0.0115, Max-Change = 0.0066, Max-Change = 0.0137, Max-Change = 0.0068, Max-Change = 0.0131, Max-Change = 0.0088, Max-Change = 0.0131, Max-Change = 0.0121, Max-Change = 0.0098, Max-Change = 0.0085, Max-Change = 0.0064, Max-Change = 0.0127, Max-Change = 0.0081, Max-Change = 0.0079, Max-Change = 0.0073, Max-Change = 0.0062, Max-Change = 0.0087, Max-Change = 0.0085, Max-Change = 0.0046, Max-Change = 0.0091, Max-Change = 0.0039, Max-Change = 0.0077, Max-Change = 0.0035, Max-Change = 0.0032, Max-Change = 0.0047, Max-Change = 0.0046, Max-Change = 0.0074, Max-Change = 0.0039, Max-Change = 0.0037, Max-Change = 0.0104, Max-Change = 0.0064, Max-Change = 0.0067, Max-Change = 0.0035, Max-Change = 0.0043, Max-Change = 0.0088, Max-Change = 0.0028, Max-Change = 0.0047, Max-Change = 0.0040, Max-Change = 0.0024, Max-Change = 0.0078, Max-Change = 0.0162, Max-Change = 0.0064, Max-Change = 0.0054, Max-Change = 0.0070, Max-Change = 0.0016, Max-Change = 0.0066, Max-Change = 0.0069, Max-Change = 0.0076, Max-Change = 0.0078, Max-Change = 0.0057, Max-Change = 0.0103, Max-Change = 0.0023, Max-Change = 0.0051, Max-Change = 0.0057, Max-Change = 0.0055, Max-Change = 0.0184, Max-Change = 0.0044, Max-Change = 0.0037, Max-Change = 0.0050, Max-Change = 0.0042, Max-Change = 0.0070, Max-Change = 0.0010, Max-Change = 0.0078, Max-Change = 0.0022, Max-Change = 0.0104, Max-Change = 0.0058, Max-Change = 0.0075, Max-Change = 0.0049, Max-Change = 0.0010, Max-Change = 0.0014, Max-Change = 0.0033, Max-Change = 0.0029, Max-Change = 0.0033, Max-Change = 0.0053, Max-Change = 0.0015, Max-Change = 0.0026, Max-Change = 0.0504, Max-Change = 0.0563, Max-Change = 0.0438, Max-Change = 0.0414, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.0674, Max-Change = 0.0488, Max-Change = 0.1112, Max-Change = 0.0397, Max-Change = 0.0278, Max-Change = 0.0117, Max-Change = 0.0143, Max-Change = 0.0157, Max-Change = 0.0098, Max-Change = 0.0107, Max-Change = 0.0456, Max-Change = 0.0102, Max-Change = 0.0108, Max-Change = 0.0286, Max-Change = 0.0242, Max-Change = 0.0158, Max-Change = 0.0098, Max-Change = 0.0145, Max-Change = 0.0062, Max-Change = 0.0076, Max-Change = 0.0117, Max-Change = 0.0107, Max-Change = 0.0120, Max-Change = 0.0100, Max-Change = 0.0085, Max-Change = 0.0268, Max-Change = 0.0089, Max-Change = 0.0072, Max-Change = 0.0066, Max-Change = 0.0051, Max-Change = 0.0076, Max-Change = 0.0049, Max-Change = 0.0051, Max-Change = 0.0058, Max-Change = 0.0080, Max-Change = 0.0052, Max-Change = 0.0136, Max-Change = 0.0078, Max-Change = 0.0079, Max-Change = 0.0079, Max-Change = 0.0061, Max-Change = 0.0028, Max-Change = 0.0061, Max-Change = 0.0110, Max-Change = 0.0032, Max-Change = 0.0023, Max-Change = 0.0071, Max-Change = 0.0048, Max-Change = 0.0087, Max-Change = 0.0048, Max-Change = 0.0096, Max-Change = 0.0060, Max-Change = 0.0052, Max-Change = 0.0035, Max-Change = 0.0057, Max-Change = 0.0061, Max-Change = 0.0036, Max-Change = 0.0041, Max-Change = 0.0070, Max-Change = 0.0063, Max-Change = 0.0112, Max-Change = 0.0021, Max-Change = 0.0141, Max-Change = 0.0145, Max-Change = 0.0035, Max-Change = 0.0038, Max-Change = 0.0023, Max-Change = 0.0084, Max-Change = 0.0054, Max-Change = 0.0073, Max-Change = 0.0036, Max-Change = 0.0117, Max-Change = 0.0045, Max-Change = 0.0050, Max-Change = 0.0066, Max-Change = 0.0070, Max-Change = 0.0050, Max-Change = 0.0008, Max-Change = 0.0061, Max-Change = 0.0089, Max-Change = 0.0036, Max-Change = 0.0127, Max-Change = 0.0072, Max-Change = 0.0045, Max-Change = 0.0094, Max-Change = 0.0102, Max-Change = 0.0087, Max-Change = 0.0114, Max-Change = 0.0088, Max-Change = 0.0058, Max-Change = 0.0016, Max-Change = 0.0072, Max-Change = 0.0096, Max-Change = 0.0061, Max-Change = 0.0060, Max-Change = 0.0020, Max-Change = 0.0113, Max-Change = 0.0087, Max-Change = 0.0036, Max-Change = 0.0066, Max-Change = 0.0037, Max-Change = 0.0041, Max-Change = 0.0044, Max-Change = 0.0051, Max-Change = 0.0075, Max-Change = 0.0020, Max-Change = 0.0050, Max-Change = 0.0055, Max-Change = 0.0047, Max-Change = 0.0049, Max-Change = 0.0113, Max-Change = 0.0050, Max-Change = 0.0044, Max-Change = 0.0080, Max-Change = 0.0076, Max-Change = 0.0047, Max-Change = 0.0054, Max-Change = 0.0075, Max-Change = 0.0026, Max-Change = 0.0035, Max-Change = 0.0099, Max-Change = 0.0038, Max-Change = 0.0108, Max-Change = 0.0072, Max-Change = 0.0086, Max-Change = 0.0042, Max-Change = 0.0025, Max-Change = 0.0094, Max-Change = 0.0063, Max-Change = 0.0023, Max-Change = 0.0100, Max-Change = 0.0037, Max-Change = 0.0064, Max-Change = 0.0031, Max-Change = 0.0068, Max-Change = 0.0047, Max-Change = 0.0077, Max-Change = 0.0042, Max-Change = 0.0045, Max-Change = 0.0079, Max-Change = 0.0060, Max-Change = 0.0025, Max-Change = 0.0040, Max-Change = 0.0071, Max-Change = 0.0033, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0065, gam = 0.1057, Max-Change = 0.0048, gam = 0.0780, Max-Change = 0.0016, gam = 0.0629, Max-Change = 0.0011, gam = 0.0532, Max-Change = 0.0018, gam = 0.0464, Max-Change = 0.0011, gam = 0.0413, Max-Change = 0.0015, gam = 0.0374, Max-Change = 0.0010, gam = 0.0342, Max-Change = 0.0007, gam = 0.0316, Max-Change = 0.0013, gam = 0.0294, Max-Change = 0.0007, gam = 0.0276, Max-Change = 0.0015, gam = 0.0260, Max-Change = 0.0004, gam = 0.0246, Max-Change = 0.0005, gam = 0.0233, Max-Change = 0.0006 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod2b) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items + group_pred, lr.random = ~1 | group) #>  #> -------------- #> FIXED EFFECTS: #>            Estimate Std.Error z.value #> group_pred    1.036     0.044  23.766 #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1 #> F1 1.12 #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $group #>           COV_group #> COV_group       0.1 #>  anova(mod1b, mod2b) #>            AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod1b 23637.58 23664.24 23660.20 23699.19 -11807.79             #> mod2b 22749.34 22778.43 22774.02 22816.55 -11362.67 890.24  1 0  mod3 <- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.random = ~ 1|group, itemtype = '2PL') #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1738, Max-Change = 0.1500, Max-Change = 0.1263, Max-Change = 0.1114, Max-Change = 0.1014, Max-Change = 0.0822, Max-Change = 0.0827, Max-Change = 0.0623, Max-Change = 0.0533, Max-Change = 0.0476, Max-Change = 0.0405, Max-Change = 0.0350, Max-Change = 0.0288, Max-Change = 0.0341, Max-Change = 0.0200, Max-Change = 0.0251, Max-Change = 0.0278, Max-Change = 0.0296, Max-Change = 0.0227, Max-Change = 0.0251, Max-Change = 0.0128, Max-Change = 0.0190, Max-Change = 0.0346, Max-Change = 0.0151, Max-Change = 0.0156, Max-Change = 0.0152, Max-Change = 0.0234, Max-Change = 0.0312, Max-Change = 0.0126, Max-Change = 0.0161, Max-Change = 0.0104, Max-Change = 0.0176, Max-Change = 0.0121, Max-Change = 0.0184, Max-Change = 0.0109, Max-Change = 0.0192, Max-Change = 0.0312, Max-Change = 0.0234, Max-Change = 0.0202, Max-Change = 0.0160, Max-Change = 0.0187, Max-Change = 0.0125, Max-Change = 0.0146, Max-Change = 0.0210, Max-Change = 0.0128, Max-Change = 0.0280, Max-Change = 0.0095, Max-Change = 0.0179, Max-Change = 0.0180, Max-Change = 0.0198, Max-Change = 0.0162, Max-Change = 0.0227, Max-Change = 0.0190, Max-Change = 0.0175, Max-Change = 0.0161, Max-Change = 0.0179, Max-Change = 0.0180, Max-Change = 0.0196, Max-Change = 0.0331, Max-Change = 0.0150, Max-Change = 0.0124, Max-Change = 0.0152, Max-Change = 0.0151, Max-Change = 0.0181, Max-Change = 0.0116, Max-Change = 0.0185, Max-Change = 0.0169, Max-Change = 0.0155, Max-Change = 0.0132, Max-Change = 0.0220, Max-Change = 0.0219, Max-Change = 0.0216, Max-Change = 0.0183, Max-Change = 0.0150, Max-Change = 0.0161, Max-Change = 0.0175, Max-Change = 0.0191, Max-Change = 0.0234, Max-Change = 0.0195, Max-Change = 0.0121, Max-Change = 0.0264, Max-Change = 0.0156, Max-Change = 0.0221, Max-Change = 0.0141, Max-Change = 0.0168, Max-Change = 0.0245, Max-Change = 0.0215, Max-Change = 0.0192, Max-Change = 0.0181, Max-Change = 0.0134, Max-Change = 0.0205, Max-Change = 0.0155, Max-Change = 0.0164, Max-Change = 0.0185, Max-Change = 0.0150, Max-Change = 0.0166, Max-Change = 0.0210, Max-Change = 0.0473, Max-Change = 0.0461, Max-Change = 0.0412, Max-Change = 0.0413, Max-Change = 0.0340, Max-Change = 0.0316, Max-Change = 0.0291, Max-Change = 0.0308, Max-Change = 0.0263, Max-Change = 0.0238, Max-Change = 0.0303, Max-Change = 0.0196, Max-Change = 0.0270, Max-Change = 0.0153, Max-Change = 0.0199, Max-Change = 0.0317, Max-Change = 0.0225, Max-Change = 0.0130, Max-Change = 0.0198, Max-Change = 0.0186, Max-Change = 0.0191, Max-Change = 0.0128, Max-Change = 0.0198, Max-Change = 0.0147, Max-Change = 0.0193, Max-Change = 0.0131, Max-Change = 0.0147, Max-Change = 0.0083, Max-Change = 0.0112, Max-Change = 0.0137, Max-Change = 0.0113, Max-Change = 0.0099, Max-Change = 0.0167, Max-Change = 0.0127, Max-Change = 0.0201, Max-Change = 0.0106, Max-Change = 0.0136, Max-Change = 0.0101, Max-Change = 0.0236, Max-Change = 0.0105, Max-Change = 0.0137, Max-Change = 0.0112, Max-Change = 0.0255, Max-Change = 0.0077, Max-Change = 0.0084, Max-Change = 0.0166, Max-Change = 0.0123, Max-Change = 0.0106, Max-Change = 0.0126, Max-Change = 0.0116, Max-Change = 0.0607, Max-Change = 0.0115, Max-Change = 0.0106, Max-Change = 0.0147, Max-Change = 0.0134, Max-Change = 0.0115, Max-Change = 0.0167, Max-Change = 0.0107, Max-Change = 0.0197, Max-Change = 0.0114, Max-Change = 0.0129, Max-Change = 0.0109, Max-Change = 0.0091, Max-Change = 0.0131, Max-Change = 0.0050, Max-Change = 0.0086, Max-Change = 0.0109, Max-Change = 0.0122, Max-Change = 0.0118, Max-Change = 0.0093, Max-Change = 0.0092, Max-Change = 0.0115, Max-Change = 0.0121, Max-Change = 0.0123, Max-Change = 0.0128, Max-Change = 0.0101, Max-Change = 0.0093, Max-Change = 0.0131, Max-Change = 0.0152, Max-Change = 0.0073, Max-Change = 0.0066, Max-Change = 0.0100, Max-Change = 0.0141, Max-Change = 0.0091, Max-Change = 0.0114, Max-Change = 0.0183, Max-Change = 0.0095, Max-Change = 0.0086, Max-Change = 0.0208, Max-Change = 0.0086, Max-Change = 0.0149, Max-Change = 0.0069, Max-Change = 0.0095, Max-Change = 0.0091, Max-Change = 0.0139, Max-Change = 0.0117, Max-Change = 0.0094, Max-Change = 0.0104, Max-Change = 0.0130, Max-Change = 0.0095, Max-Change = 0.0111, Max-Change = 0.0144, Max-Change = 0.0103, Max-Change = 0.0111, Max-Change = 0.0168, Max-Change = 0.0082, Max-Change = 0.0091, Max-Change = 0.0100, Max-Change = 0.0122, Max-Change = 0.0162, Max-Change = 0.0082, Max-Change = 0.0097, Max-Change = 0.0077, Max-Change = 0.0198, Max-Change = 0.0207, Max-Change = 0.0113, Max-Change = 0.0158, Max-Change = 0.0121, Max-Change = 0.0188, Max-Change = 0.0107, Max-Change = 0.0114, Max-Change = 0.0156, Max-Change = 0.0122, Max-Change = 0.0133, Max-Change = 0.0126, Max-Change = 0.0077, Max-Change = 0.0111, Max-Change = 0.0134, Max-Change = 0.0164, Max-Change = 0.0138, Max-Change = 0.0115, Max-Change = 0.0137, Max-Change = 0.0124, Max-Change = 0.0099, Max-Change = 0.0106, Max-Change = 0.0096, Max-Change = 0.0151, Max-Change = 0.0135, Max-Change = 0.0120, Max-Change = 0.0106, Max-Change = 0.0117, Max-Change = 0.0133, Max-Change = 0.0083, Max-Change = 0.0150, Max-Change = 0.0153, Max-Change = 0.0076, Max-Change = 0.0113, Max-Change = 0.0138, Max-Change = 0.0088, Max-Change = 0.0066, Max-Change = 0.0110, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0088, gam = 0.1057, Max-Change = 0.0072, gam = 0.0780, Max-Change = 0.0034, gam = 0.0629, Max-Change = 0.0035, gam = 0.0532, Max-Change = 0.0031, gam = 0.0464, Max-Change = 0.0023, gam = 0.0413, Max-Change = 0.0020, gam = 0.0374, Max-Change = 0.0019, gam = 0.0342, Max-Change = 0.0024, gam = 0.0316, Max-Change = 0.0020, gam = 0.0294, Max-Change = 0.0011, gam = 0.0276, Max-Change = 0.0026, gam = 0.0260, Max-Change = 0.0019, gam = 0.0246, Max-Change = 0.0019, gam = 0.0233, Max-Change = 0.0010, gam = 0.0222, Max-Change = 0.0012, gam = 0.0212, Max-Change = 0.0015, gam = 0.0203, Max-Change = 0.0012, gam = 0.0195, Max-Change = 0.0008, gam = 0.0188, Max-Change = 0.0008, gam = 0.0181, Max-Change = 0.0008 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod3) #>  #> Call: #> mixedmirt(data = dat, covdata = covdata, model = 1, fixed = ~0 +  #>     items, itemtype = \"2PL\", lr.random = ~1 | group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>    F1 #> F1  1 #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $group #>           COV_group #> COV_group         1 #>  anova(mod1b, mod3) #>            AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod1b 23637.58 23664.24 23660.20 23699.19 -11807.79             #> mod3  23571.39 23619.87 23612.52 23683.41 -11765.69 84.189  9 0  head(cbind(randef(mod3)$group, random_intercept)) #>         group random_intercept #> G1  1.2206915       1.51178117 #> G2 -0.5394258       0.38984324 #> G3 -0.3922094      -0.62124058 #> G4 -2.3431448      -2.21469989 #> G5  0.6890837       1.12493092 #> G6 -0.6933705      -0.04493361  # }"},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an estimated mirt model to a data.frame — mod2values","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"Given estimated model mirt's model fitting functions function convert model parameters design data frame starting values parameter characteristics (similar using pars = 'values' obtaining starting values).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"","code":"mod2values(x)"},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"x estimated model x mirt package","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/mod2values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert an estimated mirt model to a data.frame — mod2values","text":"","code":"# \\donttest{ dat <- expand.table(LSAT7) mod <- mirt(dat, \"F=1-5                   CONSTRAIN=(1-5, a1)\") #>  values <- mod2values(mod) values #>    group   item     class   name parnum value lbound ubound   est const nconst #> 1    all Item.1      dich     a1      1 1.011   -Inf    Inf  TRUE     1   none #> 2    all Item.1      dich      d      2 1.868   -Inf    Inf  TRUE  none   none #> 3    all Item.1      dich      g      3 0.000      0      1 FALSE  none   none #> 4    all Item.1      dich      u      4 1.000      0      1 FALSE  none   none #> 5    all Item.2      dich     a1      5 1.011   -Inf    Inf  TRUE     1   none #> 6    all Item.2      dich      d      6 0.791   -Inf    Inf  TRUE  none   none #> 7    all Item.2      dich      g      7 0.000      0      1 FALSE  none   none #> 8    all Item.2      dich      u      8 1.000      0      1 FALSE  none   none #> 9    all Item.3      dich     a1      9 1.011   -Inf    Inf  TRUE     1   none #> 10   all Item.3      dich      d     10 1.461   -Inf    Inf  TRUE  none   none #> 11   all Item.3      dich      g     11 0.000      0      1 FALSE  none   none #> 12   all Item.3      dich      u     12 1.000      0      1 FALSE  none   none #> 13   all Item.4      dich     a1     13 1.011   -Inf    Inf  TRUE     1   none #> 14   all Item.4      dich      d     14 0.521   -Inf    Inf  TRUE  none   none #> 15   all Item.4      dich      g     15 0.000      0      1 FALSE  none   none #> 16   all Item.4      dich      u     16 1.000      0      1 FALSE  none   none #> 17   all Item.5      dich     a1     17 1.011   -Inf    Inf  TRUE     1   none #> 18   all Item.5      dich      d     18 1.993   -Inf    Inf  TRUE  none   none #> 19   all Item.5      dich      g     19 0.000      0      1 FALSE  none   none #> 20   all Item.5      dich      u     20 1.000      0      1 FALSE  none   none #> 21   all  GROUP GroupPars MEAN_1     21 0.000   -Inf    Inf FALSE  none   none #> 22   all  GROUP GroupPars COV_11     22 1.000      0    Inf FALSE  none   none #>    prior.type prior_1 prior_2 #> 1        none     NaN     NaN #> 2        none     NaN     NaN #> 3        none     NaN     NaN #> 4        none     NaN     NaN #> 5        none     NaN     NaN #> 6        none     NaN     NaN #> 7        none     NaN     NaN #> 8        none     NaN     NaN #> 9        none     NaN     NaN #> 10       none     NaN     NaN #> 11       none     NaN     NaN #> 12       none     NaN     NaN #> 13       none     NaN     NaN #> 14       none     NaN     NaN #> 15       none     NaN     NaN #> 16       none     NaN     NaN #> 17       none     NaN     NaN #> 18       none     NaN     NaN #> 19       none     NaN     NaN #> 20       none     NaN     NaN #> 21       none     NaN     NaN #> 22       none     NaN     NaN  # use the converted values as starting values in a new model, and reduce TOL mod2 <- mirt(dat, 1, pars = values, TOL=1e-5) #>  coef(mod2, simplify=TRUE) #> $items #>           a1     d g u #> Item.1 1.011 1.868 0 1 #> Item.2 1.011 0.791 0 1 #> Item.3 1.011 1.461 0 1 #> Item.4 1.011 0.521 0 1 #> Item.5 1.011 1.993 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # use parameters on different dataset mod3 <- mirt(expand.table(LSAT6), pars=values) #>  coef(mod3, simplify=TRUE) #> $items #>           a1     d g u #> Item_1 0.755 2.730 0 1 #> Item_2 0.755 0.999 0 1 #> Item_3 0.755 0.240 0 1 #> Item_4 0.755 1.307 0 1 #> Item_5 0.755 2.100 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # supports differing itemtypes on second model sv <- mirt(Science, itemtype=c('graded', rep('gpcm', 3)), pars='values') mod3 <- mirt(Science, pars = sv)  # itemtype omitted #>  coef(mod3, simplify=TRUE)$items #>                a1       d1       d2         d3 ak0 ak1 ak2 ak3 d0 #> Comfort 1.0278666 4.842467 2.629427 -1.4610757  NA  NA  NA  NA NA #> Work    0.8622915 1.735970 2.608453  0.8615093   0   1   2   3  0 #> Future  2.1388465 4.498623 6.612162  4.8108956   0   1   2   3  0 #> Benefit 0.7208997 2.096130 2.894803  1.7189648   0   1   2   3  0 extract.mirt(mod3, 'itemtype') #> [1] \"graded\" \"gpcm\"   \"gpcm\"   \"gpcm\"     # }"},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Group Estimation — multipleGroup","title":"Multiple Group Estimation — multipleGroup","text":"multipleGroup performs full-information maximum-likelihood multiple group analysis combination dichotomous polytomous data item response theory paradigm using either Cai's (2010) Metropolis-Hastings Robbins-Monro (MHRM) algorithm EM algorithm approach. function may used detecting differential item functioning (DIF), thought DIF function may provide convenient approach. grouping variable specified dentype input can modified fit mixture models estimate latent group components.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Group Estimation — multipleGroup","text":"","code":"multipleGroup(   data,   model = 1,   group,   itemtype = NULL,   invariance = \"\",   method = \"EM\",   dentype = \"Gaussian\",   itemdesign = NULL,   item.formula = NULL,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple Group Estimation — multipleGroup","text":"data matrix data.frame consists numerically ordered data, organized form integers,  missing data coded NA model string passed , model object returned , mirt.model declaring global model estimated (useful apply constraints ) group character factor vector indicating group membership. character vector supplied automatically transformed factor variable. well, first level (factorized) grouping variable treated \"reference\" group itemtype can type input documented mirt, however may also ngroups nitems matrix specifying type IRT models group, respectively. Rows input correspond levels group input. mixture models rows correspond respective mixture grouping variables constructed, IRT models within mixtures invariance character vector containing following possible options: 'free_mean' 'free_means' freely estimate latent means focal groups       (reference group constrained vector 0's) 'free_var', 'free_vars', 'free_variance', 'free_variances' freely estimate latent variances focal groups       (reference group variances constrained 1) 'slopes' constrain slopes equal across groups 'intercepts' constrain intercepts equal across       groups, note nominal models also includes category specific slope parameters Additionally, specifying specific item name bundles (colnames(data))   constrain freely estimated parameters item equal across groups.   useful selecting 'anchor' items vertical horizontal scaling, detecting   differential item functioning (DIF) across groups method character object either 'EM', 'QMCEM', 'MHRM' (default 'EM'). See mirt details dentype type density form use latent trait parameters. Current options include   methods described mirt, well  'mixture-#' estimates mixtures Gaussian distributions,       # placeholder represents number potential grouping variables       (e.g., 'mixture-3' estimate 3 underlying classes). class       assigned group name MIXTURE_#, # class number.       Note internally mixture coefficients stored log values       first mixture group coefficient fixed 0 itemdesign see mirt details item.formula see mirt details ... additional arguments passed estimation engine. See mirt details examples","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple Group Estimation — multipleGroup","text":"function returns object class MultipleGroupClass   (MultipleGroupClass-class).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiple Group Estimation — multipleGroup","text":"default estimation multipleGroup assumes models maximally independent, therefore initially performed sub-setting data running identical models mirt aggregating results (e.g., log-likelihood). However, constrains may automatically imposed across groups invoking various invariance keywords. Users may also supply list parameter equality constraints constrain argument, define equality constraints using mirt.model syntax (recommended).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiple Group Estimation — multipleGroup","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Magnus, B. E.  Garnier-Villarreal (2022). multidimensional zero-inflated graded response model ordinal symptom data. Psychological Methods, 27, 261-279. Wall, M., M., Park, J., Y., Moustaki . (2015). IRT modeling presence zero-inflation application psychiatric disorder severity. Applied Psychological Measurement 39: 583-597.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiple Group Estimation — multipleGroup","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/multipleGroup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple Group Estimation — multipleGroup","text":"","code":"# \\donttest{  # single factor set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  # marginal information itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  2000            7.888          3.555 0.188 0.053 0.777     1.678 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  2000 2 0.609 0.488   0.525         0.414       0.762 #> Item_2  2000 2 0.392 0.488   0.540         0.431       0.761 #> Item_3  2000 2 0.456 0.498   0.526         0.413       0.762 #> Item_4  2000 2 0.684 0.465   0.461         0.349       0.768 #> Item_5  2000 2 0.538 0.499   0.528         0.415       0.762 #> Item_6  2000 2 0.649 0.477   0.334         0.207       0.779 #> Item_7  2000 2 0.681 0.466   0.524         0.419       0.762 #> Item_8  2000 2 0.432 0.495   0.504         0.389       0.764 #> Item_9  2000 2 0.302 0.459   0.446         0.334       0.769 #> Item_10 2000 2 0.274 0.446   0.388         0.273       0.774 #> Item_11 2000 2 0.734 0.442   0.457         0.351       0.768 #> Item_12 2000 2 0.470 0.499   0.585         0.481       0.756 #> Item_13 2000 2 0.585 0.493   0.561         0.455       0.759 #> Item_14 2000 2 0.592 0.492   0.538         0.428       0.761 #> Item_15 2000 2 0.490 0.500   0.458         0.336       0.769 #>  #> $proportions #>             0     1 #> Item_1  0.392 0.609 #> Item_2  0.608 0.392 #> Item_3  0.544 0.456 #> Item_4  0.316 0.684 #> Item_5  0.462 0.538 #> Item_6  0.351 0.649 #> Item_7  0.318 0.681 #> Item_8  0.569 0.432 #> Item_9  0.698 0.302 #> Item_10 0.726 0.274 #> Item_11 0.266 0.734 #> Item_12 0.530 0.470 #> Item_13 0.416 0.585 #> Item_14 0.408 0.592 #> Item_15 0.509 0.490 #>   # conditional information itemstats(dat, group=group) #> $D1 #> $D1$overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000             7.82          3.346 0.159 0.047  0.74     1.705 #>  #> $D1$itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  1000 2 0.605 0.489   0.484         0.361       0.725 #> Item_2  1000 2 0.368 0.483   0.507         0.388       0.722 #> Item_3  1000 2 0.461 0.499   0.471         0.343       0.727 #> Item_4  1000 2 0.673 0.469   0.439         0.315       0.729 #> Item_5  1000 2 0.526 0.500   0.500         0.376       0.723 #> Item_6  1000 2 0.654 0.476   0.355         0.222       0.739 #> Item_7  1000 2 0.683 0.466   0.508         0.394       0.722 #> Item_8  1000 2 0.431 0.495   0.462         0.333       0.728 #> Item_9  1000 2 0.287 0.453   0.419         0.298       0.731 #> Item_10 1000 2 0.274 0.446   0.372         0.249       0.735 #> Item_11 1000 2 0.739 0.439   0.401         0.282       0.732 #> Item_12 1000 2 0.456 0.498   0.563         0.448       0.715 #> Item_13 1000 2 0.584 0.493   0.535         0.416       0.719 #> Item_14 1000 2 0.592 0.492   0.483         0.358       0.725 #> Item_15 1000 2 0.487 0.500   0.451         0.321       0.729 #>  #> $D1$proportions #>             0     1 #> Item_1  0.395 0.605 #> Item_2  0.632 0.368 #> Item_3  0.539 0.461 #> Item_4  0.327 0.673 #> Item_5  0.474 0.526 #> Item_6  0.346 0.654 #> Item_7  0.317 0.683 #> Item_8  0.569 0.431 #> Item_9  0.713 0.287 #> Item_10 0.726 0.274 #> Item_11 0.261 0.739 #> Item_12 0.544 0.456 #> Item_13 0.416 0.584 #> Item_14 0.408 0.592 #> Item_15 0.513 0.487 #>  #>  #> $D2 #> $D2$overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            7.955          3.754 0.217 0.065 0.807      1.65 #>  #> $D2$itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  1000 2 0.612 0.488   0.563         0.464       0.792 #> Item_2  1000 2 0.417 0.493   0.569         0.469       0.792 #> Item_3  1000 2 0.450 0.498   0.578         0.479       0.791 #> Item_4  1000 2 0.695 0.461   0.484         0.381       0.798 #> Item_5  1000 2 0.551 0.498   0.553         0.451       0.793 #> Item_6  1000 2 0.644 0.479   0.316         0.195       0.811 #> Item_7  1000 2 0.680 0.467   0.540         0.443       0.794 #> Item_8  1000 2 0.432 0.496   0.544         0.440       0.794 #> Item_9  1000 2 0.317 0.466   0.470         0.365       0.799 #> Item_10 1000 2 0.275 0.447   0.403         0.297       0.804 #> Item_11 1000 2 0.729 0.445   0.508         0.413       0.796 #> Item_12 1000 2 0.483 0.500   0.606         0.511       0.788 #> Item_13 1000 2 0.585 0.493   0.587         0.491       0.790 #> Item_14 1000 2 0.591 0.492   0.589         0.493       0.790 #> Item_15 1000 2 0.494 0.500   0.466         0.351       0.801 #>  #> $D2$proportions #>             0     1 #> Item_1  0.388 0.612 #> Item_2  0.583 0.417 #> Item_3  0.550 0.450 #> Item_4  0.305 0.695 #> Item_5  0.449 0.551 #> Item_6  0.356 0.644 #> Item_7  0.320 0.680 #> Item_8  0.568 0.432 #> Item_9  0.683 0.317 #> Item_10 0.725 0.275 #> Item_11 0.271 0.729 #> Item_12 0.517 0.483 #> Item_13 0.415 0.585 #> Item_14 0.409 0.591 #> Item_15 0.506 0.494 #>  #>   mod_configural <- multipleGroup(dat, 1, group = group) #completely separate analyses #>  # limited information fit statistics M2(mod_configural) #>             M2  df         p RMSEA RMSEA_5 RMSEA_95   SRMSR.D1   SRMSR.D2 #> stats 142.9866 180 0.9806548     0       0        0 0.02414868 0.01901262 #>            TLI CFI #> stats 1.005381   1  mod_metric <- multipleGroup(dat, 1, group = group, invariance=c('slopes')) #equal slopes #>  # equal intercepts, free variance and means mod_scalar2 <- multipleGroup(dat, 1, group = group,                              invariance=c('slopes', 'intercepts', 'free_var','free_means')) #>  mod_scalar1 <- multipleGroup(dat, 1, group = group,  #fixed means                              invariance=c('slopes', 'intercepts', 'free_var')) #>  mod_fullconstrain <- multipleGroup(dat, 1, group = group,                              invariance=c('slopes', 'intercepts')) #>  extract.mirt(mod_fullconstrain, 'time') #time of estimation components #> TOTAL:   Data  Estep  Mstep     SE   Post  #>  0.282  0.054  0.060  0.151  0.000  0.000   # optionally use Newton-Raphson for (generally) faster convergence in the #  M-step's, though occasionally less stable mod_fullconstrain <- multipleGroup(dat, 1, group = group, optimizer = 'NR',                              invariance=c('slopes', 'intercepts')) #>  extract.mirt(mod_fullconstrain, 'time') #time of estimation components #> TOTAL:   Data  Estep  Mstep     SE   Post  #>  0.197  0.053  0.073  0.053  0.000  0.001   summary(mod_scalar2) #>  #> ---------- #> GROUP: D1  #>          F1     h2 #>  [1,] 0.544 0.2962 #>  [2,] 0.577 0.3324 #>  [3,] 0.529 0.2799 #>  [4,] 0.460 0.2118 #>  [5,] 0.536 0.2877 #>  [6,] 0.253 0.0639 #>  [7,] 0.570 0.3247 #>  [8,] 0.498 0.2479 #>  [9,] 0.459 0.2104 #> [10,] 0.373 0.1393 #> [11,] 0.487 0.2368 #> [12,] 0.632 0.3998 #> [13,] 0.596 0.3547 #> [14,] 0.561 0.3147 #> [15,] 0.414 0.1715 #>  #> SS loadings:  3.872  #> Proportion Var:  0.258  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 #>  #> ---------- #> GROUP: D2  #>          F1     h2 #>  [1,] 0.634 0.4017 #>  [2,] 0.665 0.4426 #>  [3,] 0.619 0.3827 #>  [4,] 0.548 0.3000 #>  [5,] 0.626 0.3919 #>  [6,] 0.313 0.0981 #>  [7,] 0.659 0.4341 #>  [8,] 0.587 0.3446 #>  [9,] 0.546 0.2983 #> [10,] 0.453 0.2052 #> [11,] 0.575 0.3311 #> [12,] 0.718 0.5152 #> [13,] 0.683 0.4671 #> [14,] 0.650 0.4228 #> [15,] 0.498 0.2483 #>  #> SS loadings:  5.284  #> Proportion Var:  0.352  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 coef(mod_scalar2, simplify=TRUE) #> $D1 #> $items #>            a1      d g u #> Item_1  1.104  0.538 0 1 #> Item_2  1.201 -0.630 0 1 #> Item_3  1.061 -0.265 0 1 #> Item_4  0.882  0.900 0 1 #> Item_5  1.082  0.164 0 1 #> Item_6  0.445  0.636 0 1 #> Item_7  1.180  0.976 0 1 #> Item_8  0.977 -0.377 0 1 #> Item_9  0.879 -1.035 0 1 #> Item_10 0.685 -1.118 0 1 #> Item_11 0.948  1.213 0 1 #> Item_12 1.389 -0.224 0 1 #> Item_13 1.262  0.429 0 1 #> Item_14 1.153  0.453 0 1 #> Item_15 0.774 -0.070 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1      d g u #> Item_1  1.104  0.538 0 1 #> Item_2  1.201 -0.630 0 1 #> Item_3  1.061 -0.265 0 1 #> Item_4  0.882  0.900 0 1 #> Item_5  1.082  0.164 0 1 #> Item_6  0.445  0.636 0 1 #> Item_7  1.180  0.976 0 1 #> Item_8  0.977 -0.377 0 1 #> Item_9  0.879 -1.035 0 1 #> Item_10 0.685 -1.118 0 1 #> Item_11 0.948  1.213 0 1 #> Item_12 1.389 -0.224 0 1 #> Item_13 1.262  0.429 0 1 #> Item_14 1.153  0.453 0 1 #> Item_15 0.774 -0.070 0 1 #>  #> $means #>    F1  #> 0.066  #>  #> $cov #>       F1 #> F1 1.595 #>  #>  residuals(mod_scalar2) #> $D1 #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1      NA -0.036 -0.056  0.036 -0.014  0.014  0.017 -0.020 -0.008  -0.066 #> Item_2   1.305     NA -0.052 -0.032 -0.031  0.033 -0.028  0.034  0.038   0.042 #> Item_3   3.144  2.659     NA -0.047  0.057  0.071 -0.037 -0.050  0.033  -0.047 #> Item_4   1.279  1.040  2.173     NA  0.029  0.035  0.032 -0.039 -0.038   0.032 #> Item_5   0.198  0.932  3.291  0.862     NA  0.029  0.048 -0.028  0.027  -0.027 #> Item_6   0.204  1.059  5.032  1.197  0.830     NA  0.020  0.034  0.023   0.041 #> Item_7   0.277  0.804  1.362  1.018  2.337  0.392     NA -0.023 -0.040   0.038 #> Item_8   0.402  1.143  2.484  1.545  0.774  1.125  0.518     NA -0.027   0.025 #> Item_9   0.067  1.478  1.062  1.471  0.717  0.523  1.631  0.726     NA   0.052 #> Item_10  4.303  1.756  2.228  1.054  0.744  1.650  1.453  0.610  2.692      NA #> Item_11  0.361  3.951  0.988  1.197  0.910  1.320  0.139  2.072  2.295   1.368 #> Item_12  1.718  0.586  1.038  0.725  0.218  0.454  1.323  0.473  0.322   0.604 #> Item_13  0.194  3.315  1.368  1.158  0.797  0.517  0.045  0.395  0.200   2.690 #> Item_14  0.074  0.804  3.798  2.946  0.648  0.228  0.223  0.464  0.693   0.378 #> Item_15  0.164  1.266  0.869  6.382  4.884  1.983  0.583  1.563  1.130   2.406 #>         Item_11 Item_12 Item_13 Item_14 Item_15 #> Item_1   -0.019   0.041  -0.014  -0.009   0.013 #> Item_2   -0.063   0.024   0.058   0.028   0.036 #> Item_3   -0.031   0.032  -0.037  -0.062   0.029 #> Item_4    0.035   0.027  -0.034  -0.054   0.080 #> Item_5   -0.030   0.015   0.028  -0.025  -0.070 #> Item_6    0.036   0.021   0.023  -0.015   0.045 #> Item_7    0.012   0.036  -0.007   0.015   0.024 #> Item_8   -0.046   0.022   0.020  -0.022   0.040 #> Item_9   -0.048  -0.018  -0.014   0.026   0.034 #> Item_10   0.037   0.025   0.052  -0.019  -0.049 #> Item_11      NA   0.010  -0.024  -0.053   0.021 #> Item_12   0.094      NA  -0.016  -0.016   0.012 #> Item_13   0.555   0.254      NA  -0.013   0.022 #> Item_14   2.862   0.255   0.159      NA   0.009 #> Item_15   0.424   0.148   0.486   0.073      NA #>  #> $D2 #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1      NA -0.029  0.031 -0.026  0.021 -0.042 -0.006  0.039  0.010  -0.029 #> Item_2   0.861     NA  0.047 -0.060  0.049 -0.061 -0.036 -0.036  0.043   0.035 #> Item_3   0.973  2.251     NA  0.064  0.039 -0.029  0.033  0.045  0.042   0.031 #> Item_4   0.673  3.546  4.082     NA  0.034  0.045  0.029  0.033 -0.031  -0.053 #> Item_5   0.455  2.426  1.534  1.151     NA -0.042 -0.043 -0.030  0.034  -0.026 #> Item_6   1.750  3.773  0.861  2.016  1.752     NA -0.038  0.023 -0.060   0.022 #> Item_7   0.040  1.293  1.085  0.831  1.854  1.475     NA  0.023 -0.021   0.025 #> Item_8   1.530  1.310  1.985  1.122  0.915  0.545  0.539     NA -0.028  -0.026 #> Item_9   0.106  1.832  1.780  0.934  1.137  3.654  0.453  0.760     NA   0.037 #> Item_10  0.815  1.230  0.958  2.779  0.685  0.466  0.622  0.690  1.393      NA #> Item_11  0.822  0.826  0.800  1.861  0.336  0.218  0.062  2.847  0.285   0.407 #> Item_12  0.087  1.536  1.097  0.639  0.309  0.454  0.096  0.556  0.398   0.520 #> Item_13  0.582  1.458  0.844  1.093  0.620  0.403  0.401  0.619  1.349   0.478 #> Item_14  0.403  1.550  0.914  1.292  0.544  0.799  0.534  3.153  0.137   0.344 #> Item_15  0.338  1.306  1.241  0.979  2.379  1.262  0.615  0.292  0.276   0.325 #>         Item_11 Item_12 Item_13 Item_14 Item_15 #> Item_1    0.029   0.009   0.024   0.020   0.018 #> Item_2    0.029  -0.039   0.038   0.039  -0.036 #> Item_3    0.028   0.033   0.029   0.030   0.035 #> Item_4    0.043  -0.025  -0.033   0.036  -0.031 #> Item_5    0.018  -0.018  -0.025   0.023  -0.049 #> Item_6    0.015  -0.021   0.020  -0.028  -0.036 #> Item_7   -0.008  -0.010  -0.020   0.023  -0.025 #> Item_8    0.053  -0.024  -0.025   0.056   0.017 #> Item_9   -0.017  -0.020  -0.037   0.012  -0.017 #> Item_10   0.020   0.023  -0.022   0.019   0.018 #> Item_11      NA   0.032   0.017   0.018   0.024 #> Item_12   1.010      NA   0.014  -0.022  -0.011 #> Item_13   0.280   0.185      NA   0.022  -0.012 #> Item_14   0.333   0.480   0.479      NA  -0.007 #> Item_15   0.580   0.131   0.145   0.048      NA #>  plot(mod_configural)  plot(mod_configural, type = 'info')  plot(mod_configural, type = 'trace')  plot(mod_configural, type = 'trace', which.items = 1:4)  itemplot(mod_configural, 2)  itemplot(mod_configural, 2, type = 'RE')   anova(mod_metric, mod_configural) #equal slopes only #>                     AIC    SABIC       HQ      BIC    logLik    X2 df p #> mod_metric     35937.61 36046.68 36030.15 36189.65 -17923.80            #> mod_configural 35927.53 36072.96 36050.92 36263.58 -17903.76 40.08 15 0 anova(mod_scalar2, mod_metric) #equal intercepts, free variance and mean #>                  AIC    SABIC       HQ      BIC    logLik      X2 df   p #> mod_scalar2 35894.66 35972.22 35960.47 36073.89 -17915.33                #> mod_metric  35937.61 36046.68 36030.15 36189.65 -17923.80 -16.947 13 NaN anova(mod_scalar1, mod_scalar2) #fix mean #>                  AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod_scalar1 35893.96 35969.10 35957.71 36067.58 -17915.98                #> mod_scalar2 35894.66 35972.22 35960.47 36073.89 -17915.33 1.296  1 0.255 anova(mod_fullconstrain, mod_scalar1) #fix variance #>                        AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod_fullconstrain 35917.51 35990.22 35979.20 36085.53 -17928.75             #> mod_scalar1       35893.96 35969.10 35957.71 36067.58 -17915.98 25.552  1 0  # compared all at once (in order of most constrained to least) anova(mod_fullconstrain, mod_scalar2, mod_configural) #>                        AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mod_fullconstrain 35917.51 35990.22 35979.20 36085.53 -17928.75                 #> mod_scalar2       35894.66 35972.22 35960.47 36073.89 -17915.33 26.848  2     0 #> mod_configural    35927.53 36072.96 36050.92 36263.58 -17903.76 23.133 28 0.726   # test whether first 6 slopes should be equal across groups values <- multipleGroup(dat, 1, group = group, pars = 'values') values #>     group    item     class   name parnum  value lbound ubound   est const #> 1      D1  Item_1      dich     a1      1  0.851   -Inf    Inf  TRUE  none #> 2      D1  Item_1      dich      d      2  0.541   -Inf    Inf  TRUE  none #> 3      D1  Item_1      dich      g      3  0.000      0      1 FALSE  none #> 4      D1  Item_1      dich      u      4  1.000      0      1 FALSE  none #> 5      D1  Item_2      dich     a1      5  0.851   -Inf    Inf  TRUE  none #> 6      D1  Item_2      dich      d      6 -0.536   -Inf    Inf  TRUE  none #> 7      D1  Item_2      dich      g      7  0.000      0      1 FALSE  none #> 8      D1  Item_2      dich      u      8  1.000      0      1 FALSE  none #> 9      D1  Item_3      dich     a1      9  0.851   -Inf    Inf  TRUE  none #> 10     D1  Item_3      dich      d     10 -0.220   -Inf    Inf  TRUE  none #> 11     D1  Item_3      dich      g     11  0.000      0      1 FALSE  none #> 12     D1  Item_3      dich      u     12  1.000      0      1 FALSE  none #> 13     D1  Item_4      dich     a1     13  0.851   -Inf    Inf  TRUE  none #> 14     D1  Item_4      dich      d     14  0.941   -Inf    Inf  TRUE  none #> 15     D1  Item_4      dich      g     15  0.000      0      1 FALSE  none #> 16     D1  Item_4      dich      u     16  1.000      0      1 FALSE  none #> 17     D1  Item_5      dich     a1     17  0.851   -Inf    Inf  TRUE  none #> 18     D1  Item_5      dich      d     18  0.190   -Inf    Inf  TRUE  none #> 19     D1  Item_5      dich      g     19  0.000      0      1 FALSE  none #> 20     D1  Item_5      dich      u     20  1.000      0      1 FALSE  none #> 21     D1  Item_6      dich     a1     21  0.851   -Inf    Inf  TRUE  none #> 22     D1  Item_6      dich      d     22  0.752   -Inf    Inf  TRUE  none #> 23     D1  Item_6      dich      g     23  0.000      0      1 FALSE  none #> 24     D1  Item_6      dich      u     24  1.000      0      1 FALSE  none #> 25     D1  Item_7      dich     a1     25  0.851   -Inf    Inf  TRUE  none #> 26     D1  Item_7      dich      d     26  0.927   -Inf    Inf  TRUE  none #> 27     D1  Item_7      dich      g     27  0.000      0      1 FALSE  none #> 28     D1  Item_7      dich      u     28  1.000      0      1 FALSE  none #> 29     D1  Item_8      dich     a1     29  0.851   -Inf    Inf  TRUE  none #> 30     D1  Item_8      dich      d     30 -0.339   -Inf    Inf  TRUE  none #> 31     D1  Item_8      dich      g     31  0.000      0      1 FALSE  none #> 32     D1  Item_8      dich      u     32  1.000      0      1 FALSE  none #> 33     D1  Item_9      dich     a1     33  0.851   -Inf    Inf  TRUE  none #> 34     D1  Item_9      dich      d     34 -1.019   -Inf    Inf  TRUE  none #> 35     D1  Item_9      dich      g     35  0.000      0      1 FALSE  none #> 36     D1  Item_9      dich      u     36  1.000      0      1 FALSE  none #> 37     D1 Item_10      dich     a1     37  0.851   -Inf    Inf  TRUE  none #> 38     D1 Item_10      dich      d     38 -1.178   -Inf    Inf  TRUE  none #> 39     D1 Item_10      dich      g     39  0.000      0      1 FALSE  none #> 40     D1 Item_10      dich      u     40  1.000      0      1 FALSE  none #> 41     D1 Item_11      dich     a1     41  0.851   -Inf    Inf  TRUE  none #> 42     D1 Item_11      dich      d     42  1.228   -Inf    Inf  TRUE  none #> 43     D1 Item_11      dich      g     43  0.000      0      1 FALSE  none #> 44     D1 Item_11      dich      u     44  1.000      0      1 FALSE  none #> 45     D1 Item_12      dich     a1     45  0.851   -Inf    Inf  TRUE  none #> 46     D1 Item_12      dich      d     46 -0.150   -Inf    Inf  TRUE  none #> 47     D1 Item_12      dich      g     47  0.000      0      1 FALSE  none #> 48     D1 Item_12      dich      u     48  1.000      0      1 FALSE  none #> 49     D1 Item_13      dich     a1     49  0.851   -Inf    Inf  TRUE  none #> 50     D1 Item_13      dich      d     50  0.419   -Inf    Inf  TRUE  none #> 51     D1 Item_13      dich      g     51  0.000      0      1 FALSE  none #> 52     D1 Item_13      dich      u     52  1.000      0      1 FALSE  none #> 53     D1 Item_14      dich     a1     53  0.851   -Inf    Inf  TRUE  none #> 54     D1 Item_14      dich      d     54  0.455   -Inf    Inf  TRUE  none #> 55     D1 Item_14      dich      g     55  0.000      0      1 FALSE  none #> 56     D1 Item_14      dich      u     56  1.000      0      1 FALSE  none #> 57     D1 Item_15      dich     a1     57  0.851   -Inf    Inf  TRUE  none #> 58     D1 Item_15      dich      d     58 -0.047   -Inf    Inf  TRUE  none #> 59     D1 Item_15      dich      g     59  0.000      0      1 FALSE  none #> 60     D1 Item_15      dich      u     60  1.000      0      1 FALSE  none #> 61     D1   GROUP GroupPars MEAN_1     61  0.000   -Inf    Inf FALSE  none #> 62     D1   GROUP GroupPars COV_11     62  1.000      0    Inf FALSE  none #> 63     D2  Item_1      dich     a1     63  0.851   -Inf    Inf  TRUE  none #> 64     D2  Item_1      dich      d     64  0.541   -Inf    Inf  TRUE  none #> 65     D2  Item_1      dich      g     65  0.000      0      1 FALSE  none #> 66     D2  Item_1      dich      u     66  1.000      0      1 FALSE  none #> 67     D2  Item_2      dich     a1     67  0.851   -Inf    Inf  TRUE  none #> 68     D2  Item_2      dich      d     68 -0.536   -Inf    Inf  TRUE  none #> 69     D2  Item_2      dich      g     69  0.000      0      1 FALSE  none #> 70     D2  Item_2      dich      u     70  1.000      0      1 FALSE  none #> 71     D2  Item_3      dich     a1     71  0.851   -Inf    Inf  TRUE  none #> 72     D2  Item_3      dich      d     72 -0.220   -Inf    Inf  TRUE  none #> 73     D2  Item_3      dich      g     73  0.000      0      1 FALSE  none #> 74     D2  Item_3      dich      u     74  1.000      0      1 FALSE  none #> 75     D2  Item_4      dich     a1     75  0.851   -Inf    Inf  TRUE  none #> 76     D2  Item_4      dich      d     76  0.941   -Inf    Inf  TRUE  none #> 77     D2  Item_4      dich      g     77  0.000      0      1 FALSE  none #> 78     D2  Item_4      dich      u     78  1.000      0      1 FALSE  none #> 79     D2  Item_5      dich     a1     79  0.851   -Inf    Inf  TRUE  none #> 80     D2  Item_5      dich      d     80  0.190   -Inf    Inf  TRUE  none #> 81     D2  Item_5      dich      g     81  0.000      0      1 FALSE  none #> 82     D2  Item_5      dich      u     82  1.000      0      1 FALSE  none #> 83     D2  Item_6      dich     a1     83  0.851   -Inf    Inf  TRUE  none #> 84     D2  Item_6      dich      d     84  0.752   -Inf    Inf  TRUE  none #> 85     D2  Item_6      dich      g     85  0.000      0      1 FALSE  none #> 86     D2  Item_6      dich      u     86  1.000      0      1 FALSE  none #> 87     D2  Item_7      dich     a1     87  0.851   -Inf    Inf  TRUE  none #> 88     D2  Item_7      dich      d     88  0.927   -Inf    Inf  TRUE  none #> 89     D2  Item_7      dich      g     89  0.000      0      1 FALSE  none #> 90     D2  Item_7      dich      u     90  1.000      0      1 FALSE  none #> 91     D2  Item_8      dich     a1     91  0.851   -Inf    Inf  TRUE  none #> 92     D2  Item_8      dich      d     92 -0.339   -Inf    Inf  TRUE  none #> 93     D2  Item_8      dich      g     93  0.000      0      1 FALSE  none #> 94     D2  Item_8      dich      u     94  1.000      0      1 FALSE  none #> 95     D2  Item_9      dich     a1     95  0.851   -Inf    Inf  TRUE  none #> 96     D2  Item_9      dich      d     96 -1.019   -Inf    Inf  TRUE  none #> 97     D2  Item_9      dich      g     97  0.000      0      1 FALSE  none #> 98     D2  Item_9      dich      u     98  1.000      0      1 FALSE  none #> 99     D2 Item_10      dich     a1     99  0.851   -Inf    Inf  TRUE  none #> 100    D2 Item_10      dich      d    100 -1.178   -Inf    Inf  TRUE  none #> 101    D2 Item_10      dich      g    101  0.000      0      1 FALSE  none #> 102    D2 Item_10      dich      u    102  1.000      0      1 FALSE  none #> 103    D2 Item_11      dich     a1    103  0.851   -Inf    Inf  TRUE  none #> 104    D2 Item_11      dich      d    104  1.228   -Inf    Inf  TRUE  none #> 105    D2 Item_11      dich      g    105  0.000      0      1 FALSE  none #> 106    D2 Item_11      dich      u    106  1.000      0      1 FALSE  none #> 107    D2 Item_12      dich     a1    107  0.851   -Inf    Inf  TRUE  none #> 108    D2 Item_12      dich      d    108 -0.150   -Inf    Inf  TRUE  none #> 109    D2 Item_12      dich      g    109  0.000      0      1 FALSE  none #> 110    D2 Item_12      dich      u    110  1.000      0      1 FALSE  none #> 111    D2 Item_13      dich     a1    111  0.851   -Inf    Inf  TRUE  none #> 112    D2 Item_13      dich      d    112  0.419   -Inf    Inf  TRUE  none #> 113    D2 Item_13      dich      g    113  0.000      0      1 FALSE  none #> 114    D2 Item_13      dich      u    114  1.000      0      1 FALSE  none #> 115    D2 Item_14      dich     a1    115  0.851   -Inf    Inf  TRUE  none #> 116    D2 Item_14      dich      d    116  0.455   -Inf    Inf  TRUE  none #> 117    D2 Item_14      dich      g    117  0.000      0      1 FALSE  none #> 118    D2 Item_14      dich      u    118  1.000      0      1 FALSE  none #> 119    D2 Item_15      dich     a1    119  0.851   -Inf    Inf  TRUE  none #> 120    D2 Item_15      dich      d    120 -0.047   -Inf    Inf  TRUE  none #> 121    D2 Item_15      dich      g    121  0.000      0      1 FALSE  none #> 122    D2 Item_15      dich      u    122  1.000      0      1 FALSE  none #> 123    D2   GROUP GroupPars MEAN_1    123  0.000   -Inf    Inf FALSE  none #> 124    D2   GROUP GroupPars COV_11    124  1.000      0    Inf FALSE  none #>     nconst prior.type prior_1 prior_2 #> 1     none       none     NaN     NaN #> 2     none       none     NaN     NaN #> 3     none       none     NaN     NaN #> 4     none       none     NaN     NaN #> 5     none       none     NaN     NaN #> 6     none       none     NaN     NaN #> 7     none       none     NaN     NaN #> 8     none       none     NaN     NaN #> 9     none       none     NaN     NaN #> 10    none       none     NaN     NaN #> 11    none       none     NaN     NaN #> 12    none       none     NaN     NaN #> 13    none       none     NaN     NaN #> 14    none       none     NaN     NaN #> 15    none       none     NaN     NaN #> 16    none       none     NaN     NaN #> 17    none       none     NaN     NaN #> 18    none       none     NaN     NaN #> 19    none       none     NaN     NaN #> 20    none       none     NaN     NaN #> 21    none       none     NaN     NaN #> 22    none       none     NaN     NaN #> 23    none       none     NaN     NaN #> 24    none       none     NaN     NaN #> 25    none       none     NaN     NaN #> 26    none       none     NaN     NaN #> 27    none       none     NaN     NaN #> 28    none       none     NaN     NaN #> 29    none       none     NaN     NaN #> 30    none       none     NaN     NaN #> 31    none       none     NaN     NaN #> 32    none       none     NaN     NaN #> 33    none       none     NaN     NaN #> 34    none       none     NaN     NaN #> 35    none       none     NaN     NaN #> 36    none       none     NaN     NaN #> 37    none       none     NaN     NaN #> 38    none       none     NaN     NaN #> 39    none       none     NaN     NaN #> 40    none       none     NaN     NaN #> 41    none       none     NaN     NaN #> 42    none       none     NaN     NaN #> 43    none       none     NaN     NaN #> 44    none       none     NaN     NaN #> 45    none       none     NaN     NaN #> 46    none       none     NaN     NaN #> 47    none       none     NaN     NaN #> 48    none       none     NaN     NaN #> 49    none       none     NaN     NaN #> 50    none       none     NaN     NaN #> 51    none       none     NaN     NaN #> 52    none       none     NaN     NaN #> 53    none       none     NaN     NaN #> 54    none       none     NaN     NaN #> 55    none       none     NaN     NaN #> 56    none       none     NaN     NaN #> 57    none       none     NaN     NaN #> 58    none       none     NaN     NaN #> 59    none       none     NaN     NaN #> 60    none       none     NaN     NaN #> 61    none       none     NaN     NaN #> 62    none       none     NaN     NaN #> 63    none       none     NaN     NaN #> 64    none       none     NaN     NaN #> 65    none       none     NaN     NaN #> 66    none       none     NaN     NaN #> 67    none       none     NaN     NaN #> 68    none       none     NaN     NaN #> 69    none       none     NaN     NaN #> 70    none       none     NaN     NaN #> 71    none       none     NaN     NaN #> 72    none       none     NaN     NaN #> 73    none       none     NaN     NaN #> 74    none       none     NaN     NaN #> 75    none       none     NaN     NaN #> 76    none       none     NaN     NaN #> 77    none       none     NaN     NaN #> 78    none       none     NaN     NaN #> 79    none       none     NaN     NaN #> 80    none       none     NaN     NaN #> 81    none       none     NaN     NaN #> 82    none       none     NaN     NaN #> 83    none       none     NaN     NaN #> 84    none       none     NaN     NaN #> 85    none       none     NaN     NaN #> 86    none       none     NaN     NaN #> 87    none       none     NaN     NaN #> 88    none       none     NaN     NaN #> 89    none       none     NaN     NaN #> 90    none       none     NaN     NaN #> 91    none       none     NaN     NaN #> 92    none       none     NaN     NaN #> 93    none       none     NaN     NaN #> 94    none       none     NaN     NaN #> 95    none       none     NaN     NaN #> 96    none       none     NaN     NaN #> 97    none       none     NaN     NaN #> 98    none       none     NaN     NaN #> 99    none       none     NaN     NaN #> 100   none       none     NaN     NaN #> 101   none       none     NaN     NaN #> 102   none       none     NaN     NaN #> 103   none       none     NaN     NaN #> 104   none       none     NaN     NaN #> 105   none       none     NaN     NaN #> 106   none       none     NaN     NaN #> 107   none       none     NaN     NaN #> 108   none       none     NaN     NaN #> 109   none       none     NaN     NaN #> 110   none       none     NaN     NaN #> 111   none       none     NaN     NaN #> 112   none       none     NaN     NaN #> 113   none       none     NaN     NaN #> 114   none       none     NaN     NaN #> 115   none       none     NaN     NaN #> 116   none       none     NaN     NaN #> 117   none       none     NaN     NaN #> 118   none       none     NaN     NaN #> 119   none       none     NaN     NaN #> 120   none       none     NaN     NaN #> 121   none       none     NaN     NaN #> 122   none       none     NaN     NaN #> 123   none       none     NaN     NaN #> 124   none       none     NaN     NaN constrain <- list(c(1, 63), c(5,67), c(9,71), c(13,75), c(17,79), c(21,83)) equalslopes <- multipleGroup(dat, 1, group = group, constrain = constrain) #>  anova(equalslopes, mod_configural) #>                     AIC    SABIC       HQ      BIC    logLik     X2 df     p #> equalslopes    35935.51 36066.40 36046.56 36237.96 -17913.76                 #> mod_configural 35927.53 36072.96 36050.92 36263.58 -17903.76 19.983  6 0.003  # same as above, but using mirt.model syntax newmodel <- '     F = 1-15     CONSTRAINB = (1-6, a1)' equalslopes <- multipleGroup(dat, newmodel, group = group) #>  coef(equalslopes, simplify=TRUE) #> $D1 #> $items #>            a1      d g u #> Item_1  1.246  0.546 0 1 #> Item_2  1.356 -0.720 0 1 #> Item_3  1.199 -0.201 0 1 #> Item_4  1.006  0.861 0 1 #> Item_5  1.224  0.131 0 1 #> Item_6  0.515  0.673 0 1 #> Item_7  1.305  0.999 0 1 #> Item_8  0.943 -0.328 0 1 #> Item_9  0.916 -1.058 0 1 #> Item_10 0.731 -1.079 0 1 #> Item_11 0.851  1.186 0 1 #> Item_12 1.515 -0.251 0 1 #> Item_13 1.322  0.444 0 1 #> Item_14 1.058  0.451 0 1 #> Item_15 0.885 -0.061 0 1 #>  #> $means #> F  #> 0  #>  #> $cov #>   F #> F 1 #>  #>  #> $D2 #> $items #>            a1      d g u #> Item_1  1.246  0.599 0 1 #> Item_2  1.356 -0.462 0 1 #> Item_3  1.199 -0.264 0 1 #> Item_4  1.006  1.001 0 1 #> Item_5  1.224  0.266 0 1 #> Item_6  0.515  0.631 0 1 #> Item_7  1.374  1.031 0 1 #> Item_8  1.268 -0.367 0 1 #> Item_9  1.061 -0.952 0 1 #> Item_10 0.826 -1.115 0 1 #> Item_11 1.282  1.308 0 1 #> Item_12 1.625 -0.107 0 1 #> Item_13 1.523  0.493 0 1 #> Item_14 1.545  0.532 0 1 #> Item_15 0.885 -0.030 0 1 #>  #> $means #> F  #> 0  #>  #> $cov #>   F #> F 1 #>  #>   ############ # vertical scaling (i.e., equating when groups answer items others do not) dat2 <- dat dat2[group == 'D1', 1:2] <- dat2[group != 'D1', 14:15] <- NA head(dat2) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]     NA     NA      1      1      1      0      1      1      0       0 #> [2,]     NA     NA      1      1      1      1      1      0      1       0 #> [3,]     NA     NA      0      1      1      1      1      1      0       0 #> [4,]     NA     NA      1      1      1      1      1      1      0       0 #> [5,]     NA     NA      1      0      1      1      1      1      1       0 #> [6,]     NA     NA      1      1      1      1      1      0      0       0 #>      Item_11 Item_12 Item_13 Item_14 Item_15 #> [1,]       1       1       0       1       1 #> [2,]       0       1       1       1       1 #> [3,]       1       0       1       1       1 #> [4,]       1       1       1       1       1 #> [5,]       1       1       1       1       1 #> [6,]       1       1       1       1       0 tail(dat2) #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1995,]      1      1      0      0      0      1      1      1      0       0 #> [1996,]      1      0      1      1      1      0      1      1      1       1 #> [1997,]      0      1      0      0      0      1      0      1      0       0 #> [1998,]      0      1      0      0      1      0      0      0      0       0 #> [1999,]      1      1      0      1      1      1      1      1      0       0 #> [2000,]      0      0      0      0      0      0      1      0      0       0 #>         Item_11 Item_12 Item_13 Item_14 Item_15 #> [1995,]       1       0       1      NA      NA #> [1996,]       1       1       0      NA      NA #> [1997,]       1       0       1      NA      NA #> [1998,]       0       1       0      NA      NA #> [1999,]       1       1       1      NA      NA #> [2000,]       0       0       0      NA      NA  # items with missing responses need to be constrained across groups for identification nms <- colnames(dat2) mod <- multipleGroup(dat2, 1, group, invariance = nms[c(1:2, 14:15)]) #>   # this will throw an error without proper constraints (SEs cannot be computed either) # mod <- multipleGroup(dat2, 1, group)  # model still does not have anchors, therefore need to add a few (here use items 3-5) mod_anchor <- multipleGroup(dat2, 1, group,                             invariance = c(nms[c(1:5, 14:15)], 'free_means', 'free_var')) #>  coef(mod_anchor, simplify=TRUE) #> $D1 #> $items #>            a1      d g u #> Item_1  1.108  0.542 0 1 #> Item_2  1.160 -0.564 0 1 #> Item_3  1.073 -0.272 0 1 #> Item_4  0.871  0.895 0 1 #> Item_5  1.089  0.160 0 1 #> Item_6  0.582  0.685 0 1 #> Item_7  1.292  1.009 0 1 #> Item_8  0.906 -0.328 0 1 #> Item_9  0.855 -1.049 0 1 #> Item_10 0.746 -1.089 0 1 #> Item_11 0.866  1.200 0 1 #> Item_12 1.432 -0.247 0 1 #> Item_13 1.244  0.440 0 1 #> Item_14 1.000  0.449 0 1 #> Item_15 0.852 -0.061 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1      d g u #> Item_1  1.108  0.542 0 1 #> Item_2  1.160 -0.564 0 1 #> Item_3  1.073 -0.272 0 1 #> Item_4  0.871  0.895 0 1 #> Item_5  1.089  0.160 0 1 #> Item_6  0.374  0.596 0 1 #> Item_7  1.090  0.942 0 1 #> Item_8  0.988 -0.437 0 1 #> Item_9  0.854 -1.018 0 1 #> Item_10 0.657 -1.164 0 1 #> Item_11 1.023  1.228 0 1 #> Item_12 1.324 -0.207 0 1 #> Item_13 1.212  0.399 0 1 #> Item_14 1.000  0.449 0 1 #> Item_15 0.852 -0.061 0 1 #>  #> $means #>    F1  #> 0.077  #>  #> $cov #>       F1 #> F1 1.658 #>  #>   # check if identified by computing information matrix mod_anchor <- multipleGroup(dat2, 1, group, pars = mod2values(mod_anchor), TOL=NaN, SE=TRUE,                             invariance = c(nms[c(1:5, 14:15)], 'free_means', 'free_var')) mod_anchor #>  #> Call: #> multipleGroup(data = dat2, model = 1, group = group, invariance = c(nms[c(1:5,  #>     14:15)], \"free_means\", \"free_var\"), pars = mod2values(mod_anchor),  #>     TOL = NaN, SE = TRUE) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within NaN tolerance after 1 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: nlminb  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Information matrix estimated with method: Oakes #> Second-order test: model is a possible local maximum #> Condition number of information matrix =  87.67822 #>  #> Log-likelihood = -15563.53 #> Estimated parameters: 48  #> AIC = 31223.06 #> BIC = 31491.91; SABIC = 31339.41 #>  coef(mod_anchor) #> $D1 #> $Item_1 #>            a1     d  g  u #> par     1.108 0.542  0  1 #> CI_2.5  0.842 0.330 NA NA #> CI_97.5 1.375 0.753 NA NA #>  #> $Item_2 #>            a1      d  g  u #> par     1.160 -0.564  0  1 #> CI_2.5  0.883 -0.785 NA NA #> CI_97.5 1.436 -0.342 NA NA #>  #> $Item_3 #>            a1      d  g  u #> par     1.073 -0.272  0  1 #> CI_2.5  0.896 -0.408 NA NA #> CI_97.5 1.250 -0.137 NA NA #>  #> $Item_4 #>            a1     d  g  u #> par     0.871 0.895  0  1 #> CI_2.5  0.710 0.765 NA NA #> CI_97.5 1.031 1.026 NA NA #>  #> $Item_5 #>            a1     d  g  u #> par     1.089 0.160  0  1 #> CI_2.5  0.906 0.024 NA NA #> CI_97.5 1.272 0.295 NA NA #>  #> $Item_6 #>            a1     d  g  u #> par     0.582 0.685  0  1 #> CI_2.5  0.405 0.543 NA NA #> CI_97.5 0.760 0.828 NA NA #>  #> $Item_7 #>            a1     d  g  u #> par     1.292 1.009  0  1 #> CI_2.5  1.027 0.818 NA NA #> CI_97.5 1.558 1.199 NA NA #>  #> $Item_8 #>            a1      d  g  u #> par     0.906 -0.328  0  1 #> CI_2.5  0.702 -0.476 NA NA #> CI_97.5 1.111 -0.179 NA NA #>  #> $Item_9 #>            a1      d  g  u #> par     0.855 -1.049  0  1 #> CI_2.5  0.642 -1.216 NA NA #> CI_97.5 1.069 -0.882 NA NA #>  #> $Item_10 #>            a1      d  g  u #> par     0.746 -1.089  0  1 #> CI_2.5  0.542 -1.253 NA NA #> CI_97.5 0.950 -0.926 NA NA #>  #> $Item_11 #>            a1     d  g  u #> par     0.866 1.200  0  1 #> CI_2.5  0.651 1.025 NA NA #> CI_97.5 1.081 1.375 NA NA #>  #> $Item_12 #>            a1      d  g  u #> par     1.432 -0.247  0  1 #> CI_2.5  1.152 -0.421 NA NA #> CI_97.5 1.713 -0.074 NA NA #>  #> $Item_13 #>            a1     d  g  u #> par     1.244 0.440  0  1 #> CI_2.5  0.994 0.273 NA NA #> CI_97.5 1.494 0.607 NA NA #>  #> $Item_14 #>            a1     d  g  u #> par     1.000 0.449  0  1 #> CI_2.5  0.785 0.294 NA NA #> CI_97.5 1.215 0.603 NA NA #>  #> $Item_15 #>            a1      d  g  u #> par     0.852 -0.061  0  1 #> CI_2.5  0.655 -0.205 NA NA #> CI_97.5 1.049  0.083 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0      1 #> CI_2.5      NA     NA #> CI_97.5     NA     NA #>  #>  #> $D2 #> $Item_1 #>            a1     d  g  u #> par     1.108 0.542  0  1 #> CI_2.5  0.842 0.330 NA NA #> CI_97.5 1.375 0.753 NA NA #>  #> $Item_2 #>            a1      d  g  u #> par     1.160 -0.564  0  1 #> CI_2.5  0.883 -0.785 NA NA #> CI_97.5 1.436 -0.342 NA NA #>  #> $Item_3 #>            a1      d  g  u #> par     1.073 -0.272  0  1 #> CI_2.5  0.896 -0.408 NA NA #> CI_97.5 1.250 -0.137 NA NA #>  #> $Item_4 #>            a1     d  g  u #> par     0.871 0.895  0  1 #> CI_2.5  0.710 0.765 NA NA #> CI_97.5 1.031 1.026 NA NA #>  #> $Item_5 #>            a1     d  g  u #> par     1.089 0.160  0  1 #> CI_2.5  0.906 0.024 NA NA #> CI_97.5 1.272 0.295 NA NA #>  #> $Item_6 #>            a1     d  g  u #> par     0.374 0.596  0  1 #> CI_2.5  0.236 0.454 NA NA #> CI_97.5 0.512 0.738 NA NA #>  #> $Item_7 #>            a1     d  g  u #> par     1.090 0.942  0  1 #> CI_2.5  0.823 0.722 NA NA #> CI_97.5 1.357 1.163 NA NA #>  #> $Item_8 #>            a1      d  g  u #> par     0.988 -0.437  0  1 #> CI_2.5  0.747 -0.636 NA NA #> CI_97.5 1.228 -0.239 NA NA #>  #> $Item_9 #>            a1      d  g  u #> par     0.854 -1.018  0  1 #> CI_2.5  0.635 -1.219 NA NA #> CI_97.5 1.072 -0.817 NA NA #>  #> $Item_10 #>            a1      d  g  u #> par     0.657 -1.164  0  1 #> CI_2.5  0.469 -1.350 NA NA #> CI_97.5 0.845 -0.978 NA NA #>  #> $Item_11 #>            a1     d  g  u #> par     1.023 1.228  0  1 #> CI_2.5  0.766 1.003 NA NA #> CI_97.5 1.280 1.452 NA NA #>  #> $Item_12 #>            a1      d  g  u #> par     1.324 -0.207  0  1 #> CI_2.5  1.010 -0.442 NA NA #> CI_97.5 1.637  0.027 NA NA #>  #> $Item_13 #>            a1     d  g  u #> par     1.212 0.399  0  1 #> CI_2.5  0.923 0.178 NA NA #> CI_97.5 1.502 0.620 NA NA #>  #> $Item_14 #>            a1     d  g  u #> par     1.000 0.449  0  1 #> CI_2.5  0.785 0.294 NA NA #> CI_97.5 1.215 0.603 NA NA #>  #> $Item_15 #>            a1      d  g  u #> par     0.852 -0.061  0  1 #> CI_2.5  0.655 -0.205 NA NA #> CI_97.5 1.049  0.083 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par      0.008  1.658 #> CI_2.5  -0.148  1.093 #> CI_97.5  0.164  2.222 #>  #>  coef(mod_anchor, printSE=TRUE) #> $D1 #> $Item_1 #>        a1     d logit(g) logit(u) #> par 1.108 0.542     -999      999 #> SE  0.136 0.108       NA       NA #>  #> $Item_2 #>        a1      d logit(g) logit(u) #> par 1.160 -0.564     -999      999 #> SE  0.141  0.113       NA       NA #>  #> $Item_3 #>        a1      d logit(g) logit(u) #> par 1.073 -0.272     -999      999 #> SE  0.090  0.069       NA       NA #>  #> $Item_4 #>        a1     d logit(g) logit(u) #> par 0.871 0.895     -999      999 #> SE  0.082 0.066       NA       NA #>  #> $Item_5 #>        a1     d logit(g) logit(u) #> par 1.089 0.160     -999      999 #> SE  0.093 0.069       NA       NA #>  #> $Item_6 #>        a1     d logit(g) logit(u) #> par 0.582 0.685     -999      999 #> SE  0.091 0.073       NA       NA #>  #> $Item_7 #>        a1     d logit(g) logit(u) #> par 1.292 1.009     -999      999 #> SE  0.135 0.097       NA       NA #>  #> $Item_8 #>        a1      d logit(g) logit(u) #> par 0.906 -0.328     -999      999 #> SE  0.104  0.076       NA       NA #>  #> $Item_9 #>        a1      d logit(g) logit(u) #> par 0.855 -1.049     -999      999 #> SE  0.109  0.085       NA       NA #>  #> $Item_10 #>        a1      d logit(g) logit(u) #> par 0.746 -1.089     -999      999 #> SE  0.104  0.083       NA       NA #>  #> $Item_11 #>        a1     d logit(g) logit(u) #> par 0.866 1.200     -999      999 #> SE  0.110 0.089       NA       NA #>  #> $Item_12 #>        a1      d logit(g) logit(u) #> par 1.432 -0.247     -999      999 #> SE  0.143  0.089       NA       NA #>  #> $Item_13 #>        a1     d logit(g) logit(u) #> par 1.244 0.440     -999      999 #> SE  0.127 0.085       NA       NA #>  #> $Item_14 #>       a1     d logit(g) logit(u) #> par 1.00 0.449     -999      999 #> SE  0.11 0.079       NA       NA #>  #> $Item_15 #>        a1      d logit(g) logit(u) #> par 0.852 -0.061     -999      999 #> SE  0.100  0.073       NA       NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par      0      1 #> SE      NA     NA #>  #>  #> $D2 #> $Item_1 #>        a1     d logit(g) logit(u) #> par 1.108 0.542     -999      999 #> SE  0.136 0.108       NA       NA #>  #> $Item_2 #>        a1      d logit(g) logit(u) #> par 1.160 -0.564     -999      999 #> SE  0.141  0.113       NA       NA #>  #> $Item_3 #>        a1      d logit(g) logit(u) #> par 1.073 -0.272     -999      999 #> SE  0.090  0.069       NA       NA #>  #> $Item_4 #>        a1     d logit(g) logit(u) #> par 0.871 0.895     -999      999 #> SE  0.082 0.066       NA       NA #>  #> $Item_5 #>        a1     d logit(g) logit(u) #> par 1.089 0.160     -999      999 #> SE  0.093 0.069       NA       NA #>  #> $Item_6 #>        a1     d logit(g) logit(u) #> par 0.374 0.596     -999      999 #> SE  0.071 0.073       NA       NA #>  #> $Item_7 #>        a1     d logit(g) logit(u) #> par 1.090 0.942     -999      999 #> SE  0.136 0.112       NA       NA #>  #> $Item_8 #>        a1      d logit(g) logit(u) #> par 0.988 -0.437     -999      999 #> SE  0.123  0.101       NA       NA #>  #> $Item_9 #>        a1      d logit(g) logit(u) #> par 0.854 -1.018     -999      999 #> SE  0.111  0.102       NA       NA #>  #> $Item_10 #>        a1      d logit(g) logit(u) #> par 0.657 -1.164     -999      999 #> SE  0.096  0.095       NA       NA #>  #> $Item_11 #>        a1     d logit(g) logit(u) #> par 1.023 1.228     -999      999 #> SE  0.131 0.114       NA       NA #>  #> $Item_12 #>        a1      d logit(g) logit(u) #> par 1.324 -0.207     -999      999 #> SE  0.160  0.120       NA       NA #>  #> $Item_13 #>        a1     d logit(g) logit(u) #> par 1.212 0.399     -999      999 #> SE  0.148 0.113       NA       NA #>  #> $Item_14 #>       a1     d logit(g) logit(u) #> par 1.00 0.449     -999      999 #> SE  0.11 0.079       NA       NA #>  #> $Item_15 #>        a1      d logit(g) logit(u) #> par 0.852 -0.061     -999      999 #> SE  0.100  0.073       NA       NA #>  #> $GroupPars #>     MEAN_1 COV_11 #> par  0.008  1.658 #> SE   0.080  0.288 #>  #>    ############# # DIF test for each item (using all other items as anchors) itemnames <- colnames(dat) refmodel <- multipleGroup(dat, 1, group = group, SE=TRUE,                           invariance=c('free_means', 'free_var', itemnames)) #>  #>  #> Calculating information matrix...  # loop over items (in practice, run in parallel to increase speed). May be better to use ?DIF estmodels <- vector('list', ncol(dat)) for(i in 1:ncol(dat))     estmodels[[i]] <- multipleGroup(dat, 1, group = group, verbose = FALSE,                              invariance=c('free_means', 'free_var', itemnames[-i])) anova(refmodel, estmodels[[1]]) #>                     AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel       35894.66 35972.22 35960.47 36073.89 -17915.33                #> estmodels[[1]] 35898.45 35980.86 35968.37 36088.88 -17915.22 0.213  2 0.899 (anovas <- lapply(estmodels, function(x, refmodel) anova(refmodel, x),    refmodel=refmodel)) #> [[1]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35898.45 35980.86 35968.37 36088.88 -17915.22 0.213  2 0.899 #>  #> [[2]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.81 35979.22 35966.73 36087.24 -17914.41 1.847  2 0.397 #>  #> [[3]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35893.66 35976.07 35963.58 36084.09 -17912.83 5.001  2 0.082 #>  #> [[4]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35897.07 35979.48 35967.00 36087.50 -17914.54 1.586  2 0.453 #>  #> [[5]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35897.97 35980.38 35967.89 36088.40 -17914.99 0.688  2 0.709 #>  #> [[6]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df    p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33               #> x        35894.87 35977.28 35964.79 36085.30 -17913.43 3.793  2 0.15 #>  #> [[7]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35897.53 35979.94 35967.45 36087.96 -17914.76 1.131  2 0.568 #>  #> [[8]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35897.20 35979.61 35967.12 36087.63 -17914.60 1.462  2 0.481 #>  #> [[9]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35898.46 35980.87 35968.38 36088.89 -17915.23 0.197  2 0.906 #>  #> [[10]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35897.67 35980.08 35967.59 36088.10 -17914.83 0.993  2 0.609 #>  #> [[11]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.07 35978.48 35965.99 36086.50 -17914.03 2.593  2 0.273 #>  #> [[12]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35897.57 35979.98 35967.49 36088.00 -17914.78 1.092  2 0.579 #>  #> [[13]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35898.47 35980.88 35968.39 36088.90 -17915.23 0.192  2 0.908 #>  #> [[14]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.15 35978.57 35966.08 36086.58 -17914.08 2.505  2 0.286 #>  #> [[15]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.96 35979.37 35966.88 36087.39 -17914.48 1.699  2 0.428 #>   # family-wise error control p <- do.call(rbind, lapply(anovas, function(x) x[2, 'p'])) p.adjust(p, method = 'BH') #>  [1] 0.9084069 0.8299980 0.8299980 0.8299980 0.8862364 0.8299980 0.8299980 #>  [8] 0.8299980 0.9084069 0.8299980 0.8299980 0.8299980 0.9084069 0.8299980 #> [15] 0.8299980  # same as above, except only test if slopes vary (1 df) # constrain all intercepts estmodels <- vector('list', ncol(dat)) for(i in 1:ncol(dat))     estmodels[[i]] <- multipleGroup(dat, 1, group = group, verbose = FALSE,                              invariance=c('free_means', 'free_var', 'intercepts',                              itemnames[-i]))  (anovas <- lapply(estmodels, function(x, refmodel) anova(refmodel, x),    refmodel=refmodel)) #> [[1]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.52 35976.50 35964.38 36081.35 -17915.26 0.143  1 0.705 #>  #> [[2]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.60 35976.58 35964.46 36081.43 -17915.30 0.061  1 0.804 #>  #> [[3]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35894.66 35974.65 35962.53 36079.49 -17914.33 1.997  1 0.158 #>  #> [[4]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.39 35976.38 35964.26 36081.22 -17915.20 0.268  1 0.605 #>  #> [[5]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.56 35976.54 35964.42 36081.39 -17915.28 0.103  1 0.748 #>  #> [[6]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35893.62 35973.60 35961.48 36078.45 -17913.81 3.042  1 0.081 #>  #> [[7]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35895.67 35975.66 35963.54 36080.50 -17914.84 0.985  1 0.321 #>  #> [[8]] #>               AIC    SABIC       HQ      BIC    logLik   X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33               #> x        35896.27 35976.26 35964.13 36081.10 -17915.13 0.39  1 0.532 #>  #> [[9]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.66 35976.64 35964.52 36081.49 -17915.33 0.001  1 0.979 #>  #> [[10]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35896.12 35976.11 35963.99 36080.95 -17915.06 0.538  1 0.463 #>  #> [[11]] #>               AIC    SABIC       HQ      BIC    logLik   X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33               #> x        35894.22 35974.21 35962.08 36079.05 -17914.11 2.44  1 0.118 #>  #> [[12]] #>               AIC    SABIC       HQ      BIC    logLik   X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33               #> x        35895.87 35975.86 35963.74 36080.70 -17914.94 0.79  1 0.374 #>  #> [[13]] #>               AIC    SABIC       HQ      BIC    logLik   X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33               #> x        35896.58 35976.57 35964.44 36081.41 -17915.29 0.08  1 0.778 #>  #> [[14]] #>               AIC    SABIC       HQ      BIC    logLik  X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33              #> x        35894.16 35974.15 35962.02 36078.99 -17914.08 2.5  1 0.114 #>  #> [[15]] #>               AIC    SABIC       HQ      BIC    logLik    X2 df     p #> refmodel 35894.66 35972.22 35960.47 36073.89 -17915.33                #> x        35894.99 35974.97 35962.85 36079.82 -17914.49 1.672  1 0.196 #>   # quickly test with Wald test using DIF() mod_configural2 <- multipleGroup(dat, 1, group = group, SE=TRUE) #>  #>  #> Calculating information matrix... DIF(mod_configural2, which.par = c('a1', 'd'), Wald=TRUE, p.adjust = 'fdr') #> NOTE: No hyper-parameters were estimated in the DIF model.  #>       For effective DIF testing, freeing the focal group hyper-parameters is recommended. #>         groups      W df     p adj_p #> Item_1   D1,D2  4.636  2 0.098 0.246 #> Item_2   D1,D2  7.265  2 0.026 0.099 #> Item_3   D1,D2 10.375  2 0.006 0.055 #> Item_4   D1,D2  3.210  2 0.201 0.335 #> Item_5   D1,D2  3.618  2 0.164 0.307 #> Item_6   D1,D2  0.820  2 0.664 0.804 #> Item_7   D1,D2  0.575  2  0.75 0.804 #> Item_8   D1,D2  5.782  2 0.056 0.167 #> Item_9   D1,D2  3.802  2 0.149 0.307 #> Item_10  D1,D2  0.722  2 0.697 0.804 #> Item_11  D1,D2  8.922  2 0.012 0.058 #> Item_12  D1,D2  2.340  2  0.31 0.463 #> Item_13  D1,D2  2.162  2 0.339 0.463 #> Item_14  D1,D2  9.848  2 0.007 0.055 #> Item_15  D1,D2  0.204  2 0.903 0.903    ############# # Three group model where the latent variable parameters are constrained to # be equal in the focal groups  set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dataset3 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2, dataset3) group <- rep(c('D1', 'D2', 'D3'), each=N)  # marginal information itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  3000             7.89          3.567  0.19 0.054 0.779     1.676 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  3000 2 0.605 0.489   0.525         0.415       0.764 #> Item_2  3000 2 0.403 0.491   0.563         0.458       0.761 #> Item_3  3000 2 0.457 0.498   0.504         0.388       0.767 #> Item_4  3000 2 0.676 0.468   0.458         0.345       0.770 #> Item_5  3000 2 0.545 0.498   0.539         0.429       0.763 #> Item_6  3000 2 0.645 0.478   0.334         0.207       0.782 #> Item_7  3000 2 0.688 0.464   0.529         0.426       0.764 #> Item_8  3000 2 0.427 0.495   0.498         0.382       0.767 #> Item_9  3000 2 0.292 0.455   0.454         0.344       0.770 #> Item_10 3000 2 0.284 0.451   0.393         0.279       0.775 #> Item_11 3000 2 0.738 0.440   0.451         0.345       0.770 #> Item_12 3000 2 0.460 0.499   0.598         0.496       0.757 #> Item_13 3000 2 0.591 0.492   0.556         0.449       0.761 #> Item_14 3000 2 0.591 0.492   0.548         0.441       0.762 #> Item_15 3000 2 0.488 0.500   0.452         0.330       0.772 #>  #> $proportions #>             0     1 #> Item_1  0.395 0.605 #> Item_2  0.597 0.403 #> Item_3  0.543 0.457 #> Item_4  0.324 0.676 #> Item_5  0.455 0.545 #> Item_6  0.355 0.645 #> Item_7  0.312 0.688 #> Item_8  0.573 0.427 #> Item_9  0.708 0.292 #> Item_10 0.716 0.284 #> Item_11 0.262 0.738 #> Item_12 0.540 0.460 #> Item_13 0.409 0.591 #> Item_14 0.409 0.591 #> Item_15 0.512 0.488 #>   # conditional information itemstats(dat, group=group) #> $D1 #> $D1$overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000             7.82          3.346 0.159 0.047  0.74     1.705 #>  #> $D1$itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  1000 2 0.605 0.489   0.484         0.361       0.725 #> Item_2  1000 2 0.368 0.483   0.507         0.388       0.722 #> Item_3  1000 2 0.461 0.499   0.471         0.343       0.727 #> Item_4  1000 2 0.673 0.469   0.439         0.315       0.729 #> Item_5  1000 2 0.526 0.500   0.500         0.376       0.723 #> Item_6  1000 2 0.654 0.476   0.355         0.222       0.739 #> Item_7  1000 2 0.683 0.466   0.508         0.394       0.722 #> Item_8  1000 2 0.431 0.495   0.462         0.333       0.728 #> Item_9  1000 2 0.287 0.453   0.419         0.298       0.731 #> Item_10 1000 2 0.274 0.446   0.372         0.249       0.735 #> Item_11 1000 2 0.739 0.439   0.401         0.282       0.732 #> Item_12 1000 2 0.456 0.498   0.563         0.448       0.715 #> Item_13 1000 2 0.584 0.493   0.535         0.416       0.719 #> Item_14 1000 2 0.592 0.492   0.483         0.358       0.725 #> Item_15 1000 2 0.487 0.500   0.451         0.321       0.729 #>  #> $D1$proportions #>             0     1 #> Item_1  0.395 0.605 #> Item_2  0.632 0.368 #> Item_3  0.539 0.461 #> Item_4  0.327 0.673 #> Item_5  0.474 0.526 #> Item_6  0.346 0.654 #> Item_7  0.317 0.683 #> Item_8  0.569 0.431 #> Item_9  0.713 0.287 #> Item_10 0.726 0.274 #> Item_11 0.261 0.739 #> Item_12 0.544 0.456 #> Item_13 0.416 0.584 #> Item_14 0.408 0.592 #> Item_15 0.513 0.487 #>  #>  #> $D2 #> $D2$overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            7.955          3.754 0.217 0.065 0.807      1.65 #>  #> $D2$itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  1000 2 0.612 0.488   0.563         0.464       0.792 #> Item_2  1000 2 0.417 0.493   0.569         0.469       0.792 #> Item_3  1000 2 0.450 0.498   0.578         0.479       0.791 #> Item_4  1000 2 0.695 0.461   0.484         0.381       0.798 #> Item_5  1000 2 0.551 0.498   0.553         0.451       0.793 #> Item_6  1000 2 0.644 0.479   0.316         0.195       0.811 #> Item_7  1000 2 0.680 0.467   0.540         0.443       0.794 #> Item_8  1000 2 0.432 0.496   0.544         0.440       0.794 #> Item_9  1000 2 0.317 0.466   0.470         0.365       0.799 #> Item_10 1000 2 0.275 0.447   0.403         0.297       0.804 #> Item_11 1000 2 0.729 0.445   0.508         0.413       0.796 #> Item_12 1000 2 0.483 0.500   0.606         0.511       0.788 #> Item_13 1000 2 0.585 0.493   0.587         0.491       0.790 #> Item_14 1000 2 0.591 0.492   0.589         0.493       0.790 #> Item_15 1000 2 0.494 0.500   0.466         0.351       0.801 #>  #> $D2$proportions #>             0     1 #> Item_1  0.388 0.612 #> Item_2  0.583 0.417 #> Item_3  0.550 0.450 #> Item_4  0.305 0.695 #> Item_5  0.449 0.551 #> Item_6  0.356 0.644 #> Item_7  0.320 0.680 #> Item_8  0.568 0.432 #> Item_9  0.683 0.317 #> Item_10 0.725 0.275 #> Item_11 0.271 0.729 #> Item_12 0.517 0.483 #> Item_13 0.415 0.585 #> Item_14 0.409 0.591 #> Item_15 0.506 0.494 #>  #>  #> $D3 #> $D3$overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            7.894          3.592 0.194 0.064 0.783     1.672 #>  #> $D3$itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  1000 2 0.599 0.490   0.526         0.416       0.769 #> Item_2  1000 2 0.424 0.494   0.610         0.512       0.761 #> Item_3  1000 2 0.459 0.499   0.460         0.340       0.776 #> Item_4  1000 2 0.659 0.474   0.452         0.338       0.775 #> Item_5  1000 2 0.557 0.497   0.562         0.456       0.766 #> Item_6  1000 2 0.638 0.481   0.334         0.208       0.786 #> Item_7  1000 2 0.700 0.458   0.539         0.439       0.767 #> Item_8  1000 2 0.419 0.494   0.485         0.369       0.773 #> Item_9  1000 2 0.272 0.445   0.470         0.365       0.773 #> Item_10 1000 2 0.303 0.460   0.405         0.290       0.779 #> Item_11 1000 2 0.747 0.435   0.438         0.333       0.776 #> Item_12 1000 2 0.442 0.497   0.622         0.526       0.759 #> Item_13 1000 2 0.604 0.489   0.545         0.438       0.767 #> Item_14 1000 2 0.589 0.492   0.569         0.465       0.765 #> Item_15 1000 2 0.482 0.500   0.439         0.317       0.778 #>  #> $D3$proportions #>             0     1 #> Item_1  0.401 0.599 #> Item_2  0.576 0.424 #> Item_3  0.541 0.459 #> Item_4  0.341 0.659 #> Item_5  0.443 0.557 #> Item_6  0.362 0.638 #> Item_7  0.300 0.700 #> Item_8  0.581 0.419 #> Item_9  0.728 0.272 #> Item_10 0.697 0.303 #> Item_11 0.253 0.747 #> Item_12 0.558 0.442 #> Item_13 0.396 0.604 #> Item_14 0.411 0.589 #> Item_15 0.518 0.482 #>  #>   model <- 'F1 = 1-15           FREE[D2, D3] = (GROUP, MEAN_1), (GROUP, COV_11)           CONSTRAINB[D2,D3] = (GROUP, MEAN_1), (GROUP, COV_11)'  mod <- multipleGroup(dat, model, group = group, invariance = colnames(dat)) #>  coef(mod, simplify=TRUE) #> $D1 #> $items #>            a1      d g u #> Item_1  1.089  0.517 0 1 #> Item_2  1.302 -0.601 0 1 #> Item_3  0.950 -0.251 0 1 #> Item_4  0.857  0.847 0 1 #> Item_5  1.119  0.195 0 1 #> Item_6  0.447  0.618 0 1 #> Item_7  1.209  1.023 0 1 #> Item_8  0.939 -0.396 0 1 #> Item_9  0.909 -1.110 0 1 #> Item_10 0.695 -1.073 0 1 #> Item_11 0.929  1.232 0 1 #> Item_12 1.454 -0.290 0 1 #> Item_13 1.216  0.457 0 1 #> Item_14 1.199  0.453 0 1 #> Item_15 0.751 -0.085 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $D2 #> $items #>            a1      d g u #> Item_1  1.089  0.517 0 1 #> Item_2  1.302 -0.601 0 1 #> Item_3  0.950 -0.251 0 1 #> Item_4  0.857  0.847 0 1 #> Item_5  1.119  0.195 0 1 #> Item_6  0.447  0.618 0 1 #> Item_7  1.209  1.023 0 1 #> Item_8  0.939 -0.396 0 1 #> Item_9  0.909 -1.110 0 1 #> Item_10 0.695 -1.073 0 1 #> Item_11 0.929  1.232 0 1 #> Item_12 1.454 -0.290 0 1 #> Item_13 1.216  0.457 0 1 #> Item_14 1.199  0.453 0 1 #> Item_15 0.751 -0.085 0 1 #>  #> $means #>    F1  #> 0.055  #>  #> $cov #>       F1 #> F1 1.467 #>  #>  #> $D3 #> $items #>            a1      d g u #> Item_1  1.089  0.517 0 1 #> Item_2  1.302 -0.601 0 1 #> Item_3  0.950 -0.251 0 1 #> Item_4  0.857  0.847 0 1 #> Item_5  1.119  0.195 0 1 #> Item_6  0.447  0.618 0 1 #> Item_7  1.209  1.023 0 1 #> Item_8  0.939 -0.396 0 1 #> Item_9  0.909 -1.110 0 1 #> Item_10 0.695 -1.073 0 1 #> Item_11 0.929  1.232 0 1 #> Item_12 1.454 -0.290 0 1 #> Item_13 1.216  0.457 0 1 #> Item_14 1.199  0.453 0 1 #> Item_15 0.751 -0.085 0 1 #>  #> $means #>    F1  #> 0.055  #>  #> $cov #>       F1 #> F1 1.467 #>  #>   ############# # Testing main effects in multiple independent grouping variables set.seed(1234) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 500  # generated data have interaction effect for latent means, as well as a # main effect across D but no main effect across G d11 <- simdata(a, d, N, itemtype, mu = 0) d12 <- simdata(a, d, N, itemtype, mu = 0) d13 <- simdata(a, d, N, itemtype, mu = 0) d21 <- simdata(a, d, N, itemtype, mu = 1/2) d22 <- simdata(a, d, N, itemtype, mu = 1/2) d23 <- simdata(a, d, N, itemtype, mu = -1) dat <- do.call(rbind, list(d11, d12, d13, d21, d22, d23)) group <- rep(c('G1.D1', 'G1.D2', 'G1.D3', 'G2.D1', 'G2.D2', 'G2.D3'), each=N) table(group) #> group #> G1.D1 G1.D2 G1.D3 G2.D1 G2.D2 G2.D3  #>   500   500   500   500   500   500   if (FALSE) { # \\dontrun{ # in practice, group would be organized in a data.frame as follows df <- data.frame(group) dfw <- tidyr::separate_wider_delim(df, group, delim='.', names = c('G', 'D')) head(dfw)  # for use with multipleGroup() combine into a single long group group <- with(dfw, factor(G):factor(D))  # conditional information itemstats(dat, group=group)  mod <- multipleGroup(dat, group = group, SE=TRUE,                      invariance = c(colnames(dat), 'free_mean', 'free_var')) coef(mod, simplify=TRUE) sapply(coef(mod, simplify=TRUE), \\(x) unname(x$means)) # mean estimates wald(mod) # view parameter names for later testing  # test for main effect over G group (manually compute marginal mean) wald(mod, \"0 + MEAN_1.123 + MEAN_1.185 = MEAN_1.247 + MEAN_1.309 + MEAN_1.371\")  # test for main effect over D group  (manually compute marginal means) wald(mod, c(\"0 + MEAN_1.247 = MEAN_1.123 + MEAN_1.309\",             \"0 + MEAN_1.247 = MEAN_1.185 + MEAN_1.371\"))  # post-hoc tests (better practice would include p.adjust() ) wald(mod, \"0 + MEAN_1.247 = MEAN_1.123 + MEAN_1.309\") # D1 vs D2 wald(mod, \"0 + MEAN_1.247 = MEAN_1.185 + MEAN_1.371\") # D1 vs D3 wald(mod, \"MEAN_1.123 + MEAN_1.309 = MEAN_1.185 + MEAN_1.371\") # D2 vs D3 } # }  ############# # multiple factors  a <- matrix(c(abs(rnorm(5,1,.3)), rep(0,15),abs(rnorm(5,1,.3)),      rep(0,15),abs(rnorm(5,1,.3))), 15, 3) d <- matrix(rnorm(15,0,.7),ncol=1) mu <- c(-.4, -.7, .1) sigma <- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3) itemtype <- rep('2PL', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = mu, sigma = sigma) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N))  # group models model <- '    F1 = 1-5    F2 = 6-10    F3 = 11-15'  # define mirt cluster to use parallel architecture if(interactive()) mirtCluster()  # EM approach (not as accurate with 3 factors, but generally good for quick model comparisons) mod_configural <- multipleGroup(dat, model, group = group) #completely separate analyses #>  mod_metric <- multipleGroup(dat, model, group = group, invariance=c('slopes')) #equal slopes #>  mod_fullconstrain <- multipleGroup(dat, model, group = group, #equal means, slopes, intercepts                              invariance=c('slopes', 'intercepts')) #>   anova(mod_metric, mod_configural) #>                     AIC    SABIC       HQ      BIC    logLik     X2 df     p #> mod_metric     36921.29 37030.37 37013.84 37173.33 -18415.65                 #> mod_configural 36916.10 37061.53 37039.49 37252.15 -18398.05 35.197 15 0.002 anova(mod_fullconstrain, mod_metric) #>                        AIC    SABIC       HQ      BIC    logLik      X2 df p #> mod_fullconstrain 37020.58 37093.29 37082.27 37188.60 -18480.29              #> mod_metric        36921.29 37030.37 37013.84 37173.33 -18415.65 129.284 15 0  # same as above, but with MHRM (generally  more accurate with 3+ factors, but slower) mod_configural <- multipleGroup(dat, model, group = group, method = 'MHRM') #> , Max-Change = 0.0590, Max-Change = 0.0510, Max-Change = 0.0521, Max-Change = 0.0448, Max-Change = 0.0452, Max-Change = 0.0585, Max-Change = 0.0515, Max-Change = 0.0410, Max-Change = 0.0450, Max-Change = 0.0403, Max-Change = 0.0433, Max-Change = 0.0520, Max-Change = 0.0391, Max-Change = 0.0444, Max-Change = 0.0611, Max-Change = 0.0418, Max-Change = 0.0514, Max-Change = 0.0568, Max-Change = 0.0286, Max-Change = 0.0359, Max-Change = 0.0247, Max-Change = 0.0433, Max-Change = 0.0549, Max-Change = 0.0384, Max-Change = 0.0468, Max-Change = 0.0443, Max-Change = 0.0343, Max-Change = 0.0363, Max-Change = 0.0315, Max-Change = 0.0449, Max-Change = 0.0334, Max-Change = 0.0500, Max-Change = 0.0348, Max-Change = 0.0351, Max-Change = 0.0404, Max-Change = 0.0712, Max-Change = 0.0320, Max-Change = 0.0251, Max-Change = 0.0268, Max-Change = 0.0331, Max-Change = 0.0369, Max-Change = 0.0361, Max-Change = 0.0252, Max-Change = 0.0319, Max-Change = 0.0311, Max-Change = 0.0443, Max-Change = 0.0405, Max-Change = 0.0283, Max-Change = 0.0392, Max-Change = 0.0315, Max-Change = 0.0536, Max-Change = 0.0339, Max-Change = 0.0258, Max-Change = 0.0350, Max-Change = 0.0428, Max-Change = 0.0349, Max-Change = 0.0378, Max-Change = 0.0539, Max-Change = 0.0303, Max-Change = 0.0469, Max-Change = 0.0424, Max-Change = 0.0275, Max-Change = 0.0502, Max-Change = 0.0449, Max-Change = 0.0378, Max-Change = 0.0307, Max-Change = 0.0340, Max-Change = 0.0370, Max-Change = 0.0527, Max-Change = 0.0222, Max-Change = 0.0256, Max-Change = 0.0322, Max-Change = 0.0393, Max-Change = 0.0343, Max-Change = 0.0384, Max-Change = 0.0348, Max-Change = 0.0321, Max-Change = 0.0297, Max-Change = 0.0377, Max-Change = 0.0313, Max-Change = 0.0272, Max-Change = 0.0264, Max-Change = 0.0357, Max-Change = 0.0336, Max-Change = 0.0355, Max-Change = 0.0304, Max-Change = 0.0452, Max-Change = 0.0284, Max-Change = 0.0211, Max-Change = 0.0450, Max-Change = 0.0394, Max-Change = 0.0357, Max-Change = 0.0273, Max-Change = 0.0615, Max-Change = 0.0300, Max-Change = 0.0333, Max-Change = 0.0246, Max-Change = 0.0344, Max-Change = 0.0406, Max-Change = 0.0265, Max-Change = 0.0389, Max-Change = 0.0379, Max-Change = 0.0637, Max-Change = 0.0312, Max-Change = 0.0208, Max-Change = 0.0273, Max-Change = 0.0217, Max-Change = 0.0340, Max-Change = 0.0473, Max-Change = 0.0318, Max-Change = 0.0316, Max-Change = 0.0378, Max-Change = 0.0282, Max-Change = 0.0386, Max-Change = 0.0447, Max-Change = 0.0300, Max-Change = 0.0565, Max-Change = 0.0259, Max-Change = 0.0267, Max-Change = 0.0397, Max-Change = 0.0238, Max-Change = 0.0390, Max-Change = 0.0650, Max-Change = 0.0314, Max-Change = 0.0328, Max-Change = 0.0262, Max-Change = 0.0410, Max-Change = 0.0427, Max-Change = 0.0381, Max-Change = 0.0445, Max-Change = 0.0469, Max-Change = 0.0374, Max-Change = 0.0410, Max-Change = 0.0329, Max-Change = 0.0330, Max-Change = 0.0277, Max-Change = 0.0275, Max-Change = 0.0485, Max-Change = 0.0440, Max-Change = 0.0264, Max-Change = 0.0432, Max-Change = 0.0410, Max-Change = 0.0404, Max-Change = 0.0251, Max-Change = 0.0507, Max-Change = 0.0299, Max-Change = 0.0810, Max-Change = 0.0278, Max-Change = 0.0372, Max-Change = 0.0388, Max-Change = 0.0274, Max-Change = 0.0308, Max-Change = 0.0455, Max-Change = 0.0292, Max-Change = 0.0250, Max-Change = 0.0288, Max-Change = 0.0254, Max-Change = 0.0398, Max-Change = 0.0308, Max-Change = 0.0343, Max-Change = 0.0507, Max-Change = 0.0303, Max-Change = 0.0368, Max-Change = 0.0369, Max-Change = 0.0298, Max-Change = 0.0401, Max-Change = 0.0428, Max-Change = 0.0409, Max-Change = 0.0384, Max-Change = 0.0389, Max-Change = 0.0351, Max-Change = 0.0274, Max-Change = 0.0390, Max-Change = 0.0337, Max-Change = 0.0322, Max-Change = 0.0540, Max-Change = 0.0337, Max-Change = 0.0245, Max-Change = 0.0353, Max-Change = 0.0351, Max-Change = 0.0221, Max-Change = 0.0360, Max-Change = 0.0580, Max-Change = 0.0393, Max-Change = 0.0259, Max-Change = 0.0377, Max-Change = 0.0447, Max-Change = 0.0309, Max-Change = 0.0425, Max-Change = 0.0266, Max-Change = 0.0595, Max-Change = 0.0631, Max-Change = 0.0266, Max-Change = 0.0294, Max-Change = 0.0404, Max-Change = 0.0402, Max-Change = 0.0263, Max-Change = 0.0425, Max-Change = 0.0324, Max-Change = 0.0340, Max-Change = 0.0393, Max-Change = 0.0377, Max-Change = 0.0538, Max-Change = 0.0342, Max-Change = 0.0249, Max-Change = 0.0301, Max-Change = 0.0345, Max-Change = 0.0360, Max-Change = 0.0411, Max-Change = 0.0308, Max-Change = 0.0407, Max-Change = 0.0373, Max-Change = 0.0357, Max-Change = 0.0358, Max-Change = 0.0316, Max-Change = 0.0284, Max-Change = 0.0370, Max-Change = 0.0253, Max-Change = 0.0331, Max-Change = 0.0395, Max-Change = 0.0281, Max-Change = 0.0238, Max-Change = 0.0272, Max-Change = 0.0520, Max-Change = 0.0252, Max-Change = 0.0401, Max-Change = 0.0453, Max-Change = 0.0347, Max-Change = 0.0410, Max-Change = 0.0307, Max-Change = 0.0411, Max-Change = 0.0324, Max-Change = 0.0353, Max-Change = 0.0441, Max-Change = 0.0374, Max-Change = 0.0463, Max-Change = 0.0281, Max-Change = 0.0402, Max-Change = 0.0384, Max-Change = 0.0290, Max-Change = 0.0401, Max-Change = 0.0546, Max-Change = 0.0300, Max-Change = 0.0268, Max-Change = 0.0401, Max-Change = 0.0299, Max-Change = 0.0613, Max-Change = 0.0343, Max-Change = 0.0483, Max-Change = 0.0472, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0400, gam = 0.1057, Max-Change = 0.0314, gam = 0.0780, Max-Change = 0.0153, gam = 0.0629, Max-Change = 0.0105, gam = 0.0532, Max-Change = 0.0084, gam = 0.0464, Max-Change = 0.0134, gam = 0.0413, Max-Change = 0.0099, gam = 0.0374, Max-Change = 0.0098, gam = 0.0342, Max-Change = 0.0048, gam = 0.0316, Max-Change = 0.0057, gam = 0.0294, Max-Change = 0.0032, gam = 0.0276, Max-Change = 0.0048, gam = 0.0260, Max-Change = 0.0042, gam = 0.0246, Max-Change = 0.0069, gam = 0.0233, Max-Change = 0.0037, gam = 0.0222, Max-Change = 0.0044, gam = 0.0212, Max-Change = 0.0044, gam = 0.0203, Max-Change = 0.0036, gam = 0.0195, Max-Change = 0.0051, gam = 0.0188, Max-Change = 0.0048, gam = 0.0181, Max-Change = 0.0023, gam = 0.0175, Max-Change = 0.0043, gam = 0.0169, Max-Change = 0.0035, gam = 0.0164, Max-Change = 0.0032, gam = 0.0159, Max-Change = 0.0033, gam = 0.0154, Max-Change = 0.0018, gam = 0.0150, Max-Change = 0.0024, gam = 0.0146, Max-Change = 0.0026, gam = 0.0142, Max-Change = 0.0018, gam = 0.0139, Max-Change = 0.0024, gam = 0.0135, Max-Change = 0.0018, gam = 0.0132, Max-Change = 0.0035, gam = 0.0129, Max-Change = 0.0028, gam = 0.0126, Max-Change = 0.0016, gam = 0.0124, Max-Change = 0.0023, gam = 0.0121, Max-Change = 0.0022, gam = 0.0119, Max-Change = 0.0020, gam = 0.0116, Max-Change = 0.0035, gam = 0.0114, Max-Change = 0.0032, gam = 0.0112, Max-Change = 0.0020, gam = 0.0110, Max-Change = 0.0013, gam = 0.0108, Max-Change = 0.0013, gam = 0.0106, Max-Change = 0.0021, gam = 0.0104, Max-Change = 0.0018, gam = 0.0102, Max-Change = 0.0022, gam = 0.0101, Max-Change = 0.0025, gam = 0.0099, Max-Change = 0.0018, gam = 0.0098, Max-Change = 0.0014, gam = 0.0096, Max-Change = 0.0015, gam = 0.0095, Max-Change = 0.0013, gam = 0.0093, Max-Change = 0.0017, gam = 0.0092, Max-Change = 0.0015, gam = 0.0091, Max-Change = 0.0021, gam = 0.0089, Max-Change = 0.0019, gam = 0.0088, Max-Change = 0.0012, gam = 0.0087, Max-Change = 0.0019, gam = 0.0086, Max-Change = 0.0012, gam = 0.0085, Max-Change = 0.0013, gam = 0.0084, Max-Change = 0.0011, gam = 0.0082, Max-Change = 0.0015, gam = 0.0081, Max-Change = 0.0014, gam = 0.0080, Max-Change = 0.0015, gam = 0.0080, Max-Change = 0.0016, gam = 0.0079, Max-Change = 0.0015, gam = 0.0078, Max-Change = 0.0013, gam = 0.0077, Max-Change = 0.0016, gam = 0.0076, Max-Change = 0.0012, gam = 0.0075, Max-Change = 0.0007, gam = 0.0074, Max-Change = 0.0015, gam = 0.0073, Max-Change = 0.0010, gam = 0.0073, Max-Change = 0.0015, gam = 0.0072, Max-Change = 0.0013, gam = 0.0071, Max-Change = 0.0010, gam = 0.0070, Max-Change = 0.0018, gam = 0.0070, Max-Change = 0.0023, gam = 0.0069, Max-Change = 0.0015, gam = 0.0068, Max-Change = 0.0013, gam = 0.0068, Max-Change = 0.0008, gam = 0.0067, Max-Change = 0.0010, gam = 0.0066, Max-Change = 0.0022, gam = 0.0066, Max-Change = 0.0021, gam = 0.0065, Max-Change = 0.0016, gam = 0.0065, Max-Change = 0.0014, gam = 0.0064, Max-Change = 0.0012, gam = 0.0064, Max-Change = 0.0009, gam = 0.0063, Max-Change = 0.0012, gam = 0.0062, Max-Change = 0.0012, gam = 0.0062, Max-Change = 0.0012, gam = 0.0061, Max-Change = 0.0010, gam = 0.0061, Max-Change = 0.0008, gam = 0.0060, Max-Change = 0.0013, gam = 0.0060, Max-Change = 0.0010, gam = 0.0059, Max-Change = 0.0014, gam = 0.0059, Max-Change = 0.0012, gam = 0.0058, Max-Change = 0.0018, gam = 0.0058, Max-Change = 0.0006, gam = 0.0058, Max-Change = 0.0008, gam = 0.0057, Max-Change = 0.0011, gam = 0.0057, Max-Change = 0.0010, gam = 0.0056, Max-Change = 0.0010, gam = 0.0056, Max-Change = 0.0006 #>  #> Calculating log-likelihood... mod_metric <- multipleGroup(dat, model, group = group, invariance=c('slopes'), method = 'MHRM') #> , Max-Change = 0.0602, Max-Change = 0.0556, Max-Change = 0.0444, Max-Change = 0.0508, Max-Change = 0.0365, Max-Change = 0.0433, Max-Change = 0.0317, Max-Change = 0.0330, Max-Change = 0.0324, Max-Change = 0.0245, Max-Change = 0.0334, Max-Change = 0.0232, Max-Change = 0.0176, Max-Change = 0.0321, Max-Change = 0.0257, Max-Change = 0.0304, Max-Change = 0.0253, Max-Change = 0.0199, Max-Change = 0.0240, Max-Change = 0.0202, Max-Change = 0.0239, Max-Change = 0.0248, Max-Change = 0.0311, Max-Change = 0.0186, Max-Change = 0.0301, Max-Change = 0.0316, Max-Change = 0.0253, Max-Change = 0.0146, Max-Change = 0.0204, Max-Change = 0.0180, Max-Change = 0.0305, Max-Change = 0.0229, Max-Change = 0.0400, Max-Change = 0.0192, Max-Change = 0.0343, Max-Change = 0.0320, Max-Change = 0.0285, Max-Change = 0.0170, Max-Change = 0.0337, Max-Change = 0.0177, Max-Change = 0.0206, Max-Change = 0.0226, Max-Change = 0.0167, Max-Change = 0.0183, Max-Change = 0.0259, Max-Change = 0.0128, Max-Change = 0.0273, Max-Change = 0.0211, Max-Change = 0.0283, Max-Change = 0.0258, Max-Change = 0.0327, Max-Change = 0.0224, Max-Change = 0.0153, Max-Change = 0.0245, Max-Change = 0.0285, Max-Change = 0.0165, Max-Change = 0.0225, Max-Change = 0.0195, Max-Change = 0.0179, Max-Change = 0.0302, Max-Change = 0.0240, Max-Change = 0.0266, Max-Change = 0.0268, Max-Change = 0.0258, Max-Change = 0.0243, Max-Change = 0.0174, Max-Change = 0.0205, Max-Change = 0.0201, Max-Change = 0.0533, Max-Change = 0.0199, Max-Change = 0.0250, Max-Change = 0.0225, Max-Change = 0.0267, Max-Change = 0.0159, Max-Change = 0.0182, Max-Change = 0.0229, Max-Change = 0.0242, Max-Change = 0.0285, Max-Change = 0.0240, Max-Change = 0.0294, Max-Change = 0.0171, Max-Change = 0.0156, Max-Change = 0.0214, Max-Change = 0.0175, Max-Change = 0.0262, Max-Change = 0.0279, Max-Change = 0.0195, Max-Change = 0.0337, Max-Change = 0.0234, Max-Change = 0.0289, Max-Change = 0.0167, Max-Change = 0.0206, Max-Change = 0.0106, Max-Change = 0.0424, Max-Change = 0.0174, Max-Change = 0.0168, Max-Change = 0.0176, Max-Change = 0.0296, Max-Change = 0.0258, Max-Change = 0.0122, Max-Change = 0.0307, Max-Change = 0.0214, Max-Change = 0.0319, Max-Change = 0.0384, Max-Change = 0.0263, Max-Change = 0.0241, Max-Change = 0.0285, Max-Change = 0.0269, Max-Change = 0.0253, Max-Change = 0.0247, Max-Change = 0.0192, Max-Change = 0.0207, Max-Change = 0.0181, Max-Change = 0.0184, Max-Change = 0.0219, Max-Change = 0.0138, Max-Change = 0.0198, Max-Change = 0.0203, Max-Change = 0.0233, Max-Change = 0.0218, Max-Change = 0.0253, Max-Change = 0.0177, Max-Change = 0.0142, Max-Change = 0.0181, Max-Change = 0.0279, Max-Change = 0.0251, Max-Change = 0.0152, Max-Change = 0.0171, Max-Change = 0.0185, Max-Change = 0.0206, Max-Change = 0.0165, Max-Change = 0.0222, Max-Change = 0.0181, Max-Change = 0.0308, Max-Change = 0.0201, Max-Change = 0.0198, Max-Change = 0.0216, Max-Change = 0.0272, Max-Change = 0.0205, Max-Change = 0.0160, Max-Change = 0.0271, Max-Change = 0.0137, Max-Change = 0.0107, Max-Change = 0.0176, Max-Change = 0.0271, Max-Change = 0.0208, Max-Change = 0.0286, Max-Change = 0.0181, Max-Change = 0.0215, Max-Change = 0.0196, Max-Change = 0.0151, Max-Change = 0.0218, Max-Change = 0.0253, Max-Change = 0.0201, Max-Change = 0.0179, Max-Change = 0.0144, Max-Change = 0.0141, Max-Change = 0.0208, Max-Change = 0.0124, Max-Change = 0.0194, Max-Change = 0.0172, Max-Change = 0.0254, Max-Change = 0.0225, Max-Change = 0.0228, Max-Change = 0.0310, Max-Change = 0.0388, Max-Change = 0.0211, Max-Change = 0.0142, Max-Change = 0.0228, Max-Change = 0.0273, Max-Change = 0.0402, Max-Change = 0.0296, Max-Change = 0.0256, Max-Change = 0.0389, Max-Change = 0.0127, Max-Change = 0.0248, Max-Change = 0.0446, Max-Change = 0.0215, Max-Change = 0.0230, Max-Change = 0.0198, Max-Change = 0.0142, Max-Change = 0.0202, Max-Change = 0.0441, Max-Change = 0.0276, Max-Change = 0.0145, Max-Change = 0.0263, Max-Change = 0.0201, Max-Change = 0.0193, Max-Change = 0.0273, Max-Change = 0.0223, Max-Change = 0.0262, Max-Change = 0.0329, Max-Change = 0.0240, Max-Change = 0.0166, Max-Change = 0.0283, Max-Change = 0.0325, Max-Change = 0.0273, Max-Change = 0.0236, Max-Change = 0.0310, Max-Change = 0.0176, Max-Change = 0.0152, Max-Change = 0.0246, Max-Change = 0.0227, Max-Change = 0.0188, Max-Change = 0.0203, Max-Change = 0.0197, Max-Change = 0.0246, Max-Change = 0.0160, Max-Change = 0.0277, Max-Change = 0.0216, Max-Change = 0.0315, Max-Change = 0.0404, Max-Change = 0.0293, Max-Change = 0.0267, Max-Change = 0.0246, Max-Change = 0.0153, Max-Change = 0.0272, Max-Change = 0.0182, Max-Change = 0.0182, Max-Change = 0.0171, Max-Change = 0.0230, Max-Change = 0.0163, Max-Change = 0.0182, Max-Change = 0.0223, Max-Change = 0.0229, Max-Change = 0.0210, Max-Change = 0.0210, Max-Change = 0.0235, Max-Change = 0.0204, Max-Change = 0.0273, Max-Change = 0.0164, Max-Change = 0.0122, Max-Change = 0.0173, Max-Change = 0.0154, Max-Change = 0.0420, Max-Change = 0.0345, Max-Change = 0.0169, Max-Change = 0.0182, Max-Change = 0.0172, Max-Change = 0.0225, Max-Change = 0.0239, Max-Change = 0.0172, Max-Change = 0.0171, Max-Change = 0.0267, Max-Change = 0.0205, Max-Change = 0.0246, Max-Change = 0.0335, Max-Change = 0.0183, Max-Change = 0.0198, Max-Change = 0.0259, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0167, gam = 0.1057, Max-Change = 0.0103, gam = 0.0780, Max-Change = 0.0132, gam = 0.0629, Max-Change = 0.0049, gam = 0.0532, Max-Change = 0.0077, gam = 0.0464, Max-Change = 0.0073, gam = 0.0413, Max-Change = 0.0037, gam = 0.0374, Max-Change = 0.0040, gam = 0.0342, Max-Change = 0.0062, gam = 0.0316, Max-Change = 0.0037, gam = 0.0294, Max-Change = 0.0038, gam = 0.0276, Max-Change = 0.0025, gam = 0.0260, Max-Change = 0.0025, gam = 0.0246, Max-Change = 0.0033, gam = 0.0233, Max-Change = 0.0024, gam = 0.0222, Max-Change = 0.0026, gam = 0.0212, Max-Change = 0.0023, gam = 0.0203, Max-Change = 0.0022, gam = 0.0195, Max-Change = 0.0026, gam = 0.0188, Max-Change = 0.0019, gam = 0.0181, Max-Change = 0.0021, gam = 0.0175, Max-Change = 0.0022, gam = 0.0169, Max-Change = 0.0024, gam = 0.0164, Max-Change = 0.0026, gam = 0.0159, Max-Change = 0.0018, gam = 0.0154, Max-Change = 0.0014, gam = 0.0150, Max-Change = 0.0016, gam = 0.0146, Max-Change = 0.0019, gam = 0.0142, Max-Change = 0.0021, gam = 0.0139, Max-Change = 0.0015, gam = 0.0135, Max-Change = 0.0017, gam = 0.0132, Max-Change = 0.0011, gam = 0.0129, Max-Change = 0.0016, gam = 0.0126, Max-Change = 0.0019, gam = 0.0124, Max-Change = 0.0020, gam = 0.0121, Max-Change = 0.0012, gam = 0.0119, Max-Change = 0.0014, gam = 0.0116, Max-Change = 0.0010, gam = 0.0114, Max-Change = 0.0016, gam = 0.0112, Max-Change = 0.0013, gam = 0.0110, Max-Change = 0.0013, gam = 0.0108, Max-Change = 0.0011, gam = 0.0106, Max-Change = 0.0015, gam = 0.0104, Max-Change = 0.0018, gam = 0.0102, Max-Change = 0.0009, gam = 0.0101, Max-Change = 0.0017, gam = 0.0099, Max-Change = 0.0014, gam = 0.0098, Max-Change = 0.0008, gam = 0.0096, Max-Change = 0.0011, gam = 0.0095, Max-Change = 0.0010, gam = 0.0093, Max-Change = 0.0011, gam = 0.0092, Max-Change = 0.0010, gam = 0.0091, Max-Change = 0.0010, gam = 0.0089, Max-Change = 0.0012, gam = 0.0088, Max-Change = 0.0010, gam = 0.0087, Max-Change = 0.0012, gam = 0.0086, Max-Change = 0.0020, gam = 0.0085, Max-Change = 0.0013, gam = 0.0084, Max-Change = 0.0010, gam = 0.0082, Max-Change = 0.0009, gam = 0.0081, Max-Change = 0.0008, gam = 0.0080, Max-Change = 0.0010, gam = 0.0080, Max-Change = 0.0009, gam = 0.0079, Max-Change = 0.0017, gam = 0.0078, Max-Change = 0.0011, gam = 0.0077, Max-Change = 0.0011, gam = 0.0076, Max-Change = 0.0011, gam = 0.0075, Max-Change = 0.0007, gam = 0.0074, Max-Change = 0.0010, gam = 0.0073, Max-Change = 0.0005 #>  #> Calculating log-likelihood... mod_fullconstrain <- multipleGroup(dat, model, group = group, method = 'MHRM',                              invariance=c('slopes', 'intercepts')) #> , Max-Change = 0.0462, Max-Change = 0.0312, Max-Change = 0.0468, Max-Change = 0.0362, Max-Change = 0.0366, Max-Change = 0.0420, Max-Change = 0.0307, Max-Change = 0.0387, Max-Change = 0.0375, Max-Change = 0.0293, Max-Change = 0.0436, Max-Change = 0.0336, Max-Change = 0.0242, Max-Change = 0.0422, Max-Change = 0.0259, Max-Change = 0.0239, Max-Change = 0.0230, Max-Change = 0.0316, Max-Change = 0.0240, Max-Change = 0.0363, Max-Change = 0.0179, Max-Change = 0.0254, Max-Change = 0.0253, Max-Change = 0.0183, Max-Change = 0.0200, Max-Change = 0.0310, Max-Change = 0.0170, Max-Change = 0.0156, Max-Change = 0.0182, Max-Change = 0.0207, Max-Change = 0.0165, Max-Change = 0.0149, Max-Change = 0.0216, Max-Change = 0.0224, Max-Change = 0.0145, Max-Change = 0.0270, Max-Change = 0.0279, Max-Change = 0.0149, Max-Change = 0.0259, Max-Change = 0.0210, Max-Change = 0.0206, Max-Change = 0.0219, Max-Change = 0.0140, Max-Change = 0.0169, Max-Change = 0.0216, Max-Change = 0.0183, Max-Change = 0.0198, Max-Change = 0.0179, Max-Change = 0.0232, Max-Change = 0.0250, Max-Change = 0.0163, Max-Change = 0.0236, Max-Change = 0.0200, Max-Change = 0.0197, Max-Change = 0.0172, Max-Change = 0.0158, Max-Change = 0.0193, Max-Change = 0.0190, Max-Change = 0.0220, Max-Change = 0.0230, Max-Change = 0.0186, Max-Change = 0.0296, Max-Change = 0.0231, Max-Change = 0.0481, Max-Change = 0.0297, Max-Change = 0.0308, Max-Change = 0.0308, Max-Change = 0.0180, Max-Change = 0.0390, Max-Change = 0.0172, Max-Change = 0.0234, Max-Change = 0.0193, Max-Change = 0.0254, Max-Change = 0.0181, Max-Change = 0.0215, Max-Change = 0.0160, Max-Change = 0.0166, Max-Change = 0.0258, Max-Change = 0.0360, Max-Change = 0.0239, Max-Change = 0.0197, Max-Change = 0.0104, Max-Change = 0.0318, Max-Change = 0.0146, Max-Change = 0.0212, Max-Change = 0.0155, Max-Change = 0.0236, Max-Change = 0.0220, Max-Change = 0.0236, Max-Change = 0.0348, Max-Change = 0.0215, Max-Change = 0.0211, Max-Change = 0.0137, Max-Change = 0.0191, Max-Change = 0.0173, Max-Change = 0.0278, Max-Change = 0.0195, Max-Change = 0.0296, Max-Change = 0.0235, Max-Change = 0.0242, Max-Change = 0.0243, Max-Change = 0.0204, Max-Change = 0.0289, Max-Change = 0.0258, Max-Change = 0.0236, Max-Change = 0.0155, Max-Change = 0.0178, Max-Change = 0.0196, Max-Change = 0.0361, Max-Change = 0.0260, Max-Change = 0.0187, Max-Change = 0.0257, Max-Change = 0.0156, Max-Change = 0.0224, Max-Change = 0.0232, Max-Change = 0.0190, Max-Change = 0.0199, Max-Change = 0.0265, Max-Change = 0.0220, Max-Change = 0.0149, Max-Change = 0.0185, Max-Change = 0.0219, Max-Change = 0.0183, Max-Change = 0.0118, Max-Change = 0.0267, Max-Change = 0.0155, Max-Change = 0.0256, Max-Change = 0.0168, Max-Change = 0.0207, Max-Change = 0.0146, Max-Change = 0.0292, Max-Change = 0.0255, Max-Change = 0.0188, Max-Change = 0.0227, Max-Change = 0.0214, Max-Change = 0.0237, Max-Change = 0.0221, Max-Change = 0.0202, Max-Change = 0.0217, Max-Change = 0.0157, Max-Change = 0.0199, Max-Change = 0.0221, Max-Change = 0.0198, Max-Change = 0.0221, Max-Change = 0.0226, Max-Change = 0.0144, Max-Change = 0.0213, Max-Change = 0.0244, Max-Change = 0.0204, Max-Change = 0.0209, Max-Change = 0.0223, Max-Change = 0.0211, Max-Change = 0.0243, Max-Change = 0.0182, Max-Change = 0.0212, Max-Change = 0.0169, Max-Change = 0.0222, Max-Change = 0.0175, Max-Change = 0.0117, Max-Change = 0.0244, Max-Change = 0.0132, Max-Change = 0.0295, Max-Change = 0.0264, Max-Change = 0.0170, Max-Change = 0.0299, Max-Change = 0.0272, Max-Change = 0.0218, Max-Change = 0.0182, Max-Change = 0.0183, Max-Change = 0.0232, Max-Change = 0.0264, Max-Change = 0.0202, Max-Change = 0.0174, Max-Change = 0.0290, Max-Change = 0.0104, Max-Change = 0.0218, Max-Change = 0.0276, Max-Change = 0.0135, Max-Change = 0.0214, Max-Change = 0.0140, Max-Change = 0.0195, Max-Change = 0.0220, Max-Change = 0.0296, Max-Change = 0.0229, Max-Change = 0.0161, Max-Change = 0.0216, Max-Change = 0.0149, Max-Change = 0.0214, Max-Change = 0.0296, Max-Change = 0.0155, Max-Change = 0.0166, Max-Change = 0.0368, Max-Change = 0.0242, Max-Change = 0.0273, Max-Change = 0.0292, Max-Change = 0.0323, Max-Change = 0.0143, Max-Change = 0.0187, Max-Change = 0.0243, Max-Change = 0.0199, Max-Change = 0.0243, Max-Change = 0.0252, Max-Change = 0.0202, Max-Change = 0.0118, Max-Change = 0.0160, Max-Change = 0.0221, Max-Change = 0.0160, Max-Change = 0.0171, Max-Change = 0.0196, Max-Change = 0.0193, Max-Change = 0.0238, Max-Change = 0.0498, Max-Change = 0.0380, Max-Change = 0.0254, Max-Change = 0.0113, Max-Change = 0.0181, Max-Change = 0.0214, Max-Change = 0.0208, Max-Change = 0.0169, Max-Change = 0.0105, Max-Change = 0.0187, Max-Change = 0.0166, Max-Change = 0.0153, Max-Change = 0.0185, Max-Change = 0.0314, Max-Change = 0.0178, Max-Change = 0.0231, Max-Change = 0.0235, Max-Change = 0.0242, Max-Change = 0.0181, Max-Change = 0.0204, Max-Change = 0.0214, Max-Change = 0.0164, Max-Change = 0.0184, Max-Change = 0.0259, Max-Change = 0.0249, Max-Change = 0.0174, Max-Change = 0.0201, Max-Change = 0.0339, Max-Change = 0.0264, Max-Change = 0.0203, Max-Change = 0.0191, Max-Change = 0.0231, Max-Change = 0.0241, Max-Change = 0.0169, Max-Change = 0.0333, Max-Change = 0.0246, Max-Change = 0.0137, Max-Change = 0.0204, Max-Change = 0.0226, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0188, gam = 0.1057, Max-Change = 0.0174, gam = 0.0780, Max-Change = 0.0073, gam = 0.0629, Max-Change = 0.0064, gam = 0.0532, Max-Change = 0.0125, gam = 0.0464, Max-Change = 0.0108, gam = 0.0413, Max-Change = 0.0032, gam = 0.0374, Max-Change = 0.0022, gam = 0.0342, Max-Change = 0.0045, gam = 0.0316, Max-Change = 0.0034, gam = 0.0294, Max-Change = 0.0026, gam = 0.0276, Max-Change = 0.0029, gam = 0.0260, Max-Change = 0.0037, gam = 0.0246, Max-Change = 0.0041, gam = 0.0233, Max-Change = 0.0022, gam = 0.0222, Max-Change = 0.0022, gam = 0.0212, Max-Change = 0.0033, gam = 0.0203, Max-Change = 0.0025, gam = 0.0195, Max-Change = 0.0019, gam = 0.0188, Max-Change = 0.0019, gam = 0.0181, Max-Change = 0.0018, gam = 0.0175, Max-Change = 0.0018, gam = 0.0169, Max-Change = 0.0018, gam = 0.0164, Max-Change = 0.0015, gam = 0.0159, Max-Change = 0.0017, gam = 0.0154, Max-Change = 0.0014, gam = 0.0150, Max-Change = 0.0018, gam = 0.0146, Max-Change = 0.0022, gam = 0.0142, Max-Change = 0.0014, gam = 0.0139, Max-Change = 0.0019, gam = 0.0135, Max-Change = 0.0012, gam = 0.0132, Max-Change = 0.0011, gam = 0.0129, Max-Change = 0.0013, gam = 0.0126, Max-Change = 0.0012, gam = 0.0124, Max-Change = 0.0014, gam = 0.0121, Max-Change = 0.0011, gam = 0.0119, Max-Change = 0.0017, gam = 0.0116, Max-Change = 0.0015, gam = 0.0114, Max-Change = 0.0020, gam = 0.0112, Max-Change = 0.0012, gam = 0.0110, Max-Change = 0.0010, gam = 0.0108, Max-Change = 0.0011, gam = 0.0106, Max-Change = 0.0011, gam = 0.0104, Max-Change = 0.0016, gam = 0.0102, Max-Change = 0.0010, gam = 0.0101, Max-Change = 0.0010, gam = 0.0099, Max-Change = 0.0012, gam = 0.0098, Max-Change = 0.0008, gam = 0.0096, Max-Change = 0.0011, gam = 0.0095, Max-Change = 0.0010, gam = 0.0093, Max-Change = 0.0010, gam = 0.0092, Max-Change = 0.0011, gam = 0.0091, Max-Change = 0.0006, gam = 0.0089, Max-Change = 0.0013, gam = 0.0088, Max-Change = 0.0010, gam = 0.0087, Max-Change = 0.0008, gam = 0.0086, Max-Change = 0.0007, gam = 0.0085, Max-Change = 0.0009 #>  #> Calculating log-likelihood...  anova(mod_metric, mod_configural) #>                     AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod_metric     36927.79 37036.86 37020.33 37179.83 -18418.89             #> mod_configural 36918.04 37063.47 37041.43 37254.10 -18399.02 39.745 15 0 anova(mod_fullconstrain, mod_metric) #>                        AIC    SABIC       HQ      BIC    logLik     X2 df p #> mod_fullconstrain 37023.82 37096.54 37085.52 37191.85 -18481.91             #> mod_metric        36927.79 37036.86 37020.33 37179.83 -18418.89 126.04 15 0  ############ # polytomous item example set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) d <- cbind(d, d-1, d-2) itemtype <- rep('graded', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2) group <- c(rep('D1', N), rep('D2', N)) model <- 'F1 = 1-15'  mod_configural <- multipleGroup(dat, model, group = group) #>  plot(mod_configural)  plot(mod_configural, type = 'SE')  itemplot(mod_configural, 1)  itemplot(mod_configural, 1, type = 'info')  plot(mod_configural, type = 'trace') # messy, score function typically better  plot(mod_configural, type = 'itemscore')   fs <- fscores(mod_configural, full.scores = FALSE) #>  #> Method:  EAP #>  #> Empirical Reliability: #>  #>     F1  #> 0.7942  #>  #> Method:  EAP #>  #> Empirical Reliability: #>  #>     F1  #> 0.7249  head(fs[[\"D1\"]]) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]      0      0      0      0      0      0      0      0      0       0 #> [2,]      0      0      0      0      0      0      0      0      0       0 #> [3,]      0      0      0      0      0      0      0      0      0       0 #> [4,]      0      0      0      0      0      0      0      0      0       0 #> [5,]      0      0      0      0      0      0      0      0      0       0 #> [6,]      0      0      0      0      0      0      0      0      0       0 #>      Item_11 Item_12 Item_13 Item_14 Item_15     F1 SE_F1 #> [1,]       0       0       0       0       0 -2.137 0.626 #> [2,]       0       0       0       1       0 -1.786 0.574 #> [3,]       0       0       0       2       0 -1.727 0.580 #> [4,]       0       0       0       3       0 -1.689 0.586 #> [5,]       0       0       0       3       1 -1.439 0.554 #> [6,]       0       2       0       0       0 -1.583 0.566 fscores(mod_configural, method = 'EAPsum', full.scores = FALSE) #>       df     X2  p.X2 SEM.alpha rxx.alpha rxx_F1 #> stats 39 42.374 0.328     3.869     0.784  0.776 #>  #>       df     X2  p.X2 SEM.alpha rxx.alpha rxx_F1 #> stats 42 29.475 0.928     3.825     0.842  0.832 #>  #> $D1 #>    Sum.Scores     F1 SE_F1 observed expected std.res #> 0           0 -2.137 0.626        6    5.731   0.112 #> 1           1 -1.842 0.589        6   10.082   1.286 #> 2           2 -1.645 0.575       19   15.026   1.025 #> 3           3 -1.491 0.568       22   21.117   0.192 #> 4           4 -1.323 0.548       31   26.167   0.945 #> 5           5 -1.173 0.534       21   30.811   1.768 #> 6           6 -1.033 0.523       30   34.974   0.841 #> 7           7 -0.898 0.510       37   38.286   0.208 #> 8           8 -0.770 0.500       47   40.921   0.950 #> 9           9 -0.648 0.490       40   42.896   0.442 #> 10         10 -0.531 0.481       54   44.208   1.473 #> 11         11 -0.417 0.473       52   44.945   1.052 #> 12         12 -0.307 0.466       50   45.161   0.720 #> 13         13 -0.201 0.460       35   44.909   1.479 #> 14         14 -0.097 0.455       41   44.252   0.489 #> 15         15  0.005 0.450       33   43.244   1.558 #> 16         16  0.104 0.446       50   41.936   1.245 #> 17         17  0.202 0.443       38   40.375   0.374 #> 18         18  0.298 0.440       34   38.606   0.741 #> 19         19  0.394 0.437       40   36.668   0.550 #> 20         20  0.488 0.436       30   34.599   0.782 #> 21         21  0.582 0.435       42   32.431   1.680 #> 22         22  0.675 0.434       32   30.195   0.328 #> 23         23  0.768 0.434       28   27.920   0.015 #> 24         24  0.861 0.434       19   25.631   1.310 #> 25         25  0.954 0.435       34   23.350   2.204 #> 26         26  1.048 0.436       21   21.099   0.022 #> 27         27  1.142 0.438       18   18.899   0.207 #> 28         28  1.237 0.441       21   16.765   1.034 #> 29         29  1.334 0.444       10   14.717   1.229 #> 30         30  1.431 0.447       11   12.767   0.495 #> 31         31  1.530 0.451        8   10.931   0.887 #> 32         32  1.631 0.456        8    9.221   0.402 #> 33         33  1.733 0.461        8    7.648   0.127 #> 34         34  1.838 0.466        6    6.221   0.089 #> 35         35  1.946 0.472        1    4.949   1.775 #> 36         36  2.056 0.479        4    3.835   0.084 #> 37         37  2.169 0.486        6    2.881   1.838 #> 38         38  2.287 0.494        3    2.086   0.632 #> 39         39  2.409 0.503        3    1.445   1.293 #> 40         40  2.535 0.512        1    0.946   0.055 #> 41         41  2.668 0.522        0    0.580   0.761 #> 42         42  2.809 0.534        0    0.324   0.569 #> 43         43  2.955 0.544        0    0.158   0.397 #> 44         44  3.126 0.559        0    0.066   0.256 #> 45         45  3.345 0.584        0    0.019   0.137 #>  #> $D2 #>    Sum.Scores     F1 SE_F1 observed expected std.res #> 0           0 -2.051 0.591        9   11.036   0.613 #> 1           1 -1.750 0.548       23   16.140   1.708 #> 2           2 -1.554 0.530       22   20.995   0.219 #> 3           3 -1.412 0.524       31   27.050   0.759 #> 4           4 -1.240 0.493       35   30.434   0.828 #> 5           5 -1.095 0.475       33   33.197   0.034 #> 6           6 -0.964 0.460       34   35.476   0.248 #> 7           7 -0.836 0.444       32   36.880   0.804 #> 8           8 -0.718 0.431       32   37.812   0.945 #> 9           9 -0.607 0.419       31   38.353   1.187 #> 10         10 -0.501 0.409       28   38.516   1.695 #> 11         11 -0.400 0.400       46   38.404   1.226 #> 12         12 -0.303 0.393       41   38.063   0.476 #> 13         13 -0.210 0.386       36   37.526   0.249 #> 14         14 -0.119 0.381       33   36.830   0.631 #> 15         15 -0.031 0.376       37   36.003   0.166 #> 16         16  0.055 0.372       33   35.064   0.349 #> 17         17  0.140 0.369       33   34.032   0.177 #> 18         18  0.223 0.366       42   32.921   1.582 #> 19         19  0.305 0.364       28   31.744   0.665 #> 20         20  0.386 0.363       29   30.511   0.274 #> 21         21  0.466 0.362       30   29.230   0.142 #> 22         22  0.546 0.362       24   27.908   0.740 #> 23         23  0.626 0.362       28   26.553   0.281 #> 24         24  0.706 0.363       29   25.169   0.764 #> 25         25  0.787 0.364       27   23.761   0.664 #> 26         26  0.868 0.366       29   22.334   1.411 #> 27         27  0.950 0.369       19   20.892   0.414 #> 28         28  1.033 0.372       17   19.437   0.553 #> 29         29  1.117 0.376       13   17.975   1.174 #> 30         30  1.203 0.380       19   16.510   0.613 #> 31         31  1.291 0.385       17   15.044   0.504 #> 32         32  1.381 0.391       17   13.583   0.927 #> 33         33  1.473 0.398       16   12.135   1.109 #> 34         34  1.568 0.405       11   10.703   0.091 #> 35         35  1.667 0.414        8    9.299   0.426 #> 36         36  1.769 0.423       11    7.936   1.088 #> 37         37  1.874 0.433        3    6.617   1.406 #> 38         38  1.984 0.444        6    5.370   0.272 #> 39         39  2.101 0.457        4    4.219   0.107 #> 40         40  2.219 0.469        2    3.152   0.649 #> 41         41  2.344 0.482        2    2.236   0.158 #> 42         42  2.484 0.501        0    1.485   1.219 #> 43         43  2.612 0.511        0    0.842   0.918 #> 44         44  2.766 0.525        0    0.438   0.662 #> 45         45  2.988 0.555        0    0.185   0.431 #>   # constrain slopes within each group to be equal (but not across groups) model2 <- 'F1 = 1-15            CONSTRAIN = (1-15, a1)' mod_configural2 <- multipleGroup(dat, model2, group = group) #>  plot(mod_configural2, type = 'SE')  plot(mod_configural2, type = 'RE')  itemplot(mod_configural2, 10)   ############ ## empirical histogram example (normal and bimodal groups) set.seed(1234) a <- matrix(rlnorm(50, .2, .2)) d <- matrix(rnorm(50)) ThetaNormal <- matrix(rnorm(2000)) ThetaBimodal <- scale(matrix(c(rnorm(1000, -2), rnorm(1000,2)))) #bimodal Theta <- rbind(ThetaNormal, ThetaBimodal) dat <- simdata(a, d, 4000, itemtype = '2PL', Theta=Theta) group <- rep(c('G1', 'G2'), each=2000)  EH <- multipleGroup(dat, 1, group=group, dentype=\"empiricalhist\", invariance = colnames(dat)) #>  coef(EH, simplify=TRUE) #> $G1 #> $items #>            a1      d g u #> Item_1  0.759 -1.830 0 1 #> Item_2  1.062 -0.555 0 1 #> Item_3  1.235 -1.117 0 1 #> Item_4  0.611 -0.953 0 1 #> Item_5  1.088 -0.132 0 1 #> Item_6  1.054  0.502 0 1 #> Item_7  0.849  1.581 0 1 #> Item_8  0.870 -0.779 0 1 #> Item_9  0.902  1.658 0 1 #> Item_10 0.812 -1.188 0 1 #> Item_11 0.903  0.661 0 1 #> Item_12 0.841  2.646 0 1 #> Item_13 0.843 -0.064 0 1 #> Item_14 1.009 -0.600 0 1 #> Item_15 1.167  0.013 0 1 #> Item_16 1.008  1.886 0 1 #> Item_17 0.885 -1.124 0 1 #> Item_18 0.790  1.420 0 1 #> Item_19 0.799  1.316 0 1 #> Item_20 1.565  0.294 0 1 #> Item_21 1.002  0.001 0 1 #> Item_22 0.929 -0.497 0 1 #> Item_23 0.903 -0.383 0 1 #> Item_24 1.120  0.702 0 1 #> Item_25 0.850  2.002 0 1 #> Item_26 0.706 -0.208 0 1 #> Item_27 1.048 -1.279 0 1 #> Item_28 0.826 -0.770 0 1 #> Item_29 1.062  0.221 0 1 #> Item_30 0.737 -0.333 0 1 #> Item_31 1.208 -0.178 0 1 #> Item_32 0.917 -0.202 0 1 #> Item_33 0.859 -1.360 0 1 #> Item_34 0.913 -0.252 0 1 #> Item_35 0.767  0.886 0 1 #> Item_36 0.783  0.763 0 1 #> Item_37 0.630  0.550 0 1 #> Item_38 0.736 -0.405 0 1 #> Item_39 0.917 -0.166 0 1 #> Item_40 0.895 -1.251 0 1 #> Item_41 1.251 -0.040 0 1 #> Item_42 0.882  0.202 0 1 #> Item_43 0.796  1.639 0 1 #> Item_44 1.022  1.038 0 1 #> Item_45 0.812 -0.470 0 1 #> Item_46 0.807  0.336 0 1 #> Item_47 0.815 -1.121 0 1 #> Item_48 0.739  0.892 0 1 #> Item_49 0.904  1.036 0 1 #> Item_50 0.895  2.124 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  #> $G2 #> $items #>            a1      d g u #> Item_1  0.759 -1.830 0 1 #> Item_2  1.062 -0.555 0 1 #> Item_3  1.235 -1.117 0 1 #> Item_4  0.611 -0.953 0 1 #> Item_5  1.088 -0.132 0 1 #> Item_6  1.054  0.502 0 1 #> Item_7  0.849  1.581 0 1 #> Item_8  0.870 -0.779 0 1 #> Item_9  0.902  1.658 0 1 #> Item_10 0.812 -1.188 0 1 #> Item_11 0.903  0.661 0 1 #> Item_12 0.841  2.646 0 1 #> Item_13 0.843 -0.064 0 1 #> Item_14 1.009 -0.600 0 1 #> Item_15 1.167  0.013 0 1 #> Item_16 1.008  1.886 0 1 #> Item_17 0.885 -1.124 0 1 #> Item_18 0.790  1.420 0 1 #> Item_19 0.799  1.316 0 1 #> Item_20 1.565  0.294 0 1 #> Item_21 1.002  0.001 0 1 #> Item_22 0.929 -0.497 0 1 #> Item_23 0.903 -0.383 0 1 #> Item_24 1.120  0.702 0 1 #> Item_25 0.850  2.002 0 1 #> Item_26 0.706 -0.208 0 1 #> Item_27 1.048 -1.279 0 1 #> Item_28 0.826 -0.770 0 1 #> Item_29 1.062  0.221 0 1 #> Item_30 0.737 -0.333 0 1 #> Item_31 1.208 -0.178 0 1 #> Item_32 0.917 -0.202 0 1 #> Item_33 0.859 -1.360 0 1 #> Item_34 0.913 -0.252 0 1 #> Item_35 0.767  0.886 0 1 #> Item_36 0.783  0.763 0 1 #> Item_37 0.630  0.550 0 1 #> Item_38 0.736 -0.405 0 1 #> Item_39 0.917 -0.166 0 1 #> Item_40 0.895 -1.251 0 1 #> Item_41 1.251 -0.040 0 1 #> Item_42 0.882  0.202 0 1 #> Item_43 0.796  1.639 0 1 #> Item_44 1.022  1.038 0 1 #> Item_45 0.812 -0.470 0 1 #> Item_46 0.807  0.336 0 1 #> Item_47 0.815 -1.121 0 1 #> Item_48 0.739  0.892 0 1 #> Item_49 0.904  1.036 0 1 #> Item_50 0.895  2.124 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #>  plot(EH, type = 'empiricalhist', npts = 60)   # DIF test for item 1 EH1 <- multipleGroup(dat, 1, group=group, dentype=\"empiricalhist\", invariance = colnames(dat)[-1]) #>  anova(EH, EH1) #>          AIC    SABIC       HQ      BIC    logLik    X2 df     p #> EH  216599.8 217659.4 217358.4 218739.8 -107959.9                #> EH1 216602.9 217668.7 217365.9 218755.4 -107959.4 0.916  2 0.632  #-------------------------------- # Mixture model (no prior group variable specified)  set.seed(12345) nitems <- 20 a1 <- matrix(.75, ncol=1, nrow=nitems) a2 <- matrix(1.25, ncol=1, nrow=nitems) d1 <- matrix(rnorm(nitems,0,1),ncol=1) d2 <- matrix(rnorm(nitems,0,1),ncol=1) itemtype <- rep('2PL', nrow(a1)) N1 <- 500 N2 <- N1*2 # second class twice as large  dataset1 <- simdata(a1, d1, N1, itemtype) dataset2 <- simdata(a2, d2, N2, itemtype) dat <- rbind(dataset1, dataset2) # group <- c(rep('D1', N1), rep('D2', N2))  # Mixture Rasch model (Rost, 1990) models <- 'F1 = 1-20            CONSTRAIN = (1-20, a1)' mod_mix <- multipleGroup(dat, models, dentype = 'mixture-2', GenRandomPars = TRUE) #>  coef(mod_mix, simplify=TRUE) #> $MIXTURE_1 #> $items #>            a1      d g u #> Item_1  1.302  0.772 0 1 #> Item_2  1.302  1.476 0 1 #> Item_3  1.302 -0.553 0 1 #> Item_4  1.302 -1.588 0 1 #> Item_5  1.302 -1.545 0 1 #> Item_6  1.302  2.084 0 1 #> Item_7  1.302 -0.510 0 1 #> Item_8  1.302  0.606 0 1 #> Item_9  1.302  0.550 0 1 #> Item_10 1.302 -0.167 0 1 #> Item_11 1.302  0.961 0 1 #> Item_12 1.302  2.156 0 1 #> Item_13 1.302  2.082 0 1 #> Item_14 1.302  1.733 0 1 #> Item_15 1.302  0.138 0 1 #> Item_16 1.302  0.434 0 1 #> Item_17 1.302 -0.368 0 1 #> Item_18 1.302 -1.633 0 1 #> Item_19 1.302  1.799 0 1 #> Item_20 1.302 -0.024 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #> $class_proportion #>     pi #>  0.655 #>  #>  #> $MIXTURE_2 #> $items #>            a1      d g u #> Item_1  0.681  0.664 0 1 #> Item_2  0.681  0.805 0 1 #> Item_3  0.681 -0.039 0 1 #> Item_4  0.681 -0.416 0 1 #> Item_5  0.681  0.530 0 1 #> Item_6  0.681 -2.045 0 1 #> Item_7  0.681  0.770 0 1 #> Item_8  0.681 -0.314 0 1 #> Item_9  0.681 -0.030 0 1 #> Item_10 0.681 -0.820 0 1 #> Item_11 0.681 -0.252 0 1 #> Item_12 0.681  1.939 0 1 #> Item_13 0.681  0.642 0 1 #> Item_14 0.681  0.593 0 1 #> Item_15 0.681 -0.749 0 1 #> Item_16 0.681  0.852 0 1 #> Item_17 0.681 -0.950 0 1 #> Item_18 0.681 -0.345 0 1 #> Item_19 0.681  1.230 0 1 #> Item_20 0.681  0.271 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #> $class_proportion #>     pi #>  0.345 #>  #>  summary(mod_mix) #>  #> ---------- #> GROUP: MIXTURE_1  #>          F1    h2 #>  [1,] 0.608 0.369 #>  [2,] 0.608 0.369 #>  [3,] 0.608 0.369 #>  [4,] 0.608 0.369 #>  [5,] 0.608 0.369 #>  [6,] 0.608 0.369 #>  [7,] 0.608 0.369 #>  [8,] 0.608 0.369 #>  [9,] 0.608 0.369 #> [10,] 0.608 0.369 #> [11,] 0.608 0.369 #> [12,] 0.608 0.369 #> [13,] 0.608 0.369 #> [14,] 0.608 0.369 #> [15,] 0.608 0.369 #> [16,] 0.608 0.369 #> [17,] 0.608 0.369 #> [18,] 0.608 0.369 #> [19,] 0.608 0.369 #> [20,] 0.608 0.369 #>  #> SS loadings:  7.386  #> Proportion Var:  0.369  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 #>  #> Class proportion:  0.655  #>  #> ---------- #> GROUP: MIXTURE_2  #>          F1    h2 #>  [1,] 0.371 0.138 #>  [2,] 0.371 0.138 #>  [3,] 0.371 0.138 #>  [4,] 0.371 0.138 #>  [5,] 0.371 0.138 #>  [6,] 0.371 0.138 #>  [7,] 0.371 0.138 #>  [8,] 0.371 0.138 #>  [9,] 0.371 0.138 #> [10,] 0.371 0.138 #> [11,] 0.371 0.138 #> [12,] 0.371 0.138 #> [13,] 0.371 0.138 #> [14,] 0.371 0.138 #> [15,] 0.371 0.138 #> [16,] 0.371 0.138 #> [17,] 0.371 0.138 #> [18,] 0.371 0.138 #> [19,] 0.371 0.138 #> [20,] 0.371 0.138 #>  #> SS loadings:  2.758  #> Proportion Var:  0.138  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 #>  #> Class proportion:  0.345  plot(mod_mix)  plot(mod_mix, type = 'trace')  itemplot(mod_mix, 1, type = 'info')   head(fscores(mod_mix)) # theta estimates #>      Class_1 #> [1,]  -0.361 #> [2,]  -1.695 #> [3,]  -0.822 #> [4,]   0.809 #> [5,]   0.794 #> [6,]   0.229 head(fscores(mod_mix, method = 'classify')) # classification probability #>      CLASS_1 CLASS_2 #> [1,]   0.048   0.952 #> [2,]   0.742   0.258 #> [3,]   0.025   0.975 #> [4,]   0.029   0.971 #> [5,]   0.072   0.928 #> [6,]   0.424   0.576 itemfit(mod_mix) #>       item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1 30.498      12      0.032  0.002 #> 2   Item_2 36.271      12      0.037  0.000 #> 3   Item_3 15.756      12      0.014  0.203 #> 4   Item_4  9.334      11      0.000  0.591 #> 5   Item_5 21.638      12      0.023  0.042 #> 6   Item_6 26.071      13      0.026  0.017 #> 7   Item_7  8.624      12      0.000  0.735 #> 8   Item_8 16.652      12      0.016  0.163 #> 9   Item_9 22.772      12      0.024  0.030 #> 10 Item_10 14.622      12      0.012  0.263 #> 11 Item_11  7.357      12      0.000  0.833 #> 12 Item_12 14.964      12      0.013  0.243 #> 13 Item_13 10.222      12      0.000  0.597 #> 14 Item_14 17.414      13      0.015  0.181 #> 15 Item_15  9.436      12      0.000  0.665 #> 16 Item_16 11.408      12      0.000  0.494 #> 17 Item_17 16.483      12      0.016  0.170 #> 18 Item_18 11.717      11      0.007  0.385 #> 19 Item_19 11.425      12      0.000  0.493 #> 20 Item_20 15.291      12      0.014  0.226  # Mixture 2PL model mod_mix2 <- multipleGroup(dat, 1, dentype = 'mixture-2', GenRandomPars = TRUE) #>  anova(mod_mix, mod_mix2) #>               AIC    SABIC       HQ      BIC    logLik     X2 df    p #> mod_mix  34628.19 34720.06 34713.30 34856.65 -17271.09                #> mod_mix2 34655.23 34828.29 34815.56 35085.60 -17246.62 48.957 38 0.11 coef(mod_mix2, simplify=TRUE) #> $MIXTURE_1 #> $items #>            a1      d g u #> Item_1  0.517  0.672 0 1 #> Item_2  0.516  0.826 0 1 #> Item_3  0.533 -0.012 0 1 #> Item_4  0.387 -0.363 0 1 #> Item_5  0.452  0.551 0 1 #> Item_6  0.727 -1.905 0 1 #> Item_7  1.032  0.879 0 1 #> Item_8  0.744 -0.275 0 1 #> Item_9  0.900  0.037 0 1 #> Item_10 0.709 -0.777 0 1 #> Item_11 0.538 -0.190 0 1 #> Item_12 0.915  2.079 0 1 #> Item_13 0.729  0.690 0 1 #> Item_14 1.183  0.722 0 1 #> Item_15 0.812 -0.717 0 1 #> Item_16 0.582  0.843 0 1 #> Item_17 0.791 -0.953 0 1 #> Item_18 0.657 -0.290 0 1 #> Item_19 0.498  1.222 0 1 #> Item_20 0.468  0.304 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #> $class_proportion #>     pi #>  0.349 #>  #>  #> $MIXTURE_2 #> $items #>            a1      d g u #> Item_1  1.118  0.710 0 1 #> Item_2  1.216  1.405 0 1 #> Item_3  1.244 -0.565 0 1 #> Item_4  1.684 -1.826 0 1 #> Item_5  1.669 -1.800 0 1 #> Item_6  1.473  2.151 0 1 #> Item_7  1.143 -0.510 0 1 #> Item_8  1.244  0.574 0 1 #> Item_9  1.272  0.507 0 1 #> Item_10 1.188 -0.183 0 1 #> Item_11 1.465  0.980 0 1 #> Item_12 1.403  2.208 0 1 #> Item_13 1.388  2.110 0 1 #> Item_14 1.062  1.599 0 1 #> Item_15 1.311  0.112 0 1 #> Item_16 1.191  0.410 0 1 #> Item_17 1.381 -0.387 0 1 #> Item_18 1.500 -1.798 0 1 #> Item_19 1.624  1.955 0 1 #> Item_20 1.353 -0.060 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>  #> $class_proportion #>     pi #>  0.651 #>  #>  itemfit(mod_mix2) #>       item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 #> 1   Item_1 21.271      12      0.023  0.047 #> 2   Item_2 44.619      13      0.040  0.000 #> 3   Item_3 14.259      12      0.011  0.284 #> 4   Item_4  6.550      11      0.000  0.834 #> 5   Item_5 20.639      12      0.022  0.056 #> 6   Item_6 27.956      13      0.028  0.009 #> 7   Item_7  8.628      12      0.000  0.734 #> 8   Item_8 16.261      12      0.015  0.180 #> 9   Item_9 21.304      12      0.023  0.046 #> 10 Item_10 11.460      12      0.000  0.490 #> 11 Item_11  7.091      12      0.000  0.852 #> 12 Item_12 13.838      12      0.010  0.311 #> 13 Item_13 10.444      12      0.000  0.577 #> 14 Item_14 15.704      13      0.012  0.265 #> 15 Item_15  9.439      12      0.000  0.665 #> 16 Item_16 10.128      12      0.000  0.605 #> 17 Item_17 17.474      12      0.017  0.133 #> 18 Item_18 11.833      11      0.007  0.376 #> 19 Item_19  8.071      11      0.000  0.707 #> 20 Item_20 14.542      12      0.012  0.267  # Compare to single group mod <- mirt(dat) #>  anova(mod, mod_mix2) #>               AIC    SABIC       HQ      BIC    logLik      X2 df p #> mod      35276.70 35362.16 35355.88 35489.23 -17598.35              #> mod_mix2 34655.23 34828.29 34815.56 35085.60 -17246.62 703.474 41 0  ######################################## # Zero-inflated 2PL IRT model (Wall, Park, and Moustaki, 2015)  n <- 1000 nitems <- 20  a <- rep(2, nitems) d <- rep(c(-2,-1,0,1,2), each=nitems/5) zi_p <- 0.2 # Proportion of people in zero class  theta <- rnorm(n, 0, 1) zeros <- matrix(0, n*zi_p, nitems) nonzeros <- simdata(a, d, n*(1-zi_p), itemtype = '2PL',                    Theta = as.matrix(theta[1:(n*(1-zi_p))])) data <- rbind(nonzeros, zeros)  # define class with extreme theta but fixed item parameters zi2PL <- \"F = 1-20           START [MIXTURE_1] = (GROUP, MEAN_1, -100), (GROUP, COV_11, .00001),                               (1-20, a1, 1.0), (1-20, d, 0)           FIXED [MIXTURE_1] = (GROUP, MEAN_1), (GROUP, COV_11),                               (1-20, a1), (1-20, d)\"  # define custom Theta integration grid that contains extreme theta + normal grid technical <- list(customTheta = matrix(c(-100, seq(-6,6,length.out=61))))  # fit ZIM-IRT zi2PL.fit <- multipleGroup(data, zi2PL, dentype = 'mixture-2', technical=technical) #>  coef(zi2PL.fit, simplify=TRUE) #> $MIXTURE_1 #> $items #>         a1 d g u #> Item_1   1 0 0 1 #> Item_2   1 0 0 1 #> Item_3   1 0 0 1 #> Item_4   1 0 0 1 #> Item_5   1 0 0 1 #> Item_6   1 0 0 1 #> Item_7   1 0 0 1 #> Item_8   1 0 0 1 #> Item_9   1 0 0 1 #> Item_10  1 0 0 1 #> Item_11  1 0 0 1 #> Item_12  1 0 0 1 #> Item_13  1 0 0 1 #> Item_14  1 0 0 1 #> Item_15  1 0 0 1 #> Item_16  1 0 0 1 #> Item_17  1 0 0 1 #> Item_18  1 0 0 1 #> Item_19  1 0 0 1 #> Item_20  1 0 0 1 #>  #> $means #>    F  #> -100  #>  #> $cov #>   F #> F 0 #>  #> $class_proportion #>     pi #>  0.209 #>  #>  #> $MIXTURE_2 #> $items #>            a1      d g u #> Item_1  1.867 -2.089 0 1 #> Item_2  1.998 -1.979 0 1 #> Item_3  1.954 -1.932 0 1 #> Item_4  1.595 -1.841 0 1 #> Item_5  1.922 -0.986 0 1 #> Item_6  1.924 -0.926 0 1 #> Item_7  2.045 -1.209 0 1 #> Item_8  2.069 -1.005 0 1 #> Item_9  1.782  0.101 0 1 #> Item_10 1.942  0.195 0 1 #> Item_11 2.080  0.039 0 1 #> Item_12 1.956  0.039 0 1 #> Item_13 1.540  0.835 0 1 #> Item_14 2.047  1.092 0 1 #> Item_15 1.956  0.973 0 1 #> Item_16 1.807  1.026 0 1 #> Item_17 2.084  2.069 0 1 #> Item_18 1.917  2.153 0 1 #> Item_19 1.464  1.735 0 1 #> Item_20 1.739  1.920 0 1 #>  #> $means #> F  #> 0  #>  #> $cov #>   F #> F 1 #>  #> $class_proportion #>     pi #>  0.791 #>  #>   # classification estimates pi_hat <- fscores(zi2PL.fit, method = 'classify') head(pi_hat) #>      CLASS_1 CLASS_2 #> [1,]       0       1 #> [2,]       0       1 #> [3,]       0       1 #> [4,]       0       1 #> [5,]       0       1 #> [6,]       0       1 tail(pi_hat) #>         CLASS_1 CLASS_2 #>  [995,]   0.924   0.076 #>  [996,]   0.924   0.076 #>  [997,]   0.924   0.076 #>  [998,]   0.924   0.076 #>  [999,]   0.924   0.076 #> [1000,]   0.924   0.076  # EAP estimates (not useful for zip class) fs <- fscores(zi2PL.fit) head(fs) #>      Class_1 #> [1,]   0.262 #> [2,]  -1.762 #> [3,]   0.286 #> [4,]   0.563 #> [5,]  -1.669 #> [6,]   0.006 tail(fs) #>         Class_1 #>  [995,] -92.596 #>  [996,] -92.596 #>  [997,] -92.596 #>  [998,] -92.596 #>  [999,] -92.596 #> [1000,] -92.596  ######################################## # Zero-inflated graded response model (Magnus and Garnier-Villarreal, 2022)  n <- 1000 nitems <- 20  a <- matrix(rlnorm(20,.2,.3))  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often (minimum distance of 0.3 here) diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(20)  zi_p <- 0.2 # Proportion of people in zero/lowest category class  theta <- rnorm(n, 0, 1) zeros <- matrix(0, n*zi_p, nitems) nonzeros <- simdata(a, d, n*(1-zi_p), itemtype = 'graded',                     Theta = as.matrix(theta[1:(n*(1-zi_p))])) data <- rbind(nonzeros, zeros)  # intercepts will be labelled as d1 through d4 apply(data, 2, table) #>   Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> 0    474    276    431    384    763    354    420    379    342     610 #> 1    128     61    107     26     69     99    140    137    116     114 #> 2     62    105    112     54     45     58    120    136    165      98 #> 3     89    135    159     87     37    135    118     70     68      34 #> 4    247    423    191    449     86    354    202    278    309     144 #>   Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> 0     393     756     668     605     463     321     683     664     406 #> 1     115     114      75     104      74      55      65      46      99 #> 2      54      62      55     113     119     123      58      46      66 #> 3     134      33      66      81      89     130      42      57      67 #> 4     304      35     136      97     255     371     152     187     362 #>   Item_20 #> 0     588 #> 1     103 #> 2      85 #> 3      50 #> 4     174  # ignoring zero inflation (bad idea) modGRM <- mirt(data) #>  #> Warning: EM cycles terminated after 500 iterations. coef(modGRM, simplify=TRUE) #> $items #>            a1     d1     d2     d3     d4 #> Item_1  2.540 -0.223 -1.106 -1.527 -2.166 #> Item_2  2.284  1.418  0.791 -0.010 -0.848 #> Item_3  1.771  0.167 -0.479 -1.108 -2.132 #> Item_4  3.367  0.392  0.141 -0.330 -1.021 #> Item_5  3.450 -2.806 -3.524 -4.105 -4.691 #> Item_6  2.003  0.715  0.013 -0.347 -1.145 #> Item_7  2.375  0.182 -0.781 -1.545 -2.405 #> Item_8  2.286  0.515 -0.466 -1.336 -1.795 #> Item_9  2.768  0.837 -0.152 -1.319 -1.801 #> Item_10 2.910 -1.290 -2.154 -3.034 -3.397 #> Item_11 2.681  0.382 -0.484 -0.858 -1.792 #> Item_12 1.734 -1.721 -2.648 -3.462 -4.224 #> Item_13 2.042 -1.307 -1.802 -2.209 -2.804 #> Item_14 1.914 -0.871 -1.516 -2.346 -3.185 #> Item_15 4.247 -0.504 -1.187 -2.250 -3.114 #> Item_16 2.628  1.020  0.501 -0.428 -1.305 #> Item_17 2.522 -1.628 -2.114 -2.605 -3.007 #> Item_18 2.547 -1.508 -1.835 -2.189 -2.675 #> Item_19 1.906  0.340 -0.291 -0.677 -1.065 #> Item_20 2.287 -0.906 -1.572 -2.181 -2.606 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # Define class with extreme theta but fixed item parameters #   For GRM in zero-inflated class the intercept values are arbitrary #   as the model forces the responses all into the first category (hence, #   spacing arbitrarily set to 1) ziGRM <- \"F = 1-20           START [MIXTURE_1] = (GROUP, MEAN_1, -100), (GROUP, COV_11, .00001),                               (1-20, a1, 1.0),                               (1-20, d1, 2), (1-20, d2, 1), (1-20, d3, 0), (1-20, d4, -1)           FIXED [MIXTURE_1] = (GROUP, MEAN_1), (GROUP, COV_11),                               (1-20, a1),                               (1-20, d1), (1-20, d2), (1-20, d3), (1-20, d4)\"  # define custom Theta integration grid that contains extreme theta + normal grid technical <- list(customTheta = matrix(c(-100, seq(-6,6,length.out=61))))  # fit zero-inflated GRM ziGRM.fit <- multipleGroup(data, ziGRM, dentype = 'mixture-2', technical=technical) #>  coef(ziGRM.fit, simplify=TRUE) #> $MIXTURE_1 #> $items #>         a1 d1 d2 d3 d4 #> Item_1   1  2  1  0 -1 #> Item_2   1  2  1  0 -1 #> Item_3   1  2  1  0 -1 #> Item_4   1  2  1  0 -1 #> Item_5   1  2  1  0 -1 #> Item_6   1  2  1  0 -1 #> Item_7   1  2  1  0 -1 #> Item_8   1  2  1  0 -1 #> Item_9   1  2  1  0 -1 #> Item_10  1  2  1  0 -1 #> Item_11  1  2  1  0 -1 #> Item_12  1  2  1  0 -1 #> Item_13  1  2  1  0 -1 #> Item_14  1  2  1  0 -1 #> Item_15  1  2  1  0 -1 #> Item_16  1  2  1  0 -1 #> Item_17  1  2  1  0 -1 #> Item_18  1  2  1  0 -1 #> Item_19  1  2  1  0 -1 #> Item_20  1  2  1  0 -1 #>  #> $means #>    F  #> -100  #>  #> $cov #>   F #> F 0 #>  #> $class_proportion #>   pi #>  0.2 #>  #>  #> $MIXTURE_2 #> $items #>            a1     d1     d2     d3     d4 #> Item_1  1.287  0.857 -0.022 -0.438 -1.068 #> Item_2  0.764  2.477  1.751  0.932  0.124 #> Item_3  0.695  0.975  0.325 -0.293 -1.284 #> Item_4  1.711  1.782  1.532  1.064  0.381 #> Item_5  1.928 -1.382 -2.106 -2.689 -3.276 #> Item_6  0.751  1.601  0.875  0.518 -0.255 #> Item_7  1.137  1.198  0.242 -0.506 -1.343 #> Item_8  1.030  1.498  0.515 -0.332 -0.778 #> Item_9  1.307  1.994  0.998 -0.138 -0.604 #> Item_10 1.583 -0.062 -0.930 -1.809 -2.171 #> Item_11 1.308  1.508  0.644  0.276 -0.636 #> Item_12 0.886 -0.954 -1.873 -2.677 -3.431 #> Item_13 1.048 -0.420 -0.912 -1.315 -1.903 #> Item_14 0.946 -0.030 -0.668 -1.485 -2.310 #> Item_15 2.338  1.299  0.604 -0.475 -1.353 #> Item_16 1.154  2.119  1.582  0.664 -0.180 #> Item_17 1.363 -0.559 -1.046 -1.536 -1.937 #> Item_18 1.359 -0.428 -0.755 -1.108 -1.591 #> Item_19 0.725  1.173  0.539  0.161 -0.216 #> Item_20 1.179  0.077 -0.586 -1.190 -1.609 #>  #> $means #> F  #> 0  #>  #> $cov #>   F #> F 1 #>  #> $class_proportion #>   pi #>  0.8 #>  #>   # classification estimates pi_hat <- fscores(ziGRM.fit, method = 'classify') head(pi_hat) #>      CLASS_1 CLASS_2 #> [1,]       0       1 #> [2,]       0       1 #> [3,]       0       1 #> [4,]       0       1 #> [5,]       0       1 #> [6,]       0       1 tail(pi_hat) #>         CLASS_1 CLASS_2 #>  [995,]   0.998   0.002 #>  [996,]   0.998   0.002 #>  [997,]   0.998   0.002 #>  [998,]   0.998   0.002 #>  [999,]   0.998   0.002 #> [1000,]   0.998   0.002  # EAP estimates (not useful for zip class) fs <- fscores(ziGRM.fit) head(fs) #>      Class_1 #> [1,]  -0.541 #> [2,]   0.857 #> [3,]   1.506 #> [4,]   1.194 #> [5,]   0.221 #> [6,]  -1.409 tail(fs) #>         Class_1 #>  [995,] -99.829 #>  [996,] -99.829 #>  [997,] -99.829 #>  [998,] -99.829 #>  [999,] -99.829 #> [1000,] -99.829  # }"},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute numerical derivatives — numerical_deriv","title":"Compute numerical derivatives — numerical_deriv","text":"Compute numerical derivatives using forward/backward difference, central difference, Richardson extrapolation.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute numerical derivatives — numerical_deriv","text":"","code":"numerical_deriv(   par,   f,   ...,   delta = 1e-05,   gradient = TRUE,   type = \"Richardson\" )"},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute numerical derivatives — numerical_deriv","text":"par vector parameters find partial derivative f objective function evaluated ... additional arguments passed f delta term used perturb f function. Default 1e-5 gradient logical; compute gradient terms? FALSE Hessian computed instead type type difference compute. Can either 'forward' forward difference, 'central' central difference, 'Richardson' Richardson extrapolation (default). Backward difference achieved supplying negative delta value 'forward'. type = 'Richardson', default value delta increased delta * 1000 Hessian delta * 10 gradient provide reasonable perturbation starting location (delta halved iteration).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute numerical derivatives — numerical_deriv","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/numerical_deriv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute numerical derivatives — numerical_deriv","text":"","code":"# \\donttest{ f <- function(x) 3*x[1]^3 - 4*x[2]^2 par <- c(3,8)  # grad = 9 * x^2 , -8 * y (actual <- c(9 * par[1]^2, -8 * par[2])) #> [1]  81 -64 numerical_deriv(par, f, type = 'forward') #> [1]  81.00027 -64.00004 numerical_deriv(par, f, type = 'central') #> [1]  81 -64 numerical_deriv(par, f, type = 'Richardson') # default #> [1]  81 -64  # Hessian = h11 -> 18 * x, h22 -> -8, h12 -> h21 -> 0 (actual <- matrix(c(18 * par[1], 0, 0, -8), 2, 2)) #>      [,1] [,2] #> [1,]   54    0 #> [2,]    0   -8 numerical_deriv(par, f, type = 'forward', gradient = FALSE) #>          [,1]      [,2] #> [1,] 54.00011  0.000000 #> [2,]  0.00000 -7.999574 numerical_deriv(par, f, type = 'central', gradient = FALSE) #>          [,1]      [,2] #> [1,] 54.00004  0.000000 #> [2,]  0.00000 -7.999645 numerical_deriv(par, f, type = 'Richardson', gradient = FALSE) # default #>      [,1] [,2] #> [1,]   54    0 #> [2,]    0   -8  # }"},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Person fit statistics — personfit","title":"Person fit statistics — personfit","text":"personfit calculates Zh values Drasgow, Levine Williams (1985) unidimensional multidimensional models, well infit outfit statistics. returned object data.frame consisting either tabulated data full data statistics appended rightmost columns.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Person fit statistics — personfit","text":"","code":"personfit(   x,   method = \"EAP\",   Theta = NULL,   stats.only = TRUE,   return.resids = FALSE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Person fit statistics — personfit","text":"x computed model object class SingleGroupClass MultipleGroupClass method type factor score estimation method. See fscores detail Theta matrix factor scores used statistics require empirical estimates. supplied, arguments typically passed fscores() ignored values used instead stats.logical; return person fit statistics without associated response pattern? return.resids logical; return standardized unstandardized N J matrices person item residuals? TRUE return named list residual type ... additional arguments passed fscores()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Person fit statistics — personfit","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Drasgow, F., Levine, M. V., & Williams, E. . (1985). Appropriateness measurement polychotomous item response models standardized indices. British Journal Mathematical Statistical Psychology, 38, 67-86. Reise, S. P. (1990). comparison item- person-fit methods assessing model-data fit IRT. Applied Psychological Measurement, 14, 127-137. Wright B. D. & Masters, G. N. (1982). Rating scale analysis. MESA Press.","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Person fit statistics — personfit","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/personfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Person fit statistics — personfit","text":"","code":"# \\donttest{  #make some data set.seed(1) a <- matrix(rlnorm(20),ncol=1) d <- matrix(rnorm(20),ncol=1) items <- rep('2PL', 20) data <- simdata(a,d, 2000, items)  # first observation responds 1 for most difficult, 0 for easiest data[1,] <- ifelse(d > 0, 0, 1)  # second observations answers first half as 1 second half as 0 data[2,] <- rep(1:0, each = 10)  x <- mirt(data, 1) #>  fit <- personfit(x) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’ head(fit) #> Error: object 'fit' not found  # raw/standardized residuals resid_list <- personfit(x, return.resids=TRUE) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’ head(resid_list$resid) # unstandardized #> Error: object 'resid_list' not found head(resid_list$std.resid) # standardized (approximate z-scores) #> Error: object 'resid_list' not found  # with missing data data[3, c(1,3,5,7)] <- NA x.miss <- mirt(data, 1) #>  fit.miss <- personfit(x.miss) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’ head(fit.miss) #> Error: object 'fit.miss' not found head(personfit(x.miss, return.resids=TRUE)) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’  #using precomputed Theta Theta <- fscores(x, method = 'MAP', full.scores = TRUE) head(personfit(x, Theta=Theta)) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"dich\", Theta = \"mirt_matrix\"’  # multiple group Rasch model example set.seed(12345) a <- matrix(rep(1, 16), ncol=1) d <- matrix(rnorm(16,0,.7),ncol=1) itemtype <- rep('dich', nrow(a)) N <- 1000 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, sigma = matrix(1.5)) dat <- rbind(dataset1, dataset2)  # first observation responds 1 for most difficult, 0 for easiest dat[1,] <- ifelse(d > 0, 0, 1)  group <- c(rep('D1', N), rep('D2', N)) models <- 'F1 = 1-16' mod_Rasch <- multipleGroup(dat, models, itemtype = 'Rasch', group = group) #>  coef(mod_Rasch, simplify=TRUE) #> $D1 #> $items #>         a1      d g u #> Item_1   1  0.431 0 1 #> Item_2   1  0.446 0 1 #> Item_3   1 -0.039 0 1 #> Item_4   1 -0.217 0 1 #> Item_5   1  0.517 0 1 #> Item_6   1 -1.240 0 1 #> Item_7   1  0.492 0 1 #> Item_8   1 -0.138 0 1 #> Item_9   1 -0.113 0 1 #> Item_10  1 -0.709 0 1 #> Item_11  1  0.054 0 1 #> Item_12  1  1.346 0 1 #> Item_13  1  0.197 0 1 #> Item_14  1  0.436 0 1 #> Item_15  1 -0.456 0 1 #> Item_16  1  0.553 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 1.099 #>  #>  #> $D2 #> $items #>         a1      d g u #> Item_1   1  0.407 0 1 #> Item_2   1  0.547 0 1 #> Item_3   1 -0.057 0 1 #> Item_4   1 -0.240 0 1 #> Item_5   1  0.290 0 1 #> Item_6   1 -1.293 0 1 #> Item_7   1  0.455 0 1 #> Item_8   1 -0.277 0 1 #> Item_9   1 -0.209 0 1 #> Item_10  1 -0.660 0 1 #> Item_11  1 -0.219 0 1 #> Item_12  1  1.230 0 1 #> Item_13  1  0.332 0 1 #> Item_14  1  0.322 0 1 #> Item_15  1 -0.496 0 1 #> Item_16  1  0.449 0 1 #>  #> $means #> F1  #>  0  #>  #> $cov #>       F1 #> F1 1.563 #>  #>  pf <- personfit(mod_Rasch, method='MAP') head(pf) #>      outfit   z.outfit     infit    z.infit         Zh #> 1 1.7020980  3.8601866 1.6168778  4.1292792 -4.7705221 #> 2 1.1927207  1.2391298 1.1583820  1.2242405 -1.2507554 #> 3 1.1600703  0.9795701 1.0933660  0.6952324 -0.7640134 #> 4 0.6421989 -1.2734374 0.7045519 -1.2639179  1.2138761 #> 5 1.0726731  0.3149890 1.0446560  0.2466146 -0.1792089 #> 6 0.8189958 -0.9216193 0.8518569 -0.8904852  0.9128864    # }"},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"Plot various test implied response functions models estimated mirt package.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"","code":"# S4 method for class 'MultipleGroupClass,missing' plot(   x,   y,   type = \"score\",   npts = 200,   drop2 = TRUE,   degrees = 45,   which.items = 1:extract.mirt(x, \"nitems\"),   rot = list(xaxis = -70, yaxis = 30, zaxis = 10),   facet_items = TRUE,   theta_lim = c(-6, 6),   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   ... )  # S4 method for class 'SingleGroupClass,missing' plot(   x,   y,   type = \"score\",   npts = 200,   drop2 = TRUE,   degrees = 45,   theta_lim = c(-6, 6),   which.items = 1:extract.mirt(x, \"nitems\"),   MI = 0,   CI = 0.95,   rot = list(xaxis = -70, yaxis = 30, zaxis = 10),   facet_items = TRUE,   main = NULL,   drape = TRUE,   colorkey = TRUE,   ehist.cut = 1e-10,   add.ylab2 = TRUE,   par.strip.text = list(cex = 0.7),   par.settings = list(strip.background = list(col = \"#9ECAE1\"), strip.border = list(col =     \"black\")),   auto.key = list(space = \"right\", points = FALSE, lines = TRUE),   profile = FALSE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"x object class SingleGroupClass, MultipleGroupClass, DiscreteClass y arbitrary missing argument required R CMD check type type plot view. Can 'info' test information function 'rxx' reliability function 'infocontour' test information contours 'SE' test standard error function 'infotrace' item information traceline plots 'infoSE' combined test information standard error plot 'trace' item probability traceline plots 'itemscore' item scoring traceline plots 'score' expected total score surface 'scorecontour' expected total score contour plot 'posteriorTheta' posterior latent trait distribution 'EAPsum' compares sum-scores expected values based       EAP sum-scores method (see fscores) Note dentype = 'empiricalhist' used estimation   type 'empiricalhist'   also available generate empirical histogram plot,   dentype = 'Davidian-#' used type 'Davidian'   also available generate curve estimates quadrature   nodes used estimation npts number quadrature points used plotting features. Larger values make plots look smoother drop2 logical; appropriate, dichotomous response items drop lowest category provide information pertaining second response option? degrees numeric value ranging 0 90 used plot compute angle information-based plots respect first dimension. vector used bubble plot created summed information across angles specified (e.g., degrees = seq(0, 90, =10)) .items numeric vector indicating items used plotting. Default use available items rot allows rotation 3D graphics facet_items logical; apply grid plots across items? FALSE, items placed one plot group theta_lim lower upper limits latent trait (theta) evaluated, used conjunction npts par.strip.text plotting argument passed lattice par.settings plotting argument passed lattice auto.key plotting argument passed lattice ... additional arguments passed lattice MI single number indicating many imputations draw form bootstrapped confidence intervals selected test statistic. greater 0 plot drawn shaded region interval CI number 0 1 indicating confidence interval select MI input used. Default uses 95% confidence (CI = .95) main argument passed lattice. Default generated automatically drape logical argument passed lattice. Default generated automatically colorkey logical argument passed lattice. Default generated automatically ehist.cut probability value indicating threshold excluding cases empirical histogram plots. Values larger default include points tails plot, potentially squishing 'meat' plot take less area visually desired add.ylab2 logical argument passed lattice. Default generated automatically profile logical; provide profile plot response probabilities (objects returned mdirt )","code":""},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/plot-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot various test-implied functions from models — plot,MultipleGroupClass,missing-method","text":"","code":"# \\donttest{ x <- mirt(Science, 1, SE=TRUE) #>  #>  #> Calculating information matrix... plot(x)  plot(x, type = 'info')  plot(x, type = 'infotrace')  plot(x, type = 'infotrace', facet_items = FALSE)  plot(x, type = 'infoSE')  plot(x, type = 'rxx')  plot(x, type = 'posteriorTheta')   # confidence interval plots when information matrix computed plot(x)  plot(x, MI=100)  plot(x, type='info', MI=100)  plot(x, type='SE', MI=100)  plot(x, type='rxx', MI=100)   # use the directlabels package to put labels on tracelines library(directlabels) plt <- plot(x, type = 'trace') direct.label(plt, 'top.points')   # additional modifications can be made via update(). # See ?update.trellis for further documentation plt  update(plt, ylab = expression(Prob(theta)),             main = \"Item Traceline Functions\") # ylab/main changed   set.seed(1234) group <- sample(c('g1','g2'), nrow(Science), TRUE) x2 <- multipleGroup(Science, 1, group) #>  plot(x2)  plot(x2, type = 'trace')  plot(x2, type = 'trace', which.items = 1:2)  plot(x2, type = 'itemscore', which.items = 1:2)  plot(x2, type = 'trace', which.items = 1, facet_items = FALSE) #facet by group  plot(x2, type = 'info')   x3 <- mirt(Science, 2) #>  plot(x3, type = 'info')  plot(x3, type = 'SE', theta_lim = c(-3,3))   # }"},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":null,"dir":"Reference","previous_headings":"","what":"Change polytomous items to dichotomous item format — poly2dich","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Transforms matrix items new matrix select polytomous items converted comparable dichotomous items information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change polytomous items to dichotomous item format — poly2dich","text":"","code":"poly2dich(data, which.items = 1:ncol(data), sep = \"_cat.\")"},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change polytomous items to dichotomous item format — poly2dich","text":"data object class data.frame matrix .items vector indicating items transformed dichotomous form. Default uses input items sep character vector pattern append item name data","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Returns integer matrix","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Change polytomous items to dichotomous item format — poly2dich","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/poly2dich.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change polytomous items to dichotomous item format — poly2dich","text":"","code":"# \\donttest{ data(Science)  head(Science) #>   Comfort Work Future Benefit #> 1       4    4      3       2 #> 2       3    3      3       3 #> 3       3    2      2       3 #> 4       3    2      2       3 #> 5       3    4      4       1 #> 6       4    4      3       3 newScience <- poly2dich(Science) head(newScience) #>      Comfort_cat.1 Comfort_cat.2 Comfort_cat.3 Comfort_cat.4 Work_cat.1 #> [1,]             0             0             0             1          0 #> [2,]             0             0             1             0          0 #> [3,]             0             0             1             0          0 #> [4,]             0             0             1             0          0 #> [5,]             0             0             1             0          0 #> [6,]             0             0             0             1          0 #>      Work_cat.2 Work_cat.3 Work_cat.4 Future_cat.1 Future_cat.2 Future_cat.3 #> [1,]          0          0          1            0            0            1 #> [2,]          0          1          0            0            0            1 #> [3,]          1          0          0            0            1            0 #> [4,]          1          0          0            0            1            0 #> [5,]          0          0          1            0            0            0 #> [6,]          0          0          1            0            0            1 #>      Future_cat.4 Benefit_cat.1 Benefit_cat.2 Benefit_cat.3 Benefit_cat.4 #> [1,]            0             0             1             0             0 #> [2,]            0             0             0             1             0 #> [3,]            0             0             0             1             0 #> [4,]            0             0             0             1             0 #> [5,]            1             1             0             0             0 #> [6,]            0             0             0             1             0  newScience2 <- poly2dich(Science, which.items = 2) head(newScience2) #>   Comfort Work_cat.1 Work_cat.2 Work_cat.3 Work_cat.4 Future Benefit #> 1       4          0          0          0          1      3       2 #> 2       3          0          0          1          0      3       3 #> 3       3          0          1          0          0      2       3 #> 4       3          0          1          0          0      2       3 #> 5       3          0          0          0          1      4       1 #> 6       4          0          0          0          1      3       3  # }"},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the model objects — print-method","title":"Print the model objects — print-method","text":"Print model object summaries console.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the model objects — print-method","text":"","code":"# S4 method for class 'SingleGroupClass' print(x)"},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the model objects — print-method","text":"x object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print the model objects — print-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print the model objects — print-method","text":"","code":"# \\donttest{ x <- mirt(Science, 1) #>  print(x) #>  #> Call: #> mirt(data = Science, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 36 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1608.87 #> Estimated parameters: 16  #> AIC = 3249.739 #> BIC = 3313.279; SABIC = 3262.512 #> G2 (239) = 213.56, p = 0.8804 #> RMSEA = 0, CFI = NaN, TLI = NaN # }"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Print generic for customized data.frame console output — print.mirt_df","title":"Print generic for customized data.frame console output — print.mirt_df","text":"Provides nicer output printed data.frame objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print generic for customized data.frame console output — print.mirt_df","text":"","code":"# S3 method for class 'mirt_df' print(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print generic for customized data.frame console output — print.mirt_df","text":"x object class 'mirt_df' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Print generic for customized list console output — print.mirt_list","title":"Print generic for customized list console output — print.mirt_list","text":"Provides nicer output printed list objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print generic for customized list console output — print.mirt_list","text":"","code":"# S3 method for class 'mirt_list' print(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print generic for customized list console output — print.mirt_list","text":"x object class 'mirt_list' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Print generic for customized matrix console output — print.mirt_matrix","title":"Print generic for customized matrix console output — print.mirt_matrix","text":"Provides nicer output printed matrix objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print generic for customized matrix console output — print.mirt_matrix","text":"","code":"# S3 method for class 'mirt_matrix' print(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/print.mirt_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print generic for customized matrix console output — print.mirt_matrix","text":"x object class 'mirt_matrix' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate probability trace lines — probtrace","title":"Function to calculate probability trace lines — probtrace","text":"Given internal mirt object extracted estimated model, single-group estimated model , compute probability trace lines categories.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate probability trace lines — probtrace","text":"","code":"probtrace(x, Theta)"},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate probability trace lines — probtrace","text":"x either extracted internal mirt object containing item information (see extract.item) model class SingleGroupClass typically returned function mirt bfactor Theta vector (unidimensional) matrix (unidimensional/multidimensional) latent trait values","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate probability trace lines — probtrace","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate probability trace lines — probtrace","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/probtrace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate probability trace lines — probtrace","text":"","code":"mod <- mirt(Science, 1) #>   # single item probabilty tracelines for Item 2 extr.2 <- extract.item(mod, 2) Theta <- matrix(seq(-4,4, by = .1)) traceline <- probtrace(extr.2, Theta) head(data.frame(traceline, Theta=Theta)) #>         P.1       P.2        P.3          P.4 Theta #> 1 0.8786646 0.1033965 0.01717048 0.0007684150  -4.0 #> 2 0.8649759 0.1147928 0.01936274 0.0008685506  -3.9 #> 3 0.8500065 0.1271837 0.02182811 0.0009817226  -3.8 #> 4 0.8336966 0.1405950 0.02459876 0.0011096245  -3.7 #> 5 0.8159972 0.1550385 0.02771018 0.0012541689  -3.6 #> 6 0.7968730 0.1705082 0.03120137 0.0014175155  -3.5  # probability tracelines for all items in test tracelines <- probtrace(mod, Theta) head(tracelines) #>      Comfort.P.1 Comfort.P.2 Comfort.P.3 Comfort.P.4  Work.P.1  Work.P.2 #> [1,]   0.3324476   0.4891306   0.1748568 0.003564956 0.8786646 0.1033965 #> [2,]   0.3097452   0.4960477   0.1902523 0.003954823 0.8649759 0.1147928 #> [3,]   0.2879244   0.5010453   0.2066432 0.004387139 0.8500065 0.1271837 #> [4,]   0.2670460   0.5040571   0.2240304 0.004866481 0.8336966 0.1405950 #> [5,]   0.2471562   0.5050429   0.2424030 0.005397913 0.8159972 0.1550385 #> [6,]   0.2282864   0.5039894   0.2617372 0.005987029 0.7968730 0.1705082 #>        Work.P.3     Work.P.4 Future.P.1 Future.P.2   Future.P.3   Future.P.4 #> [1,] 0.01717048 0.0007684150  0.9809133 0.01813820 0.0009339072 1.456036e-05 #> [2,] 0.01936274 0.0008685506  0.9761110 0.02269637 0.0011743453 1.831346e-05 #> [3,] 0.02182811 0.0009817226  0.9701371 0.02836330 0.0014765907 2.303394e-05 #> [4,] 0.02459876 0.0011096245  0.9627263 0.03538820 0.0018564770 2.897114e-05 #> [5,] 0.02771018 0.0012541689  0.9535646 0.04406509 0.0023338620 3.643864e-05 #> [6,] 0.03120137 0.0014175155  0.9422860 0.05473458 0.0029336324 4.583085e-05 #>      Benefit.P.1 Benefit.P.2 Benefit.P.3 Benefit.P.4 #> [1,]   0.7372533   0.2300751  0.03036097 0.002310633 #> [2,]   0.7155002   0.2481850  0.03373746 0.002577309 #> [3,]   0.6926969   0.2669559  0.03747256 0.002874673 #> [4,]   0.6689116   0.2862818  0.04160042 0.003206237 #> [5,]   0.6442308   0.3060358  0.04615750 0.003575906 #> [6,]   0.6187588   0.3260706  0.05118258 0.003988026"},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute posterior estimates of random effect — randef","title":"Compute posterior estimates of random effect — randef","text":"Stochastically compute random effects MixedClass objects Metropolis-Hastings samplers averaging draws obtain expected posteriori predictions. Returns list estimated effects.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute posterior estimates of random effect — randef","text":"","code":"randef(x, ndraws = 1000, thin = 10, return.draws = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute posterior estimates of random effect — randef","text":"x estimated model object mixedmirt function ndraws total number draws perform. Default 1000 thin amount thinning apply. Default use every 10th draw return.draws logical; return list containing thinned draws posterior?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute posterior estimates of random effect — randef","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models MH-RM Algorithm. Journal Educational Measurement, 52, 200-222. doi:10.1111/jedm.12072  doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute posterior estimates of random effect — randef","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/randef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute posterior estimates of random effect — randef","text":"","code":"# \\donttest{ # make an arbitrary groups covdat <- data.frame(group = rep(paste0('group', 1:49), each=nrow(Science)/49))  # partial credit model mod <- mixedmirt(Science, covdat, model=1, random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1915, Max-Change = 0.1573, Max-Change = 0.1007, Max-Change = 0.0881, Max-Change = 0.0682, Max-Change = 0.0656, Max-Change = 0.0356, Max-Change = 0.0255, Max-Change = 0.0751, Max-Change = 0.0268, Max-Change = 0.0304, Max-Change = 0.0229, Max-Change = 0.0200, Max-Change = 0.0445, Max-Change = 0.0308, Max-Change = 0.0444, Max-Change = 0.0135, Max-Change = 0.0410, Max-Change = 0.0253, Max-Change = 0.0290, Max-Change = 0.0157, Max-Change = 0.0171, Max-Change = 0.0140, Max-Change = 0.0117, Max-Change = 0.0350, Max-Change = 0.0598, Max-Change = 0.0187, Max-Change = 0.0132, Max-Change = 0.0261, Max-Change = 0.0297, Max-Change = 0.0074, Max-Change = 0.0052, Max-Change = 0.0281, Max-Change = 0.0186, Max-Change = 0.0302, Max-Change = 0.0417, Max-Change = 0.0215, Max-Change = 0.0501, Max-Change = 0.0178, Max-Change = 0.0388, Max-Change = 0.0248, Max-Change = 0.0528, Max-Change = 0.0227, Max-Change = 0.0224, Max-Change = 0.0226, Max-Change = 0.0182, Max-Change = 0.0037, Max-Change = 0.0091, Max-Change = 0.0254, Max-Change = 0.0213, Max-Change = 0.0231, Max-Change = 0.0188, Max-Change = 0.0261, Max-Change = 0.0165, Max-Change = 0.0136, Max-Change = 0.0445, Max-Change = 0.0255, Max-Change = 0.0269, Max-Change = 0.0198, Max-Change = 0.0410, Max-Change = 0.0160, Max-Change = 0.0145, Max-Change = 0.0096, Max-Change = 0.0160, Max-Change = 0.0495, Max-Change = 0.0382, Max-Change = 0.0194, Max-Change = 0.0273, Max-Change = 0.0555, Max-Change = 0.0118, Max-Change = 0.0238, Max-Change = 0.0052, Max-Change = 0.0371, Max-Change = 0.0250, Max-Change = 0.0414, Max-Change = 0.0157, Max-Change = 0.0294, Max-Change = 0.0270, Max-Change = 0.0228, Max-Change = 0.0059, Max-Change = 0.0323, Max-Change = 0.0277, Max-Change = 0.0092, Max-Change = 0.0094, Max-Change = 0.0214, Max-Change = 0.0300, Max-Change = 0.0302, Max-Change = 0.0401, Max-Change = 0.0091, Max-Change = 0.0820, Max-Change = 0.0138, Max-Change = 0.0163, Max-Change = 0.0619, Max-Change = 0.0539, Max-Change = 0.0059, Max-Change = 0.0250, Max-Change = 0.0126, Max-Change = 0.0472, Max-Change = 0.0278, Max-Change = 0.0999, Max-Change = 0.0248, Max-Change = 0.0933, Max-Change = 0.2000, Max-Change = 0.0784, Max-Change = 0.0183, Max-Change = 0.0312, Max-Change = 0.0170, Max-Change = 0.0667, Max-Change = 0.0366, Max-Change = 0.1640, Max-Change = 0.0398, Max-Change = 0.0143, Max-Change = 0.0223, Max-Change = 0.0374, Max-Change = 0.0143, Max-Change = 0.0153, Max-Change = 0.0348, Max-Change = 0.0118, Max-Change = 0.0261, Max-Change = 0.1477, Max-Change = 0.0443, Max-Change = 0.0091, Max-Change = 0.0144, Max-Change = 0.0168, Max-Change = 0.0444, Max-Change = 0.0190, Max-Change = 0.0157, Max-Change = 0.0231, Max-Change = 0.0213, Max-Change = 0.0231, Max-Change = 0.0278, Max-Change = 0.0082, Max-Change = 0.0440, Max-Change = 0.0320, Max-Change = 0.0238, Max-Change = 0.0408, Max-Change = 0.0082, Max-Change = 0.0251, Max-Change = 0.0223, Max-Change = 0.2000, Max-Change = 0.0111, Max-Change = 0.0245, Max-Change = 0.0052, Max-Change = 0.0256, Max-Change = 0.0124, Max-Change = 0.0316, Max-Change = 0.0363, Max-Change = 0.0302, Max-Change = 0.0088, Max-Change = 0.0356, Max-Change = 0.0298, Max-Change = 0.0329, Max-Change = 0.0517, Max-Change = 0.0219, Max-Change = 0.0085, Max-Change = 0.0108, Max-Change = 0.0283, Max-Change = 0.0234, Max-Change = 0.0235, Max-Change = 0.0381, Max-Change = 0.0311, Max-Change = 0.0693, Max-Change = 0.0397, Max-Change = 0.0596, Max-Change = 0.0471, Max-Change = 0.0343, Max-Change = 0.0371, Max-Change = 0.0371, Max-Change = 0.0160, Max-Change = 0.0327, Max-Change = 0.0152, Max-Change = 0.0242, Max-Change = 0.0370, Max-Change = 0.0250, Max-Change = 0.0365, Max-Change = 0.0145, Max-Change = 0.0242, Max-Change = 0.0182, Max-Change = 0.0203, Max-Change = 0.0343, Max-Change = 0.0251, Max-Change = 0.0231, Max-Change = 0.0061, Max-Change = 0.0145, Max-Change = 0.0328, Max-Change = 0.0212, Max-Change = 0.0181, Max-Change = 0.0260, Max-Change = 0.0101, Max-Change = 0.0139, Max-Change = 0.0107, Max-Change = 0.0053, Max-Change = 0.0552, Max-Change = 0.0186, Max-Change = 0.0305, Max-Change = 0.0174, Max-Change = 0.0232, Max-Change = 0.0176, Max-Change = 0.0055, Max-Change = 0.0257, Max-Change = 0.0202, Max-Change = 0.0191, Max-Change = 0.0085, Max-Change = 0.0236, Max-Change = 0.0117, Max-Change = 0.0123, Max-Change = 0.0412, Max-Change = 0.0324, Max-Change = 0.0294, Max-Change = 0.0184, Max-Change = 0.0159, Max-Change = 0.0174, Max-Change = 0.0132, Max-Change = 0.0290, Max-Change = 0.0222, Max-Change = 0.0331, Max-Change = 0.0446, Max-Change = 0.0547, Max-Change = 0.0381, Max-Change = 0.0320, Max-Change = 0.0527, Max-Change = 0.0478, Max-Change = 0.0351, Max-Change = 0.0380, Max-Change = 0.0211, Max-Change = 0.0213, Max-Change = 0.0547, Max-Change = 0.0155, Max-Change = 0.0092, Max-Change = 0.0178, Max-Change = 0.0393, Max-Change = 0.0074, Max-Change = 0.0178, Max-Change = 0.0199, Max-Change = 0.0740, Max-Change = 0.0120, Max-Change = 0.0230, Max-Change = 0.0285, Max-Change = 0.0158, Max-Change = 0.0081, Max-Change = 0.0257, Max-Change = 0.0076, Max-Change = 0.0203, Max-Change = 0.0119, Max-Change = 0.0317, Max-Change = 0.0153, Max-Change = 0.0327, Max-Change = 0.0362, Max-Change = 0.0118, Max-Change = 0.0187, Max-Change = 0.0571, Max-Change = 0.0288, Max-Change = 0.0133, Max-Change = 0.0365, Max-Change = 0.0157, Max-Change = 0.0135, Max-Change = 0.0211, Max-Change = 0.0368, Max-Change = 0.0104, Max-Change = 0.0265, Max-Change = 0.0138, Max-Change = 0.0203, Max-Change = 0.0366, Max-Change = 0.0227, Max-Change = 0.0356, Max-Change = 0.0329, Max-Change = 0.0566, Max-Change = 0.0124, Max-Change = 0.0127, Max-Change = 0.0163, Max-Change = 0.0133, Max-Change = 0.0307, Max-Change = 0.0247, Max-Change = 0.0069, Max-Change = 0.0221, Max-Change = 0.0158, Max-Change = 0.0242, Max-Change = 0.0052, Max-Change = 0.0228, Max-Change = 0.0170, Max-Change = 0.0107, Max-Change = 0.0293, Max-Change = 0.0277, Max-Change = 0.0145, Max-Change = 0.0471, Max-Change = 0.0053, Max-Change = 0.0236, Max-Change = 0.0284, Max-Change = 0.0147, Max-Change = 0.0189, Max-Change = 0.0147, Max-Change = 0.0253, Max-Change = 0.0429, Max-Change = 0.0081, Max-Change = 0.0276, Max-Change = 0.0364, Max-Change = 0.0184, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0217, gam = 0.1057, Max-Change = 0.0110, gam = 0.0780, Max-Change = 0.0088, gam = 0.0629, Max-Change = 0.0031, gam = 0.0532, Max-Change = 0.0044, gam = 0.0464, Max-Change = 0.0037, gam = 0.0413, Max-Change = 0.0045, gam = 0.0374, Max-Change = 0.0044, gam = 0.0342, Max-Change = 0.0029, gam = 0.0316, Max-Change = 0.0062, gam = 0.0294, Max-Change = 0.0045, gam = 0.0276, Max-Change = 0.0019, gam = 0.0260, Max-Change = 0.0010, gam = 0.0246, Max-Change = 0.0030, gam = 0.0233, Max-Change = 0.0011, gam = 0.0222, Max-Change = 0.0026, gam = 0.0212, Max-Change = 0.0026, gam = 0.0203, Max-Change = 0.0017, gam = 0.0195, Max-Change = 0.0023, gam = 0.0188, Max-Change = 0.0007, gam = 0.0181, Max-Change = 0.0036, gam = 0.0175, Max-Change = 0.0007, gam = 0.0169, Max-Change = 0.0025, gam = 0.0164, Max-Change = 0.0033, gam = 0.0159, Max-Change = 0.0020, gam = 0.0154, Max-Change = 0.0011, gam = 0.0150, Max-Change = 0.0030, gam = 0.0146, Max-Change = 0.0009, gam = 0.0142, Max-Change = 0.0022, gam = 0.0139, Max-Change = 0.0029, gam = 0.0135, Max-Change = 0.0014, gam = 0.0132, Max-Change = 0.0010, gam = 0.0129, Max-Change = 0.0010, gam = 0.0126, Max-Change = 0.0017, gam = 0.0124, Max-Change = 0.0010, gam = 0.0121, Max-Change = 0.0014, gam = 0.0119, Max-Change = 0.0025, gam = 0.0116, Max-Change = 0.0012, gam = 0.0114, Max-Change = 0.0010, gam = 0.0112, Max-Change = 0.0003, gam = 0.0110, Max-Change = 0.0009 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod) #>  #> Call: #> mixedmirt(data = Science, covdata = covdat, model = 1, random = ~1 |  #>     group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>      F1 #> F1 0.95 #>  #> $group #>           COV_group #> COV_group    0.0185 #>   effects <- randef(mod, ndraws = 2000, thin = 20) head(effects$Theta) #>               F1 #> [1,]  0.48376254 #> [2,]  0.02647082 #> [3,] -0.79617991 #> [4,] -0.61431286 #> [5,]  0.07214221 #> [6,]  0.95175232 head(effects$group) #>               group #> group1  0.018147425 #> group2 -0.010680763 #> group3 -0.017647082 #> group4  0.012056710 #> group5 -0.051149307 #> group6  0.006640287  # lr.random input mod2 <- mixedmirt(Science, covdat, model=1, lr.random = ~ 1|group) #> , Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.2000, Max-Change = 0.1915, Max-Change = 0.1573, Max-Change = 0.1007, Max-Change = 0.0881, Max-Change = 0.0682, Max-Change = 0.0656, Max-Change = 0.0356, Max-Change = 0.0255, Max-Change = 0.0751, Max-Change = 0.0268, Max-Change = 0.0304, Max-Change = 0.0229, Max-Change = 0.0200, Max-Change = 0.0445, Max-Change = 0.0308, Max-Change = 0.0444, Max-Change = 0.0135, Max-Change = 0.0410, Max-Change = 0.0253, Max-Change = 0.0290, Max-Change = 0.0157, Max-Change = 0.0171, Max-Change = 0.0140, Max-Change = 0.0117, Max-Change = 0.0350, Max-Change = 0.0598, Max-Change = 0.0187, Max-Change = 0.0132, Max-Change = 0.0261, Max-Change = 0.0297, Max-Change = 0.0074, Max-Change = 0.0052, Max-Change = 0.0281, Max-Change = 0.0186, Max-Change = 0.0302, Max-Change = 0.0417, Max-Change = 0.0215, Max-Change = 0.0501, Max-Change = 0.0178, Max-Change = 0.0388, Max-Change = 0.0248, Max-Change = 0.0528, Max-Change = 0.0227, Max-Change = 0.0224, Max-Change = 0.0226, Max-Change = 0.0182, Max-Change = 0.0037, Max-Change = 0.0091, Max-Change = 0.0254, Max-Change = 0.0213, Max-Change = 0.0231, Max-Change = 0.0188, Max-Change = 0.0261, Max-Change = 0.0165, Max-Change = 0.0136, Max-Change = 0.0445, Max-Change = 0.0255, Max-Change = 0.0269, Max-Change = 0.0198, Max-Change = 0.0410, Max-Change = 0.0160, Max-Change = 0.0145, Max-Change = 0.0096, Max-Change = 0.0160, Max-Change = 0.0495, Max-Change = 0.0382, Max-Change = 0.0194, Max-Change = 0.0273, Max-Change = 0.0555, Max-Change = 0.0118, Max-Change = 0.0238, Max-Change = 0.0052, Max-Change = 0.0371, Max-Change = 0.0250, Max-Change = 0.0414, Max-Change = 0.0157, Max-Change = 0.0294, Max-Change = 0.0270, Max-Change = 0.0228, Max-Change = 0.0059, Max-Change = 0.0323, Max-Change = 0.0277, Max-Change = 0.0092, Max-Change = 0.0094, Max-Change = 0.0214, Max-Change = 0.0300, Max-Change = 0.0302, Max-Change = 0.0401, Max-Change = 0.0091, Max-Change = 0.0820, Max-Change = 0.0138, Max-Change = 0.0163, Max-Change = 0.0619, Max-Change = 0.0539, Max-Change = 0.0059, Max-Change = 0.0250, Max-Change = 0.1899, Max-Change = 0.1933, Max-Change = 0.1280, Max-Change = 0.1086, Max-Change = 0.0546, Max-Change = 0.0750, Max-Change = 0.1542, Max-Change = 0.1966, Max-Change = 0.2000, Max-Change = 0.0711, Max-Change = 0.0324, Max-Change = 0.0147, Max-Change = 0.0462, Max-Change = 0.0279, Max-Change = 0.0309, Max-Change = 0.0194, Max-Change = 0.0733, Max-Change = 0.1374, Max-Change = 0.0180, Max-Change = 0.0347, Max-Change = 0.1197, Max-Change = 0.0132, Max-Change = 0.0149, Max-Change = 0.0380, Max-Change = 0.0629, Max-Change = 0.0111, Max-Change = 0.0315, Max-Change = 0.0404, Max-Change = 0.0238, Max-Change = 0.0206, Max-Change = 0.0161, Max-Change = 0.0327, Max-Change = 0.0365, Max-Change = 0.0163, Max-Change = 0.0540, Max-Change = 0.0262, Max-Change = 0.0420, Max-Change = 0.0280, Max-Change = 0.0219, Max-Change = 0.0658, Max-Change = 0.0245, Max-Change = 0.0234, Max-Change = 0.0276, Max-Change = 0.0224, Max-Change = 0.0245, Max-Change = 0.0237, Max-Change = 0.0184, Max-Change = 0.0427, Max-Change = 0.0290, Max-Change = 0.0313, Max-Change = 0.0370, Max-Change = 0.0373, Max-Change = 0.0347, Max-Change = 0.0522, Max-Change = 0.0189, Max-Change = 0.0250, Max-Change = 0.0195, Max-Change = 0.0284, Max-Change = 0.0366, Max-Change = 0.0176, Max-Change = 0.0289, Max-Change = 0.0262, Max-Change = 0.0490, Max-Change = 0.0336, Max-Change = 0.0446, Max-Change = 0.0192, Max-Change = 0.0195, Max-Change = 0.0348, Max-Change = 0.0537, Max-Change = 0.0329, Max-Change = 0.0317, Max-Change = 0.0398, Max-Change = 0.0264, Max-Change = 0.0277, Max-Change = 0.0317, Max-Change = 0.0294, Max-Change = 0.0340, Max-Change = 0.0406, Max-Change = 0.0338, Max-Change = 0.0178, Max-Change = 0.0254, Max-Change = 0.0089, Max-Change = 0.0878, Max-Change = 0.0468, Max-Change = 0.0329, Max-Change = 0.0246, Max-Change = 0.0071, Max-Change = 0.0205, Max-Change = 0.0308, Max-Change = 0.0178, Max-Change = 0.0359, Max-Change = 0.0225, Max-Change = 0.0100, Max-Change = 0.0261, Max-Change = 0.0228, Max-Change = 0.0223, Max-Change = 0.0326, Max-Change = 0.0343, Max-Change = 0.0368, Max-Change = 0.0338, Max-Change = 0.0122, Max-Change = 0.0081, Max-Change = 0.0109, Max-Change = 0.0453, Max-Change = 0.0249, Max-Change = 0.0423, Max-Change = 0.0133, Max-Change = 0.0187, Max-Change = 0.0289, Max-Change = 0.0234, Max-Change = 0.0390, Max-Change = 0.0520, Max-Change = 0.0172, Max-Change = 0.0222, Max-Change = 0.0316, Max-Change = 0.0104, Max-Change = 0.0097, Max-Change = 0.0311, Max-Change = 0.0140, Max-Change = 0.0150, Max-Change = 0.0247, Max-Change = 0.0106, Max-Change = 0.0261, Max-Change = 0.0283, Max-Change = 0.0419, Max-Change = 0.0289, Max-Change = 0.0121, Max-Change = 0.0154, Max-Change = 0.0470, Max-Change = 0.0236, Max-Change = 0.0899, Max-Change = 0.0252, Max-Change = 0.0080, Max-Change = 0.0071, Max-Change = 0.0292, Max-Change = 0.0153, Max-Change = 0.0314, Max-Change = 0.0378, Max-Change = 0.0465, Max-Change = 0.0288, Max-Change = 0.0138, Max-Change = 0.0226, Max-Change = 0.0142, Max-Change = 0.0498, Max-Change = 0.0157, Max-Change = 0.0099, Max-Change = 0.0156, Max-Change = 0.0520, Max-Change = 0.0221, Max-Change = 0.0362, Max-Change = 0.0481, gam = 0.0000, Max-Change = 0.0000, gam = 0.1778, Max-Change = 0.0163, gam = 0.1057, Max-Change = 0.0270, gam = 0.0780, Max-Change = 0.0130, gam = 0.0629, Max-Change = 0.0047, gam = 0.0532, Max-Change = 0.0046, gam = 0.0464, Max-Change = 0.0076, gam = 0.0413, Max-Change = 0.0048, gam = 0.0374, Max-Change = 0.0059, gam = 0.0342, Max-Change = 0.0076, gam = 0.0316, Max-Change = 0.0091, gam = 0.0294, Max-Change = 0.0013, gam = 0.0276, Max-Change = 0.0029, gam = 0.0260, Max-Change = 0.0009, gam = 0.0246, Max-Change = 0.0028, gam = 0.0233, Max-Change = 0.0025, gam = 0.0222, Max-Change = 0.0031, gam = 0.0212, Max-Change = 0.0024, gam = 0.0203, Max-Change = 0.0025, gam = 0.0195, Max-Change = 0.0061, gam = 0.0188, Max-Change = 0.0031, gam = 0.0181, Max-Change = 0.0017, gam = 0.0175, Max-Change = 0.0028, gam = 0.0169, Max-Change = 0.0032, gam = 0.0164, Max-Change = 0.0024, gam = 0.0159, Max-Change = 0.0015, gam = 0.0154, Max-Change = 0.0014, gam = 0.0150, Max-Change = 0.0011, gam = 0.0146, Max-Change = 0.0020, gam = 0.0142, Max-Change = 0.0023, gam = 0.0139, Max-Change = 0.0007, gam = 0.0135, Max-Change = 0.0029, gam = 0.0132, Max-Change = 0.0012, gam = 0.0129, Max-Change = 0.0026, gam = 0.0126, Max-Change = 0.0017, gam = 0.0124, Max-Change = 0.0004, gam = 0.0121, Max-Change = 0.0012, gam = 0.0119, Max-Change = 0.0013, gam = 0.0116, Max-Change = 0.0010, gam = 0.0114, Max-Change = 0.0014, gam = 0.0112, Max-Change = 0.0007, gam = 0.0110, Max-Change = 0.0017, gam = 0.0108, Max-Change = 0.0011, gam = 0.0106, Max-Change = 0.0008, gam = 0.0104, Max-Change = 0.0011, gam = 0.0102, Max-Change = 0.0021, gam = 0.0101, Max-Change = 0.0004, gam = 0.0099, Max-Change = 0.0005, gam = 0.0098, Max-Change = 0.0005 #>  #> Calculating information matrix... #>  #> Calculating log-likelihood... summary(mod2) #>  #> Call: #> mixedmirt(data = Science, covdata = covdat, model = 1, lr.random = ~1 |  #>     group) #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $Theta #>       F1 #> F1 0.969 #>  #>  #> -------------- #> RANDOM EFFECT COVARIANCE(S): #> Correlations on upper diagonal #>  #> $group #>           COV_group #> COV_group     0.284 #>   effects <- randef(mod2, ndraws = 2000) head(effects$Theta) #>              F1 #> [1,]  0.5394407 #> [2,]  0.1455433 #> [3,] -0.6378953 #> [4,] -0.6759862 #> [5,]  0.1386898 #> [6,]  0.9169677 head(effects$group) #>               group #> group1  0.114992688 #> group2 -0.005099345 #> group3 -0.419388182 #> group4 -0.295091225 #> group5  0.167373066 #> group6 -0.214672140  # }"},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate mirt parameters into suitable structure for plink package — read.mirt","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"function exports item parameters mirt package plink package.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"","code":"read.mirt(x, as.irt.pars = TRUE, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"x single object (list objects) returned mirt, bfactor, single object returned multipleGroup .irt.pars TRUE, parameters output irt.pars object ... additional arguments passed coef()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/read.mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Translate mirt parameters into suitable structure for plink package — read.mirt","text":"","code":"# \\donttest{  ## unidimensional library(plink)  data <- expand.table(LSAT7) (mod1 <- mirt(data, 1)) #>  #>  #> Call: #> mirt(data = data, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 28 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2658.805 #> Estimated parameters: 10  #> AIC = 5337.61 #> BIC = 5386.688; SABIC = 5354.927 #> G2 (21) = 31.7, p = 0.0628 #> RMSEA = 0.023, CFI = NaN, TLI = NaN plinkpars <- read.mirt(mod1) plot(plinkpars)  plot(mod1, type = 'trace')   # graded mod2 <- mirt(Science, 1) #>  plinkpars <- read.mirt(mod2) plot(plinkpars)  plot(mod2, type = 'trace')   # gpcm mod3 <- mirt(Science, 1, itemtype = 'gpcm') #>  plinkpars <- read.mirt(mod3) plot(plinkpars)  plot(mod3, type = 'trace')   # nominal mod4 <- mirt(Science, 1, itemtype = 'nominal') #>  plinkpars <- read.mirt(mod4) plot(plinkpars)  plot(mod4, type = 'trace')   ## multidimensional  data <- expand.table(LSAT7) (mod1 <- mirt(data, 2)) #>  #>  #> Call: #> mirt(data = data, model = 2) #>  #> Full-information item factor analysis with 2 factor(s). #> Converged within 1e-04 tolerance after 436 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 31 #> Latent density type: Gaussian  #>  #> Log-likelihood = -2653.52 #> Estimated parameters: 14  #> AIC = 5335.039 #> BIC = 5403.748; SABIC = 5359.283 #> G2 (17) = 21.13, p = 0.2205 #> RMSEA = 0.016, CFI = NaN, TLI = NaN plinkpars <- read.mirt(mod1) plinkpars #> An object of class \"irt.pars\" #> Slot \"pars\": #>              a1         a2             #> [1,] -2.0071991  0.8703411 2.6479286 0 #> [2,] -0.8488431 -0.5221152 0.7876390 0 #> [3,] -2.1529666 -1.8364974 2.4829603 0 #> [4,] -0.7559009 -0.0280359 0.4847286 0 #> [5,] -0.7572746  0.0000000 1.8640966 0 #>  #> Slot \"cat\": #> [1] 2 2 2 2 2 #>  #> Slot \"poly.mod\": #> An object of class \"poly.mod\" #> Slot \"model\": #> [1] \"drm\" #>  #> Slot \"items\": #> $drm #> [1] 1 2 3 4 5 #>  #>  #>  #> Slot \"common\": #> NULL #>  #> Slot \"location\": #> [1] FALSE #>  #> Slot \"groups\": #> [1] 1 #>  #> Slot \"dimensions\": #> [1] 2 #>  plot(plinkpars)  plot(mod1, type = 'trace')   cmod <- mirt.model('    F1 = 1,4,5    F2 = 2-4') model <- mirt(data, cmod) #>  plot(read.mirt(model))  itemplot(model, 1)   # graded mod2 <- mirt(Science, 2) #>  plinkpars <- read.mirt(mod2) plinkpars #> An object of class \"irt.pars\" #> Slot \"pars\": #>              a1         a2       b1       b2        b3 #> [1,] -1.3350281 0.09676376 5.210669 2.865549 -1.602826 #> [2,] -0.8789508 1.85253465 3.703802 1.153176 -2.904255 #> [3,] -1.4696076 1.16485648 4.663467 1.956626 -1.735796 #> [4,] -1.7220434 0.00000000 3.988789 1.195247 -2.043998 #>  #> Slot \"cat\": #> [1] 4 4 4 4 #>  #> Slot \"poly.mod\": #> An object of class \"poly.mod\" #> Slot \"model\": #> [1] \"grm\" #>  #> Slot \"items\": #> $grm #> [1] 1 2 3 4 #>  #>  #>  #> Slot \"common\": #> NULL #>  #> Slot \"location\": #> [1] FALSE #>  #> Slot \"groups\": #> [1] 1 #>  #> Slot \"dimensions\": #> [1] 2 #>  plot(plinkpars)  plot(mod2, type = 'trace')   ### multiple group equating example set.seed(1234) dat <- expand.table(LSAT7) group <- sample(c('g1', 'g2'), nrow(dat), TRUE) dat1 <- dat[group == 'g1', ] dat2 <- dat[group == 'g2', ] mod1 <- mirt(dat1, 1) #>  mod2 <- mirt(dat2, 1) #>   # convert and combine pars plinkMG <- read.mirt(list(g1=mod1, g2=mod2))  # equivalently: # mod <- multipleGroup(dat, 1, group) # plinkMG <- read.mirt(mod)  combine <- matrix(1:5, 5, 2) comb <- combine.pars(plinkMG, combine, grp.names=unique(group)) out <- plink(comb, rescale=\"SL\") equate(out) #> Maximum iterations reached for true score: 0  #> $tse #>         theta g2       g1 #> 1 -160.732949  0 0.000000 #> 2   -3.233741  1 0.973481 #> 3   -1.910192  2 2.023409 #> 4   -0.999050  3 3.021848 #> 5    0.048359  4 3.973672 #> 6   57.411786  5 5.000000 #>  #> $ose #> $ose$scores #>   eap.theta.g2 eap.sd.g2 g2        g1 #> 1    -1.896444  0.698843  0 0.0000000 #> 2    -1.474472  0.697610  1 0.9893317 #> 3    -1.002953  0.716007  2 1.9956600 #> 4    -0.455590  0.747730  3 2.9912425 #> 5     0.123384  0.782773  4 3.9901784 #> 6     0.678747  0.812793  5 4.9949444 #>  #> $ose$dist #> $ose$dist$g2 #>      score       pop1       pop2        syn #> [1,]     0 0.03273187 0.03273187 0.03273187 #> [2,]     1 0.17343742 0.17343742 0.17343742 #> [3,]     2 0.48733074 0.48733074 0.48733074 #> [4,]     3 0.99873451 0.99873451 0.99873451 #> [5,]     4 1.61799716 1.61799716 1.61799716 #> [6,]     5 1.56457520 1.56457520 1.56457520 #>  #> $ose$dist$g1 #>      score      pop1      pop2       syn #> [1,]     0 0.0338755 0.0338755 0.0338755 #> [2,]     1 0.1748815 0.1748815 0.1748815 #> [3,]     2 0.4863770 0.4863770 0.4863770 #> [4,]     3 1.0132130 1.0132130 1.0132130 #> [5,]     4 1.6175460 1.6175460 1.6175460 #> [6,]     5 1.5489139 1.5489139 1.5489139 #>  #>  #>  equate(out, method = 'OSE') #> $scores #>   eap.theta.g2 eap.sd.g2 g2        g1 #> 1    -1.896444  0.698843  0 0.0000000 #> 2    -1.474472  0.697610  1 0.9893317 #> 3    -1.002953  0.716007  2 1.9956600 #> 4    -0.455590  0.747730  3 2.9912425 #> 5     0.123384  0.782773  4 3.9901784 #> 6     0.678747  0.812793  5 4.9949444 #>  #> $dist #> $dist$g2 #>      score       pop1       pop2        syn #> [1,]     0 0.03273187 0.03273187 0.03273187 #> [2,]     1 0.17343742 0.17343742 0.17343742 #> [3,]     2 0.48733074 0.48733074 0.48733074 #> [4,]     3 0.99873451 0.99873451 0.99873451 #> [5,]     4 1.61799716 1.61799716 1.61799716 #> [6,]     5 1.56457520 1.56457520 1.56457520 #>  #> $dist$g1 #>      score      pop1      pop2       syn #> [1,]     0 0.0338755 0.0338755 0.0338755 #> [2,]     1 0.1748815 0.1748815 0.1748815 #> [3,]     2 0.4863770 0.4863770 0.4863770 #> [4,]     3 1.0132130 1.0132130 1.0132130 #> [5,]     4 1.6175460 1.6175460 1.6175460 #> [6,]     5 1.5489139 1.5489139 1.5489139 #>  #>   # }"},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Remap item categories to have integer distances of 1 — remap.distance","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"mirt package's estimation setup requires item responses spaces equal 1 (e.g., Likert scale scored 1 5). event categories missing categories must re-coded. function automatically called package estimation functions (e.g., mirt), however convince function extracted users better understand remapping consequences.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"","code":"remap.distance(data, message = TRUE)"},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"data response data remap data.frame matrix message logical; print message information pertaining items remapped?","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/remap.distance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remap item categories to have integer distances of 1 — remap.distance","text":"","code":"# category 2 for item 1 missing dat <- Science dat[,1] <- ifelse(Science[,1] == 2, 1, Science[,1]) apply(dat, 2, table) #> $Comfort #>  #>   1   3   4  #>  37 266  89  #>  #> $Work #>  #>   1   2   3   4  #>  33  98 206  55  #>  #> $Future #>  #>   1   2   3   4  #>  14  72 210  96  #>  #> $Benefit #>  #>   1   2   3   4  #>  21 100 193  78  #>   # mirt() automatically remaps categories mod <- mirt(dat, 1) #> \"Comfort\" re-mapped to ensure all categories have a distance of 1 #>  coef(mod, simplify=TRUE) #> $items #>            a1    d1     d2     d3 #> Comfort 0.995 2.626 -1.447     NA #> Work    1.231 2.928  0.903 -2.271 #> Future  2.338 5.293  2.245 -1.989 #> Benefit 1.079 3.333  0.988 -1.681 #>  #> $means #> F1  #>  0  #>  #> $cov #>    F1 #> F1  1 #>   # this is the transformed data used by mirt() remap_dat <- remap.distance(dat) #> \"Comfort\" re-mapped to ensure all categories have a distance of 1 apply(remap_dat, 2, table) #> $Comfort #>  #>   1   2   3  #>  37 266  89  #>  #> $Work #>  #>   1   2   3   4  #>  33  98 206  55  #>  #> $Future #>  #>   1   2   3   4  #>  14  72 210  96  #>  #> $Benefit #>  #>   1   2   3   4  #>  21 100 193  78  #>"},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute model residuals — residuals-method","title":"Compute model residuals — residuals-method","text":"Return model implied residuals linear dependencies items person level. latent trait density approximated (e.g., Davidian curves, Empirical histograms, etc) passing use_dentype_estimate = TRUE use internally saved quadrature density components (applicable).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute model residuals — residuals-method","text":"","code":"# S4 method for class 'SingleGroupClass' residuals(   object,   type = \"LD\",   p.adjust = \"none\",   df.p = FALSE,   approx.z = FALSE,   full.scores = FALSE,   QMC = FALSE,   printvalue = NULL,   tables = FALSE,   verbose = TRUE,   Theta = NULL,   suppress = NA,   theta_lim = c(-6, 6),   quadpts = NULL,   fold = TRUE,   upper = TRUE,   technical = list(),   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute model residuals — residuals-method","text":"object object class SingleGroupClass MultipleGroupClass. Bifactor models automatically detected utilized better accuracy type type residuals displayed. Can either 'LD' 'LDG2' local dependence matrix based X2 G2 statistics (Chen & Thissen, 1997), 'Q3' statistic proposed Yen (1984), 'JSI' jack-knife statistic proposed Edwards et al. (2018), 'exp' expected values frequencies every response pattern, 'expfull' expected values every theoretically observable response pattern. 'LD' 'LDG2' types, upper diagonal elements represent standardized residuals form signed Cramers V coefficients p.adjust method use adjusting p-values (see p.adjust available options). Default 'none' df.p logical; print degrees freedom p-values? approx.z logical; transform \\(\\chi^2(df)\\) information LD tests approximate z-ratios instead using transformation \\(z=\\sqrt{2 * \\chi^2} - \\sqrt{2 * df - 1}\\)? full.scores logical; compute relevant statistics subject original data? QMC logical; use quasi-Monte Carlo integration? quadpts omitted default number nodes 5000 printvalue numeric value specified using res='exp' option. prints patterns standardized residuals greater abs(printvalue). default (NULL) prints response patterns tables logical; LD type, return observed, expected, standardized residual tables item combination? verbose logical; allow information printed console? Theta matrix factor scores used statistics require empirical estimates (.e., Q3). supplied, arguments typically passed fscores() ignored values used instead suppress numeric value indicating parameter local dependency combinations flag high (LD, LDG2, Q3 standardize correlations used; JSI, z-ratios used). Absolute values standardized estimates greater value returned, values less value set missing theta_lim range integration grid quadpts number quadrature nodes use. default extracted model (available) generated automatically available fold logical; apply sum 'folding' described Edwards et al. (2018) JSI statistic? upper logical; portion matrix (upper versus lower triangle) suppress argument applied ? technical list technical arguments models re-estimated (see mirt details) ... additional arguments passed fscores()","code":""},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute model residuals — residuals-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Chen, W. H. & Thissen, D. (1997). Local dependence indices item pairs using item response theory. Journal Educational Behavioral Statistics, 22, 265-289. Edwards, M. C., Houts, C. R. & Cai, L. (2018). Diagnostic Procedure Detect Departures Local Independence Item Response Theory Models. Psychological Methods, 23, 138-149. Yen, W. (1984). Effects local item dependence fit equating performance three parameter logistic model. Applied Psychological Measurement, 8, 125-145.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/residuals-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute model residuals — residuals-method","text":"","code":"# \\donttest{  x <- mirt(Science, 1) #>  residuals(x) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.147  -0.136  -0.111  -0.045   0.041   0.152  #>  #>         Comfort   Work Future Benefit #> Comfort         -0.147 -0.101   0.152 #> Work     25.512         0.088  -0.141 #> Future   12.002  9.208         -0.122 #> Benefit  27.321 23.235 17.461         residuals(x, tables = TRUE) #> $Comfort_Work #> $Comfort_Work$Obs #>     #>       1   2   3   4 #>   1   2   0   1   2 #>   2   2  11  15   4 #>   3  24  71 148  23 #>   4   5  16  42  26 #>  #> $Comfort_Work$Exp #>           [,1]      [,2]       [,3]      [,4] #> [1,]  1.046123  1.787854   1.922925  0.262908 #> [2,]  5.722535 11.386923  13.625623  1.972172 #> [3,] 23.322258 69.348472 140.029013 31.718143 #> [4,]  3.487224 14.109434  50.763258 21.495135 #>  #> $Comfort_Work$std_res #>     #>              1          2          3          4 #>   1  0.9326115 -1.3371066 -0.6655567  3.3878247 #>   2 -1.5561252 -0.1146625  0.3723298  1.4439717 #>   3  0.1403392  0.1983204  0.6736015 -1.5479971 #>   4  0.8100928  0.5033119 -1.2299596  0.9716541 #>  #>  #> $Comfort_Future #> $Comfort_Future$Obs #>     #>       1   2   3   4 #>   1   2   2   1   0 #>   2   3  11  11   7 #>   3   8  51 155  52 #>   4   1   8  43  37 #>  #> $Comfort_Future$Exp #>           [,1]      [,2]       [,3]       [,4] #> [1,] 0.7680477  1.812936   2.091572  0.3472546 #> [2,] 3.6749826 11.241583  15.084907  2.7057791 #> [3,] 9.1976778 52.384929 148.579175 54.2561060 #> [4,] 0.7527106  6.828614  42.541147 39.7325783 #>  #> $Comfort_Future$std_res #>     #>               1           2           3           4 #>   1  1.40572316  0.13893088 -0.75477217 -0.58928310 #>   2 -0.35209910 -0.07205318 -1.05174604  2.61058722 #>   3 -0.39491253 -0.19134814  0.52675890 -0.30629167 #>   4  0.28503062  0.44826372  0.07035076 -0.43351011 #>  #>  #> $Comfort_Benefit #> $Comfort_Benefit$Obs #>     #>       1   2   3   4 #>   1   4   0   1   0 #>   2   5  10  13   4 #>   3  11  81 133  41 #>   4   1   9  46  33 #>  #> $Comfort_Benefit$Exp #>            [,1]     [,2]       [,3]       [,4] #> [1,]  0.6710457  1.95217   1.959779  0.4368153 #> [2,]  3.6241191 12.16983  13.682082  3.2312240 #> [3,] 14.8454892 71.28246 131.343241 46.9466978 #> [4,]  2.3173267 14.55596  44.803655 28.1781067 #>  #> $Comfort_Benefit$std_res #>     #>              1          2          3          4 #>   1  4.0637950 -1.3972006 -0.6855953 -0.6609200 #>   2  0.7227359 -0.6219892 -0.1844000  0.4276774 #>   3 -0.9980547  1.1509727  0.1445624 -0.8679073 #>   4 -0.8653661 -1.4562597  0.1787310  0.9083677 #>  #>  #> $Work_Future #> $Work_Future$Obs #>     #>       1   2   3   4 #>   1   7  10  14   2 #>   2   3  28  57  10 #>   3   3  31 122  50 #>   4   1   3  17  34 #>  #> $Work_Future$Exp #>           [,1]      [,2]      [,3]      [,4] #> [1,] 4.6004355 12.483087  14.34426  2.150355 #> [2,] 5.8020446 27.786418  52.26417 10.780046 #> [3,] 3.6903551 28.936581 118.01439 55.699488 #> [4,] 0.3005835  3.061977  23.67397 28.411829 #>  #> $Work_Future$std_res #>     #>               1           2           3           4 #>   1  1.11874979 -0.70279865 -0.09089724 -0.10253275 #>   2 -1.16328067  0.04051800  0.65507895 -0.23757996 #>   3 -0.35936723  0.38358699  0.36688237 -0.76367799 #>   4  1.27571400 -0.03541829 -1.37166696  1.04838334 #>  #>  #> $Work_Benefit #> $Work_Benefit$Obs #>     #>       1   2   3   4 #>   1   4   8  12   9 #>   2   6  34  47  11 #>   3   8  52 111  35 #>   4   3   6  23  23 #>  #> $Work_Benefit$Exp #>          [,1]      [,2]      [,3]      [,4] #> [1,] 4.233251 13.170723  13.31610  2.858063 #> [2,] 7.660483 32.196149  44.96112 11.814929 #> [3,] 8.417022 46.931424 106.55195 44.440425 #> [4,] 1.147224  7.662122  26.95958 19.679427 #>  #> $Work_Benefit$std_res #>     #>              1          2          3          4 #>   1 -0.1133671 -1.4247756 -0.3606627  3.6330344 #>   2 -0.5999380  0.3179060  0.3040694 -0.2370851 #>   3 -0.1437407  0.7398678  0.4309125 -1.4161278 #>   4  1.7298113 -0.6004660 -0.7625934  0.7485258 #>  #>  #> $Future_Benefit #> $Future_Benefit$Obs #>     #>       1   2   3   4 #>   1   5   1   6   2 #>   2   5  32  30   5 #>   3   8  53 118  31 #>   4   3  14  39  40 #>  #> $Future_Benefit$Exp #>          [,1]      [,2]       [,3]       [,4] #> [1,] 2.960508  6.706374   4.143629  0.5829072 #> [2,] 7.760422 29.142832  29.887302  5.4775063 #> [3,] 9.227453 52.779344 109.948223 36.3417805 #> [4,] 1.509597 11.331867  47.809604 36.3906499 #>  #> $Future_Benefit$std_res #>     #>               1           2           3           4 #>   1  1.18532911 -2.20351681  0.91195681  1.85608815 #>   2 -0.99090687  0.52926095  0.02061456 -0.20402700 #>   3 -0.40407692  0.03037266  0.76788760 -0.88610042 #>   4  1.21303423  0.79260501 -1.27408623  0.59832081 #>  #>  residuals(x, type = 'exp') #>    Comfort Work Future Benefit freq    exp std.res #> 1        1    1      1       1    2  0.124   5.324 #> 2        1    3      2       1    1  0.067   3.605 #> 3        1    4      2       3    1  0.019   7.046 #> 4        1    4      3       1    1  0.006  12.642 #> 5        2    1      1       1    1  0.460   0.796 #> 6        2    1      2       4    1  0.095   2.930 #> 7        2    2      1       1    1  0.351   1.095 #> 8        2    2      2       2    4  2.147   1.264 #> 9        2    2      2       3    2  1.616   0.302 #> 10       2    2      3       1    1  0.377   1.015 #> 11       2    2      3       2    1  1.716  -0.547 #> 12       2    2      3       3    1  2.228  -0.823 #> 13       2    2      4       3    1  0.251   1.497 #> 14       2    3      1       3    1  0.213   1.707 #> 15       2    3      2       2    2  1.545   0.366 #> 16       2    3      2       3    1  1.489  -0.401 #> 17       2    3      3       2    3  2.248   0.502 #> 18       2    3      3       3    3  3.910  -0.460 #> 19       2    3      3       4    2  1.035   0.948 #> 20       2    3      4       1    1  0.041   4.763 #> 21       2    3      4       3    2  0.866   1.218 #> 22       2    4      2       1    1  0.029   5.690 #> 23       2    4      4       3    2  0.259   3.418 #> 24       2    4      4       4    1  0.184   1.902 #> 25       3    1      1       1    1  0.644   0.444 #> 26       3    1      1       3    2  0.638   1.705 #> 27       3    1      2       2    2  3.923  -0.971 #> 28       3    1      2       3    4  3.077   0.526 #> 29       3    1      3       2    5  3.567   0.759 #> 30       3    1      3       3    5  5.097  -0.043 #> 31       3    1      3       4    3  1.160   1.709 #> 32       3    1      4       3    1  0.764   0.269 #> 33       3    1      4       4    1  0.320   1.203 #> 34       3    2      1       2    1  1.781  -0.585 #> 35       3    2      1       4    1  0.154   2.157 #> 36       3    2      2       1    1  2.250  -0.833 #> 37       3    2      2       2   10  8.471   0.525 #> 38       3    2      2       3    7  8.067  -0.376 #> 39       3    2      3       1    1  2.221  -0.819 #> 40       3    2      3       2   16 11.743   1.242 #> 41       3    2      3       3   22 19.584   0.546 #> 42       3    2      3       4    5  4.950   0.023 #> 43       3    2      4       1    1  0.193   1.835 #> 44       3    2      4       2    1  1.293  -0.258 #> 45       3    2      4       3    3  3.778  -0.400 #> 46       3    2      4       4    2  1.716   0.217 #> 47       3    3      1       3    2  0.971   1.044 #> 48       3    3      2       1    1  1.764  -0.575 #> 49       3    3      2       2   13  7.852   1.837 #> 50       3    3      2       3   10  9.780   0.070 #> 51       3    3      2       4    2  1.975   0.018 #> 52       3    3      3       1    5  3.363   0.893 #> 53       3    3      3       2   23 20.447   0.565 #> 54       3    3      3       3   52 45.243   1.005 #> 55       3    3      3       4    8 14.757  -1.759 #> 56       3    3      4       2    7  4.389   1.246 #> 57       3    3      4       3   13 16.979  -0.966 #> 58       3    3      4       4   12 10.323   0.522 #> 59       3    4      1       3    1  0.090   3.030 #> 60       3    4      2       3    1  1.098  -0.093 #> 61       3    4      3       2    2  3.043  -0.598 #> 62       3    4      3       3    4  8.562  -1.559 #> 63       3    4      3       4    4  3.637   0.191 #> 64       3    4      4       1    1  0.160   2.100 #> 65       3    4      4       2    1  1.287  -0.253 #> 66       3    4      4       3    6  6.466  -0.183 #> 67       3    4      4       4    3  5.659  -1.118 #> 68       4    1      1       4    1  0.006  12.587 #> 69       4    1      2       2    1  0.325   1.183 #> 70       4    1      2       4    2  0.057   8.158 #> 71       4    1      3       4    1  0.300   1.278 #> 72       4    2      2       1    1  0.193   1.836 #> 73       4    2      2       3    3  1.017   1.967 #> 74       4    2      3       3    8  4.462   1.675 #> 75       4    2      3       4    2  1.448   0.459 #> 76       4    2      4       2    1  0.433   0.862 #> 77       4    2      4       4    1  1.080  -0.077 #> 78       4    3      2       3    1  1.665  -0.516 #> 79       4    3      3       2    2  4.874  -1.302 #> 80       4    3      3       3   21 14.002   1.870 #> 81       4    3      3       4    3  5.965  -1.214 #> 82       4    3      4       2    2  2.097  -0.067 #> 83       4    3      4       3    5 10.419  -1.679 #> 84       4    3      4       4    8  8.830  -0.279 #> 85       4    4      3       2    1  0.966   0.034 #> 86       4    4      3       3    2  3.571  -0.831 #> 87       4    4      3       4    3  2.063   0.652 #> 88       4    4      4       2    2  0.906   1.149 #> 89       4    4      4       3    6  5.780   0.092 #> 90       4    4      4       4   12  7.470   1.657 residuals(x, suppress = .15) #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.147  -0.136  -0.111  -0.045   0.041   0.152  #>  #>         Comfort Work Future Benefit #> Comfort                       0.152 #> Work                                #> Future                              #> Benefit  27.321                     residuals(x, df.p = TRUE) #> Degrees of freedom (lower triangle) and p-values: #>  #>         Comfort  Work Future Benefit #> Comfort         0.002  0.213   0.001 #> Work          9        0.418   0.006 #> Future        9 9.000          0.042 #> Benefit       9 9.000  9.000         #>  #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.147  -0.136  -0.111  -0.045   0.041   0.152  #>  #>         Comfort   Work Future Benefit #> Comfort         -0.147 -0.101   0.152 #> Work     25.512         0.088  -0.141 #> Future   12.002  9.208         -0.122 #> Benefit  27.321 23.235 17.461         residuals(x, df.p = TRUE, p.adjust = 'fdr') # apply FWE control #> Degrees of freedom (lower triangle) and p-values: #>  #>         Comfort  Work Future Benefit #> Comfort         0.007  0.256   0.007 #> Work          9        0.418   0.011 #> Future        9 9.000          0.063 #> Benefit       9 9.000  9.000         #>  #> LD matrix (lower triangle) and standardized residual correlations (upper triangle) #>  #> Upper triangle summary: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.147  -0.136  -0.111  -0.045   0.041   0.152  #>  #>         Comfort   Work Future Benefit #> Comfort         -0.147 -0.101   0.152 #> Work     25.512         0.088  -0.141 #> Future   12.002  9.208         -0.122 #> Benefit  27.321 23.235 17.461          # Pearson's X2 estimate for goodness-of-fit full_table <- residuals(x, type = 'expfull') head(full_table) #>   Comfort Work Future Benefit freq   exp    res #> 1       1    1      1       1    2 0.124  5.324 #> 2       1    1      1       2    0 0.160 -0.400 #> 3       1    1      1       3    0 0.054 -0.233 #> 4       1    1      1       4    0 0.005 -0.073 #> 5       1    1      2       1    0 0.092 -0.303 #> 6       1    1      2       2    0 0.219 -0.468 X2 <- with(full_table, sum((freq - exp)^2 / exp)) df <- nrow(full_table) - extract.mirt(x, 'nest') - 1 p <- pchisq(X2, df = df, lower.tail=FALSE) data.frame(X2, df, p, row.names='Pearson-X2') #>                  X2  df            p #> Pearson-X2 689.3347 239 2.942933e-45  # above FOG test as a function PearsonX2 <- function(x){    full_table <- residuals(x, type = 'expfull')    X2 <- with(full_table, sum((freq - exp)^2 / exp))    df <- nrow(full_table) - extract.mirt(x, 'nest') - 1    p <- pchisq(X2, df = df, lower.tail=FALSE)    data.frame(X2, df, p, row.names='Pearson-X2') } PearsonX2(x) #>                  X2  df            p #> Pearson-X2 689.3347 239 2.942933e-45   # extract results manually out <- residuals(x, df.p = TRUE, verbose=FALSE) str(out) #> List of 2 #>  $ df.p: 'mirt_matrix' num [1:4, 1:4] NA 9 9 9 0.00245 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"Comfort\" \"Work\" \"Future\" \"Benefit\" #>   .. ..$ : chr [1:4] \"Comfort\" \"Work\" \"Future\" \"Benefit\" #>  $ LD  : 'mirt_matrix' num [1:4, 1:4] NA 25.512 12.002 27.321 -0.147 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4] \"Comfort\" \"Work\" \"Future\" \"Benefit\" #>   .. ..$ : chr [1:4] \"Comfort\" \"Work\" \"Future\" \"Benefit\" out$df.p[1,2] #> [1] 0.002454207  # with and without supplied factor scores Theta <- fscores(x) residuals(x, type = 'Q3', Theta=Theta) #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"graded\", Theta = \"mirt_matrix\"’ residuals(x, type = 'Q3', method = 'ML') #> Error: unable to find an inherited method for function ‘ProbTrace’ for signature ‘x = \"graded\", Theta = \"mirt_matrix\"’  # Edwards et al. (2018) JSI statistic N <- 250 a <- rnorm(10, 1.7, 0.3) d <- rnorm(10) dat <- simdata(a, d, N=250, itemtype = '2PL')  mod <- mirt(dat, 1) #>  residuals(mod, type = 'JSI') #> JSI summary statistics: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.751  -0.239  -0.057  -0.016   0.243   0.754  #>  #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1         -0.049 -0.222 -0.081 -0.751  0.108  0.355 -0.327 -0.018   0.703 #> Item_2  -0.049         0.245  0.754 -0.057  0.146 -0.531 -0.357 -0.339   0.370 #> Item_3  -0.222  0.245        -0.696  0.243 -0.059 -0.505  0.115  0.535  -0.027 #> Item_4  -0.081  0.754 -0.696         0.127  0.252 -0.088  0.318 -0.239  -0.249 #> Item_5  -0.751 -0.057  0.243  0.127         0.461 -0.156 -0.107  0.252  -0.249 #> Item_6   0.108  0.146 -0.059  0.252  0.461        -0.152 -0.356 -0.006  -0.310 #> Item_7   0.355 -0.531 -0.505 -0.088 -0.156 -0.152         0.234  0.188  -0.236 #> Item_8  -0.327 -0.357  0.115  0.318 -0.107 -0.356  0.234        -0.151   0.389 #> Item_9  -0.018 -0.339  0.535 -0.239  0.252 -0.006  0.188 -0.151         -0.215 #> Item_10  0.703  0.370 -0.027 -0.249 -0.249 -0.310 -0.236  0.389 -0.215         residuals(mod, type = 'JSI', fold=FALSE) # unfolded #> JSI summary statistics: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -0.480  -0.121  -0.029  -0.008   0.107   0.419  #>  #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1         -0.058 -0.075 -0.038 -0.480  0.044  0.234 -0.168 -0.022   0.371 #> Item_2   0.009         0.166  0.419 -0.004  0.078 -0.250 -0.201 -0.196   0.197 #> Item_3  -0.148  0.079        -0.377  0.180 -0.054 -0.232  0.045  0.275  -0.017 #> Item_4  -0.043  0.335 -0.319         0.070  0.114 -0.035  0.152 -0.122  -0.115 #> Item_5  -0.272 -0.053  0.063  0.056         0.142 -0.089 -0.059  0.081  -0.093 #> Item_6   0.064  0.068 -0.005  0.139  0.319        -0.048 -0.195 -0.008  -0.175 #> Item_7   0.120 -0.281 -0.273 -0.052 -0.066 -0.104         0.109  0.099  -0.137 #> Item_8  -0.159 -0.155  0.071  0.166 -0.049 -0.161  0.125        -0.073   0.198 #> Item_9   0.004 -0.143  0.260 -0.117  0.171  0.003  0.089 -0.078         -0.098 #> Item_10  0.332  0.172 -0.010 -0.134 -0.155 -0.136 -0.099  0.191 -0.117          # LD between items 1-2 aLD <- numeric(10) aLD[1:2] <- rnorm(2, 2.55, 0.15) a2 <- cbind(a, aLD) dat <- simdata(a2, d, N=250, itemtype = '2PL')  mod <- mirt(dat, 1) #>   # JSI executed in parallel over multiple cores if(interactive()) mirtCluster() residuals(mod, type = 'JSI') #> JSI summary statistics: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  -1.142  -0.427  -0.071   0.032   0.437   2.777  #>  #>         Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> Item_1          2.777 -0.427 -0.734 -0.783 -0.090 -0.312 -0.741 -0.860   0.740 #> Item_2   2.777        -0.121 -0.338 -0.624 -0.882 -0.071 -0.600 -0.698   0.418 #> Item_3  -0.427 -0.121         1.148  0.192 -1.142  0.589 -0.247  0.166   0.145 #> Item_4  -0.734 -0.338  1.148         0.517 -0.257 -0.010  0.038  0.496  -0.328 #> Item_5  -0.783 -0.624  0.192  0.517         0.576  0.281  0.092  0.482  -0.226 #> Item_6  -0.090 -0.882 -1.142 -0.257  0.576        -0.158  1.277  0.437   0.982 #> Item_7  -0.312 -0.071  0.589 -0.010  0.281 -0.158         0.398  0.118  -0.637 #> Item_8  -0.741 -0.600 -0.247  0.038  0.092  1.277  0.398         0.780  -0.274 #> Item_9  -0.860 -0.698  0.166  0.496  0.482  0.437  0.118  0.780         -0.672 #> Item_10  0.740  0.418  0.145 -0.328 -0.226  0.982 -0.637 -0.274 -0.672          # }"},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse score one or more items from a response matrix — reverse.score","title":"Reverse score one or more items from a response matrix — reverse.score","text":"Reverse score specific items given empirical range specific scoring range.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse score one or more items from a response matrix — reverse.score","text":"","code":"reverse.score(data, which, range = NULL, append = \".RS\")"},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse score one or more items from a response matrix — reverse.score","text":"data object class data.frame, matrix, table response patterns names items column integer location data rescored. missing columns data reverse scored range (optional) named list specify low high score ranges. Specified names must match names found data, element list contain two values. items specified omitted list empirical min/max information used instead append character vector indicating append item names rescored","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse score one or more items from a response matrix — reverse.score","text":"returns original data object specified   items reverse scored replacing original scoring scheme","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reverse score one or more items from a response matrix — reverse.score","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reverse score one or more items from a response matrix — reverse.score","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/reverse.score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reverse score one or more items from a response matrix — reverse.score","text":"","code":"a <- rlnorm(20) a[c(1,5,10)] <- -a[c(1,5,10)] diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(20) dat <- simdata(a,d,itemtype='graded', N=300) head(dat) #>      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> [1,]      4      4      2      4      4      4      2      4      4       0 #> [2,]      4      4      1      2      4      0      4      0      4       0 #> [3,]      3      0      4      0      4      0      4      0      0       0 #> [4,]      0      4      3      4      4      4      4      4      4       0 #> [5,]      0      0      0      1      4      4      0      1      1       1 #> [6,]      1      0      0      0      3      1      3      0      0       0 #>      Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19 #> [1,]       4       4       0       4       4       4       1       4       1 #> [2,]       4       0       2       4       4       2       0       1       4 #> [3,]       4       2       0       0       0       2       0       1       4 #> [4,]       4       4       3       4       4       4       4       4       4 #> [5,]       4       2       1       0       4       2       2       4       3 #> [6,]       0       4       3       3       1       1       0       1       2 #>      Item_20 #> [1,]       4 #> [2,]       4 #> [3,]       3 #> [4,]       4 #> [5,]       0 #> [6,]       4  # \\donttest{ # fitted model has negative slopes due to flipped scoring mod <- mirt(dat) #>  coef(mod, simplify=TRUE)$items #>                 a1         d1          d2          d3         d4 #> Item_1  -1.1171924  2.4296469  1.73288248  1.26067403  0.2297665 #> Item_2   7.7979262  0.6344815  0.10842378 -0.40343108 -0.5373447 #> Item_3   0.2629820  1.0227374  0.40406181  0.05877758 -0.7416570 #> Item_4   4.7612348  0.4181758  0.09659425 -0.39620617 -0.8081206 #> Item_5  -0.2508314  1.7270595  1.44413339  1.00569169  0.4374845 #> Item_6   0.2825226  0.6987403  0.33984035 -0.10978202 -0.5318410 #> Item_7   0.5483014  1.1687726  0.61066779 -0.17876210 -0.8428922 #> Item_8   0.2589735  0.1645560 -0.50937611 -0.97348674 -1.6301845 #> Item_9   4.7482498  0.4760300 -0.17069300 -1.25756806 -2.0364066 #> Item_10 -3.4544141 -0.9539374 -1.70812723 -1.99858134 -2.6710047 #> Item_11  4.5041025  1.3508597  0.82245138  0.38868246 -0.6469871 #> Item_12  0.6126098  2.0281560  1.23506017  0.35720032 -0.2322765 #> Item_13  0.9980961 -0.4148028 -1.06332972 -1.72305387 -2.4443652 #> Item_14  2.9404701  1.4499665  0.65492514  0.16151658 -0.1173663 #> Item_15  3.0592768  1.0422137  0.65828309  0.23004194 -0.8853085 #> Item_16  2.1588771  1.2437703  0.88064791 -0.61804921 -1.1362945 #> Item_17  0.9028578  1.2465837  0.38556807 -0.45153380 -0.9196150 #> Item_18  0.2863930  2.4301695  1.84214734  1.30810063  0.9140620 #> Item_19  1.3145920  1.6329817  0.90542889 -0.07961438 -0.6340161 #> Item_20  1.0298438  2.3208002  1.75183674  0.90002111  0.6407807 plot(mod, type = 'itemscore')  # }  # reverse the scoring for items 1, 5, and 10 only using empirical min/max revdat <- reverse.score(dat, c('Item_1', 'Item_5', 'Item_10')) head(revdat) #>      Item_1.RS Item_2 Item_3 Item_4 Item_5.RS Item_6 Item_7 Item_8 Item_9 #> [1,]         0      4      2      4         0      4      2      4      4 #> [2,]         0      4      1      2         0      0      4      0      4 #> [3,]         1      0      4      0         0      0      4      0      0 #> [4,]         4      4      3      4         0      4      4      4      4 #> [5,]         4      0      0      1         0      4      0      1      1 #> [6,]         3      0      0      0         1      1      3      0      0 #>      Item_10.RS Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 #> [1,]          4       4       4       0       4       4       4       1       4 #> [2,]          4       4       0       2       4       4       2       0       1 #> [3,]          4       4       2       0       0       0       2       0       1 #> [4,]          4       4       4       3       4       4       4       4       4 #> [5,]          3       4       2       1       0       4       2       2       4 #> [6,]          4       0       4       3       3       1       1       0       1 #>      Item_19 Item_20 #> [1,]       1       4 #> [2,]       4       4 #> [3,]       4       3 #> [4,]       4       4 #> [5,]       3       0 #> [6,]       2       4  # compare apply(dat[,c(1,5,10)], 2, table) #>   Item_1 Item_5 Item_10 #> 0     35     46     179 #> 1     23     12      23 #> 2     21     23       8 #> 3     57     37      17 #> 4    164    182      73 apply(revdat[,c(1,5,10)], 2, table) #>   Item_1.RS Item_5.RS Item_10.RS #> 0       164       182         73 #> 1        57        37         17 #> 2        21        23          8 #> 3        23        12         23 #> 4        35        46        179  # \\donttest{ # slopes all positive now mod2 <- mirt(revdat) #>  coef(mod2, simplify=TRUE)$items #>                   a1         d1         d2          d3         d4 #> Item_1.RS  1.1182344 -0.2276345 -1.2585807 -1.73084542 -2.4277274 #> Item_2     7.8235698  0.6524445  0.1261525 -0.38602040 -0.5201021 #> Item_3     0.2632045  1.0232150  0.4045218  0.05926287 -0.7411866 #> Item_4     4.7761244  0.4286916  0.1068883 -0.38632467 -0.7986421 #> Item_5.RS  0.2510760 -0.4370332 -1.0052289 -1.44369998 -1.7266003 #> Item_6     0.2827955  0.6992590  0.3403556 -0.10926752 -0.5313230 #> Item_7     0.5487299  1.1697835  0.6116507 -0.17771403 -0.8418820 #> Item_8     0.2591667  0.1650238 -0.5089098 -0.97301720 -1.6297131 #> Item_9     4.7606067  0.4861014 -0.1609173 -1.24853436 -2.0280968 #> Item_10.RS 3.4634667  2.6802518  2.0073365  1.71669942  0.9620659 #> Item_11    4.5179204  1.3616041  0.8328228  0.39869560 -0.6378781 #> Item_12    0.6132529  2.0293027  1.2362469  0.35825699 -0.2310679 #> Item_13    0.9990765 -0.4129181 -1.0614558 -1.72125802 -2.4426937 #> Item_14    2.9461576  1.4563648  0.6611071  0.16754860 -0.1114038 #> Item_15    3.0649176  1.0485816  0.6646115  0.23628993 -0.8793653 #> Item_16    2.1617219  1.2479992  0.8848828 -0.61395520 -1.1322718 #> Item_17    0.9038909  1.2483193  0.3872151 -0.44980307 -0.9180791 #> Item_18    0.2866437  2.4306786  1.8426855  1.30858320  0.9146260 #> Item_19    1.3159613  1.6354544  0.9078839 -0.07718882 -0.6315840 #> Item_20    1.0310717  2.3228460  1.7538611  0.90199444  0.6427890 plot(mod2, type = 'itemscore')  # }  # use different empirical scoring information due to options not used   # 0 score not observed for item 1, though should have been rescored to a 4 dat[dat[,1] == 0, 1] <- 1 table(dat[,1]) #>  #>   1   2   3   4  #>  58  21  57 164   # 4 score not observed for item 5, though should have been rescored to a 0 dat[dat[,5] == 4, 5] <- 3 table(dat[,5]) #>  #>   0   1   2   3  #>  46  12  23 219   # specify theoretical scoring values in the range list revdat2 <- reverse.score(dat, c('Item_1', 'Item_5', 'Item_10'),                               range = list(Item_1 = c(0,4), Item_5 = c(0,4))) head(revdat2) #>      Item_1.RS Item_2 Item_3 Item_4 Item_5.RS Item_6 Item_7 Item_8 Item_9 #> [1,]         1      4      2      4         1      4      2      4      4 #> [2,]         1      4      1      2         1      0      4      0      4 #> [3,]         2      0      4      0         1      0      4      0      0 #> [4,]         4      4      3      4         1      4      4      4      4 #> [5,]         4      0      0      1         1      4      0      1      1 #> [6,]         4      0      0      0         1      1      3      0      0 #>      Item_10.RS Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 #> [1,]          4       4       4       0       4       4       4       1       4 #> [2,]          4       4       0       2       4       4       2       0       1 #> [3,]          4       4       2       0       0       0       2       0       1 #> [4,]          4       4       4       3       4       4       4       4       4 #> [5,]          3       4       2       1       0       4       2       2       4 #> [6,]          4       0       4       3       3       1       1       0       1 #>      Item_19 Item_20 #> [1,]       1       4 #> [2,]       4       4 #> [3,]       4       3 #> [4,]       4       4 #> [5,]       3       0 #> [6,]       2       4 table(dat[,1]) #>  #>   1   2   3   4  #>  58  21  57 164  table(revdat2[,1]) #>  #>   1   2   3   4  #> 164  57  21  58   table(dat[,5]) #>  #>   0   1   2   3  #>  46  12  23 219  table(revdat2[,5]) #>  #>   1   2   3   4  #> 219  23  12  46"},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Second-order test of convergence — secondOrderTest","title":"Second-order test of convergence — secondOrderTest","text":"Test whether terminated estimation criteria given model passes second order test checking positive definiteness resulting Hessian matrix. function, accepts symmetric Hessian/information matrix input, returns TRUE matrix positive definite FALSE otherwise.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Second-order test of convergence — secondOrderTest","text":"","code":"secondOrderTest(mat, ..., method = \"eigen\")"},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Second-order test of convergence — secondOrderTest","text":"mat symmetric matrix test positive definiteness (typically Hessian highest point model estimator, MLE MAP) ... arguments passed either eigen, chol, 'det' positiveness eigen values, positiveness leading minors via Cholesky decomposition, evaluation whether determinant greater 0 method method use test positive definiteness. Default 'eigen'","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Second-order test of convergence — secondOrderTest","text":"matrix possible combinations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Second-order test of convergence — secondOrderTest","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Second-order test of convergence — secondOrderTest","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/secondOrderTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Second-order test of convergence — secondOrderTest","text":"","code":"# \\donttest{  # PD matrix mod <- mirt(Science, 1, SE=TRUE) #>  #>  #> Calculating information matrix... info <- solve(vcov(mod))   ## observed information secondOrderTest(info) #> [1] TRUE secondOrderTest(info, method = 'chol') #> [1] TRUE secondOrderTest(info, method = 'det') #> [1] TRUE  # non-PD matrix mat <- matrix(c(1,0,0,0,1,1,0,1,1), ncol=3) mat #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    1 #> [3,]    0    1    1 secondOrderTest(mat) #> [1] FALSE secondOrderTest(mat, method = 'chol') #> [1] FALSE secondOrderTest(mat, method = 'det') #> [1] FALSE  # }"},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Show model object — show-method","title":"Show model object — show-method","text":"Print model object summaries console.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show model object — show-method","text":"","code":"# S4 method for class 'SingleGroupClass' show(object)"},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show model object — show-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Show model object — show-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/show-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show model object — show-method","text":"","code":"# \\donttest{ x <- mirt(Science, 1) #>  show(x) #>  #> Call: #> mirt(data = Science, model = 1) #>  #> Full-information item factor analysis with 1 factor(s). #> Converged within 1e-04 tolerance after 36 EM iterations. #> mirt version: 1.45.2  #> M-step optimizer: BFGS  #> EM acceleration: Ramsay  #> Number of rectangular quadrature: 61 #> Latent density type: Gaussian  #>  #> Log-likelihood = -1608.87 #> Estimated parameters: 16  #> AIC = 3249.739 #> BIC = 3313.279; SABIC = 3262.512 #> G2 (239) = 213.56, p = 0.8804 #> RMSEA = 0, CFI = NaN, TLI = NaN # }"},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate response patterns — simdata","title":"Simulate response patterns — simdata","text":"Simulates response patterns compensatory noncompensatory MIRT models multivariate normally distributed factor (\\(\\theta\\)) scores, user input matrix \\(\\theta\\)'s.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate response patterns — simdata","text":"","code":"simdata(   a,   d,   N,   itemtype,   sigma = NULL,   mu = NULL,   guess = 0,   upper = 1,   rho = NULL,   nominal = NULL,   t = NULL,   Theta = NULL,   gpcm_mats = list(),   returnList = FALSE,   model = NULL,   equal.K = TRUE,   which.items = NULL,   mins = 0,   lca_cats = NULL,   prob.list = NULL )"},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate response patterns — simdata","text":"matrix/vector slope parameters. slopes constrained zero use NA simply set equal 0 d matrix/vector intercepts. matrix many columns item largest number categories, filled empty locations NA. vector used test assumed consist dichotomous items (one intercept per item provided). itemtype = 'lca' intercepts used N sample size itemtype character vector length nrow() (1, item types   ) specifying type items simulate. Inputs can either   inputs found itemtype argument mirt   internal classes defined package. Typical itemtype inputs   passed mirt used converted   respective internal classes automatically. internal class object specified instead, inputs can   'dich', 'graded', 'gpcm', 'sequential', 'nominal', 'nestlogit', 'partcomp', 'gumm',   'lca', models Luo (2001) family (see mirt),   dichotomous, graded, generalized partial credit, sequential,   nominal, nested logit, partially compensatory,   generalized graded unfolding model, latent class analysis model, ordered unfolding models.   Note gpcm, nominal, nested logit models   many parameters desired categories, however parametrized meaningful   interpretation first category intercept   equal 0 models (second column 'nestlogit', since first column   correct item traceline). nested logit models 'correct' category always lowest   category (.e., == 1). may helpful use mod2values data-sets   already estimated understand itemtypes intimately sigma covariance matrix underlying distribution. Default identity matrix. Used Theta supplied mu mean vector underlying distribution. Default vector zeros. Used Theta supplied guess vector guessing parameters item; applicable dichotomous items. Must either scalar value affect dichotomous items, vector many values simulated items upper guess, upper bound parameters rho matrix rho values used Lui (2001) family ordered unfolding models (see mirt) control latitude acceptance. values must positive nominal matrix specific item category slopes nominal models. dimensions intercept specification one less column, NA locations applicable. Note estimation first slope constrained 0 last constrained number categories minus 1, best set values first last categories well t matrix t-values 'ggum' itemtype, row corresponds given item. Also determines number categories, NA can used non-applicable categories Theta user specified matrix underlying ability parameters, nrow(Theta) == N ncol(Theta) == ncol(). supplied N input required gpcm_mats list matrices specifying scoring scheme generalized partial credit models (see mirt details) returnList logical; return list containing data, item objects defined mirt containing population parameters item structure, latent trait matrix Theta? Default FALSE model single group object, typically returned functions mirt bfactor. Supplying render parameter elements (excluding Theta, N, mu, sigma inputs) redundant (unless explicitly provided). input can therefore used create parametric bootstrap data whereby plausible data implied estimated model can generated evaluated equal.K logical; model input supplied, generated data contain number categories original data indicated extract.mirt(model, 'K')? Default TRUE, redrawn data condition satisfied .items integer vector used indicate items simulate model input included. Default simulates items mins integer vector (single value used item) indicating lowest category . model supplied extracted slot(mod, 'Data')$mins, otherwise default 0 lca_cats vector indicating many categories lca item . supplied assumed 2 categories generated item prob.list optional list containing matrix/data.frames probabilities values category simulated. useful creating customized probability functions sampled ","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate response patterns — simdata","text":"Returns data matrix simulated parameters, list containing data, item objects, Theta matrix.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate response patterns — simdata","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06 Reckase, M. D. (2009). Multidimensional Item Response Theory. New York: Springer.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate response patterns — simdata","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/simdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate response patterns — simdata","text":"","code":"### Parameters from Reckase (2009), p. 153  set.seed(1234)  a <- matrix(c(  .7471, .0250, .1428,  .4595, .0097, .0692,  .8613, .0067, .4040, 1.0141, .0080, .0470,  .5521, .0204, .1482, 1.3547, .0064, .5362, 1.3761, .0861, .4676,  .8525, .0383, .2574, 1.0113, .0055, .2024,  .9212, .0119, .3044,  .0026, .0119, .8036,  .0008, .1905,1.1945,  .0575, .0853, .7077,  .0182, .3307,2.1414,  .0256, .0478, .8551,  .0246, .1496, .9348,  .0262, .2872,1.3561,  .0038, .2229, .8993,  .0039, .4720, .7318,  .0068, .0949, .6416,  .3073, .9704, .0031,  .1819, .4980, .0020,  .4115,1.1136, .2008,  .1536,1.7251, .0345,  .1530, .6688, .0020,  .2890,1.2419, .0220,  .1341,1.4882, .0050,  .0524, .4754, .0012,  .2139, .4612, .0063,  .1761,1.1200, .0870),30,3,byrow=TRUE)*1.702  d <- matrix(c(.1826,-.1924,-.4656,-.4336,-.4428,-.5845,-1.0403,   .6431,.0122,.0912,.8082,-.1867,.4533,-1.8398,.4139,   -.3004,-.1824,.5125,1.1342,.0230,.6172,-.1955,-.3668,   -1.7590,-.2434,.4925,-.3410,.2896,.006,.0329),ncol=1)*1.702  mu <- c(-.4, -.7, .1) sigma <- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3)  dataset1 <- simdata(a, d, 2000, itemtype = '2PL') dataset2 <- simdata(a, d, 2000, itemtype = '2PL', mu = mu, sigma = sigma)  #mod <- mirt(dataset1, 3, method = 'MHRM') #coef(mod)  # \\donttest{  ### Unidimensional graded response model with 5 categories each  a <- matrix(rlnorm(20,.2,.3))  # for the graded model, ensure that there is enough space between the intercepts, # otherwise closer categories will not be selected often (minimum distance of 0.3 here) diffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum)) diffs <- -(diffs - rowMeans(diffs)) d <- diffs + rnorm(20)  dat <- simdata(a, d, 500, itemtype = 'graded') # mod <- mirt(dat, 1)  ### An example of a mixed item, bifactor loadings pattern with correlated specific factors  a <- matrix(c( .8,.4,NA, .4,.4,NA, .7,.4,NA, .8,NA,.4, .4,NA,.4, .7,NA,.4),ncol=3,byrow=TRUE)  d <- matrix(c( -1.0,NA,NA,  1.5,NA,NA,  0.0,NA,NA, 0.0,-1.0,1.5,  #the first 0 here is the recommended constraint for nominal 0.0,1.0,-1, #the first 0 here is the recommended constraint for gpcm 2.0,0.0,NA),ncol=3,byrow=TRUE)  nominal <- matrix(NA, nrow(d), ncol(d)) # the first 0 and last (ncat - 1) = 2 values are the recommended constraints nominal[4, ] <- c(0,1.2,2)  sigma <- diag(3) sigma[2,3] <- sigma[3,2] <- .25 items <- c('2PL','2PL','2PL','nominal','gpcm','graded')  dataset <- simdata(a,d,2000,items,sigma=sigma,nominal=nominal)  #mod <- bfactor(dataset, c(1,1,1,2,2,2), itemtype=c(rep('2PL', 3), 'nominal', 'gpcm','graded')) #coef(mod)  #### Convert standardized factor loadings to slopes  F2a <- function(F, D=1.702){     h2 <- rowSums(F^2)     a <- (F / sqrt(1 - h2)) * D     a }  (F <- matrix(c(rep(.7, 5), rep(.5,5)))) #>       [,1] #>  [1,]  0.7 #>  [2,]  0.7 #>  [3,]  0.7 #>  [4,]  0.7 #>  [5,]  0.7 #>  [6,]  0.5 #>  [7,]  0.5 #>  [8,]  0.5 #>  [9,]  0.5 #> [10,]  0.5 (a <- F2a(F)) #>            [,1] #>  [1,] 1.6682937 #>  [2,] 1.6682937 #>  [3,] 1.6682937 #>  [4,] 1.6682937 #>  [5,] 1.6682937 #>  [6,] 0.9826502 #>  [7,] 0.9826502 #>  [8,] 0.9826502 #>  [9,] 0.9826502 #> [10,] 0.9826502 d <- rnorm(10)  dat <- simdata(a, d, 5000, itemtype = '2PL') mod <- mirt(dat, 1) #>  coef(mod, simplify=TRUE)$items #>                a1           d g u #> Item_1  1.5912124  0.09329250 0 1 #> Item_2  1.6611479  0.77704003 0 1 #> Item_3  1.6100289  0.04348744 0 1 #> Item_4  1.5251147 -0.39866322 0 1 #> Item_5  1.7126206 -0.69888431 0 1 #> Item_6  0.9352647 -1.71863199 0 1 #> Item_7  0.9211469  0.73522267 0 1 #> Item_8  0.9893392 -1.25501247 0 1 #> Item_9  0.9999014  0.41687594 0 1 #> Item_10 0.9416579 -1.00423353 0 1 summary(mod) #>            F1    h2 #> Item_1  0.683 0.466 #> Item_2  0.698 0.488 #> Item_3  0.687 0.472 #> Item_4  0.667 0.445 #> Item_5  0.709 0.503 #> Item_6  0.482 0.232 #> Item_7  0.476 0.227 #> Item_8  0.503 0.253 #> Item_9  0.507 0.257 #> Item_10 0.484 0.234 #>  #> SS loadings:  3.577  #> Proportion Var:  0.358  #>  #> Factor correlations:  #>  #>    F1 #> F1  1  mod2 <- mirt(dat, 'F1 = 1-10                    CONSTRAIN = (1-5, a1), (6-10, a1)') #>  summary(mod2) #>            F1    h2 #> Item_1  0.689 0.475 #> Item_2  0.689 0.475 #> Item_3  0.689 0.475 #> Item_4  0.689 0.475 #> Item_5  0.689 0.475 #> Item_6  0.491 0.241 #> Item_7  0.491 0.241 #> Item_8  0.491 0.241 #> Item_9  0.491 0.241 #> Item_10 0.491 0.241 #>  #> SS loadings:  3.576  #> Proportion Var:  0.358  #>  #> Factor correlations:  #>  #>    F1 #> F1  1 anova(mod2, mod) #>           AIC    SABIC       HQ      BIC    logLik    X2 df   p #> mod2 58058.43 58098.51 58085.85 58136.64 -29017.22              #> mod  58068.01 58134.80 58113.69 58198.35 -29014.01 6.425  8 0.6  #### Convert classical 3PL paramerization into slope-intercept form nitems <- 50 as <- rlnorm(nitems, .2, .2) bs <- rnorm(nitems, 0, 1) gs <- rbeta(nitems, 5, 17)  # convert first item (only intercepts differ in resulting transformation) traditional2mirt(c('a'=as[1], 'b'=bs[1], 'g'=gs[1], 'u'=1), cls='3PL') #>         a1          d          g          u  #>  1.2795115 -0.1107008  0.2525144  1.0000000   # convert all difficulties to intercepts ds <- numeric(nitems) for(i in 1:nitems)    ds[i] <- traditional2mirt(c('a'=as[i], 'b'=bs[i], 'g'=gs[i], 'u'=1),                              cls='3PL')[2]  dat <- simdata(as, ds, N=5000, guess=gs, itemtype = '3PL')  # estimate with beta prior for guessing parameters # mod <- mirt(dat, model=\"Theta = 1-50 #                         PRIOR = (1-50, g, expbeta, 5, 17)\", itemtype = '3PL') # coef(mod, simplify=TRUE, IRTpars=TRUE)$items # data.frame(as, bs, gs, us=1)   #### Unidimensional nonlinear factor pattern  theta <- rnorm(2000) Theta <- cbind(theta,theta^2)  a <- matrix(c( .8,.4, .4,.4, .7,.4, .8,NA, .4,NA, .7,NA),ncol=2,byrow=TRUE) d <- matrix(rnorm(6)) itemtype <- rep('2PL',6)  nonlindata <- simdata(a=a, d=d, itemtype=itemtype, Theta=Theta)  #model <- ' #F1 = 1-6 #(F1 * F1) = 1-3' #mod <- mirt(nonlindata, model) #coef(mod)  #### 2PLNRM model for item 4 (with 4 categories), 2PL otherwise  a <- matrix(rlnorm(4,0,.2))  # first column of item 4 is the intercept for the correct category of 2PL model, #    otherwise nominal model configuration d <- matrix(c( -1.0,NA,NA,NA,  1.5,NA,NA,NA,  0.0,NA,NA,NA,  1, 0.0,-0.5,0.5),ncol=4,byrow=TRUE)  nominal <- matrix(NA, nrow(d), ncol(d)) nominal[4, ] <- c(NA,0,.5,.6)  items <- c(rep('2PL',3),'nestlogit')  dataset <- simdata(a,d,2000,items,nominal=nominal)  #mod <- mirt(dataset, 1, itemtype = c('2PL', '2PL', '2PL', '2PLNRM'), key=c(NA,NA,NA,0)) #coef(mod) #itemplot(mod,4)  # return list of simulation parameters listobj <- simdata(a,d,2000,items,nominal=nominal, returnList=TRUE) str(listobj) #> List of 3 #>  $ itemobjects:List of 4 #>   ..$ :Formal class 'dich' [package \"mirt\"] with 23 slots #>   .. .. ..@ par          : num [1:4] 0.863 -1 -999 999 #>   .. .. .. ..- attr(*, \"na.action\")= 'omit' int [1:3] 3 4 5 #>   .. .. ..@ SEpar        : num(0)  #>   .. .. ..@ parnames     : chr(0)  #>   .. .. ..@ est          : logi(0)  #>   .. .. ..@ dps          :function ()   #>   .. .. ..@ dps2         :function ()   #>   .. .. ..@ constr       : logi(0)  #>   .. .. ..@ itemclass    : int(0)  #>   .. .. ..@ parnum       : num(0)  #>   .. .. ..@ nfact        : int 1 #>   .. .. ..@ nfixedeffects: num(0)  #>   .. .. ..@ fixed.design : num[0 , 0 ]  #>   .. .. ..@ dat          : num[0 , 0 ]  #>   .. .. ..@ ncat         : int 2 #>   .. .. ..@ gradient     : num(0)  #>   .. .. ..@ hessian      : num[0 , 0 ]  #>   .. .. ..@ itemtrace    : num[0 , 0 ]  #>   .. .. ..@ lbound       : num(0)  #>   .. .. ..@ ubound       : num(0)  #>   .. .. ..@ any.prior    : logi(0)  #>   .. .. ..@ prior.type   : int(0)  #>   .. .. ..@ prior_1      : num(0)  #>   .. .. ..@ prior_2      : num(0)  #>   ..$ :Formal class 'dich' [package \"mirt\"] with 23 slots #>   .. .. ..@ par          : num [1:4] 1.25 1.5 -999 999 #>   .. .. .. ..- attr(*, \"na.action\")= 'omit' int [1:3] 3 4 5 #>   .. .. ..@ SEpar        : num(0)  #>   .. .. ..@ parnames     : chr(0)  #>   .. .. ..@ est          : logi(0)  #>   .. .. ..@ dps          :function ()   #>   .. .. ..@ dps2         :function ()   #>   .. .. ..@ constr       : logi(0)  #>   .. .. ..@ itemclass    : int(0)  #>   .. .. ..@ parnum       : num(0)  #>   .. .. ..@ nfact        : int 1 #>   .. .. ..@ nfixedeffects: num(0)  #>   .. .. ..@ fixed.design : num[0 , 0 ]  #>   .. .. ..@ dat          : num[0 , 0 ]  #>   .. .. ..@ ncat         : int 2 #>   .. .. ..@ gradient     : num(0)  #>   .. .. ..@ hessian      : num[0 , 0 ]  #>   .. .. ..@ itemtrace    : num[0 , 0 ]  #>   .. .. ..@ lbound       : num(0)  #>   .. .. ..@ ubound       : num(0)  #>   .. .. ..@ any.prior    : logi(0)  #>   .. .. ..@ prior.type   : int(0)  #>   .. .. ..@ prior_1      : num(0)  #>   .. .. ..@ prior_2      : num(0)  #>   ..$ :Formal class 'dich' [package \"mirt\"] with 23 slots #>   .. .. ..@ par          : num [1:4] 1.02 0 -999 999 #>   .. .. .. ..- attr(*, \"na.action\")= 'omit' int [1:3] 3 4 5 #>   .. .. ..@ SEpar        : num(0)  #>   .. .. ..@ parnames     : chr(0)  #>   .. .. ..@ est          : logi(0)  #>   .. .. ..@ dps          :function ()   #>   .. .. ..@ dps2         :function ()   #>   .. .. ..@ constr       : logi(0)  #>   .. .. ..@ itemclass    : int(0)  #>   .. .. ..@ parnum       : num(0)  #>   .. .. ..@ nfact        : int 1 #>   .. .. ..@ nfixedeffects: num(0)  #>   .. .. ..@ fixed.design : num[0 , 0 ]  #>   .. .. ..@ dat          : num[0 , 0 ]  #>   .. .. ..@ ncat         : int 2 #>   .. .. ..@ gradient     : num(0)  #>   .. .. ..@ hessian      : num[0 , 0 ]  #>   .. .. ..@ itemtrace    : num[0 , 0 ]  #>   .. .. ..@ lbound       : num(0)  #>   .. .. ..@ ubound       : num(0)  #>   .. .. ..@ any.prior    : logi(0)  #>   .. .. ..@ prior.type   : int(0)  #>   .. .. ..@ prior_1      : num(0)  #>   .. .. ..@ prior_2      : num(0)  #>   ..$ :Formal class 'nestlogit' [package \"mirt\"] with 24 slots #>   .. .. ..@ correctcat   : int 1 #>   .. .. ..@ par          : num [1:10] 0.771 1 -999 999 0 ... #>   .. .. ..@ SEpar        : num(0)  #>   .. .. ..@ parnames     : chr(0)  #>   .. .. ..@ est          : logi(0)  #>   .. .. ..@ dps          :function ()   #>   .. .. ..@ dps2         :function ()   #>   .. .. ..@ constr       : logi(0)  #>   .. .. ..@ itemclass    : int(0)  #>   .. .. ..@ parnum       : num(0)  #>   .. .. ..@ nfact        : int 1 #>   .. .. ..@ nfixedeffects: num(0)  #>   .. .. ..@ fixed.design : num[0 , 0 ]  #>   .. .. ..@ dat          : num[0 , 0 ]  #>   .. .. ..@ ncat         : int 4 #>   .. .. ..@ gradient     : num(0)  #>   .. .. ..@ hessian      : num[0 , 0 ]  #>   .. .. ..@ itemtrace    : num[0 , 0 ]  #>   .. .. ..@ lbound       : num(0)  #>   .. .. ..@ ubound       : num(0)  #>   .. .. ..@ any.prior    : logi(0)  #>   .. .. ..@ prior.type   : int(0)  #>   .. .. ..@ prior_1      : num(0)  #>   .. .. ..@ prior_2      : num(0)  #>  $ data       : num [1:2000, 1:4] 1 1 1 0 0 1 0 1 0 1 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:4] \"Item_1\" \"Item_2\" \"Item_3\" \"Item_4\" #>  $ Theta      : num [1:2000, 1] -0.399 1.931 1.621 -0.424 1.343 ...  # generate dataset from converged model mod <- mirt(Science, 1, itemtype = c(rep('gpcm', 3), 'nominal')) #>  sim <- simdata(model=mod, N=1000) head(sim) #>      Comfort Work Future Benefit #> [1,]       4    3      3       4 #> [2,]       3    2      3       3 #> [3,]       3    2      4       2 #> [4,]       4    3      4       3 #> [5,]       3    3      2       3 #> [6,]       2    3      3       2  Theta <- matrix(rnorm(100)) sim <- simdata(model=mod, Theta=Theta) head(sim) #>      Comfort Work Future Benefit #> [1,]       3    3      4       4 #> [2,]       4    2      3       2 #> [3,]       3    2      3       2 #> [4,]       3    3      3       3 #> [5,]       3    3      3       3 #> [6,]       3    3      4       3  # alternatively, define a suitable object with functions from the mirtCAT package # help(generate.mirt_object) library(mirtCAT) #> Loading required package: shiny  nitems <- 50 a1 <- rlnorm(nitems, .2,.2) d <- rnorm(nitems) g <- rbeta(nitems, 20, 80) pars <- data.frame(a1=a1, d=d, g=g) head(pars) #>          a1          d         g #> 1 1.1271598 -0.6479570 0.2637693 #> 2 1.3539630 -1.4832170 0.1903528 #> 3 1.1640507  0.3390045 0.1782070 #> 4 0.9568311 -1.3578148 0.1389409 #> 5 1.0394247  0.3835373 0.2361323 #> 6 1.1479152  1.3522255 0.1990177  obj <- generate.mirt_object(pars, '3PL') dat <- simdata(N=200, model=obj)  #### 10 item GGUMs test with 4 categories each a <- rlnorm(10, .2, .2) b <- rnorm(10) #passed to d= input, but used as the b parameters diffs <- t(apply(matrix(runif(10*3, .3, 1), 10), 1, cumsum)) t <- -(diffs - rowMeans(diffs))  dat <- simdata(a, b, 1000, 'ggum', t=t) apply(dat, 2, table) #>   Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10 #> 0    477    496    674    332    438    417    558    458    475     513 #> 1    299    309    218    388    364    365    288    320    314     305 #> 2    153    155     79    232    158    175    109    167    162     138 #> 3     71     40     29     48     40     43     45     55     49      44 # mod <- mirt(dat, 1, 'ggum') # coef(mod)  ### 10 items with the hyperbolic cosine model with differing category lengths a <- matrix(1, 10) d <- rnorm(10) rho <- matrix(1:2, nrow=10, ncol=2, byrow=TRUE) rho[1:2,2] <- NA   # first two items have K=2 categories  dat <- simdata(a, d, 1000, 'hcm', rho=rho) itemstats(dat) #> $overall #>     N mean_total.score sd_total.score ave.r  sd.r alpha SEM.alpha #>  1000            8.522          2.709 0.015 0.212 0.119     2.543 #>  #> $itemstats #>            N K  mean    sd total.r total.r_if_rm alpha_if_rm #> Item_1  1000 2 0.475 0.500   0.128        -0.057       0.146 #> Item_2  1000 2 0.343 0.475   0.352         0.186       0.056 #> Item_3  1000 3 0.574 0.796   0.367         0.079       0.082 #> Item_4  1000 3 0.989 0.895   0.531         0.231      -0.038 #> Item_5  1000 3 1.159 0.867   0.163        -0.158       0.234 #> Item_6  1000 3 0.911 0.874   0.511         0.214      -0.021 #> Item_7  1000 3 1.001 0.884   0.525         0.228      -0.034 #> Item_8  1000 3 0.965 0.896   0.016        -0.300       0.323 #> Item_9  1000 3 0.886 0.895   0.517         0.213      -0.023 #> Item_10 1000 3 1.219 0.861   0.210        -0.110       0.204 #>  #> $proportions #>             0     1     2 #> Item_1  0.525 0.475    NA #> Item_2  0.657 0.343    NA #> Item_3  0.620 0.186 0.194 #> Item_4  0.406 0.199 0.395 #> Item_5  0.309 0.223 0.468 #> Item_6  0.430 0.229 0.341 #> Item_7  0.390 0.219 0.391 #> Item_8  0.419 0.197 0.384 #> Item_9  0.464 0.186 0.350 #> Item_10 0.285 0.211 0.504 #>  # mod <- mirt(dat, 1, 'hcm') # list(est=coef(mod, simplify=TRUE)$items, pop=cbind(a, d, log(rho)))   ###### # prob.list example  # custom probability function that returns a matrix fun <- function(a, b, theta){     P <- 1 / (1 + exp(-a * (theta-b)))     cbind(1-P, P) }  set.seed(1) theta <- matrix(rnorm(100)) prob.list <- list() nitems <- 5 a <- rlnorm(nitems, .2, .2); b <- rnorm(nitems, 0, 1/2) for(i in 1:nitems) prob.list[[i]] <- fun(a[i], b[i], theta) str(prob.list) #> List of 5 #>  $ : num [1:100, 1:2] 0.836 0.68 0.865 0.317 0.645 ... #>  $ : num [1:100, 1:2] 0.771 0.554 0.813 0.179 0.509 ... #>  $ : num [1:100, 1:2] 0.75 0.569 0.788 0.239 0.532 ... #>  $ : num [1:100, 1:2] 0.737 0.503 0.785 0.146 0.457 ... #>  $ : num [1:100, 1:2] 0.828 0.669 0.858 0.308 0.634 ...  dat <- simdata(prob.list=prob.list) head(dat) #>      Item_1 Item_2 Item_3 Item_4 Item_5 #> [1,]      0      0      0      1      1 #> [2,]      0      0      0      1      0 #> [3,]      0      0      0      0      0 #> [4,]      1      1      0      0      0 #> [5,]      1      1      0      0      0 #> [6,]      0      1      0      1      0  # prob.list input is useful when defining custom items as well name <- 'old2PL' par <- c(a = .5, b = -2) est <- c(TRUE, TRUE) P.old2PL <- function(par,Theta, ncat){      a <- par[1]      b <- par[2]      P1 <- 1 / (1 + exp(-1*a*(Theta - b)))      cbind(1-P1, P1) }  x <- createItem(name, par=par, est=est, P=P.old2PL)  prob.list[[1]] <- x@P(x@par, theta)   # }"},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of model object — summary-method","title":"Summary of model object — summary-method","text":"Transforms coefficients standardized factor loading's metric. MixedClass objects, fixed random coefficients printed. Note output console rounded three digits, returned list objects . simulations, use output <- summary(mod, verbose = FALSE) suppress console messages.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of model object — summary-method","text":"","code":"# S4 method for class 'SingleGroupClass' summary(   object,   SE = TRUE,   rotate = \"oblimin\",   Target = NULL,   suppress = 0,   suppress.cor = 0,   verbose = TRUE,   ... )"},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of model object — summary-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass SE logical; include standard errors standardized loadings? Requires initial model included estimated asymptotic covariance matrix (via, instance, mirt(..., SE = TRUE)). TRUE SEs computed using delta method rotate string indicating rotation use exploratory models, primarily   GPArotation package (see documentation therein). Rotations currently supported : 'promax', 'oblimin', 'varimax',   'quartimin', 'targetT', 'targetQ', 'pstT', 'pstQ',   'oblimax', 'entropy', 'quartimax', 'simplimax',   'bentlerT', 'bentlerQ', 'tandemI', 'tandemII',   'geominT', 'geominQ', 'cfT', 'cfQ', 'infomaxT',   'infomaxQ', 'mccammon', 'bifactorT', 'bifactorQ'. models exploratory input automatically set 'none' Target dummy variable matrix indicting target rotation pattern. required rotations 'targetT', 'targetQ', 'pstT', 'pstQ' suppress numeric value indicating (possibly rotated) factor loadings suppressed. Typical values around .3 statistical software. Default 0 suppression suppress.cor suppress, correlation matrix output verbose logical; allow information printed console? ... additional arguments passed","code":""},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary of model object — summary-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":[]},{"path":"https://philchalmers.github.io/mirt/reference/summary-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of model object — summary-method","text":"","code":"# \\donttest{ x <- mirt(Science, 2) #>  summary(x) #>  #> Rotation:  oblimin  #>  #> Rotated factor loadings:  #>  #>              F1      F2    h2 #> Comfort  0.6016  0.0312 0.382 #> Work    -0.0573  0.7971 0.592 #> Future   0.3302  0.5153 0.548 #> Benefit  0.7231 -0.0239 0.506 #>  #> Rotated SS loadings:  0.997 0.902  #>  #> Factor correlations:  #>  #>       F1 F2 #> F1 1.000    #> F2 0.511  1 summary(x, rotate = 'varimax') #>  #> Rotation:  varimax  #>  #> Rotated factor loadings:  #>  #>            F1    F2    h2 #> Comfort 0.579 0.216 0.382 #> Work    0.121 0.760 0.592 #> Future  0.428 0.605 0.548 #> Benefit 0.683 0.200 0.506 #>  #> Rotated SS loadings:  0.999 1.03  #>  #> Factor correlations:  #>  #>    F1 F2 #> F1  1    #> F2  0  1  # }"},{"path":"https://philchalmers.github.io/mirt/reference/tail.mirt_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Tail generic for customized matrix console output — tail.mirt_matrix","title":"Tail generic for customized matrix console output — tail.mirt_matrix","text":"Provides nicer output printed matrix objects defined functions mirt.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/tail.mirt_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tail generic for customized matrix console output — tail.mirt_matrix","text":"","code":"# S3 method for class 'mirt_matrix' tail(x, digits = 3, ...)"},{"path":"https://philchalmers.github.io/mirt/reference/tail.mirt_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tail generic for customized matrix console output — tail.mirt_matrix","text":"x object class 'mirt_matrix' digits number digits round ... additional arguments passed print(...)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate test information — testinfo","title":"Function to calculate test information — testinfo","text":"Given estimated model compute test information.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate test information — testinfo","text":"","code":"testinfo(   x,   Theta,   degrees = NULL,   group = NULL,   individual = FALSE,   which.items = 1:extract.mirt(x, \"nitems\") )"},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate test information — testinfo","text":"x object class 'SingleGroupClass', object class 'MultipleGroupClass' suitable group input supplied Theta matrix latent trait values degrees vector angles degrees 0 90. applicable input object multidimensional group group argument pass extract.group function. Required input object multiple-group model individual logical; return data.frame information traceline item? .items integer vector indicating items include expected information function. Default uses possible items","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to calculate test information — testinfo","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to calculate test information — testinfo","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/testinfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to calculate test information — testinfo","text":"","code":"dat <- expand.table(deAyala) (mirt(dat, 1, '2PL', pars = 'values')) #>    group   item     class   name parnum  value lbound ubound   est const nconst #> 1    all Item.1      dich     a1      1  0.851   -Inf    Inf  TRUE  none   none #> 2    all Item.1      dich      d      2  2.384   -Inf    Inf  TRUE  none   none #> 3    all Item.1      dich      g      3  0.000      0      1 FALSE  none   none #> 4    all Item.1      dich      u      4  1.000      0      1 FALSE  none   none #> 5    all Item.2      dich     a1      5  0.851   -Inf    Inf  TRUE  none   none #> 6    all Item.2      dich      d      6  0.726   -Inf    Inf  TRUE  none   none #> 7    all Item.2      dich      g      7  0.000      0      1 FALSE  none   none #> 8    all Item.2      dich      u      8  1.000      0      1 FALSE  none   none #> 9    all Item.3      dich     a1      9  0.851   -Inf    Inf  TRUE  none   none #> 10   all Item.3      dich      d     10  0.327   -Inf    Inf  TRUE  none   none #> 11   all Item.3      dich      g     11  0.000      0      1 FALSE  none   none #> 12   all Item.3      dich      u     12  1.000      0      1 FALSE  none   none #> 13   all Item.4      dich     a1     13  0.851   -Inf    Inf  TRUE  none   none #> 14   all Item.4      dich      d     14 -0.362   -Inf    Inf  TRUE  none   none #> 15   all Item.4      dich      g     15  0.000      0      1 FALSE  none   none #> 16   all Item.4      dich      u     16  1.000      0      1 FALSE  none   none #> 17   all Item.5      dich     a1     17  0.851   -Inf    Inf  TRUE  none   none #> 18   all Item.5      dich      d     18 -0.563   -Inf    Inf  TRUE  none   none #> 19   all Item.5      dich      g     19  0.000      0      1 FALSE  none   none #> 20   all Item.5      dich      u     20  1.000      0      1 FALSE  none   none #> 21   all  GROUP GroupPars MEAN_1     21  0.000   -Inf    Inf FALSE  none   none #> 22   all  GROUP GroupPars COV_11     22  1.000      0    Inf FALSE  none   none #>    prior.type prior_1 prior_2 #> 1        none     NaN     NaN #> 2        none     NaN     NaN #> 3        none     NaN     NaN #> 4        none     NaN     NaN #> 5        none     NaN     NaN #> 6        none     NaN     NaN #> 7        none     NaN     NaN #> 8        none     NaN     NaN #> 9        none     NaN     NaN #> 10       none     NaN     NaN #> 11       none     NaN     NaN #> 12       none     NaN     NaN #> 13       none     NaN     NaN #> 14       none     NaN     NaN #> 15       none     NaN     NaN #> 16       none     NaN     NaN #> 17       none     NaN     NaN #> 18       none     NaN     NaN #> 19       none     NaN     NaN #> 20       none     NaN     NaN #> 21       none     NaN     NaN #> 22       none     NaN     NaN mod <- mirt(dat, 1, '2PL', constrain = list(c(1,5,9,13,17))) #>   Theta <- matrix(seq(-4,4,.01)) tinfo <- testinfo(mod, Theta) plot(Theta, tinfo, type = 'l')   # \\donttest{  # compare information loss between two tests tinfo_smaller <- testinfo(mod, Theta, which.items = 3:5)  # removed item informations plot(Theta, iteminfo(extract.item(mod, 1), Theta), type = 'l')  plot(Theta, iteminfo(extract.item(mod, 2), Theta), type = 'l')   # most loss of info around -1 when removing items 1 and 2; expected given item info functions plot(Theta, tinfo_smaller - tinfo, type = 'l')    # }"},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create all possible combinations of vector input — thetaComb","title":"Create all possible combinations of vector input — thetaComb","text":"function constructs possible k-way combinations input vector. primarily useful used conjunction mdirt function, though users may uses well. See expand.grid flexible combination formats.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create all possible combinations of vector input — thetaComb","text":"","code":"thetaComb(theta, nfact, intercept = FALSE)"},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create all possible combinations of vector input — thetaComb","text":"theta vector possible combinations obtained nfact number observations (therefore number columns return matrix combinations) intercept logical; vector 1's appended first column result include intercept design component? Default FALSE","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create all possible combinations of vector input — thetaComb","text":"matrix possible combinations","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create all possible combinations of vector input — thetaComb","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create all possible combinations of vector input — thetaComb","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/thetaComb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create all possible combinations of vector input — thetaComb","text":"","code":"# all possible joint combinations for the vector -4 to 4 thetaComb(-4:4, 2) #>       [,1] [,2] #>  [1,]   -4   -4 #>  [2,]   -3   -4 #>  [3,]   -2   -4 #>  [4,]   -1   -4 #>  [5,]    0   -4 #>  [6,]    1   -4 #>  [7,]    2   -4 #>  [8,]    3   -4 #>  [9,]    4   -4 #> [10,]   -4   -3 #> [11,]   -3   -3 #> [12,]   -2   -3 #> [13,]   -1   -3 #> [14,]    0   -3 #> [15,]    1   -3 #> [16,]    2   -3 #> [17,]    3   -3 #> [18,]    4   -3 #> [19,]   -4   -2 #> [20,]   -3   -2 #> [21,]   -2   -2 #> [22,]   -1   -2 #> [23,]    0   -2 #> [24,]    1   -2 #> [25,]    2   -2 #> [26,]    3   -2 #> [27,]    4   -2 #> [28,]   -4   -1 #> [29,]   -3   -1 #> [30,]   -2   -1 #> [31,]   -1   -1 #> [32,]    0   -1 #> [33,]    1   -1 #> [34,]    2   -1 #> [35,]    3   -1 #> [36,]    4   -1 #> [37,]   -4    0 #> [38,]   -3    0 #> [39,]   -2    0 #> [40,]   -1    0 #> [41,]    0    0 #> [42,]    1    0 #> [43,]    2    0 #> [44,]    3    0 #> [45,]    4    0 #> [46,]   -4    1 #> [47,]   -3    1 #> [48,]   -2    1 #> [49,]   -1    1 #> [50,]    0    1 #> [51,]    1    1 #> [52,]    2    1 #> [53,]    3    1 #> [54,]    4    1 #> [55,]   -4    2 #> [56,]   -3    2 #> [57,]   -2    2 #> [58,]   -1    2 #> [59,]    0    2 #> [60,]    1    2 #> [61,]    2    2 #> [62,]    3    2 #> [63,]    4    2 #> [64,]   -4    3 #> [65,]   -3    3 #> [66,]   -2    3 #> [67,]   -1    3 #> [68,]    0    3 #> [69,]    1    3 #> [70,]    2    3 #> [71,]    3    3 #> [72,]    4    3 #> [73,]   -4    4 #> [74,]   -3    4 #> [75,]   -2    4 #> [76,]   -1    4 #> [77,]    0    4 #> [78,]    1    4 #> [79,]    2    4 #> [80,]    3    4 #> [81,]    4    4  # all possible binary combinations for four observations thetaComb(c(0,1), 4) #>       [,1] [,2] [,3] [,4] #>  [1,]    0    0    0    0 #>  [2,]    1    0    0    0 #>  [3,]    0    1    0    0 #>  [4,]    1    1    0    0 #>  [5,]    0    0    1    0 #>  [6,]    1    0    1    0 #>  [7,]    0    1    1    0 #>  [8,]    1    1    1    0 #>  [9,]    0    0    0    1 #> [10,]    1    0    0    1 #> [11,]    0    1    0    1 #> [12,]    1    1    0    1 #> [13,]    0    0    1    1 #> [14,]    1    0    1    1 #> [15,]    0    1    1    1 #> [16,]    1    1    1    1  # all possible binary combinations for four observations (with intercept) thetaComb(c(0,1), 4, intercept=TRUE) #>       [,1] [,2] [,3] [,4] [,5] #>  [1,]    1    0    0    0    0 #>  [2,]    1    1    0    0    0 #>  [3,]    1    0    1    0    0 #>  [4,]    1    1    1    0    0 #>  [5,]    1    0    0    1    0 #>  [6,]    1    1    0    1    0 #>  [7,]    1    0    1    1    0 #>  [8,]    1    1    1    1    0 #>  [9,]    1    0    0    0    1 #> [10,]    1    1    0    0    1 #> [11,]    1    0    1    0    1 #> [12,]    1    1    1    0    1 #> [13,]    1    0    0    1    1 #> [14,]    1    1    0    1    1 #> [15,]    1    0    1    1    1 #> [16,]    1    1    1    1    1"},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"helper function users previously available traditional/classical IRT parameters want know equivalent slope-intercept translation used mirt. Note function assumes supplied models unidimensional definition (.e., one slope/discrimination) logistic metric (.e., logistic-ogive scaling coefficient D=1). supported slope-intercept transformation available original vector parameters returned default.","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"","code":"traditional2mirt(x, cls, ncat)"},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"x vector parameters transform cls class itemtype supplied model ncat number categories implied IRT model","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"named vector slope-intercept parameters (supported)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"Supported class transformations cls input : Rasch, 2PL, 3PL, 3PLu, 4PL Form must : (discrimination, difficulty, lower-bound, upper-bound) graded Form must : (discrimination, difficulty 1, difficulty 2, ..., difficulty k-1) gpcm Form must : (discrimination, difficulty 1, difficulty 2, ..., difficulty k-1) nominal Form must : (discrimination 1, discrimination 2, ..., discrimination k,       difficulty 1, difficulty 2, ..., difficulty k)","code":""},{"path":"https://philchalmers.github.io/mirt/reference/traditional2mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert traditional IRT metric into slope-intercept form used in mirt — traditional2mirt","text":"","code":"# classical 3PL model vec <- c(a=1.5, b=-1, g=.1, u=1) slopeint <- traditional2mirt(vec, '3PL', ncat=2) slopeint #>  a1   d   g   u  #> 1.5 1.5 0.1 1.0   # classical graded model (four category) vec <- c(a=1.5, b1=-1, b2=0, b3=1.5) slopeint <- traditional2mirt(vec, 'graded', ncat=4) slopeint #>    a1    d1    d2    d3  #>  1.50  1.50  0.00 -2.25   # classical generalize partial credit model (four category) vec <- c(a=1.5, b1=-1, b2=0, b3=1.5) slopeint <- traditional2mirt(vec, 'gpcm', ncat=4) slopeint #>    a1   ak0   ak1   ak2   ak3    d0    d1    d2    d3  #>  1.50  0.00  1.00  2.00  3.00  0.00  1.50  1.50 -0.75   # classical nominal model (4 category) vec <- c(a1=.5, a2 = -1, a3=1, a4=-.5, d1=1, d2=-1, d3=-.5, d4=.5) slopeint <- traditional2mirt(vec, 'nominal', ncat=4) slopeint #>         a1        ak0        ak1        ak2        ak3         d0         d1  #> -0.3333333  0.0000000  4.5000000 -1.5000000  3.0000000  0.0000000 -2.0000000  #>         d2         d3  #> -1.5000000 -0.5000000"},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract parameter variance covariance matrix — vcov-method","title":"Extract parameter variance covariance matrix — vcov-method","text":"Extract parameter variance covariance matrix","code":""},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract parameter variance covariance matrix — vcov-method","text":"","code":"# S4 method for class 'SingleGroupClass' vcov(object)"},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract parameter variance covariance matrix — vcov-method","text":"object object class SingleGroupClass, MultipleGroupClass, MixedClass","code":""},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract parameter variance covariance matrix — vcov-method","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/vcov-method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract parameter variance covariance matrix — vcov-method","text":"","code":"# \\donttest{ x <- mirt(Science, 1, SE=TRUE) #>  #>  #> Calculating information matrix... vcov(x) #>                a1.1         d1.2          d2.3          d3.4          a1.5 #> a1.1   0.0354557222  0.031747211  0.0218991330 -1.337062e-02 -0.0020114572 #> d1.2   0.0317472109  0.240747985  0.0496914145 -7.728604e-03 -0.0039962941 #> d2.3   0.0218991330  0.049691414  0.0495440979 -3.353138e-03 -0.0026118813 #> d3.4  -0.0133706166 -0.007728604 -0.0033531385  2.516506e-02  0.0016239413 #> a1.5  -0.0020114572 -0.003996294 -0.0026118813  1.623941e-03  0.0330717252 #> d1.6  -0.0027776758  0.000321554  0.0013455096  4.475090e-03  0.0222002454 #> d2.7  -0.0008339773  0.002234984  0.0026641307  3.634982e-03  0.0084726682 #> d3.8   0.0025280813  0.006109937  0.0050768040  2.151939e-03 -0.0194002583 #> a1.9  -0.0292529857 -0.032667514 -0.0224516013  1.338132e-02  0.0001401001 #> d1.10 -0.0438210135 -0.037345358 -0.0240181907  2.417470e-02 -0.0060425885 #> d2.11 -0.0206416044 -0.015080644 -0.0081996180  1.457986e-02 -0.0023410675 #> d3.12  0.0177727573  0.023980089  0.0183114800 -1.142724e-03  0.0022121845 #> a1.13  0.0096842437  0.008486325  0.0055838516 -3.358253e-03 -0.0026345430 #> d1.14  0.0070930997  0.010415451  0.0077963642  4.886260e-06 -0.0038164066 #> d2.15  0.0021935448  0.005091505  0.0044161993  2.013700e-03 -0.0013475415 #> d3.16 -0.0040629009 -0.001253710  0.0001366316  4.584220e-03  0.0020482028 #>                d1.6          d2.7         d3.8          a1.9         d1.10 #> a1.1  -0.0027776758 -0.0008339773  0.002528081 -0.0292529857 -0.0438210135 #> d1.2   0.0003215540  0.0022349842  0.006109937 -0.0326675141 -0.0373453579 #> d2.3   0.0013455096  0.0026641307  0.005076804 -0.0224516013 -0.0240181907 #> d3.4   0.0044750896  0.0036349818  0.002151939  0.0133813229  0.0241746980 #> a1.5   0.0222002454  0.0084726682 -0.019400258  0.0001401001 -0.0060425885 #> d1.6   0.0572478298  0.0178719080 -0.008242431 -0.0042731331  0.0008943475 #> d2.7   0.0178719080  0.0204197987  0.001805256 -0.0022635445  0.0034073931 #> d3.8  -0.0082424309  0.0018052557  0.041235925  0.0021523979  0.0112367277 #> a1.9  -0.0042731331 -0.0022635445  0.002152398  0.2343596829  0.3068823432 #> d1.10  0.0008943475  0.0034073931  0.011236728  0.3068823432  0.5333187949 #> d2.11  0.0043839472  0.0058509494  0.008542531  0.1425287134  0.2140840706 #> d3.12  0.0095948178  0.0084870680  0.005845643 -0.1227407708 -0.1520698557 #> a1.13 -0.0031158076 -0.0007826477  0.003057944 -0.0316626320 -0.0478697496 #> d1.14  0.0007925371  0.0027067338  0.006134230 -0.0304997627 -0.0348586852 #> d2.15  0.0024475628  0.0032306664  0.004352544 -0.0097796669 -0.0072522805 #> d3.16  0.0048748828  0.0037848620  0.002008196  0.0177300358  0.0307235701 #>               d2.11        d3.12         a1.13         d1.14         d2.15 #> a1.1  -0.0206416044  0.017772757  0.0096842437  7.093100e-03  0.0021935448 #> d1.2  -0.0150806437  0.023980089  0.0084863254  1.041545e-02  0.0050915045 #> d2.3  -0.0081996180  0.018311480  0.0055838516  7.796364e-03  0.0044161993 #> d3.4   0.0145798573 -0.001142724 -0.0033582533  4.886260e-06  0.0020137003 #> a1.5  -0.0023410675  0.002212184 -0.0026345430 -3.816407e-03 -0.0013475415 #> d1.6   0.0043839472  0.009594818 -0.0031158076  7.925371e-04  0.0024475628 #> d2.7   0.0058509494  0.008487068 -0.0007826477  2.706734e-03  0.0032306664 #> d3.8   0.0085425306  0.005845643  0.0030579443  6.134230e-03  0.0043525441 #> a1.9   0.1425287134 -0.122740771 -0.0316626320 -3.049976e-02 -0.0097796669 #> d1.10  0.2140840706 -0.152069856 -0.0478697496 -3.485869e-02 -0.0072522805 #> d2.11  0.1276826104 -0.062018021 -0.0219424374 -1.277452e-02  0.0003957921 #> d3.12 -0.0620180212  0.104233499  0.0192987094  2.313630e-02  0.0117967217 #> a1.13 -0.0219424374  0.019298709  0.0335900564  2.461211e-02  0.0088923418 #> d1.14 -0.0127745164  0.023136304  0.0246121055  7.645466e-02  0.0179733534 #> d2.15  0.0003957921  0.011796722  0.0088923418  1.797335e-02  0.0197363548 #> d3.16  0.0175005019 -0.003280364 -0.0143630948 -5.930600e-03  0.0028978863 #>               d3.16 #> a1.1  -0.0040629009 #> d1.2  -0.0012537103 #> d2.3   0.0001366316 #> d3.4   0.0045842200 #> a1.5   0.0020482028 #> d1.6   0.0048748828 #> d2.7   0.0037848620 #> d3.8   0.0020081962 #> a1.9   0.0177300358 #> d1.10  0.0307235701 #> d2.11  0.0175005019 #> d3.12 -0.0032803641 #> a1.13 -0.0143630948 #> d1.14 -0.0059305999 #> d2.15  0.0028978863 #> d3.16  0.0284229583  # }"},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald statistics for mirt models — wald","title":"Wald statistics for mirt models — wald","text":"Compute Wald test given L vector matrix numeric contrasts. Requires model information matrix computed (passing SE = TRUE estimating model). Use wald(model) observe information matrix columns named, especially estimated model contains constrained parameters (e.g., 1PL).","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald statistics for mirt models — wald","text":"","code":"wald(object, L, C = NULL)"},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald statistics for mirt models — wald","text":"object estimated object mirt, bfactor, multipleGroup, mixedmirt, mdirt L coefficient matrix dimensions nconstrasts x npars.estimated, character vector giving hypothesis symbolic form (syntax format borrowed car package; see Details ). Omitting value return column names information matrix used identify (potentially constrained) parameters C constant vector population parameters compared along side L,   length(C) == row(L). default vector 0's constructed. Note using   syntax input L argument ignored following description borrowed car package documentation pertaining character vector input argument L: \"hypothesis matrix can supplied numeric matrix (vector), rows specify linear combinations model coefficients, tested equal corresponding entries right-hand-side vector, defaults vector zeroes. Alternatively, hypothesis can specified symbolically character vector one elements, gives either linear combination coefficients, linear equation coefficients (.e., left right side separated equals sign). Components linear expression linear equation can consist numeric constants, numeric constants multiplying coefficient names (case number precedes coefficient, may separated spaces asterisk); constants 1 -1 may omitted. Spaces always optional. Components separated plus minus signs. Newlines tabs hypotheses treated spaces. See examples .\"","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wald statistics for mirt models — wald","text":"Chalmers, R., P. (2012). mirt: Multidimensional Item Response Theory Package R Environment. Journal Statistical Software, 48(6), 1-29. doi:10.18637/jss.v048.i06","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Wald statistics for mirt models — wald","text":"Phil Chalmers rphilip.chalmers@gmail.com","code":""},{"path":"https://philchalmers.github.io/mirt/reference/wald.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wald statistics for mirt models — wald","text":"","code":"# \\donttest{  # View parnumber index data(LSAT7) data <- expand.table(LSAT7) mod <- mirt(data, 1, SE = TRUE) #>  #>  #> Calculating information matrix... coef(mod) #> $Item.1 #>            a1     d  g  u #> par     0.988 1.856  0  1 #> CI_2.5  0.641 1.598 NA NA #> CI_97.5 1.335 2.114 NA NA #>  #> $Item.2 #>            a1     d  g  u #> par     1.081 0.808  0  1 #> CI_2.5  0.750 0.629 NA NA #> CI_97.5 1.412 0.987 NA NA #>  #> $Item.3 #>            a1     d  g  u #> par     1.706 1.804  0  1 #> CI_2.5  1.078 1.404 NA NA #> CI_97.5 2.334 2.205 NA NA #>  #> $Item.4 #>            a1     d  g  u #> par     0.765 0.486  0  1 #> CI_2.5  0.502 0.339 NA NA #> CI_97.5 1.028 0.633 NA NA #>  #> $Item.5 #>            a1     d  g  u #> par     0.736 1.855  0  1 #> CI_2.5  0.440 1.630 NA NA #> CI_97.5 1.032 2.079 NA NA #>  #> $GroupPars #>         MEAN_1 COV_11 #> par          0      1 #> CI_2.5      NA     NA #> CI_97.5     NA     NA #>   # see how the information matrix relates to estimated parameters, and how it lines up #   with the parameter index (infonames <- wald(mod)) #>  a1.1   d.2  a1.5   d.6  a1.9  d.10 a1.13  d.14 a1.17  d.18  #> 0.988 1.856 1.081 0.808 1.706 1.804 0.765 0.486 0.736 1.855  index <- mod2values(mod) index[index$est, ] #>    group   item class name parnum value lbound ubound  est const nconst #> 1    all Item.1  dich   a1      1 0.988   -Inf    Inf TRUE  none   none #> 2    all Item.1  dich    d      2 1.856   -Inf    Inf TRUE  none   none #> 5    all Item.2  dich   a1      5 1.081   -Inf    Inf TRUE  none   none #> 6    all Item.2  dich    d      6 0.808   -Inf    Inf TRUE  none   none #> 9    all Item.3  dich   a1      9 1.706   -Inf    Inf TRUE  none   none #> 10   all Item.3  dich    d     10 1.804   -Inf    Inf TRUE  none   none #> 13   all Item.4  dich   a1     13 0.765   -Inf    Inf TRUE  none   none #> 14   all Item.4  dich    d     14 0.486   -Inf    Inf TRUE  none   none #> 17   all Item.5  dich   a1     17 0.736   -Inf    Inf TRUE  none   none #> 18   all Item.5  dich    d     18 1.855   -Inf    Inf TRUE  none   none #>    prior.type prior_1 prior_2 #> 1        none     NaN     NaN #> 2        none     NaN     NaN #> 5        none     NaN     NaN #> 6        none     NaN     NaN #> 9        none     NaN     NaN #> 10       none     NaN     NaN #> 13       none     NaN     NaN #> 14       none     NaN     NaN #> 17       none     NaN     NaN #> 18       none     NaN     NaN  # second item slope equal to 0? L <- matrix(0, 1, 10) L[1,3] <- 1 wald(mod, L) #>         W df            p #> 1 41.0005  1 1.521906e-10  # same as above using character syntax input infonames #>  a1.1   d.2  a1.5   d.6  a1.9  d.10 a1.13  d.14 a1.17  d.18  #> 0.988 1.856 1.081 0.808 1.706 1.804 0.765 0.486 0.736 1.855  wald(mod, \"a1.5 = 0\") #>         W df            p #> 1 41.0005  1 1.521906e-10  # simultaneously test equal factor slopes for item 1 and 2, and 4 and 5 L <- matrix(0, 2, 10) L[1,1] <- L[2, 7] <- 1 L[1,3] <- L[2, 9] <- -1 L #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #> [1,]    1    0   -1    0    0    0    0    0    0     0 #> [2,]    0    0    0    0    0    0    1    0   -1     0 wald(mod, L) #>           W df         p #> 1 0.1528867  2 0.9264054  # Again, using more efficient syntax infonames #>  a1.1   d.2  a1.5   d.6  a1.9  d.10 a1.13  d.14 a1.17  d.18  #> 0.988 1.856 1.081 0.808 1.706 1.804 0.765 0.486 0.736 1.855  wald(mod, c(\"a1.1 = a1.5\", \"a1.13 = a1.17\")) #>           W df         p #> 1 0.1528867  2 0.9264054  # log-Liklihood tests (requires estimating a new model) cmodel <- 'theta = 1-5            CONSTRAIN = (1,2, a1), (4,5, a1)' mod2 <- mirt(data, cmodel) #>  # or, equivalently #mod2 <- mirt(data, 1, constrain = list(c(1,5), c(13,17))) anova(mod2, mod) #>           AIC    SABIC       HQ      BIC    logLik    X2 df     p #> mod2 5333.763 5347.616 5348.685 5373.025 -2658.881                #> mod  5337.610 5354.927 5356.263 5386.688 -2658.805 0.152  2 0.927  ##### # test equality of means in multi-group model: #    H0: (mu1 - mu2) = (mu3 - mu4)  set.seed(12345) a <- matrix(abs(rnorm(15,1,.3)), ncol=1) d <- matrix(rnorm(15,0,.7),ncol=1) itemtype <- rep('2PL', nrow(a)) N <- 500 dataset1 <- simdata(a, d, N, itemtype) dataset2 <- simdata(a, d, N, itemtype, mu = .5) dataset3 <- simdata(a, d, N, itemtype, mu = -1) dataset4 <- simdata(a, d, N, itemtype, mu = -.5) dat <- rbind(dataset1, dataset2, dataset3, dataset4) group <- factor(rep(paste0('D', 1:4), each=N)) levels(group) #> [1] \"D1\" \"D2\" \"D3\" \"D4\" models <- 'F1 = 1-15'  # 3 means estimated mod_free <- multipleGroup(dat, models, group = group, SE=TRUE,                           invariance=c('slopes', 'intercepts', 'free_var','free_means')) #>  #>  #> Calculating information matrix... wald(mod_free) # obtain parameter names #>   a1.1.63.125.187    d.2.64.126.188   a1.5.67.129.191    d.6.68.130.192  #>             1.234             0.643             1.189            -0.573  #>   a1.9.71.133.195   d.10.72.134.196  a1.13.75.137.199   d.14.76.138.200  #>             0.981            -0.141             1.058             0.864  #>  a1.17.79.141.203   d.18.80.142.204  a1.21.83.145.207   d.22.84.146.208  #>             1.146             0.248             0.499             0.537  #>  a1.25.87.149.211   d.26.88.150.212  a1.29.91.153.215   d.30.92.154.216  #>             1.274             1.204             0.997            -0.368  #>  a1.33.95.157.219   d.34.96.158.220  a1.37.99.161.223  d.38.100.162.224  #>             0.899            -1.032             0.735            -1.087  #> a1.41.103.165.227  d.42.104.166.228 a1.45.107.169.231  d.46.108.170.232  #>             1.031             1.345             1.603            -0.160  #> a1.49.111.173.235  d.50.112.174.236 a1.53.115.177.239  d.54.116.178.240  #>             1.272             0.578             1.228             0.501  #> a1.57.119.181.243  d.58.120.182.244        MEAN_1.123        COV_11.124  #>             0.850            -0.080             0.382             0.865  #>        MEAN_1.185        COV_11.186        MEAN_1.247        COV_11.248  #>            -1.062             0.864            -0.594             0.936  # View(mod2values(mod_free))  # reference group mean = 0 by default wald(mod_free, c(\"0 - MEAN_1.123 = MEAN_1.185 - MEAN_1.247\")) #>           W df         p #> 1 0.7142209  1 0.3980461   # }"},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1451","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.45.1","title":"Changes in mirt 1.45.1","text":"CRAN release: 2025-09-06 Added argument fscores(..., expected.info = FALSE) allow computation expected vs observed information Fixed extraction bug randef() lr.random structures used extract.item() extract.group() now support objects class MixtureClass RMSD_DIF() now works single group models investigate goodness fit Number response options (K) per item added itemstats() output, well option report raw counts instead proportions","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-144","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.44","title":"Changes in mirt 1.44","text":"Added Attitude dataset Andrich (1988) publication demonstrate constrained hyperbolic cosine model (HCM) model estimated latitude acceptance parameters Added several itemtype inputs specify family unfolding models dichotomous polytomous data. currently include unidimensional multidimensional versions (generalized) hyperbolic cosine model, (generalized) absolute logistic model, (generalized) simple squared logistic model, (generalized) parallellogram analysis model. simdata() also gained support Luo (2001) family generating models, among secondary functions summary() now automatically outputs delta-method SEs standardized factor loadings. applied non-EFA models include estimate ACOV (e.g., via mirt(..., SE=TRUE)) Standardized factor loadings multidimensional nominal response model now report consistent values regardless category ordering Exported general-purpose DeltaMethod() function numerical version delta method Fixed M2() computations large amounts missing data, particularly prevalent C2 statistic (reported Hynek Cigler) Fixed minor coef(..., IRTpars=TRUE) issue output reported constant SE term 0.0 converting Rasch models (bk = -dk correctly tracked)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-143","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.43","title":"Changes in mirt 1.43","text":"CRAN release: 2024-11-14 M2() family longer requires row-wise removal missing data behave correctly. , na.rm argument removed longer required (requested Ulrich Schroeders) Added support latent regression ACOV/SE estimation Oakes method mirt() Related points , general MLTM (Embretson, 1984) added itemtype specified PC1PL itemdesign set used, formula must include name factor formula expressions. See examples mirt documentation (requested Susan Embretson) Added PC1PL itemtype easily specify conjunctive models slopes fixed 1 estimation latent variance term, mimicking Rasch itemtype family mirt() multipleGroup() gain itemdesign item.formula arguments fit fixed item design characteristics (e.g. LLTMs; Fischer, 1983) subset items. Arguments similar mixedmirt(), though currently flexible Partially-compensatory family itemtypes now behave consistently loading structures specified trace lines products computed dimensions non-zero slopes RCI() gains shiny logical create interactive scoring interface","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-142","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.42","title":"Changes in mirt 1.42","text":"CRAN release: 2024-07-14 model argument bfactor() can now specified using mirt.model() syntax include cognitively friendly tracking item names respective locations (requested Afshin Khosravi) Add reverse.score() function reverse scoring specific items within matrix data.frame Fixed issue related missing data patterns resulted bias estimating hyper-parameters single multi-group models (reported Paul Jewsbury) mirt.model() syntax gains negation operator omitting specific observed/latent groups specifications. example, following omit “Group3” identifies groups equality constraint definitions CONSTRAINB[-Group3] = ... RMSD_DIF() now supports datasets follow vertical scaling structures (.e., groups answer items others). Requested Alexandre Jaloto M2() functions now compute null model SRMR fall models whenever possible, including latent class variance (reported Hynek Cigler) VCOV memory leak bugfix mixture models (see Github issue #247) Standardized residuals point estimates now returned personfit() passing return.resids=TRUE (requested Raymond Hernandez)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-141","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.41","title":"Changes in mirt 1.41","text":"CRAN release: 2023-10-17 Fix DIF() sparse data included mixed item formats (reported Heather Leigh Kayton) computing category-level information curves include negative Hessian computations (reported Milica Kabic) Allow missing data patterns personfit(), well new option return raw item person residuals (requested George Karabatsos) Fix Zero-inflated model example multipleGroup(), required discontinuous trait location populated explicitly customTheta syntax (reported Brooke Magnus) Empirical reliability estimates fscores() empirical_rxx() include option use true score variance estimate observed score variance (suggested Hynek Cigler)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-140","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.40","title":"Changes in mirt 1.40","text":"CRAN release: 2023-08-10 technical list gains nconstrain argument specifying equality constraints negative relationships (e.g., a12 = -a21). Requested Berend Terluin Added unipolar log‑logistic model (Lucke, 2015) itemtype, specified itemtype = 'ULL'. Note automatically changes number internal defaults, using log-normal(0,1) density latent traits, theta_lim specified positive Added complementary log‑log model (Shim, Bonifay, Wiedermann, 2022) itemtype, specified itemtype = 'CLL' Added itemtype = '5PL' model unidimensional dichotomous data included asymmetric response functions. Example help(mirt) also demonstrates asymmetric 2PL model 5PL unstable requires strong priors Methods using Quasi-Monte Carlo integration post-convergence respecting correlated latent variable structures (reported George Kephart using M2()) Bugfix fscores() supplying mixture models introduced changing previous classification default latent class models (reported Karel Veldkamp) residuals() gains p.adjust argument FWE control DRF() gains DIF.cat argument compute statistics per-category basis studying polytomous items expected.test() gains probs.logical return probability functions category (used individual = TRUE) Small bug fixes C++ code resulted memory leaks","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-139","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.39","title":"Changes in mirt 1.39","text":"CRAN release: 2023-05-30 models fit using mdirt() fscores() EAP EAPsum methods now always returns classification probabilities default (reported Matthew Madison) SIBTEST() gains DIF logical perform DIF tests across suspect_set DIF() SIBTEST() gain pairwise logical input perform pairwise post-hoc comparisons multi-group applications DRF() gains groups2test argument friends multi-group models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1381","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.38.1","title":"Changes in mirt 1.38.1","text":"CRAN release: 2023-02-28 infit outfit statistics can now computed itemfit() missing data present (requested Hanif mirt-package forum: https://groups.google.com/g/mirt-package/c/_mA3YbMmbzM/m/CydOl-F4BQAJ?utm_medium=email&utm_source=footer) coef(..., IRTpars=TRUE) now applied multidimensional IRT models, provided item contains simple structure (suggested Sverre Ofstad) Fixed match() bug SIBTEST() total score missing (reported Ziying Li) fscores(..., method ='EAPsum') now supports returning ACOV matrices, matching behaviour estimators Store previously defined customItems customGroup lists use secondary functions (e.g., DIF(), boot.mirt(), etc). Reported Nataly Beribisky Combining priors equality constraints longer uses multiple prior definitions likelihood computations. Hence, constrained parameters now treated though single parameter one prior distribution (reported Matthias von Davier context multiple-group models group item priors) Added groups2test argument DIF() isolate individual grouping variable specification using 2 groups Implicit argument ‘invariance’ stored multiple-group objects now automatically used boot.mirt() (previously manually passed) Bugfix using items2test DIF input character vector (reported @jbuncher) Bug fixes multiple-group DIF testing DIF() using two groups (reported Ruben Neda Davin Díaz García)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1371","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.37.1","title":"Changes in mirt 1.37.1","text":"CRAN release: 2022-08-10 boot.mirt() gains boot.fun argument accept user-defined functions extracting associated statistics bootstrap verbose = TRUE residuals() set summary statistics reported easier flagging itemfit() arguments changed accommodate outputting tables consistently. Now single return.tables argument used specify tables return anova() removes support verbose flag, instead labels rows resulting output identify models X2 G2 classes item-fit statistics now better deal large missing value vectors per-item basis better consistency technical list gains storeEMhistory flag store EM history (requested @netique) DRF() gains best-fitting prior support (currently limited Gaussian distributions) Correct index subset caused tmp row removals MG objects (fixes #227)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-136","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.36","title":"Changes in mirt 1.36","text":"CRAN release: 2022-03-21 Progress bar added automatically (controlled via verbose argument) using several package’s secondary functions (e.g., fscores(), DIF(), 'DRF(), mdirt(), etc) Added itemstats() function give basic item information statistics Item-EFA models now automatically flips negative signs rotate solutions (e.g., via summary()) according sign largest observed loading (allows easier interpretation resulting correlation matrix) response.pattern deals completely missing vectors now (issue #220) residuals() gains approx.z logical transform LD values approximate z-ratios mirt(), mixedmirt(), multipleGroup() now model = 1 fit unidimensional IRT model default","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1351","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.35.1","title":"Changes in mirt 1.35.1","text":"CRAN release: 2021-12-08 Added covdata argument fscores() allow latent regression covariate information well. Example added fscores() documentation demonstrate addition Added RCI() function compute reliable change index via IRT modelling Added delta method SE coef(., IRTpars = TRUE) nominal nested-logit models itemfit() gains S_X2.plot argument visualize expected-observed probability differences based S-X2 conditional sum-score strategy Added type = 'EAPsum' plot() generic view expected vs observed sum-scores plot itemfit() gains p.adjust argument allow p-value adjustments output methods anova() generic now supports ... input compare many nested models, compared sequence Added type = 'threshold' itemplot() plot cumulative probability information (requested Azman Sami) Fixed Bug Error ((SEtmp < 0)) appeared due new R 4.0+ behaviour (reported Ziying Li Caroline Böhm) Fix bug itemfit() plotting multiple-group objects Bugfix fscores() report row failed converge datsets contain response patterns completely missing","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-134","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.34","title":"Changes in mirt 1.34","text":"CRAN release: 2021-06-28 Previous technical = list(removeEmptyRows = TRUE) input now deprecated. Response patterns now completely missing supplied NA placeholders within estimation post-estimation supporting functions (e.g., fscores(), personfit(), fixed(), etc) Added converged element DIF() output evaluate whether nested model iteration converged Added support plausible-value draws fscores() using response.pattern argument Fix SE.type = 'Fisher' computation multi-group models (reported Felix Zimmer) Switch par f inputs numerical_deriv()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1331","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.33.1","title":"Changes in mirt 1.33.1","text":"Added gen.difficulty() compute generalized difficulty statistics described Ali, Chang, Anderson (2015) polytomous response models (suggested Alexander Freund) Added RMSD_DIF() compute marginal effect size measure recently used PISA anlayses investigating ‘badness--fit’ DIF effects using constrained multiple-group models extract.group() now explicitly requires group name passed rather group number (far natural route) plot(..., type =) now supports 'trace', 'infotrace', 'itemscore', '' two-dimensional models create faceted graphics Added read.mirt() function back package now plink available CRAN Syntax input car package’s lht() function adopted within mirt’s wald() function easier specifications (see examples) Better cope syntax definitions models DIF(), particularly CONSTRAINB form (reported Hao Wu) Corrected outer-product summation SE.type = 'Fisher' computation (reported Felix Zimmer) Added fixedCalib() function perform five fixed-calibration methods describe Kim (2006) Empirical histogram dentype convergence tolerance longer modified (default now Gaussian dentype criteria) Fix GGUMs using model syntax input (ignoring slope loading specifications; reported Ben Listyg) fixed traditional2mirt() math gpcm 5 category items supplied (reported Aiden Loe)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1321","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.32.1","title":"Changes in mirt 1.32.1","text":"CRAN release: 2020-04-25 OpenMP support added E-step portion package, number threads can specified via mirtCluster() function argument omp_threads. Special thanks Matthias von Davier providing omp reduction code Estep.cpp file Behaviour mirt(..., large) now modified, large = TRUE now skips computing unique response patterns datasets likely contain little repeated response patterns (suggested Matthias von Davier). previous two-step behaviour now achieved passing large = 'return', storing list object, passing back large input argument Positive/negative sign remove chi-square components residuals(type = 'LD') (requested Cengiz Zopluoglu help avoid confusion). Sign still however present standardized correlation estimates itemtype = 'rsm' reported incorrect information functions due use - instead + traditional2mirt() (reported Nasser Hasan) column names fscores() results now correspond model syntax definition names instead previous F# convention fix method = 'classify' option fscores() two mixtures fitted (reported Lisa Limeri) fix bug 'drop_sequential' scheme DIF() introduced previous version mirt due internal organization changes (reported Balal Izanloo) allow infit/outfit statistics computed non-Rasch models (suggested Alexander Freund use GGUMs) added p.adjust argument DRF() (requested Keri J. S. Brady) support computation ACOV matrix variance specific factors freely estimated bfactor() fix invariance = 'free_var' argument multipleGroup() multidimensional models correlated traits, previously fixed correlation parameters inadvertently (reported Ruoyi Zhu) use proper mins internal using extract.group() keep original minimum response scoring pattern (reported Adam Ťápal) bugfix single-group models draw_parameters() (reported Keri Brady @ddueber) numeric model specification bfactor() bug patched intervals 1 unit apart due NA placeholders (reported Luis Manuel Lozano) latent trait/class names now forced different data column names (bug reported Nathan Carter) fixed X2*_df PV_Q1* missing data pattern resulted dropped categories (reported Mac Pank)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-131","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.31","title":"Changes in mirt 1.31","text":"CRAN release: 2019-09-14 added likert2int() convert Likert-type character/factor responses integer data estfun() gains centering argument center scores (contributed Rudolf Debelak) impute argument itemfit() M2() deprecated favour removing data row-wise via na.rm=TRUE Acceptance ratio using MH samplers now returned prior ‘Stage 2’ estimation ratios better behaved. well, heuristic improved method increasing/decreasing acceptance ratios now implemented Added return_seq_model DIF() return final MG model last iteration sequential search schemes Bugfix DIF() sequential scheme selected items contained DIF first iteration (reported Scott Withrow) SIBTEST() gains plot argument create various plots depicting (weighted) differences focal subtest versus matched subtest information residuals() gains 'JSI' type compute JSI statistics proposed Edwards et al. (2018) residuals() gains 'expfull' type compute expected value table possible response patterns (just observed data) Fix key variable nested-logit models data collapsed equal intervals (reported Emil Kirkegaard) Added delta method IRT parameter transformations using multiple-group models (reported Alex Miller)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-130","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.30","title":"Changes in mirt 1.30","text":"CRAN release: 2019-01-29 empirical.poly.collapse argument added itemfit() plot expected score functions polytomous items (suggested Keri Brady) SRMSR now reported M2() GGUMs (suggested Bo mirt-package forum) weights argument added estfun.AllModelClass allow inclusion survey.weights calculate scores DIF() now simplifies output default rather returning lists anova(). Wald tests always simplified applicable, RMSEA statistics reported itemfit() tests return suitable X2 df components Fix negative TLI CFI values using C2 statistic M2() function (reported Jake Kraska Charlie Iaconangelo) Fix delta method SEs 'gpcm' itemtype (reported Lennart Schneider)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-129","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.29","title":"Changes in mirt 1.29","text":"CRAN release: 2018-08-12 lower/upper bounded parameters included default optimizer now ‘nlminb’ rather ‘L-BFGS-B’. mainly due instability ‘L-BFGS-B’ algorithm prone converging instantly unknown reasons mdirt() gains item.Q list specify Q-matrices item-category level item createItem() functions gain optional argument function definitions allow list-specified data functions mirt() via silent mirt(..., customItemsData) argument lattice auto.key default now reports lines rather points. now consistent , example, color theme changed black white trellis window Added Differential Response Function (DRF) statistics upcoming publication (Chalmers, accepted) new function entitled DRF(). related compensatory non-compensatory measures response bias DIF, DBF, DTF available SIBTEST framework IRT model fitted within multiple-group estimation framework structure argument added mdirt() function allow log-linear models simplifying profile probability model computations export internally used traditional2mirt() function transform small selection classical IRT parameterizations slope-intercept form fix survey.weights input multiple group models (reported Leigh Allison) fix itemtype = \"rsm\" block restriction items contain unequal category lengths (reported Aiden Loe) SIBTEST() computation beta coefficient changed match Shealy Stout’s (1993) form p_k * (Y_R - Y_F) (previously p_k * (Y_F - Y_R); reported Craig Wells). well, Jmin default increased 5 avoid conservative Type error behavior longer tests Fix negative chi-square differences DIF() function due non-converged sub-models (reported Daniel McKelvey)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-128","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.28","title":"Changes in mirt 1.28","text":"CRAN release: 2018-05-20 M2() function gains type input distinguish univariate-bivariate collapsed M2* statistic bivariate collapsed C2 statistic (Cai Monro, 2014). C2 can useful polytomous items degrees freedom compute fully collapsed M2* multipleGroup() gains dentype argument allow mixture IRT models fitted (e.g., dentype = 'mixture-3' fits three-class mixture model). also allow modifications zero-inflated IRT model fitted technical gains zeroExtreme logical flag assign survey weights 0 extreme response patterns (FALSE default). may required Woods’ extrapolation-interpolation method used empirical histograms avoid ill defined extrapolated densities fscores(), itemfit(), M2(), residuals() gain use_dentype_estimate argument compute EAP-based scores whenever latent trait density estimated (e.g., via empirical histograms) Empirical histograms can now now scaled [0,1] using Woods’ extrapolation-interpolation method via input dentype = 'empiricalhist_Woods'. Degrees freedom updated reflect change, 121 quadrature points used instead previous 199 better stability Semi-parametric Davidian curve estimation shape latent trait distribution unidimensional IRT models contributed Oguzhan Ogreden, well associated components used within framework (interpolation-extrapolation method described Woods, 2006). estimation method available new dentype input. mirt also now links dcurver package obtain associated computation functions EM algorithm M2(), itemfit(), SIBTEST(), fscores() gain na.rm logical remove rows missing data fscores() gains append_response.pattern logical indicate whether response patterns via response.pattern input appended factor score results new dentype argument added estimation-based functions specify density structure latent traits (default 'Gaussian'). update breaks previous empiricalhist logical option anova() accept single fitted model object return information related AIC, BIC, log-likelihood, etc Hannan–Quinn (HQ) Criterion added anova()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-127","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.27","title":"Changes in mirt 1.27","text":"Added multidimensional version sequential response model (e.g., Tutz, 1990). Includes itemtype = 'sequential' multidimensional 2PL variant, itemtype = 'Tutz' Rasch variant Printing IRT parameters via coef(mod, IRTpars = TRUE) now computes delta method g u terms well. Interpreting generally recommended due bounded parameter nature (CIs can outside range [0,1]), included posterity createItem() gains bytecompile flag indicate whether internal functions byte-compiled using (default TRUE) Special GROUP location holder mirt.model() index group-level hyper-parameter terms key2binary() gains score_missing flag indicate whether missing values scored 0 left NA createItem() gains support derivType = 'symbolic' derivType.hss = 'symbolic' symbolically compute gradient/Hessian functions (template code-base contributed Chen-Wei Liu) createItem() gains derivType.hss argument distinguish gradient Hessian numerical computations mdirt() gains support createItem() inputs plotting points added default plot() itemplot() generics create smoother traceline functions","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-27","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"Changes in mirt 1.27","text":"fix simdata() bug new ggum itemtype fix new grouping syntax specification mirt.model() combining START FIXED (reported Garron Gianopulos) fix IRTpars = TRUE input itemtype Rasch (reported Benjamin Shear)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1263","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.26.3","title":"Changes in mirt 1.26.3","text":"CRAN release: 2017-11-29 mod2values() passing pars = 'values' now return data.frame objects without factor variables (previously defaults data.frame() used, created factors categorical variables default) Add monopoly itemtype fit unidimensional monotonic polynomial item response model polytomous data (see Falk Cai, 2016) Add ggum itemtype fit unidimensional/multidimensional graded unfolding model (e.g., Roberts & Laughlin, 1996). Special thanks David King providing necessary C++ derivative functions starting values Square brackets can now included mirt.model() syntax indicate group-specific constraints, priors, starting/fixed values, . general form \"CONSTRAIN [group1, group2] = ...\" \"FIXED [group1] = ...\" Added delta method several classical IRT parameterization (via coef(model, IRTpars = TRUE)) suitable information matrix previously estimated numDeriv dependency removed numerical_deriv() now supports local Richardson extrapolation type. best accuracy, now used default throughout package createItem() lagrange() now use Richardson extrapolation default instead less accurate forward/central difference method estfun() function added extract gradient information directly fitted objects (contributed Lennart Schneider) simdata() gains equal.K argument redraw data KK categories populated given item Fix initialization fscores() using ‘MH’ plausible value imputations (reported Charlie Iaconangelo) Various small bug fixes performance improvements, fixes Solaris compatibility, run small number examples R CMD check","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-125","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.25","title":"Changes in mirt 1.25","text":"CRAN release: 2017-07-23 mdirt() now supports latent regression covariate predictors. Associated function (e.g., fscores()) also include latent regression information discrete models default SIBTEST() replaced asymptotic sampling distribution version CSIBTEST described Chalmers (accepted) calcNull set FALSE default Sandwich ACOV estimate now uses Oakes estimate computations rather intensive Louis form (require low-level coding item-level Hessian terms). Added new SE.type = 'sandwich.Louis' original sandwich VCOV estimate previous version mirt fix latent regression models QMCEM MCEM algorithms (reported Seongho Bae) fscores() gains max_theta argument apply upper/lower bounds iterative searching algorithms (issue reported Sebastian Born), start input set starting values well (primarily useful mirtCAT reduce iterations) alabama package optimizer longer used. Replaced generic interface nloptr package support numerous optimizers greater control instead. Associated inputs (e.g., alabama_args) replaced well Export missing S4 methods external R packages import","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-124","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.24","title":"Changes in mirt 1.24","text":"CRAN release: 2017-05-04 MDIFF MDISC longer normal ogive metric (1.702 scaling value removed) added QMC option residuals() LD LDG2 methods. Also globally set number QMC points 5000 throughout package consistency info_if_converged logLik_if_converged added technical list indicate whether information matrix stochastic log-likelihood computed model converges. Default now TRUE added 'MCEM' method Monte Carlo EM. associated MCEM_draws function added technical list well control number draws throughout EM cycles support information matrix computations QMCEM method added (e.g., Oakes, crossprod, Louis) globally improve numerical efficiency QMC methods, including QMCEM estimator include missing data values itemfit() parametric bootstrap methods replicate missing data pattern ensure nest-logit models least 3 categories (reported Seongho Bae) convergence set FALSE g > u found 4PL model verbose console output log-posterior printed priors included EM (previously marginal likelihood) various bug fixes SIBTEST, particularly small sample sizes","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-123","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.23","title":"Changes in mirt 1.23","text":"CRAN release: 2017-03-02 anova() LRT comparison gains bounded logical indicate whether bounded parameter compared, well mix argument indicate mixture chi-squared distributions MH-RM estimation optimizer argument can now modified BFGS, L-BFGS-B, NR instead default NR1 distinction NR optimizer EM MH-RM applications included, MH-RM now defaults NR1 indicate single Newton-Raphson update uses RM filtered Hessian term method = 'SEM' added perform stochastic EM algorithm (first two stages MH-RM algorithm setup). Alternatively, setting technical = list(NCYCLES = NA) using MH-RM algorithm now returns stochastic EM results added multidim_matrix option iteminfo() expose computation information matrices bounded parameter spaces handled better using NR optimizer various bug fixes performance improvements","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-122","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.22","title":"Changes in mirt 1.22","text":"CRAN release: 2017-02-01 SE.type = 'Oakes' set new default computing standard errors via ACOV matrix using EM algorithm new SE.type = 'Oakes' compute Oakes’ 1999 form observed information matrix using central difference approximation. Applicable IRT models (including customized IRT types) added support gpcmIRT rsm itemtypes traditional generalized partial credit model Rasch rating scale model (may modified generalized rating scale model freeing slope parameters) SE.type = 'Fisher' now supports inclusion latent distribution hyper-parameters. Officially, SE-types now provide proper hyper-parameter influence information matrices wrapped various output objects mirt_df, mirt_matrix, mirt_list class avoid need passing digits argument rounding output console. Now, returned objects never rounded, makes writing Monte Carlo simulation code safer rounded results appear results added Stone’s (2000) fit statistics forthcoming PV-Q1 fit statistics itemfit()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-22","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"Changes in mirt 1.22","text":"patched underflow bug fscores() EAP estimates used extremely long (1000+ item) tests. Error now reported happens. Using MAP estimates extreme situations essentially equivalent now recommended","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-121","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.21","title":"Changes in mirt 1.21","text":"CRAN release: 2016-12-01 add information number freely estimated parameters print() generic plot(), auto.key disabled facet_items = FALSE dichotomous items. Also, adjusted ordering plot(mod, type = 'itemscore') reflect actual item ordering data Stretched theoretical bounds y-axis score-based functions plot() itemplot() (e.g., 3PL models now always stretch S(theta) = 0) plot(mod, type = 'score') supports .items input make expected score plots bundles items penalized term added EM algorithm estimation subroutines help keep covariance matrix latent trait parameters positive definite M-step (helps convergence properties optimizers, especially ‘L-BFGS-B’). turn penalized term use technical = list(keep_vcov_PD = FALSE) added type = 'itemscore' plot() generic plot faceted version item scoring functions. Particularly useful investigating DIF multipleGroup() better support splines itemtype multiple-group models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-21","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"Changes in mirt 1.21","text":"fix problem ‘EAPsum’ fscores() response.pattern input supplied (reported Eva de Schipper) plot(mod, type = 'rxx') now uses latent variance computations (reported Amin Mousavi) fix syntax input customized IRT models supplied","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1201","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.20.1","title":"Changes in mirt 1.20.1","text":"CRAN release: 2016-10-05 df adjustment S_X2 item-fit statistic models latent trait hyper-parameters estimated itemfit() personfit() properly detect dichotomous Rasch models defined constrained slopes approach argument 'fit_stats' now used itemfit() replace longer list logicals (e.g., itemfit(mod, S_X2 = FALSE, X2 = TRUE, infit = FALSE, ...)). Now fit stats explicitly requested character vector input. Default still uses S_X2 statistic using 'lnorm' prior lower bound automatically set 0, 'beta' prior lower upper bounds set [0,1] mdirt() now uses optimizer = 'nlminb' default revert using default ‘penalized version BFGS algorithm’ instead L-BFGS-B box-constraints used (introduced version 1.19) Neale & Miller 1997 approximation added PLCI() (default still computes exact PL CIs) type = 'score' supported multiple group models itemplot() added poly2dich function quickly change polytomous response data comparable matrix dichotomous response data","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-119","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.19","title":"Changes in mirt 1.19","text":"CRAN release: 2016-08-18 penalized version BFGS algorithm now used instead L-BFGS-B upper lower bounds included (provides robust estimates) variances orthogonal factors bfactor() can now freely estimated. allows modeling designs testlet response model (example included documentation) new spline itemtype model B-spline response functions dichotomous models. Useful diagnostic purposes detecting item-misfit. Additional arguments can passed spline_args list input control behaviour splines item. Currently limited unidimensional models fscores() gains plausible.type argument select normal approximation PVs Metropolis-Hastings samples (suggested Yang Liu) mdirt() modified support DINA, DINO, located latent class, diagnostic classification models. Additionally, customTheta input required build customized latent class patterns changed previously cumbersomemdirt(..., technical = list(customTheta = Theta)) simply mdirt(..., customTheta = Theta) simdata() gains prob.list input supply list matrices probability values sampled (useful specialized response functions outside package required) simdata() supports ‘lca’ itemtypes latent class model generation improved M2 accuracy latent trait variances estimated corrected behaviour M2() linear constraints applied (M2 test previously conservative constraints used). affects single well multiple-group models (reported Rudolf Debelak) add plausible values latent class related models estimated mdirt()","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-19","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.19","text":"multipleGroup() throws proper error vertical scaling identified correctly due NAs S-X2 itemfit statistic fix rare expected categories appear (reported Seongho Bae)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-118","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.18","title":"Changes in mirt 1.18","text":"CRAN release: 2016-06-24 mdirt() function now includes explicit parameters latent class intercepts (log-form). implies correct standard errors can computed using various methods (e.g., SEM, Richardson, etc) new customGroup() function define hyper-parameter objects latent trait distributions (generally assumed Gaussian mean covariance structure) new boot.LR() function perform parametric bootstrap likelihood-ratio test nested models. Useful testing nested models contain bounded parameters (e.g., testing 3PL versus 2PL model) adjust lagrange() function use full information matrix (previously quasi-lagrange approximation) greatly improved speed simdata(), consequently changes default seed","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-18","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.18","text":"fix crash error mirtmirt() multidimensional models lr.random effects (reported Diah Wihardini) expbeta prior starting values fix setting mean prior rather mode (reported Insu Paek)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-1171","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.17.1","title":"Changes in mirt 1.17.1","text":"CRAN release: 2016-04-27 itemfit() function reworked statistics input flag (e.g., Zh = TRUE, infit = TRUE, etc). Additionally, S-X2 computed default X2/G2 (associated graphics tables) computed using 10 fixed bins added empirical.table argument return tables expected/observed values X2 G2 group.bins group.fun argument added itemfit() control size bins central tendancy function X2 G2 computations 'expbeta' option added implement beta prior specifically g u parameters internally transformed logits (performes back transformation computing values) check whether multiple-group models contain enough data estimate parameters uniquely constraints applied set starting values using parprior list mirt.model() syntax (reported Insu Paek) empirical_ES() function added effect size estimates DIF/DBF/DTF analyses (contributed Adam Meade)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-17-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.17.1","text":"standardized loadings correct factor correlations included confirmatory models (reported Seongho Bae) MDISC MDIFF values missing 1.702 multiplicitive constant (reported Yi-Ling Cheng) fix information trace-lines multiple-group plots (reported Conal Monaghan) suppress standard errors exploratory models rotate != 'none' (suggested Hao Wu) sequential schemes DIF() generated wrong results (reported Adam Meade) M2() properly accounting latent variance terms (reported Ismail Cuhadar)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-116","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.16","title":"Changes in mirt 1.16","text":"CRAN release: 2016-03-07 enable lr.random input mixedmirt() multilevel-IRT models Rasch family add common vcov() logLik() methods latent regression EM models now standard error computation supporte ‘complete’, ‘forward’, ‘central’, ‘Richardson’ methods new areainfo() function compute area information curves within specified ranges (suggested Conal Monaghan) method = 'BL' supported multiple-group models. well, SE.type = 'numerical' included return observed-data ACOV matrix call optim() (can used BL method selected) new SE.type = 'FMHRM' compute information matrix based fixed number MHRM draws, associated technical = list(MHRM_SE_draws) argument added control number draws added lagrange (.e., score) test function testing whether parameters freed single multiple group models estimated EM algorithm numerical_deriv function made available simple numerical derivatives, may useful defining fast custom itemtype derivative terms SE.type used compute ACOV matrix gained three numerical estimates forward difference (‘forward’), central difference (‘central’), Richardson extropolation (‘Richardson’)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-16","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.16","text":"SE methods based Louis (1982) computations longer contain NA placeholders latent trait hyper-parameters","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-115","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.15","title":"Changes in mirt 1.15","text":"CRAN release: 2016-01-21","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"minor-changes-1-15","dir":"Changelog","previous_headings":"","what":"MINOR CHANGES","title":"Changes in mirt 1.15","text":"added SIBTEST crossed-SIBTEST procedures new function SIBTEST() added empirical_plot function building empirical plots (potential smoothing) conditioning total score low-level elements included extract.mirt() function added grsmIRT itemtype classical graded rating scale form (contributed KwonHyun Kim) added missing analytic Hessian terms gpcm_mats used (contributed Carl Falk)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-15","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.15","text":"fixed row-removal bug using technical = list(removeEmptyRows = TRUE) (reported Aaron Kaat)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-114","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.14","title":"Changes in mirt 1.14","text":"CRAN release: 2015-11-19","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-14","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.14","text":"structure output objects now contains considerably fewer S4 slots, instead organized structured list elements Data, Model, Fit, . Additionally, information matrix slot removed favour providing asymptotic covariance matrix (.k.., inverse information matrix)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"minor-changes-1-14","dir":"Changelog","previous_headings":"","what":"MINOR CHANGES","title":"Changes in mirt 1.14","text":"added extract.mirt() function allow convenient extracting internal elements crossprod SE.type now incorporates latent variable information (replaces NA placeholders) changed default full.scores = FALSE argument TRUE fscores() added profile argument plot() mdirt() objects profile plots can generated converge_info option added fscores() return convergence information add removeEmptyRows option technical list","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-14","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.14","text":"return vector NAs WLE estimation Fisher information matrix determinant 0 (reported Christopher Gess) fix df multiple-group models crossed /within constrains (reported Leah Feuerstahler) compute residuals responses sparse, return NaN residual computed (reported Aaron Kaat)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-113","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.13","title":"Changes in mirt 1.13","text":"CRAN release: 2015-09-10 adjust plausible values format multiple group objects simdata() gains model input impute data pre-organized models (useful conjunction mirtCAT generate datasets already converged models). Also gains mins argument specify lowest category item model supplied (default 0) number SEMCYCLES increased 50 100 MH-RM algorithm, RM gain rate changed c(.15, .65) c(.1, .75) improve item fit statistics using imputations facet plots now try keep items respective order panel theme lattice plots changed default lighter blue colour, legend now automatically placed right hand side rather top","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-13","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.13","text":"fix Q3 computations (noticed Katherine Castellano)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-110","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.10","title":"Changes in mirt 1.10","text":"CRAN release: 2015-06-16 using prior distributions, starting values now automatically set equal mode prior distribution, appropriate lower upper parameter bounds supplied added NEXPLORE term mirt.model() specify exploratory models via syntax add itemGAM() function provide non-linear smoother better understanding mis-functioning items (without loosing established precision reverting purely non-parametric IRT methods) category scores now automatically recoded spaces 1, message printed /occurs added MDISC() MDIFF() functions inclusion prior parameter distributions now report log-posterior rather log-likelihood. Functions anova() also report Bayesian criteria rather previous likelihood-based model comparison statistics impute argument itemfit() M2() now use plausible values instead point estimates START syntax element mirt.model() now supports multiple parameters, FIXED argument added declare parameters ‘fixed’ staring values added LBOUND UBOUND syntax support mirt.model() report proper lower upper bounds starting values data frame mod2values() invariance argument bfactor() now automatically indexes second-tier factors make multiple-group testing bfactor() easier remove rotate Target arguments model objects, pass axillary functions summary(), fscores(), etc model based arguments now can strings, passed mirt.model(). now preferred method defining models syntactically, though previous methods still work integration range (theta_lim) globally set c(-6, 6), number default quadrature nodes systematically increased parameter estimation functions. slightly change numerical results, provides consistence throughout package add theta_lim arguments various functions better control QMC grid, effective usage higher dimensions internal code organization now makes easier add user defined itemtypes (can natively added package, requested)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-10","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.10","text":"fix conservative imputation standard errors itemfit() M2() (reported Irshad Mujawar) fixed plausible value draws multidimensional latent regression models (reported Tongyun Li) don’t allow crossprod, Louis, sandwich information matrices using custom item types (reported Charlie Rutgers)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-19","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.9","title":"Changes in mirt 1.9","text":"CRAN release: 2015-03-29 using coef(mod, printSE=TRUE) g u parameters relabeled logit(g) logit(u) represent internal labels added various facet plots three dimensional models plot() generic support optimizer = 'nlminb', pass optimizer control arguments contol list added fixef() function extract expected values implied fixed effect parameters latent regression models added gpcm_mats argument estimation functions specifying customize scoring pattern multidimensional generalized partial credit models added custom_theta input fscores() including customized integration grids add suppress argument residuals() M2() suppress local dependence values less specific value print message DIF() DTF() hyper-parameters freely estimated focal groups constraits hetorogenous item names added mirt.model() syntax WLE support multidimensional models added added 'SEcontour' argument plot() generic use NA’s fscores() response patterns contain NA responses (suggested Tomasz Zoltak)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fix-1-9","dir":"Changelog","previous_headings":"","what":"BUG FIX","title":"Changes in mirt 1.9","text":"S-X2 itemfit() now returns appropriate values multiple-group models multidimensional plausible value imputation fix (reported KK Sasa) plot(..., type = 'infotrace') multiple group objects fixed (reported Danilo Pereira)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-18","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.8","title":"Changes in mirt 1.8","text":"CRAN release: 2015-01-22 fscores() nows accepts method = \"plausible\" draw single plausible value set plot() default type now score, accept rotation arguments exploratory models (default rotation 'none') imputeMissing() supports list plausible values generate multiple complete datasets new custom_den input fscores() use custom prior density functions Bayesian estimates optimized version ‘WLE’ estimator fscores() empirical reliability added method = 'EAPsum' fscores() new START argument mirt.model() specifying simple starting values one parameter time","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fix-1-8","dir":"Changelog","previous_headings":"","what":"BUG FIX","title":"Changes in mirt 1.8","text":"fix carryover print-error summary() confirmatory models estimated bound contraints included group hyper-parameters (reported KK Sasa)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-17","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.7","title":"Changes in mirt 1.7","text":"CRAN release: 2014-12-15","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-7","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.7","text":"improved estimation efficiency using MH-RM algorithm. result, default seed changed, therefore results previous versions slightly different objects class ‘ExploratoryClass’ ‘ConfirmatoryClass’ merged single class ‘SingleGroupClass’ exploratory logical slot technical = list(SEtol) criteria approximating information matrix lowered 1e-4 mixedmirt() provide better standard error estiamtes","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-7","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.7","text":"boot.mirt now uses optimizer used estimate model (default previously EM) mixedmirt now supports interaction effects random intercepts, including cross-level interactions added averageMI() function compute multiple imputation averages plausible values methodology using Rubin’s 1987 method plausible value imputation now available fscores() using new plausible.draws numeric input add return.models argument DIF() return estimated models free/constrained parameters latent regression models added mixedmirt() non-Rasch models using new lr.formula input mirt.model() syntax can now define within individual item equality constraints using 1 parameter specification name syntax latent regression models added mirt() function using new covdata formula inputs added confidence envelope plots PLCI.mirt, throw warnings intervals located coef() now accepts simplify logical, indicating whether items collapsed matrix returned list length 2 (suggested Michael Friendly)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-7","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.7","text":"bias correction variance estimates mixedmirt random effects included (reported KK Sasa) fix missing data imputation bug itemfit() (reported KK Sasa) M2 statistic bifactor/two-tier models overly conservative better checks numerical underflow issues use triangle 0’s identifying exploratory IFA models. , standard errors/condition numbers exploratory models can estimated ","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-161","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.6.1","title":"Changes in mirt 1.6.1","text":"CRAN release: 2014-10-10","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-6-1","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.6.1","text":"sirt package added suggests list. Special thanks Alexander Robitzsch (author sirt) developing useful wrapper functions mirt mirt.wrapper.coef(), tam2mirt(), andlavaan2mirt(). well, many examples sirt demonstrate possibility estimating specialized IRT models mirt, : Ramsay quotient, latent class, mixed Rasch, located latent class, probabilistic Guttman, nonparametric, discrete graded membership, multidimensional IRT discrete traits, DINA, Rasch copula models. exploratory IRT models longer rotated default coef(), now requires explicit rotate argument computation S_X2 statistic itemfit now much stable polytomous item types support plink package now unofficially dropped removed CRAN data inputs now required category spacing codings exactly equal 1 (e.g., [0, 1, 2, …]; patterns [0, 2, 3] implicitly missing spaces now invalid)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-6-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.6.1","text":"mdirt function added model discrete latent variables latent class analysis dichotomous polytomous items. Can used model several discrete IRT models well, located latent class model, multidimensional IRT discrete traits, DINA models, etc. See examples documentation details axillary support DiscreteClass objects added itemfit(), M2(), fscores(), wald(), boot.mirt() S-X2 statistic available itemfit() generalized include multidimensional models method 'QMCEM' added quasi-Monte Carlo integration mirt() multipleGroup() estimating higher dimensional models greater accuracy (suggested Alexander Robitzsch). Several axillary function fscores(), itemfit(), M2() also now contain QMC argument (accept one … argument) use integration scheme better accuracy higher dimensional models nonlinear parameter constraints EM estimation can specified using Rsolnp alabama packages passing optimizer = 'solnp' optimizer = 'alabama', well relevant package arguments solnp_ags alabama_ags list inputs itemnames argument added mirt.model() allow model specifications using raw item names rather location indicators accelerate argument changed logical character vector, now allowing three potential options: ‘Ramsay’ (default), ‘squarem’, ‘none’ modifying EM acceleration approach","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-6-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.6.1","text":"fixed bug bfactor() starting values NAs specified model argument adjust overly optimistic termination criteria EM algorithm","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-15","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.5","title":"Changes in mirt 1.5","text":"CRAN release: 2014-08-14","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-5","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.5","text":"efficiency, Hessian longer computed fscores() unless required returned object estimation method = 'MHRM' now requires explicitly SE=TRUE call compute information matrix. matrix now computed using ML estimates rather approximated sequentially iteration (unstable), therefore separate stage performed. provides much better accuracy computations","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-5","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.5","text":"new extract.group() function extract single group object objects previously returned multipleGroup() return SRMSR statistic M2() along residual matrix (suggested Dave Flora) accept Etable default input customPriorFun (suggested Alexander Robitzsch) vignette files package examples now hosted Github can accessed following link mentioned vignette location index ?mirt help file E-step now computed parallel (available) following mirtCluster() definition run M-step optimizations passing TOL = NaN. Useful model converge instantly parameters exactly equal starting values confidence envelope plots itemplot() generate shaded regions instead dotted lines, confidence interval plots added plot() generic MI input passes fscores() slightly optimized upcoming mirtCAT package release method = 'EAPsum' argument fscores() support multidimensional models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-5","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.5","text":"fix forcing SEs MHRM information matrix computations positive imputeMissing() crash fix multiple-group models fix divide--0 bug E-step number items large fix crash EM estimation SE.type = 'MHRM'","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-14","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.4","title":"Changes in mirt 1.4","text":"CRAN release: 2014-06-22","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-4","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.4","text":"calculating information matrix exploratory item factor analysis models disabled since rotational indeterminacy model results improper parameter variation changed default theta_lim c(-6,6) number quadrature defaults increased well @Data slot added organizing data based arguments. Removed several data slots estimated objects consequence removed ‘Freq’ column passing response.pattern argument fscores() increase number Mstep iterations proportionally quasi-Newton algorithms estimation approaches ML location ‘rsm’ itemtype removed now optimized version implemented","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-4","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.4","text":"link mirt vignettes Github registered knitr package now available package index optimizer argument added estimation function switch default optimizer. Multiple optimizers now available, including BFGS (EM default), L-BFGS-B, Newton-Raphson, Nelder-Mead, SANN new survey.weights argument can passed parameter estimation functions (.e., mirt()) apply -called stratification/survey-weights estimation returnList argument added simdata() return list containing S4 item objects, Theta matrix, simulated data support custom item type fscores() computations response.pattern passed instead original data impute option itemfit() M2() estimate statistics via plausible imputation missing data present multidimensional ideal-point models added dichotomous items M2* statistic added polytomous item types Bock Lieberman ('BL') method argument added (recommend serious use)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-4","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.4","text":"large bias correction information matrix standard errors models contain equality constraints (standard errors high) drop dimensions fix nested logit models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-13","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.3","title":"Changes in mirt 1.3","text":"CRAN release: 2014-04-23","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-3","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.3","text":"default SE.type changed crossprod since better detecting models identified compared SEM, generally much cheaper compute larger models M-step optimizer now automatically selected ‘BFGS’ bounded parameters, ‘L-BFGS-B’ otherwise. models notably different parameter estimates , nearly identical model log-likelihoods better shiny UI adapts itemtype specifically, allows classical parameter inputs (special thanks Jonathan Lehrfeld providing code inspired changes) scores.option now set TRUE fscores() type = 'score' plot generics longer adjusts categories expected test scores M-step optimizer EM now deters --order graded response model intercepts (problem startvalues far ML estimate graded models)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-3","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.3","text":"return.acov logical added fscores() return list matrices containing ACOV theta values used compute SEs (suggested Shiyang Su) printCI logical option summary() print confidence intervals standardized loadings new expected.test() function, extension expected.item() whole test mirt.model() syntax supports multiple * combinations COV = easily specifying covariation blocks factors. Also allows variances freed specifying factor name, e.g., F*F full.scores.SE logical option fscores() return standard errors respondent multiple imputation (MI) option fscores(), useful obtaining less biased factor score estimates model parameter variability large (usually due smaller sample size) group-level (.e., means/covariances) equality constrains now available EM algorithm theta_lim input plot(), itemplot(), fscores() modifying range latent values evaluated","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-3","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.3","text":"personfit() crash multipleGroup objects since itemtype slot filled (reported Michael Hunter) fix crash two-tier models correlations estimated (reported David Wu) R 3.1.0 appears evaluate List objects differently c level causing strange behaviour, therefore slower R versions internal function (mirt:::reloadPars()) used patch formed behaviour mvtnorm::dmvnorm changed version 0.9-9999, causing widely different convergence results. Similar versions older mvtnorm functions now implemented instead","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-121-1","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.2.1","title":"Changes in mirt 1.2.1","text":"CRAN release: 2014-02-21","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"major-changes-1-2-1","dir":"Changelog","previous_headings":"","what":"MAJOR CHANGES","title":"Changes in mirt 1.2.1","text":"fitIndices() replaced M2() function, currently limited dichotomous items class ‘dich’ bfactor() default SE.type set ‘crossprod’ rather ‘SEM’ generalized partial credit models now display fixed scoring coefs TOL convergence criteria moved outside technical input argument restype argument residuals() changed type consistent package removed fitted() since residuals(model, type = 'exp') gives essentially output mixedmirt SE set TRUE default help construct accurate information matrix specified, S-EM TOL dropped 1e-6 EM, SEtol = .001 parameter better approximate information matrix","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-2-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.2.1","text":"two new SE.type inputs: ‘Louis’ ‘sandwich’ computing Louis’ 1982 computation observed information matrix, sandwich estimate covariance matrix .data.frame logical option coef() convert list row-stacked data.frame type = 'scorecontour' added plot() contour plot expected total scores type = 'infotrace' added itemplot() plot trace lines information plot, type = 'tracecontour' contour plot using trace lines (suggested Armi Lantano) mirt.model() support multi-line inputs new type = 'LDG2' input residuals() compute local dependence stat based G2 instead X2, type = 'Q3' added well S-EM computation information matrix support latent parameters, previously effective estimation item-level parameters. technical option also added force information matrix symmetric (default set TRUE better numerical stability) new empirical.CI argument itemfit() used plotting confidence intervals dichotomous items (suggested Okan Bulut) printSE argument can now passed coef() printing standard errors instead confidence intervals. consequence, rawug automatically set TRUE (suggested Olivia Bertelli) second-order test condition number added estimated objects information matrix computed tables argument can passed residuals() return observed expected tables used computing LD statistics","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-2-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.2.1","text":"using scores.= TRUE multipleGroup objects returns correct person ordering (reported Mateusz Zoltak) read.mirt() crash fix multiple group analyses objects (reported Felix Hansen) updated math SE.type = 'crossprod'","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-11","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.1","title":"Changes in mirt 1.1","text":"CRAN release: 2013-12-20","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.1","text":"facet_items argument added plot() control whether separate plots constructed item merge onto single plot three dimensional models supported itemplot() types trace, score, info, SE new DIF() function quicky calculate common differential item functioning routines, similar IRTLRDIF worked. Supports likelihood ratio testings well Wald approach, includes forward backword sequential DIF searching methods added shiny = TRUE option itemplot() run interactive shiny applet. Useful instructive purposes, well understanding internal parameters mirt behave type = 'trace' type = 'infotrace' support added plot generic multiple group objects fscores(..., method = 'EAPsum') returns observed expected values, along general fit statistics printed console returned ‘fit’ attribute removed multinomial constant log-likelihood since influence nested model comparisons SE.type = 'crossprod' Fisher added computing parameter information matrix based variance Fisher scoring vector complete Fisher information matrix, respectively customPriorFun input technical list now available utilizing user defined prior distribution functions EM algorithm empirical histogram estimation now available mirt() multipleGroup() unidimensional models. Additional plot type = 'empiricalhist' also added plot() generic re-implement read.mirt() better consistency checking plink package","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-1","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.1","text":"starting values multipleGroup() now returns proper estimated parameter information invariance input argument remove .integer() MultipleGroup df slot pass proper item type using custom pattern calles fscores() return proper object personfit gpcm models used","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-10","dir":"Changelog","previous_headings":"","what":"Changes in mirt 1.0","title":"Changes in mirt 1.0","text":"CRAN release: 2013-11-01","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-1-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 1.0","text":"GenRandomPars logical argument now supported technical = list() input. generate random starting values freely estimated parameters, can helpful determine obtained solutions local minimums seperate free_var free_cov invariance options available multipleGroup new CONSTRAIN CONSTRAINB arguments mirt.model() syntax specifying equality constraints explicitly parameters accross items groups. Also PRIOR = ... specification brought back uses similar format new CONSTRAIN options plot(..., type = 'trace') now supports polytomous dichotomous tracelines, type = 'infotrace' better y-axis range removed ‘1PL’ itemtype since name ambiguous. Still possible obtain however applying slope constraints 2PL/graded response models plot() contains .items argument specify items plot aggregate type, 'infotrace' 'trace' fitIndicies() return CFI.M2 TLI.M2 argument calcNull = TRUE passed. CFI stats also normed fall 0 1 data.frame returned mod2values() pars = 'values' now contains column indicating internal item class use ginv() MASS package improve accuracy fitIndices() calculation M2","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-1-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 1.0","text":"fix error thrown PLCI.mirt parameter value equal bound fix global df values, restrict G2 statistic tables sparse","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-090","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.9.0","title":"Changes in mirt 0.9.0","text":"CRAN release: 2013-08-31","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-9-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.9.0","text":"PLCI.mirt() function added computing profiled likelihood standard errors. Currently applicable unidimensional models prior distributions returned pars = 'values' data.frame along input parameters, can edited returned well full.scores option residuals() compute residuals row original data bfactor() can include additional model argument modeling two-tier structures introduced Cai (2010), now supports 'group' input multiple group analyses added general Ramsey (1975) acceleration EM estimation default. Can disable accelerate = FALSE (done automatically estimating SEM standard errors) renamed response.vector response.pattern fscores(), now supports matrix input computing factor scores larger data sets (suggested Felix Hansen) total.info logical added iteminfo() return either total item information information category mirt.model() supports -called Q-matrix input format, along matrix input covariance terms MH-RM algorithm now accessible passing mirt(..., method = 'MHRM'), confmirt() function removed completely. confmirt.model() also renamed mirt.model() support polynomial interaction terms EM estimation lognormal priors may now passed parprior iterative computations fscores() can now run parallel automatically following mirtCluster() definition mirtCluster() function added make utilizing parallel cores convenient. Globally removed cl argument multi-core objects updated documentation data sets adding relevant examples, added Bock1997 data set replicating table 3 van der Linden, W. J. & Hambleton, R. K. (1997) Handbook modern item response theory general speed improvements functions","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.9.0","text":"WLE estimation fixed now estimates extreme response patterns exploratory starting values longer crash datasets huge number NAs, caused standard deviations zero math fix beta priors","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-080","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.8.0","title":"Changes in mirt 0.8.0","text":"CRAN release: 2013-07-02","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.8.0","text":"support random effect predictors now available mixedmirt(), along randef() function computing MAP predictions random parameters EAPsum support fscores() mixed item types consistency current IRT software (rather TESTFACT POLYFACT), scaling constant set D = 1 fixed value nominal.highlow option added specify categories highest lowest nominal models. Often provide better numerical stability utilized. Default still use highest lowest categories increase number draws Monte Carlo calculation log-likelihood 3000 5000 itemtype equal ‘Rasch’ ‘rsm’ models latent variance parameter(s) automatically freed estimated mixedmirt() supportive user defined R formulas, now includes internal ‘items’ argument create item design matrix used estimate intercepts. closely mirrors results lme4 Rasch models well (special thanks Kevin Joldersma testing debugging) drop.zeros option added extract.item itemplot reduce dimensionality factor structures contain slopes equal zero EM tolerance (TOL argument) default dropped .0001 (originally .001) type = 'score' type = 'infoSE' added plot() generic expected total score joint test standard error/information custom latent mean covariance matrix can passed fscores() EAP, MAP, EAPsum methods. Also applies personfit() itemfit() diagnostics scores.option fscores() returning just estimated factor scores bfactor can include NA values model omit estimation specific factors corresponding item","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-8-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.8.0","text":"limiting values z.outfit z.infit statistics small sample sizes (fix suggested Mike Linacre) missing data gradient bug fix MH-RM dichotomous item models global df fix multidimensional confirmatory models SEM information matrix computed accuracy (M-step identical original EM), fixed equality constrains imposed","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-070","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.7.0","title":"Changes in mirt 0.7.0","text":"CRAN release: 2013-04-21","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.7.0","text":"new '#PLNRM' models fit Suh & Bolt (2010) nested logistic models 'large' option added estimation functions. Useful datasets analysed large organizing data becomes computationally burdensome task avoided fitting new models. Also, overall faster handling datasets plot(), fitted(), residuals() generic support added MultipleGroup objects CFI X2 model statistics added, output now includes fit stats w.r.t. G2 X2 z stats added itemfit/personfit infit outfit statistics supplemented EM (‘SEM’) added calculating information matrix EM history. default TOL value dropped help make EM iterations longer stable. Supports parallel computing added return empirical reliability (returnER) option fscores() plot() supports individual item information trace lines graph (dichotomous items ) option type = 'infotrace' createItem() function available defining item types can passed estimation functions. can used model items available package (anywhere matter) EM MHRM. Derivatives computed numerically default using numDeriv package defining item types fly Mstep EM moved quasi-Newton instead home grown MV Newton-Raphson approach. Gives stability estimation Hessian ill-conditioned, provide easier front-end defining user rolled IRT models","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.7.0","text":"small bias fix Hessian gradients mirt() implementation causing likelihood always increasing near maximum fix input itemplot() object list model objects fixed implementation infit outfit Rasch statistics order nominal category intercepts sometimes backwards. Fixed now S_X2 collapsed cells much caused negative df response.vector input now supports NA inputs (reported Neil Rubens)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-060","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.6.0","title":"Changes in mirt 0.6.0","text":"CRAN release: 2013-03-19","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"Changes in mirt 0.6.0","text":"S-X2 statistic computed automatically unidimensional models via itemfit() EAP sum-scores added fscores() method = ‘EAPsum’. Works full.scores option well improve speed estimation multipleGroup() latent means/variances estimated multipleGroup(invariance = ’’) can include item names specify items considered invariant across groups. Useful anchoring DIF testing type = ‘trace’ option added plot() display item trace lines single graph (dichotomous items ) default estimation method multipleGroup() switched ‘EM’ boot.mirt() function added computing bootstrapped standard errors via boot package (supports parallel computing well), well new option SE.type = ’’ choosing Bock Lieberman MHRM type information matrix computations indexing items itemplot, itemfit, extract.item can called using either number original item name added probtrace() function front end users generate probability trace functions models plotting item tracelines two categories now omits lowest category (common) parallel option passed calcLogLik compute Monte Carlo log-likelihood quickly. Can also passed call stack confmirt, multipleGroup, mixedmirt Confidence envelopes option added itemplot() trace lines information plots lbound ubound parameter bounds now available user restricting parameter estimation space mod2values() function added convert estimated mirt model appropriate data.frame used determine parameter estimation characteristics (starting values, group names, etc) added imputeMissing() function impute missing values given estimated mirt model. Useful checking item person fit diagnostics obtaining overall model fit statistics allow Rasch itemtype multidimensional confirmatory models oblimin new default exploratory rotation (suggested Dave Flora) flexible calculation M2 statistic fitIndicies(), user prompt option internal variables grow large cause time/RAM problems","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"Changes in mirt 0.6.0","text":"read.mirt() fixed objects contain standard errors (didn’t properly line ) mixedmirt() fix COV argument supplied (reported Aaron Kaat) fix multipleGroup independent groups don’t contain potential response options (reported Scot McNary) prevent using ‘free_means’ ‘free_varcov’ multipleGroup since identified without constraints (reported Ken Beath)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-050","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.5.0","title":"Changes in mirt 0.5.0","text":"CRAN release: 2013-01-17 dichotomous, graded rating scale, (generalized) partial credit, rating scale, nominal models better optimized wald() now support information matrices contain constrained parameters confmirt.model() can accept string inputs, may useful knitr/sweave documents since scan() function tends hang multipleGroup() now logical options bfactor = TRUE use dimensional reduction algorithm factor pattern structured like bifactor model new fitIndices() function added compute additional model fit statistics M2 testinfo() function added test information lower bound parameters stringent control estimation bounded never higher .6 infit outfit stats itemfit() now work Rasch partial credit rating scale models Rasch rating scale models can now estimated potential rsm.blocks (grsm model). “Generalized” rating scale models can also estimated, though requires manipulating starting values directly added sample size adjusted BIC (SABIC) information statistics new mixedmirt() function estimating IRT models person item level (e.g., LLTM) covariates. Currently supports fixed effect predictors, random effect predictors developed structured output using anova() generic","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-042","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.4.2","title":"Changes in mirt 0.4.2","text":"CRAN release: 2012-11-25 item probability functions now permit permissible values, models may converge even log-likelihood decreases estimation. EM model strictly increasing log-likelihood warning message printed infit outfit statistics now applicable Rasch models (), itemfit/personfit() ‘method’ argument added specify factor score estimates used read.mirt() re-added package allow translating estimated models format usable plink package test standard error added plot() generic using type = ‘SE’, expected score plot added itemplot() using type = ‘score’ weighted likelihood estimation (WLE) factor scores now available (without standard errors) removed allpars option coef() generics return named list (possibly rotated) item group coefficients information functions slightly positively biased due logistic constant adjustment, fixed models. Also, information functions now available almost item response models (mcm items missing) constant (D) used estimating logistic functions can now modified (default still 1.702) partcomp models recently broken, fixed now one parameter can now passed parprior make specifying identical priors convenient","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-041","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.4.1","title":"Changes in mirt 0.4.1","text":"CRAN release: 2012-10-23 relative efficiency plots added itemplot(). Works directly multipleGroup analysis comparing different item types (e.g., 1PL vs 2PL) can wrapped named list infit outfit statistics added personfit() itemfit() empirical reliability printed dimension fscores(…, fulldata = FALSE) called better system specify fixed/free parameters starting values using pars = ‘values’. allow much better simulation based work graded model type rating scale added (Muraki, 1990) optional estimation ‘blocks’. Use itemtype = ‘grsm’, grsm.block option multipleGroup(), optional input added change current freely estimated parameters values previously computed model. save needless iterations EM MHRM since parameters much closer new ML estimates itemplot() supports multipleGroup objects now analytical derivatives much stable, although yet optimized estimation bug fix bfactor(), slight bias fix mirt() estimation (introduced version 0.4.0 multipleGroup() added) updated documentation beamer slide show included background MIRT packages capabilities labels added coef() standard errors computed. Also allpars = TRUE now default kernel estimation moved entirely one method. Much easier maintain guarantees consistency across methods (.e., quasi-Newton algorithms used)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-040","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.4.0","title":"Changes in mirt 0.4.0","text":"CRAN release: 2012-09-22 Added itemfit() personfit() functions uni multidimensional models. Within itemfit empirical response curves can also plotted unidimensional models Wrapped itemplot() fscores() S3 function better documentation. Also response curve now contained individual plots Added free.start list option estimation functions. Allows quicker way specify free fixed parameters Added iteminfo() extract.item() calculate item information extract desired items Multiple group estimation available multipleGroup() function. Uses EM MHRM estimation engines. MHRM seems faster two factors+ though naturally accurate, therefore set default wald() function added testing linear constraints. Useful situations testing sets parameters rather estimating new model likelihood ratio test Methods use MHRM can now estimate nominal, gpcm, mcm, 4PL models fscores computable multiple group objects general play nicer missing data (reported Judith Conijn). Also, using options full.scores = TRUE optimized Rcpp Oblique rotation bug fix fscores coef (reported Pedro . Barbetta) Added item probability equations ?mirt documentation reference General bug fixes usual spawned added features. Overall, stay frosty.","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-031","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.3.1","title":"Changes in mirt 0.3.1","text":"Individual classes now correspond type methods: ExploratoryClass, ConfirmatoryClass, MultipleGroupClass plot itemplot now works confmirt objects mirt can now make use confmirt.model specified objects hence confirmatory well stochastic estimation factor scores removed entirely, now quadrature based methods objects. Also, bfactor returned objects now estimate factors scores instead just general dimension Standard errors mirt now automatically calculated (borrowed running tweaked MHRM run)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-030","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.3.0","title":"Changes in mirt 0.3.0","text":"CRAN release: 2012-08-23 radically changed underlying mechanisms estimation functions decided polymirt() redundant replaced completely calling confmirt(data, number_of_factors). reason change facilitate wider range MIRT models allow easier extensions future multiple group analysis multilevel modelling new univariate MV models available, including 1-4 parameter logistic generalized partial credit, nominal, multiple choice models. called specifying character vector called ‘itemtype’ length nitems options ‘2PL’,‘3PL’,‘4PL’,‘graded’,‘gpcm’, ‘nominal’, ‘mcm’; use ‘PC2PL’ ‘PC3PL’ partially-compensatory items. itemtype = ‘1PL’ ‘Rasch’, 1-parameter logistic/1-parameter ordinal Rasch/partial credit models estimated data. default assumes items either ‘2PL’ ‘graded’, . flexible user defined linear equality restrictions may imposed estimation functions, can prior parameter distributions, start values, choice parameters estimate. follow general 2 steps: Call function normally use, example, mirt(data, 1, startvalues = ‘index’) return start values indexed Edit please (without changing structure), input back function mirt(data, 1, startvalues = editedstartvalues). true parprior (MAP priors), constrain (linear equality constraints), freepars (parameters freely estimated), little quirk. inputs lists named parameters easy identification manipulation. Note means partial credit model Rasch models may calculated well modifying either start values constraints accordingly (e.g., constrain slopes equal 1/1.702 freely estimated classical Rasch model, equal estimated 1PL model) number confmirt.model() options decreased due new way specify item types, startvalues, prior parameter distributions, constraints plink package kept item information curves, ’ll implement now. Replaced plink item plots ‘itemplots’ function ones rolled package descriptions documentation updated coef() now prints slightly different output, new option ‘allpars = TRUE’ display item group parameters, returned list simdata() updated support new item types accurate standard errors MAP ML factor scores, specific factors bfactorClass objects can now estimated methods","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-026-1","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.6-1","title":"Changes in mirt 0.2.6-1","text":"dropped ball lots bug fixes round. Future commits avoid problem utilizing testthat package test code extensively release internal change confmirt function move MHRM engine outside function better maintenance theta_angle added mirt polymirt plots changing viewing angle w.r.t theta_1 null model longer calculated missing data present fixed item slope models estimated mirt() associated standard errors","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-026","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.6","title":"Changes in mirt 0.2.6","text":"CRAN release: 2012-07-15 null model computed, allowing model statistics TLI documentation changes many back end technical details estimation moved technical lists support GPArotation methods options, including Target rotations polymirt() uses confmirt() estimation engine 4PL support mirt() bfactor(), treating upper bound fixed coef() now rotate option returning rotated IRT parameters","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-025","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.5","title":"Changes in mirt 0.2.5","text":"CRAN release: 2012-06-07 Fixed translation bug C++ code bfactor() causing illegal vector length throw Fixed fscores() bug using polychotomous items mirt() bfactor() pass rotate=‘rotation’ mirt polymirt override default ‘varimax’ rotation estimation time (suggested Niels Waller) RMSEA, G^2, p set NaN instead internal placeholder missing data df adjusted missing data present oblique rotations return invisible factor correlation matrix","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-024","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.4","title":"Changes in mirt 0.2.4","text":"CRAN release: 2012-05-09 degrees freedom correctly adjusted using noncompensatory items confmirtClass reorganized work S4 methods, now work consistently methods. fixed G^2 log-likelihood logLik() product terms included bugfix drawThetas noncompensatory items used","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-023","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.3","title":"Changes in mirt 0.2.3","text":"CRAN release: 2012-05-02 bugfixes fscores, itemplot, generic functions read.mirt() added creating suitable plink object mirt() bfactor() can now accommodate polychotomous items using ordinal IRT scheme itemplot() now makes use handy plink package plots, giving good deal flexibility. Generic plot()’s now use lattice plots extensively","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-022","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.2","title":"Changes in mirt 0.2.2","text":"Ported src code Rcpp future tweaking. Added better fitted() function missing data exist (noticed Erin Horn)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-021","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.1","title":"Changes in mirt 0.2.1","text":"CRAN release: 2012-04-06 ML estimation factor scores mirt bfactor RMSEA statistic added fitted models Nonlinear polynomial estimation specification confmirt models, now consistent returned labels Provide better identification criteria confmirt() (suggested Hendrik Lohse)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-020","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.2.0","title":"Changes in mirt 0.2.0","text":"CRAN release: 2012-02-15 parameter standard errors added mirt() (1 factor ) bfactor() models bfactor() values ommited recoded NA summary coef better viewing ‘technical’ added confmirt function, allowing various tweaks varying beta prior weights product relations added confmirt.model(). Specified enclosing brackets using asterisk documentation fixes roxygenize","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-0120","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.1.20","title":"Changes in mirt 0.1.20","text":"allow lower bound beta priors vary items (suggested James Lee)","code":""},{"path":"https://philchalmers.github.io/mirt/news/index.html","id":"changes-in-mirt-016","dir":"Changelog","previous_headings":"","what":"Changes in mirt 0.1.6","title":"Changes in mirt 0.1.6","text":"bias fix mirt() function (noticed Pedro Barbetta)","code":""}]
